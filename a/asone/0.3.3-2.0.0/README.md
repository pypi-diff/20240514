# Comparing `tmp/asone-0.3.3-py3-none-any.whl.zip` & `tmp/asone-2.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,245 +1,327 @@
-Zip file size: 477411 bytes, number of entries: 243
--rw-rw-r--  2.0 unx     2850 b- defN 23-May-23 13:52 asone/__init__.py
--rw-rw-r--  2.0 unx    10674 b- defN 23-Jun-11 02:29 asone/asone.py
--rw-rw-r--  2.0 unx     2634 b- defN 23-Jun-11 02:52 asone/demo_detector.py
--rw-rw-r--  2.0 unx     2149 b- defN 23-Apr-20 08:09 asone/demo_ocr.py
--rw-rw-r--  2.0 unx     2451 b- defN 23-Jun-05 08:30 asone/demo_pose_estimator.py
--rw-rw-r--  2.0 unx     1722 b- defN 23-Jun-06 09:49 asone/demo_tracker.py
--rw-rw-r--  2.0 unx     2942 b- defN 23-May-23 13:34 asone/pose_estimator.py
--rw-rw-r--  2.0 unx      573 b- defN 23-May-23 13:52 asone/detectors/__init__.py
--rw-rw-r--  2.0 unx     5450 b- defN 23-Jun-08 15:14 asone/detectors/detector.py
--rw-rw-r--  2.0 unx       66 b- defN 23-Apr-10 06:15 asone/detectors/easyocr_detector/__init__.py
--rw-rw-r--  2.0 unx     2094 b- defN 23-Apr-20 08:09 asone/detectors/easyocr_detector/text_detector.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/utils/__init__.py
--rw-rw-r--  2.0 unx      533 b- defN 23-Apr-10 06:15 asone/detectors/utils/cfg_path.py
--rw-rw-r--  2.0 unx     1545 b- defN 23-Apr-20 08:09 asone/detectors/utils/coreml_utils.py
--rw-rw-r--  2.0 unx     1478 b- defN 23-Apr-10 06:15 asone/detectors/utils/exp_name.py
--rw-rw-r--  2.0 unx     9122 b- defN 23-May-23 13:52 asone/detectors/utils/weights_path.py
--rw-rw-r--  2.0 unx       66 b- defN 23-May-23 13:52 asone/detectors/yolonas/__init__.py
--rw-rw-r--  2.0 unx     3957 b- defN 23-Jun-11 01:48 asone/detectors/yolonas/yolonas.py
--rw-rw-r--  2.0 unx       69 b- defN 23-Apr-10 06:15 asone/detectors/yolor/__init__.py
--rw-rw-r--  2.0 unx     5315 b- defN 23-Apr-20 08:09 asone/detectors/yolor/yolor_detector.py
--rw-rw-r--  2.0 unx    14241 b- defN 23-Apr-10 06:15 asone/detectors/yolor/cfg/yolor_csp.cfg
--rw-rw-r--  2.0 unx    16338 b- defN 23-Apr-10 06:15 asone/detectors/yolor/cfg/yolor_csp_x.cfg
--rw-rw-r--  2.0 unx    18330 b- defN 23-Apr-10 06:15 asone/detectors/yolor/cfg/yolor_p6.cfg
--rw-rw-r--  2.0 unx        1 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/__init__.py
--rw-rw-r--  2.0 unx    38971 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/common.py
--rw-rw-r--  2.0 unx     2733 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/export.py
--rw-rw-r--  2.0 unx    36694 b- defN 23-Apr-10 06:15 asone/detectors/yolor/models/models.py
--rw-rw-r--  2.0 unx        1 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/__init__.py
--rw-rw-r--  2.0 unx     2200 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/activations.py
--rw-rw-r--  2.0 unx     6707 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/autoanchor.py
--rw-rw-r--  2.0 unx    54966 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/datasets.py
--rw-rw-r--  2.0 unx     3310 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/export.py
--rw-rw-r--  2.0 unx    18709 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/general.py
--rw-rw-r--  2.0 unx     4964 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/google_utils.py
--rw-rw-r--  2.0 unx    18495 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/layers.py
--rw-rw-r--  2.0 unx     7443 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/loss.py
--rw-rw-r--  2.0 unx     5137 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/metrics.py
--rw-rw-r--  2.0 unx     2995 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/parse_config.py
--rw-rw-r--  2.0 unx    15468 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/plots.py
--rw-rw-r--  2.0 unx     9396 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/torch_utils.py
--rw-rw-r--  2.0 unx     9267 b- defN 23-Apr-10 06:15 asone/detectors/yolor/utils/yolor_utils.py
--rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/__init__.py
--rw-rw-r--  2.0 unx     6417 b- defN 23-May-23 10:40 asone/detectors/yolov5/yolov5_detector.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/__init__.py
--rw-rw-r--  2.0 unx       64 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/__init__.py
--rw-rw-r--  2.0 unx    36615 b- defN 23-May-23 08:54 asone/detectors/yolov5/yolov5/models/common.py
--rw-rw-r--  2.0 unx     2340 b- defN 23-May-23 08:54 asone/detectors/yolov5/yolov5/models/experimental.py
--rw-rw-r--  2.0 unx    42725 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/general.py
--rw-rw-r--  2.0 unx    15923 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/models/yolo.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/utils/__init__.py
--rw-rw-r--  2.0 unx    15973 b- defN 23-Apr-10 06:15 asone/detectors/yolov5/yolov5/utils/torch_utils.py
--rw-rw-r--  2.0 unx     8854 b- defN 23-May-23 08:54 asone/detectors/yolov5/yolov5/utils/yolov5_utils.py
--rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/__init__.py
--rw-rw-r--  2.0 unx     5640 b- defN 23-Apr-20 08:09 asone/detectors/yolov6/yolov6_detector.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/__init__.py
--rw-rw-r--  2.0 unx       85 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/__init__.py
--rw-rw-r--  2.0 unx     2372 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/anchor_generator.py
--rw-rw-r--  2.0 unx     3682 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/assigner_utils.py
--rw-rw-r--  2.0 unx     7099 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/atss_assigner.py
--rw-rw-r--  2.0 unx     9211 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/iou2d_calculator.py
--rw-rw-r--  2.0 unx     6143 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/assigners/tal_assigner.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/layers/__init__.py
--rw-rw-r--  2.0 unx    18272 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/layers/common.py
--rw-rw-r--  2.0 unx     1913 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/layers/dbb_transforms.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/__init__.py
--rw-rw-r--  2.0 unx     5842 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/efficientrep.py
--rw-rw-r--  2.0 unx     8278 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/effidehead.py
--rw-rw-r--  2.0 unx    10838 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/end2end.py
--rw-rw-r--  2.0 unx     8760 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/loss.py
--rw-rw-r--  2.0 unx    13474 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/loss_distill.py
--rw-rw-r--  2.0 unx     7217 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/reppan.py
--rw-rw-r--  2.0 unx     3951 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/models/yolo.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/__init__.py
--rw-rw-r--  2.0 unx     1880 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/events.py
--rw-rw-r--  2.0 unx     2674 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/general.py
--rw-rw-r--  2.0 unx     3373 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/torch_utils.py
--rw-rw-r--  2.0 unx     9628 b- defN 23-Apr-10 06:15 asone/detectors/yolov6/yolov6/utils/yolov6_utils.py
--rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/__init__.py
--rw-rw-r--  2.0 unx     6904 b- defN 23-May-25 15:17 asone/detectors/yolov7/yolov7_detector.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/__init__.py
--rw-rw-r--  2.0 unx       64 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/__init__.py
--rw-rw-r--  2.0 unx    84188 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/common.py
--rw-rw-r--  2.0 unx     1603 b- defN 23-May-23 13:24 asone/detectors/yolov7/yolov7/models/experimental.py
--rw-rw-r--  2.0 unx    41743 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/models/yolo.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/utils/__init__.py
--rw-rw-r--  2.0 unx    15467 b- defN 23-Apr-10 06:15 asone/detectors/yolov7/yolov7/utils/torch_utils.py
--rw-rw-r--  2.0 unx     8212 b- defN 23-May-23 10:34 asone/detectors/yolov7/yolov7/utils/yolov7_utils.py
--rw-rw-r--  2.0 unx       72 b- defN 23-Apr-10 06:15 asone/detectors/yolov8/__init__.py
--rw-rw-r--  2.0 unx     5911 b- defN 23-Apr-20 08:09 asone/detectors/yolov8/yolov8_detector.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolov8/utils/__init__.py
--rw-rw-r--  2.0 unx     2043 b- defN 23-Apr-20 08:09 asone/detectors/yolov8/utils/yolov8_utils.py
--rw-rw-r--  2.0 unx       69 b- defN 23-Apr-10 06:15 asone/detectors/yolox/__init__.py
--rw-rw-r--  2.0 unx     6573 b- defN 23-Apr-20 08:09 asone/detectors/yolox/yolox_detector.py
--rw-rw-r--  2.0 unx     4277 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox_utils.py
--rw-rw-r--  2.0 unx       95 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/__init__.py
--rw-rw-r--  2.0 unx     1042 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolov3.py
--rw-rw-r--  2.0 unx      377 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_l.py
--rw-rw-r--  2.0 unx      379 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_m.py
--rw-rw-r--  2.0 unx     1561 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_nano.py
--rw-rw-r--  2.0 unx      379 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_s.py
--rw-rw-r--  2.0 unx      562 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_tiny.py
--rw-rw-r--  2.0 unx      379 b- defN 23-Apr-10 06:15 asone/detectors/yolox/exps/yolox_x.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/__init__.py
--rw-rw-r--  2.0 unx      181 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/exp/__init__.py
--rw-rw-r--  2.0 unx     2017 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/exp/base_exp.py
--rw-rw-r--  2.0 unx     1334 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/exp/build.py
--rw-rw-r--  2.0 unx    11986 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/exp/yolox_base.py
--rw-rw-r--  2.0 unx      995 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/exp/default/__init__.py
--rw-rw-r--  2.0 unx      308 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/__init__.py
--rw-rw-r--  2.0 unx     4266 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/build.py
--rw-rw-r--  2.0 unx     6019 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/darknet.py
--rw-rw-r--  2.0 unx     1677 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/losses.py
--rw-rw-r--  2.0 unx     6092 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/network_blocks.py
--rw-rw-r--  2.0 unx     2476 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/yolo_fpn.py
--rw-rw-r--  2.0 unx    23361 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/yolo_head.py
--rw-rw-r--  2.0 unx     3530 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/yolo_pafpn.py
--rw-rw-r--  2.0 unx     1364 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/models/yolox.py
--rw-rw-r--  2.0 unx      475 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/__init__.py
--rw-rw-r--  2.0 unx     2835 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/allreduce_norm.py
--rw-rw-r--  2.0 unx     4521 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/boxes.py
--rw-rw-r--  2.0 unx     1312 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/checkpoint.py
--rw-rw-r--  2.0 unx      310 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/compat.py
--rw-rw-r--  2.0 unx     3829 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/demo_utils.py
--rw-rw-r--  2.0 unx     8062 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/dist.py
--rw-rw-r--  2.0 unx     2073 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/ema.py
--rw-rw-r--  2.0 unx    12664 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/logger.py
--rw-rw-r--  2.0 unx     6551 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/lr_scheduler.py
--rw-rw-r--  2.0 unx     3256 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/metric.py
--rw-rw-r--  2.0 unx     5614 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/model_utils.py
--rw-rw-r--  2.0 unx     2675 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/setup_env.py
--rw-rw-r--  2.0 unx     3599 b- defN 23-Apr-10 06:15 asone/detectors/yolox/yolox/utils/visualize.py
--rw-rw-r--  2.0 unx      146 b- defN 23-May-23 13:34 asone/pose_estimators/__init__.py
--rw-rw-r--  2.0 unx       73 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/__init__.py
--rw-rw-r--  2.0 unx     1001 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/main.py
--rw-rw-r--  2.0 unx     2538 b- defN 23-May-23 13:52 asone/pose_estimators/yolov7_pose/yolov7.py
--rw-rw-r--  2.0 unx        6 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/models/__init__.py
--rw-rw-r--  2.0 unx    86543 b- defN 23-May-23 13:52 asone/pose_estimators/yolov7_pose/models/common.py
--rw-rw-r--  2.0 unx    10697 b- defN 23-May-23 13:52 asone/pose_estimators/yolov7_pose/models/experimental.py
--rw-rw-r--  2.0 unx    36966 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/models/yolo.py
--rw-rw-r--  2.0 unx        6 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/__init__.py
--rw-rw-r--  2.0 unx     2320 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/activations.py
--rw-rw-r--  2.0 unx     5795 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/add_nms.py
--rw-rw-r--  2.0 unx     7307 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/autoanchor.py
--rw-rw-r--  2.0 unx    57539 b- defN 23-May-23 13:52 asone/pose_estimators/yolov7_pose/utils/datasets.py
--rw-rw-r--  2.0 unx    37568 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/general.py
--rw-rw-r--  2.0 unx     4875 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/google_utils.py
--rw-rw-r--  2.0 unx    76641 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/loss.py
--rw-rw-r--  2.0 unx     9192 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/metrics.py
--rw-rw-r--  2.0 unx    23225 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/plots.py
--rw-rw-r--  2.0 unx    15840 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/torch_utils.py
--rw-rw-r--  2.0 unx      640 b- defN 23-May-23 13:52 asone/pose_estimators/yolov7_pose/utils/yolov7_pose_utils.py
--rw-rw-r--  2.0 unx        6 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/wandb_logging/__init__.py
--rw-rw-r--  2.0 unx      839 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/wandb_logging/log_dataset.py
--rw-rw-r--  2.0 unx    16571 b- defN 23-May-23 13:34 asone/pose_estimators/yolov7_pose/utils/wandb_logging/wandb_utils.py
--rw-rw-r--  2.0 unx       73 b- defN 23-May-23 13:34 asone/pose_estimators/yolov8_pose/__init__.py
--rw-rw-r--  2.0 unx    22441 b- defN 23-May-23 13:34 asone/pose_estimators/yolov8_pose/plots.py
--rw-rw-r--  2.0 unx      374 b- defN 23-May-23 13:34 asone/pose_estimators/yolov8_pose/yolov8.py
--rw-rw-r--  2.0 unx      182 b- defN 23-Apr-10 06:15 asone/recognizers/__init__.py
--rw-rw-r--  2.0 unx      933 b- defN 23-Apr-10 06:15 asone/recognizers/recognizer.py
--rw-rw-r--  2.0 unx       81 b- defN 23-Apr-10 06:15 asone/recognizers/easyocr_recognizer/__init__.py
--rw-rw-r--  2.0 unx     1721 b- defN 23-Apr-20 08:09 asone/recognizers/easyocr_recognizer/easyocr_recognizer.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/recognizers/utils/__init__.py
--rw-rw-r--  2.0 unx      196 b- defN 23-Apr-10 06:15 asone/recognizers/utils/recognizer_name.py
--rw-rw-r--  2.0 unx      458 b- defN 23-Apr-20 08:09 asone/trackers/__init__.py
--rw-rw-r--  2.0 unx     1157 b- defN 23-Apr-20 08:09 asone/trackers/tracker.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/__init__.py
--rw-rw-r--  2.0 unx     2252 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/bytetracker.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/__init__.py
--rw-rw-r--  2.0 unx      950 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/basetrack.py
--rw-rw-r--  2.0 unx    11950 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/byte_tracker.py
--rw-rw-r--  2.0 unx     9547 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/kalman_filter.py
--rw-rw-r--  2.0 unx     6208 b- defN 23-Apr-10 06:15 asone/trackers/byte_track/tracker/matching.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/__init__.py
--rw-rw-r--  2.0 unx     2208 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/deepsort.py
--rw-rw-r--  2.0 unx      508 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/__init__.py
--rw-rw-r--  2.0 unx     4000 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep_sort.py
--rw-rw-r--  2.0 unx     1076 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/parser.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/__init__.py
--rw-rw-r--  2.0 unx      294 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/evaluate.py
--rw-rw-r--  2.0 unx     1770 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/feature_extractor.py
--rw-rw-r--  2.0 unx     3316 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/model.py
--rw-rw-r--  2.0 unx     3339 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/original_model.py
--rw-rw-r--  2.0 unx     2464 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/test.py
--rw-rw-r--  2.0 unx     6315 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/deep/train.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/__init__.py
--rw-rw-r--  2.0 unx     1461 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/detection.py
--rw-rw-r--  2.0 unx     2843 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/iou_matching.py
--rw-rw-r--  2.0 unx     7787 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/kalman_filter.py
--rw-rw-r--  2.0 unx     7894 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/linear_assignment.py
--rw-rw-r--  2.0 unx     5469 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/nn_matching.py
--rw-rw-r--  2.0 unx     1914 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/preprocessing.py
--rw-rw-r--  2.0 unx     5063 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/track.py
--rw-rw-r--  2.0 unx     5605 b- defN 23-Apr-10 06:15 asone/trackers/deep_sort/tracker/sort/tracker.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/motpy/__init__.py
--rw-rw-r--  2.0 unx     1844 b- defN 23-Apr-20 08:09 asone/trackers/motpy/motpy.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-10 06:15 asone/trackers/nor_fair/__init__.py
--rw-rw-r--  2.0 unx     1909 b- defN 23-Apr-10 06:15 asone/trackers/nor_fair/norfair.py
--rw-rw-r--  2.0 unx       56 b- defN 23-Apr-20 08:09 asone/trackers/oc_sort/__init__.py
--rw-rw-r--  2.0 unx     1026 b- defN 23-Apr-20 08:09 asone/trackers/oc_sort/ocsort.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-20 08:09 asone/trackers/oc_sort/tracker/__init__.py
--rw-rw-r--  2.0 unx    14315 b- defN 23-Apr-20 08:09 asone/trackers/oc_sort/tracker/association.py
--rw-rw-r--  2.0 unx    59022 b- defN 23-Apr-20 08:09 asone/trackers/oc_sort/tracker/kalmanfilter.py
--rw-rw-r--  2.0 unx    13155 b- defN 23-Apr-20 08:09 asone/trackers/oc_sort/tracker/ocsort.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/__init__.py
--rw-rw-r--  2.0 unx     1181 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/strongsort.py
--rw-rw-r--  2.0 unx      510 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/__init__.py
--rw-rw-r--  2.0 unx     5178 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/strong_sort.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/deep/__init__.py
--rw-rw-r--  2.0 unx     4858 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/deep/reid_model_factory.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/__init__.py
--rw-rw-r--  2.0 unx     1439 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/detection.py
--rw-rw-r--  2.0 unx     2843 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/iou_matching.py
--rw-rw-r--  2.0 unx     8114 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/kalman_filter.py
--rw-rw-r--  2.0 unx     7624 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/linear_assignment.py
--rw-rw-r--  2.0 unx     5770 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/nn_matching.py
--rw-rw-r--  2.0 unx     1914 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/preprocessing.py
--rw-rw-r--  2.0 unx    10653 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/track.py
--rw-rw-r--  2.0 unx     7684 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/sort/tracker.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/__init__.py
--rw-rw-r--  2.0 unx      316 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/asserts.py
--rw-rw-r--  2.0 unx     1125 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/draw.py
--rw-rw-r--  2.0 unx     3532 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/evaluation.py
--rw-rw-r--  2.0 unx     4357 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/io.py
--rw-rw-r--  2.0 unx    11762 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/json_logger.py
--rw-rw-r--  2.0 unx      463 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/log.py
--rw-rw-r--  2.0 unx     1078 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/parser.py
--rw-rw-r--  2.0 unx      734 b- defN 23-Apr-20 08:09 asone/trackers/strong_sort/tracker/utils/tools.py
--rw-rw-r--  2.0 unx      581 b- defN 23-May-23 13:34 asone/utils/__init__.py
--rw-rw-r--  2.0 unx     1066 b- defN 23-Apr-10 06:15 asone/utils/classes.py
--rw-rw-r--  2.0 unx      697 b- defN 23-Apr-10 06:15 asone/utils/colors.py
--rw-rw-r--  2.0 unx      558 b- defN 23-Apr-10 06:15 asone/utils/counting.py
--rw-rw-r--  2.0 unx      358 b- defN 23-Apr-10 06:15 asone/utils/default_cfg.py
--rw-rw-r--  2.0 unx     5728 b- defN 23-May-23 13:52 asone/utils/download.py
--rw-rw-r--  2.0 unx    11844 b- defN 23-May-23 13:34 asone/utils/draw.py
--rw-rw-r--  2.0 unx      864 b- defN 23-Apr-10 06:15 asone/utils/ponits_conversion.py
--rw-rw-r--  2.0 unx     1017 b- defN 23-May-23 13:34 asone/utils/pose_estimators_weights.py
--rw-rw-r--  2.0 unx      796 b- defN 23-Apr-10 06:15 asone/utils/temp_loader.py
--rw-rw-r--  2.0 unx    35148 b- defN 23-Jun-11 02:54 asone-0.3.3.dist-info/LICENCE
--rw-rw-r--  2.0 unx    14376 b- defN 23-Jun-11 02:54 asone-0.3.3.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Jun-11 02:54 asone-0.3.3.dist-info/WHEEL
--rw-rw-r--  2.0 unx       72 b- defN 23-Jun-11 02:54 asone-0.3.3.dist-info/dependency_links.txt
--rw-rw-r--  2.0 unx        6 b- defN 23-Jun-11 02:54 asone-0.3.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    24135 b- defN 23-Jun-11 02:54 asone-0.3.3.dist-info/RECORD
-243 files, 1694780 bytes uncompressed, 438011 bytes compressed:  74.2%
+Zip file size: 761714 bytes, number of entries: 325
+-rw-rw-r--  2.0 unx     3080 b- defN 24-May-14 05:02 asone/__init__.py
+-rw-rw-r--  2.0 unx    17811 b- defN 24-May-14 05:02 asone/asone.py
+-rw-rw-r--  2.0 unx     2639 b- defN 24-May-14 05:02 asone/demo_detector.py
+-rw-rw-r--  2.0 unx     2149 b- defN 24-Mar-18 06:22 asone/demo_ocr.py
+-rw-rw-r--  2.0 unx     2451 b- defN 24-Mar-18 06:22 asone/demo_pose_estimator.py
+-rw-rw-r--  2.0 unx     2875 b- defN 24-May-14 05:02 asone/demo_segmentor.py
+-rw-rw-r--  2.0 unx     1722 b- defN 24-Apr-05 10:50 asone/demo_tracker.py
+-rw-rw-r--  2.0 unx     5527 b- defN 24-May-14 05:02 asone/pose_estimator.py
+-rw-rw-r--  2.0 unx      652 b- defN 24-May-14 05:02 asone/detectors/__init__.py
+-rw-rw-r--  2.0 unx     5272 b- defN 24-May-14 05:02 asone/detectors/detector.py
+-rw-rw-r--  2.0 unx       66 b- defN 24-Mar-18 06:22 asone/detectors/easyocr_detector/__init__.py
+-rw-rw-r--  2.0 unx     2094 b- defN 24-Mar-18 06:22 asone/detectors/easyocr_detector/text_detector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/utils/__init__.py
+-rw-rw-r--  2.0 unx      533 b- defN 24-Mar-18 06:22 asone/detectors/utils/cfg_path.py
+-rw-rw-r--  2.0 unx     1545 b- defN 24-Mar-18 06:22 asone/detectors/utils/coreml_utils.py
+-rw-rw-r--  2.0 unx     1478 b- defN 24-Mar-18 06:22 asone/detectors/utils/exp_name.py
+-rw-rw-r--  2.0 unx     9796 b- defN 24-May-14 05:02 asone/detectors/utils/weights_path.py
+-rw-rw-r--  2.0 unx       66 b- defN 24-Mar-18 06:22 asone/detectors/yolonas/__init__.py
+-rw-rw-r--  2.0 unx     4038 b- defN 24-May-14 05:02 asone/detectors/yolonas/yolonas.py
+-rw-rw-r--  2.0 unx       69 b- defN 24-Mar-18 06:22 asone/detectors/yolor/__init__.py
+-rw-rw-r--  2.0 unx     5417 b- defN 24-May-14 05:02 asone/detectors/yolor/yolor_detector.py
+-rw-rw-r--  2.0 unx    14241 b- defN 24-Mar-18 06:22 asone/detectors/yolor/cfg/yolor_csp.cfg
+-rw-rw-r--  2.0 unx    16338 b- defN 24-Mar-18 06:22 asone/detectors/yolor/cfg/yolor_csp_x.cfg
+-rw-rw-r--  2.0 unx    18330 b- defN 24-Mar-18 06:22 asone/detectors/yolor/cfg/yolor_p6.cfg
+-rw-rw-r--  2.0 unx        1 b- defN 24-Mar-18 06:22 asone/detectors/yolor/models/__init__.py
+-rw-rw-r--  2.0 unx    38971 b- defN 24-Mar-18 06:22 asone/detectors/yolor/models/common.py
+-rw-rw-r--  2.0 unx     2733 b- defN 24-Mar-18 06:22 asone/detectors/yolor/models/export.py
+-rw-rw-r--  2.0 unx    36694 b- defN 24-Mar-18 06:22 asone/detectors/yolor/models/models.py
+-rw-rw-r--  2.0 unx        1 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/__init__.py
+-rw-rw-r--  2.0 unx     2200 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/activations.py
+-rw-rw-r--  2.0 unx     6729 b- defN 24-May-14 05:02 asone/detectors/yolor/utils/autoanchor.py
+-rw-rw-r--  2.0 unx    54966 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/datasets.py
+-rw-rw-r--  2.0 unx     3310 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/export.py
+-rw-rw-r--  2.0 unx    18709 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/general.py
+-rw-rw-r--  2.0 unx     4964 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/google_utils.py
+-rw-rw-r--  2.0 unx    18495 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/layers.py
+-rw-rw-r--  2.0 unx     7443 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/loss.py
+-rw-rw-r--  2.0 unx     5137 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/metrics.py
+-rw-rw-r--  2.0 unx     2995 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/parse_config.py
+-rw-rw-r--  2.0 unx    15468 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/plots.py
+-rw-rw-r--  2.0 unx     9396 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/torch_utils.py
+-rw-rw-r--  2.0 unx     9267 b- defN 24-Mar-18 06:22 asone/detectors/yolor/utils/yolor_utils.py
+-rw-rw-r--  2.0 unx       72 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/__init__.py
+-rw-rw-r--  2.0 unx     6498 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5_detector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/yolov5/__init__.py
+-rw-rw-r--  2.0 unx    42563 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/export.py
+-rw-rw-r--  2.0 unx       70 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/models/__init__.py
+-rw-rw-r--  2.0 unx    36653 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/models/common.py
+-rw-rw-r--  2.0 unx     2340 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/yolov5/models/experimental.py
+-rw-rw-r--  2.0 unx    42733 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/models/general.py
+-rw-rw-r--  2.0 unx    32135 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/models/tf.py
+-rw-rw-r--  2.0 unx    15923 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/yolov5/models/yolo.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/yolov5/utils/__init__.py
+-rw-rw-r--  2.0 unx     4608 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/utils/activations.py
+-rw-rw-r--  2.0 unx    18703 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/utils/augmentations.py
+-rw-rw-r--  2.0 unx    60093 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/utils/dataloaders.py
+-rw-rw-r--  2.0 unx     5307 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/utils/downloads.py.py
+-rw-rw-r--  2.0 unx    50965 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/utils/general.py
+-rw-rw-r--  2.0 unx    15500 b- defN 24-May-14 05:02 asone/detectors/yolov5/yolov5/utils/metrics.py
+-rw-rw-r--  2.0 unx    15973 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/yolov5/utils/torch_utils.py
+-rw-rw-r--  2.0 unx     8854 b- defN 24-Mar-18 06:22 asone/detectors/yolov5/yolov5/utils/yolov5_utils.py
+-rw-rw-r--  2.0 unx       72 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/__init__.py
+-rw-rw-r--  2.0 unx     5723 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6_detector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/__init__.py
+-rw-rw-r--  2.0 unx       85 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/assigners/__init__.py
+-rw-rw-r--  2.0 unx     2372 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/assigners/anchor_generator.py
+-rw-rw-r--  2.0 unx     3682 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/assigners/assigner_utils.py
+-rw-rw-r--  2.0 unx     7145 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/assigners/atss_assigner.py
+-rw-rw-r--  2.0 unx     9211 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/assigners/iou2d_calculator.py
+-rw-rw-r--  2.0 unx     6166 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/assigners/tal_assigner.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/layers/__init__.py
+-rw-rw-r--  2.0 unx    18295 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/layers/common.py
+-rw-rw-r--  2.0 unx     1913 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/layers/dbb_transforms.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/models/__init__.py
+-rw-rw-r--  2.0 unx     5865 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/models/efficientrep.py
+-rw-rw-r--  2.0 unx     8347 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/models/effidehead.py
+-rw-rw-r--  2.0 unx    10838 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/models/end2end.py
+-rw-rw-r--  2.0 unx     8875 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/models/loss.py
+-rw-rw-r--  2.0 unx    13589 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/models/loss_distill.py
+-rw-rw-r--  2.0 unx     7240 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/models/reppan.py
+-rw-rw-r--  2.0 unx     4066 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/models/yolo.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/utils/__init__.py
+-rw-rw-r--  2.0 unx     2306 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/utils/checkpoint.py
+-rw-rw-r--  2.0 unx     1880 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/utils/events.py
+-rw-rw-r--  2.0 unx     5739 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/utils/figure_iou.py
+-rw-rw-r--  2.0 unx     2674 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/utils/general.py
+-rw-rw-r--  2.0 unx     3419 b- defN 24-May-14 05:02 asone/detectors/yolov6/yolov6/utils/torch_utils.py
+-rw-rw-r--  2.0 unx     9628 b- defN 24-Mar-18 06:22 asone/detectors/yolov6/yolov6/utils/yolov6_utils.py
+-rw-rw-r--  2.0 unx       72 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/__init__.py
+-rw-rw-r--  2.0 unx     6917 b- defN 24-May-14 05:02 asone/detectors/yolov7/yolov7_detector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/yolov7/__init__.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-14 05:02 asone/detectors/yolov7/yolov7/models/__init__.py
+-rw-rw-r--  2.0 unx    84188 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/yolov7/models/common.py
+-rw-rw-r--  2.0 unx     1639 b- defN 24-May-14 05:02 asone/detectors/yolov7/yolov7/models/experimental.py
+-rw-rw-r--  2.0 unx    41743 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/yolov7/models/yolo.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/yolov7/utils/__init__.py
+-rw-rw-r--  2.0 unx    15467 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/yolov7/utils/torch_utils.py
+-rw-rw-r--  2.0 unx     8212 b- defN 24-Mar-18 06:22 asone/detectors/yolov7/yolov7/utils/yolov7_utils.py
+-rw-rw-r--  2.0 unx       72 b- defN 24-Mar-18 06:22 asone/detectors/yolov8/__init__.py
+-rw-rw-r--  2.0 unx     6014 b- defN 24-May-14 05:02 asone/detectors/yolov8/yolov8_detector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolov8/utils/__init__.py
+-rw-rw-r--  2.0 unx     2033 b- defN 24-May-14 05:02 asone/detectors/yolov8/utils/yolov8_utils.py
+-rw-rw-r--  2.0 unx       72 b- defN 24-May-14 05:02 asone/detectors/yolov9/__init__.py
+-rw-rw-r--  2.0 unx    32555 b- defN 24-May-14 05:02 asone/detectors/yolov9/export.py
+-rw-rw-r--  2.0 unx     6981 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9_detector.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/__init__.py
+-rw-rw-r--  2.0 unx        7 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/models/__init__.py
+-rw-rw-r--  2.0 unx    54084 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/models/common.py
+-rw-rw-r--  2.0 unx    11697 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/models/experimental.py
+-rw-rw-r--  2.0 unx    26813 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/models/tf.py
+-rw-rw-r--  2.0 unx    38730 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/models/yolo.py
+-rw-rw-r--  2.0 unx     2203 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/__init__.py
+-rw-rw-r--  2.0 unx     3373 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/activations.py
+-rw-rw-r--  2.0 unx    17123 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/augmentations.py
+-rw-rw-r--  2.0 unx     7438 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/autoanchor.py
+-rw-rw-r--  2.0 unx     2977 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/autobatch.py
+-rw-rw-r--  2.0 unx     2591 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/callbacks.py
+-rw-rw-r--  2.0 unx     3256 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/coco_utils.py
+-rw-rw-r--  2.0 unx    55706 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/dataloaders.py
+-rw-rw-r--  2.0 unx     4641 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/downloads.py
+-rw-rw-r--  2.0 unx    47085 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/general.py
+-rw-rw-r--  2.0 unx     2518 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/lion.py
+-rw-rw-r--  2.0 unx    16136 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/loss.py
+-rw-rw-r--  2.0 unx     9838 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/loss_tal.py
+-rw-rw-r--  2.0 unx    18187 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/loss_tal_dual.py
+-rw-rw-r--  2.0 unx    13742 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/loss_tal_triple.py
+-rw-rw-r--  2.0 unx    15943 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/metrics.py
+-rw-rw-r--  2.0 unx    25358 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/plots.py
+-rw-rw-r--  2.0 unx    23464 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/torch_utils.py
+-rw-rw-r--  2.0 unx     3528 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/triton.py
+-rw-rw-r--  2.0 unx     8777 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/yolov9_utils.py
+-rw-rw-r--  2.0 unx        6 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/__init__.py
+-rw-rw-r--  2.0 unx     3672 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/augmentations.py
+-rw-rw-r--  2.0 unx    13855 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/dataloaders.py
+-rw-rw-r--  2.0 unx     4934 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/general.py
+-rw-rw-r--  2.0 unx     8620 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/loss.py
+-rw-rw-r--  2.0 unx    12024 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/loss_tal.py
+-rw-rw-r--  2.0 unx    34900 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/loss_tal_dual.py
+-rw-rw-r--  2.0 unx     5377 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/metrics.py
+-rw-rw-r--  2.0 unx     6390 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/plots.py
+-rw-rw-r--  2.0 unx        6 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/tal/__init__.py
+-rw-rw-r--  2.0 unx     1557 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/tal/anchor_generator.py
+-rw-rw-r--  2.0 unx     8316 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/segment/tal/assigner.py
+-rw-rw-r--  2.0 unx        6 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/tal/__init__.py
+-rw-rw-r--  2.0 unx     1587 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/tal/anchor_generator.py
+-rw-rw-r--  2.0 unx     8231 b- defN 24-May-14 05:02 asone/detectors/yolov9/yolov9/utils/tal/assigner.py
+-rw-rw-r--  2.0 unx       69 b- defN 24-Mar-18 06:22 asone/detectors/yolox/__init__.py
+-rw-rw-r--  2.0 unx     6666 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox_detector.py
+-rw-rw-r--  2.0 unx     4277 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox_utils.py
+-rw-rw-r--  2.0 unx       95 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/__init__.py
+-rw-rw-r--  2.0 unx     1042 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolov3.py
+-rw-rw-r--  2.0 unx      377 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolox_l.py
+-rw-rw-r--  2.0 unx      379 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolox_m.py
+-rw-rw-r--  2.0 unx     1561 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolox_nano.py
+-rw-rw-r--  2.0 unx      379 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolox_s.py
+-rw-rw-r--  2.0 unx      562 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolox_tiny.py
+-rw-rw-r--  2.0 unx      379 b- defN 24-Mar-18 06:22 asone/detectors/yolox/exps/yolox_x.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/__init__.py
+-rw-rw-r--  2.0 unx      152 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/core/__init__.py
+-rw-rw-r--  2.0 unx     4387 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/core/launch.py
+-rw-rw-r--  2.0 unx    13707 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/core/trainer.py
+-rw-rw-r--  2.0 unx      354 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/__init__.py
+-rw-rw-r--  2.0 unx     7360 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/data_augment.py
+-rw-rw-r--  2.0 unx     1649 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/data_prefetcher.py
+-rw-rw-r--  2.0 unx     3671 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/dataloading.py
+-rw-rw-r--  2.0 unx     2854 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/samplers.py
+-rw-rw-r--  2.0 unx      325 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/__init__.py
+-rw-rw-r--  2.0 unx     6363 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/coco.py
+-rw-rw-r--  2.0 unx     1296 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/coco_classes.py
+-rw-rw-r--  2.0 unx    10878 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/datasets_wrapper.py
+-rw-rw-r--  2.0 unx     9573 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/mosaicdetection.py
+-rw-rw-r--  2.0 unx    11946 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/voc.py
+-rw-rw-r--  2.0 unx      442 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/data/datasets/voc_classes.py
+-rw-rw-r--  2.0 unx      178 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/evaluators/__init__.py
+-rw-rw-r--  2.0 unx    11467 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/evaluators/coco_evaluator.py
+-rw-rw-r--  2.0 unx     5631 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/evaluators/voc_eval.py
+-rw-rw-r--  2.0 unx     6564 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/evaluators/voc_evaluator.py
+-rw-rw-r--  2.0 unx      181 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/exp/__init__.py
+-rw-rw-r--  2.0 unx     2017 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/exp/base_exp.py
+-rw-rw-r--  2.0 unx     1334 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/exp/build.py
+-rw-rw-r--  2.0 unx    12149 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/exp/yolox_base.py
+-rw-rw-r--  2.0 unx      995 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/exp/default/__init__.py
+-rw-rw-r--  2.0 unx      308 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/models/__init__.py
+-rw-rw-r--  2.0 unx     4288 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/models/build.py
+-rw-rw-r--  2.0 unx     6053 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/models/darknet.py
+-rw-rw-r--  2.0 unx     1677 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/models/losses.py
+-rw-rw-r--  2.0 unx     6092 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/models/network_blocks.py
+-rw-rw-r--  2.0 unx     2544 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/models/yolo_fpn.py
+-rw-rw-r--  2.0 unx    23429 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/models/yolo_head.py
+-rw-rw-r--  2.0 unx     3598 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/models/yolo_pafpn.py
+-rw-rw-r--  2.0 unx     1432 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/models/yolox.py
+-rw-rw-r--  2.0 unx      475 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/__init__.py
+-rw-rw-r--  2.0 unx     2868 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/utils/allreduce_norm.py
+-rw-rw-r--  2.0 unx     4521 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/boxes.py
+-rw-rw-r--  2.0 unx     1312 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/checkpoint.py
+-rw-rw-r--  2.0 unx      310 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/compat.py
+-rw-rw-r--  2.0 unx     3829 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/demo_utils.py
+-rw-rw-r--  2.0 unx     8062 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/dist.py
+-rw-rw-r--  2.0 unx     2073 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/ema.py
+-rw-rw-r--  2.0 unx    12664 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/logger.py
+-rw-rw-r--  2.0 unx     6551 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/lr_scheduler.py
+-rw-rw-r--  2.0 unx     3256 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/metric.py
+-rw-rw-r--  2.0 unx     5636 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/utils/model_utils.py
+-rw-rw-r--  2.0 unx     2708 b- defN 24-May-14 05:02 asone/detectors/yolox/yolox/utils/setup_env.py
+-rw-rw-r--  2.0 unx     3599 b- defN 24-Mar-18 06:22 asone/detectors/yolox/yolox/utils/visualize.py
+-rw-rw-r--  2.0 unx      146 b- defN 24-Mar-18 06:22 asone/pose_estimators/__init__.py
+-rw-rw-r--  2.0 unx       73 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/__init__.py
+-rw-rw-r--  2.0 unx     1001 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/main.py
+-rw-rw-r--  2.0 unx     2703 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/yolov7.py
+-rw-rw-r--  2.0 unx        6 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/models/__init__.py
+-rw-rw-r--  2.0 unx    86543 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/models/common.py
+-rw-rw-r--  2.0 unx    10737 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/models/experimental.py
+-rw-rw-r--  2.0 unx    37172 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/models/yolo.py
+-rw-rw-r--  2.0 unx        6 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/__init__.py
+-rw-rw-r--  2.0 unx     2320 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/activations.py
+-rw-rw-r--  2.0 unx     5795 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/add_nms.py
+-rw-rw-r--  2.0 unx     7375 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/autoanchor.py
+-rw-rw-r--  2.0 unx    57617 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/datasets.py
+-rw-rw-r--  2.0 unx    37685 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/general.py
+-rw-rw-r--  2.0 unx     4875 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/google_utils.py
+-rw-rw-r--  2.0 unx    76709 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/loss.py
+-rw-rw-r--  2.0 unx     9230 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/metrics.py
+-rw-rw-r--  2.0 unx    23303 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/plots.py
+-rw-rw-r--  2.0 unx    15840 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/torch_utils.py
+-rw-rw-r--  2.0 unx      640 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/yolov7_pose_utils.py
+-rw-rw-r--  2.0 unx        6 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/wandb_logging/__init__.py
+-rw-rw-r--  2.0 unx      839 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov7_pose/utils/wandb_logging/log_dataset.py
+-rw-rw-r--  2.0 unx    16573 b- defN 24-May-14 05:02 asone/pose_estimators/yolov7_pose/utils/wandb_logging/wandb_utils.py
+-rw-rw-r--  2.0 unx       73 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov8_pose/__init__.py
+-rw-rw-r--  2.0 unx    22441 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov8_pose/plots.py
+-rw-rw-r--  2.0 unx      374 b- defN 24-Mar-18 06:22 asone/pose_estimators/yolov8_pose/yolov8.py
+-rw-rw-r--  2.0 unx      182 b- defN 24-Mar-18 06:22 asone/recognizers/__init__.py
+-rw-rw-r--  2.0 unx      933 b- defN 24-Mar-18 06:22 asone/recognizers/recognizer.py
+-rw-rw-r--  2.0 unx       81 b- defN 24-Mar-18 06:22 asone/recognizers/easyocr_recognizer/__init__.py
+-rw-rw-r--  2.0 unx     1721 b- defN 24-Mar-18 06:22 asone/recognizers/easyocr_recognizer/easyocr_recognizer.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/recognizers/utils/__init__.py
+-rw-rw-r--  2.0 unx      196 b- defN 24-Mar-18 06:22 asone/recognizers/utils/recognizer_name.py
+-rw-rw-r--  2.0 unx       74 b- defN 24-May-14 05:02 asone/segmentors/__init__.py
+-rw-rw-r--  2.0 unx      856 b- defN 24-May-14 05:02 asone/segmentors/segmentor.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-14 05:02 asone/segmentors/segment_anything/__init__.py
+-rw-rw-r--  2.0 unx     1872 b- defN 24-May-14 05:02 asone/segmentors/segment_anything/sam.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-May-14 05:02 asone/segmentors/utils/__init__.py
+-rw-rw-r--  2.0 unx      256 b- defN 24-May-14 05:02 asone/segmentors/utils/weights_path.py
+-rw-rw-r--  2.0 unx      458 b- defN 24-Mar-18 06:22 asone/trackers/__init__.py
+-rw-rw-r--  2.0 unx     1157 b- defN 24-Mar-18 06:22 asone/trackers/tracker.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/__init__.py
+-rw-rw-r--  2.0 unx     2252 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/bytetracker.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/tracker/__init__.py
+-rw-rw-r--  2.0 unx      950 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/tracker/basetrack.py
+-rw-rw-r--  2.0 unx    11950 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/tracker/byte_tracker.py
+-rw-rw-r--  2.0 unx     9547 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/tracker/kalman_filter.py
+-rw-rw-r--  2.0 unx     6208 b- defN 24-Mar-18 06:22 asone/trackers/byte_track/tracker/matching.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/__init__.py
+-rw-rw-r--  2.0 unx     2208 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/deepsort.py
+-rw-rw-r--  2.0 unx      508 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/__init__.py
+-rw-rw-r--  2.0 unx     4000 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep_sort.py
+-rw-rw-r--  2.0 unx     1076 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/parser.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/__init__.py
+-rw-rw-r--  2.0 unx      294 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/evaluate.py
+-rw-rw-r--  2.0 unx     1770 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/feature_extractor.py
+-rw-rw-r--  2.0 unx     3316 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/model.py
+-rw-rw-r--  2.0 unx     3339 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/original_model.py
+-rw-rw-r--  2.0 unx     2464 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/test.py
+-rw-rw-r--  2.0 unx     6315 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/deep/train.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/__init__.py
+-rw-rw-r--  2.0 unx     1461 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/detection.py
+-rw-rw-r--  2.0 unx     2843 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/iou_matching.py
+-rw-rw-r--  2.0 unx     7787 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/kalman_filter.py
+-rw-rw-r--  2.0 unx     7894 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/linear_assignment.py
+-rw-rw-r--  2.0 unx     5469 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/nn_matching.py
+-rw-rw-r--  2.0 unx     1914 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/preprocessing.py
+-rw-rw-r--  2.0 unx     5063 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/track.py
+-rw-rw-r--  2.0 unx     5605 b- defN 24-Mar-18 06:22 asone/trackers/deep_sort/tracker/sort/tracker.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/motpy/__init__.py
+-rw-rw-r--  2.0 unx     1844 b- defN 24-Mar-18 06:22 asone/trackers/motpy/motpy.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/nor_fair/__init__.py
+-rw-rw-r--  2.0 unx     1909 b- defN 24-Mar-18 06:22 asone/trackers/nor_fair/norfair.py
+-rw-rw-r--  2.0 unx       56 b- defN 24-Mar-18 06:22 asone/trackers/oc_sort/__init__.py
+-rw-rw-r--  2.0 unx     1026 b- defN 24-Mar-18 06:22 asone/trackers/oc_sort/ocsort.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/oc_sort/tracker/__init__.py
+-rw-rw-r--  2.0 unx    14315 b- defN 24-Mar-18 06:22 asone/trackers/oc_sort/tracker/association.py
+-rw-rw-r--  2.0 unx    59022 b- defN 24-Mar-18 06:22 asone/trackers/oc_sort/tracker/kalmanfilter.py
+-rw-rw-r--  2.0 unx    13155 b- defN 24-Mar-18 06:22 asone/trackers/oc_sort/tracker/ocsort.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/__init__.py
+-rw-rw-r--  2.0 unx     1181 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/strongsort.py
+-rw-rw-r--  2.0 unx      510 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/__init__.py
+-rw-rw-r--  2.0 unx     5178 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/strong_sort.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/deep/__init__.py
+-rw-rw-r--  2.0 unx     4858 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/deep/reid_model_factory.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/__init__.py
+-rw-rw-r--  2.0 unx     1439 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/detection.py
+-rw-rw-r--  2.0 unx     2843 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/iou_matching.py
+-rw-rw-r--  2.0 unx     8114 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/kalman_filter.py
+-rw-rw-r--  2.0 unx     7624 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/linear_assignment.py
+-rw-rw-r--  2.0 unx     5770 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/nn_matching.py
+-rw-rw-r--  2.0 unx     1914 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/preprocessing.py
+-rw-rw-r--  2.0 unx    10653 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/track.py
+-rw-rw-r--  2.0 unx     7684 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/sort/tracker.py
+-rw-rw-r--  2.0 unx        0 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/__init__.py
+-rw-rw-r--  2.0 unx      316 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/asserts.py
+-rw-rw-r--  2.0 unx     1125 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/draw.py
+-rw-rw-r--  2.0 unx     3532 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/evaluation.py
+-rw-rw-r--  2.0 unx     4357 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/io.py
+-rw-rw-r--  2.0 unx    11762 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/json_logger.py
+-rw-rw-r--  2.0 unx      463 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/log.py
+-rw-rw-r--  2.0 unx     1078 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/parser.py
+-rw-rw-r--  2.0 unx      734 b- defN 24-Mar-18 06:22 asone/trackers/strong_sort/tracker/utils/tools.py
+-rw-rw-r--  2.0 unx      581 b- defN 24-Mar-18 06:22 asone/utils/__init__.py
+-rw-rw-r--  2.0 unx     1066 b- defN 24-Mar-18 06:22 asone/utils/classes.py
+-rw-rw-r--  2.0 unx      697 b- defN 24-Mar-18 06:22 asone/utils/colors.py
+-rw-rw-r--  2.0 unx      558 b- defN 24-Mar-18 06:22 asone/utils/counting.py
+-rw-rw-r--  2.0 unx      359 b- defN 24-May-14 05:02 asone/utils/default_cfg.py
+-rw-rw-r--  2.0 unx     6374 b- defN 24-May-14 05:02 asone/utils/download.py
+-rw-rw-r--  2.0 unx    12218 b- defN 24-May-14 05:02 asone/utils/draw.py
+-rw-rw-r--  2.0 unx      864 b- defN 24-Mar-18 06:22 asone/utils/ponits_conversion.py
+-rw-rw-r--  2.0 unx     1017 b- defN 24-Mar-18 06:22 asone/utils/pose_estimators_weights.py
+-rw-rw-r--  2.0 unx      796 b- defN 24-Mar-18 06:22 asone/utils/temp_loader.py
+-rw-rw-r--  2.0 unx      552 b- defN 24-May-14 05:02 asone/utils/utils.py
+-rw-rw-r--  2.0 unx     1096 b- defN 24-May-14 05:02 asone/utils/video_reader.py
+-rw-rw-r--  2.0 unx    35148 b- defN 24-May-14 05:11 asone-2.0.0.dist-info/LICENCE
+-rw-rw-r--  2.0 unx    13914 b- defN 24-May-14 05:11 asone-2.0.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 24-May-14 05:11 asone-2.0.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       72 b- defN 24-May-14 05:11 asone-2.0.0.dist-info/dependency_links.txt
+-rw-rw-r--  2.0 unx        6 b- defN 24-May-14 05:11 asone-2.0.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    32705 b- defN 24-May-14 05:11 asone-2.0.0.dist-info/RECORD
+325 files, 2625671 bytes uncompressed, 708276 bytes compressed:  73.0%
```

## zipnote {}

```diff
@@ -9,14 +9,17 @@
 
 Filename: asone/demo_ocr.py
 Comment: 
 
 Filename: asone/demo_pose_estimator.py
 Comment: 
 
+Filename: asone/demo_segmentor.py
+Comment: 
+
 Filename: asone/demo_tracker.py
 Comment: 
 
 Filename: asone/pose_estimator.py
 Comment: 
 
 Filename: asone/detectors/__init__.py
@@ -126,32 +129,56 @@
 
 Filename: asone/detectors/yolov5/yolov5_detector.py
 Comment: 
 
 Filename: asone/detectors/yolov5/yolov5/__init__.py
 Comment: 
 
+Filename: asone/detectors/yolov5/yolov5/export.py
+Comment: 
+
 Filename: asone/detectors/yolov5/yolov5/models/__init__.py
 Comment: 
 
 Filename: asone/detectors/yolov5/yolov5/models/common.py
 Comment: 
 
 Filename: asone/detectors/yolov5/yolov5/models/experimental.py
 Comment: 
 
 Filename: asone/detectors/yolov5/yolov5/models/general.py
 Comment: 
 
+Filename: asone/detectors/yolov5/yolov5/models/tf.py
+Comment: 
+
 Filename: asone/detectors/yolov5/yolov5/models/yolo.py
 Comment: 
 
 Filename: asone/detectors/yolov5/yolov5/utils/__init__.py
 Comment: 
 
+Filename: asone/detectors/yolov5/yolov5/utils/activations.py
+Comment: 
+
+Filename: asone/detectors/yolov5/yolov5/utils/augmentations.py
+Comment: 
+
+Filename: asone/detectors/yolov5/yolov5/utils/dataloaders.py
+Comment: 
+
+Filename: asone/detectors/yolov5/yolov5/utils/downloads.py.py
+Comment: 
+
+Filename: asone/detectors/yolov5/yolov5/utils/general.py
+Comment: 
+
+Filename: asone/detectors/yolov5/yolov5/utils/metrics.py
+Comment: 
+
 Filename: asone/detectors/yolov5/yolov5/utils/torch_utils.py
 Comment: 
 
 Filename: asone/detectors/yolov5/yolov5/utils/yolov5_utils.py
 Comment: 
 
 Filename: asone/detectors/yolov6/__init__.py
@@ -213,17 +240,23 @@
 
 Filename: asone/detectors/yolov6/yolov6/models/yolo.py
 Comment: 
 
 Filename: asone/detectors/yolov6/yolov6/utils/__init__.py
 Comment: 
 
+Filename: asone/detectors/yolov6/yolov6/utils/checkpoint.py
+Comment: 
+
 Filename: asone/detectors/yolov6/yolov6/utils/events.py
 Comment: 
 
+Filename: asone/detectors/yolov6/yolov6/utils/figure_iou.py
+Comment: 
+
 Filename: asone/detectors/yolov6/yolov6/utils/general.py
 Comment: 
 
 Filename: asone/detectors/yolov6/yolov6/utils/torch_utils.py
 Comment: 
 
 Filename: asone/detectors/yolov6/yolov6/utils/yolov6_utils.py
@@ -267,14 +300,146 @@
 
 Filename: asone/detectors/yolov8/utils/__init__.py
 Comment: 
 
 Filename: asone/detectors/yolov8/utils/yolov8_utils.py
 Comment: 
 
+Filename: asone/detectors/yolov9/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/export.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9_detector.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/models/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/models/common.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/models/experimental.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/models/tf.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/models/yolo.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/activations.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/augmentations.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/autoanchor.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/autobatch.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/callbacks.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/coco_utils.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/dataloaders.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/downloads.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/general.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/lion.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/loss.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/loss_tal.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/loss_tal_dual.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/loss_tal_triple.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/metrics.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/plots.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/torch_utils.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/triton.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/yolov9_utils.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/augmentations.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/dataloaders.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/general.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/loss.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/loss_tal.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/loss_tal_dual.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/metrics.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/plots.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/tal/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/tal/anchor_generator.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/segment/tal/assigner.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/tal/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/tal/anchor_generator.py
+Comment: 
+
+Filename: asone/detectors/yolov9/yolov9/utils/tal/assigner.py
+Comment: 
+
 Filename: asone/detectors/yolox/__init__.py
 Comment: 
 
 Filename: asone/detectors/yolox/yolox_detector.py
 Comment: 
 
 Filename: asone/detectors/yolox/yolox_utils.py
@@ -303,14 +468,71 @@
 
 Filename: asone/detectors/yolox/exps/yolox_x.py
 Comment: 
 
 Filename: asone/detectors/yolox/yolox/__init__.py
 Comment: 
 
+Filename: asone/detectors/yolox/yolox/core/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/core/launch.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/core/trainer.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/data_augment.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/data_prefetcher.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/dataloading.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/samplers.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/coco.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/coco_classes.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/datasets_wrapper.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/mosaicdetection.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/voc.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/data/datasets/voc_classes.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/evaluators/__init__.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/evaluators/coco_evaluator.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/evaluators/voc_eval.py
+Comment: 
+
+Filename: asone/detectors/yolox/yolox/evaluators/voc_evaluator.py
+Comment: 
+
 Filename: asone/detectors/yolox/yolox/exp/__init__.py
 Comment: 
 
 Filename: asone/detectors/yolox/yolox/exp/base_exp.py
 Comment: 
 
 Filename: asone/detectors/yolox/yolox/exp/build.py
@@ -483,14 +705,32 @@
 
 Filename: asone/recognizers/utils/__init__.py
 Comment: 
 
 Filename: asone/recognizers/utils/recognizer_name.py
 Comment: 
 
+Filename: asone/segmentors/__init__.py
+Comment: 
+
+Filename: asone/segmentors/segmentor.py
+Comment: 
+
+Filename: asone/segmentors/segment_anything/__init__.py
+Comment: 
+
+Filename: asone/segmentors/segment_anything/sam.py
+Comment: 
+
+Filename: asone/segmentors/utils/__init__.py
+Comment: 
+
+Filename: asone/segmentors/utils/weights_path.py
+Comment: 
+
 Filename: asone/trackers/__init__.py
 Comment: 
 
 Filename: asone/trackers/tracker.py
 Comment: 
 
 Filename: asone/trackers/byte_track/__init__.py
@@ -705,26 +945,32 @@
 
 Filename: asone/utils/pose_estimators_weights.py
 Comment: 
 
 Filename: asone/utils/temp_loader.py
 Comment: 
 
-Filename: asone-0.3.3.dist-info/LICENCE
+Filename: asone/utils/utils.py
+Comment: 
+
+Filename: asone/utils/video_reader.py
+Comment: 
+
+Filename: asone-2.0.0.dist-info/LICENCE
 Comment: 
 
-Filename: asone-0.3.3.dist-info/METADATA
+Filename: asone-2.0.0.dist-info/METADATA
 Comment: 
 
-Filename: asone-0.3.3.dist-info/WHEEL
+Filename: asone-2.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: asone-0.3.3.dist-info/dependency_links.txt
+Filename: asone-2.0.0.dist-info/dependency_links.txt
 Comment: 
 
-Filename: asone-0.3.3.dist-info/top_level.txt
+Filename: asone-2.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: asone-0.3.3.dist-info/RECORD
+Filename: asone-2.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## asone/__init__.py

```diff
@@ -1,12 +1,14 @@
 from .asone import ASOne
 import asone.detectors
 import asone.trackers
 import asone.recognizers
+import asone.segmentors
 from .pose_estimator import PoseEstimator
+from asone.utils.video_reader import VideoReader
 
 BYTETRACK = 0
 DEEPSORT = 1
 NORFAIR = 2
 MOTPY = 3
 OCSORT = 4
 STRONGSORT = 5
@@ -149,18 +151,30 @@
 YOLOV8X_POSE = 148
 
 YOLOV7_W6_POSE = 149
 
 YOLONAS_S_PYTORCH = 160
 YOLONAS_M_PYTORCH = 161
 YOLONAS_L_PYTORCH = 162
+
+# YOLOv9
+YOLOV9_C_CONVERTED = 164
+YOLOV9_E_CONVERTED = 165
+YOLOV9_C = 166
+YOLOV9_E = 167
+GELAN_C = 168
+GELAN_E = 169
+
+# Segmentors
+SAM = 171
+
 # Text Detectors
 # easyocr
 CRAFT = 82
 DBNET18 = 83
 
 # Text Recognizers
 EASYOCR = 200
 
 
 
-__all__ = ['ASOne', 'detectors', 'trackers', 'recognizers', 'PoseEstimator'] 
+__all__ = ['ASOne', 'detectors', 'trackers', 'recognizers', 'segmentors', 'PoseEstimator']
```

## asone/asone.py

```diff
@@ -1,32 +1,49 @@
 import copy
+import warnings
 import cv2
 from loguru import logger
 import os
 import time
 import asone.utils as utils
 from asone.trackers import Tracker
 from asone.detectors import Detector
 from asone.recognizers import TextRecognizer
+from asone.segmentors import Segmentor
 from asone.utils.default_cfg import config
+from asone.utils.video_reader import VideoReader
+from asone.utils import compute_color_for_labels
+from asone.schemas.output_schemas import ModelOutput
+
 import numpy as np
 
 
 class ASOne:
     def __init__(self,
                  detector: int = 0,
                  tracker: int = -1,
+                 segmentor: int = -1,
                  weights: str = None,
+                 segmentor_weights: str = None,
                  use_cuda: bool = True,
                  recognizer: int = None,
                  languages: list = ['en'],
                  num_classes=80
                  ) -> None:
 
         self.use_cuda = use_cuda
+        self.use_segmentation = False
+        self.model_output = ModelOutput()
+        
+        # Check if user want to use segmentor
+        if segmentor != -1:
+            self.use_segmentation = True
+
+            # Load Segmentation model
+            self.segmentor = self.get_segmentor(segmentor, segmentor_weights)
 
         # get detector object
         self.detector = self.get_detector(detector, weights, recognizer, num_classes)
         self.recognizer = self.get_recognizer(recognizer, languages=languages)
     
         if tracker == -1:
             self.tracker = None
@@ -47,200 +64,248 @@
 
         return recognizer
 
     def get_tracker(self, tracker: int):
         tracker = Tracker(tracker, self.detector,
                           use_cuda=self.use_cuda)
         return tracker
+    
+    def get_segmentor(self, segmentor, segmentor_weights):
+        segmentor = Segmentor(segmentor, segmentor_weights, self.use_cuda)
+        return segmentor
 
     def _update_args(self, kwargs):
         for key, value in kwargs.items():
             if key in config.keys():
                 config[key] = value
             else:
                 print(f'"{key}" argument not found! valid args: {list(config.keys())}')
                 exit()
         return config
 
     def track_stream(self,
                     stream_url,
                     **kwargs
                     ):
+        
+        # Emit the warning for DeprecationWarning
+        with warnings.catch_warnings():
+            warnings.simplefilter("always", DeprecationWarning)
+            warnings.warn("track_stream function is deprecated. Kindly use stream_tracker instead", DeprecationWarning)
 
         output_filename = 'result.mp4'
         kwargs['filename'] = output_filename
         config = self._update_args(kwargs)
 
         for (bbox_details, frame_details) in self._start_tracking(stream_url, config):
             # yeild bbox_details, frame_details to main script
             yield bbox_details, frame_details
+    
+    def stream_tracker(self,
+                    stream_url,
+                    **kwargs
+                    ):
+
+        output_filename = 'result.mp4'
+        kwargs['filename'] = output_filename
+        config = self._update_args(kwargs)
+
+        for (bbox_details, frame_details) in self._start_tracking(stream_url, config):
+            # yeild bbox_details, frame_details to main script
+            yield self.format_output(bbox_details, frame_details)
 
     def track_video(self,
                     video_path,
                     **kwargs
                     ):            
+           
+        # Emit the warning for DeprecationWarning
+        with warnings.catch_warnings():
+            warnings.simplefilter("always", DeprecationWarning)
+            warnings.warn("track_video function is deprecated. Kindly use video_tracker instead", DeprecationWarning)
+              
         output_filename = os.path.basename(video_path)
         kwargs['filename'] = output_filename
         config = self._update_args(kwargs)
 
         for (bbox_details, frame_details) in self._start_tracking(video_path, config):
             # yeild bbox_details, frame_details to main script
             yield bbox_details, frame_details
-
-    def detect_video(self,
+    
+    def video_tracker(self,
                     video_path,
                     **kwargs
                     ):            
         output_filename = os.path.basename(video_path)
         kwargs['filename'] = output_filename
         config = self._update_args(kwargs)
-        
-        # os.makedirs(output_path, exist_ok=True)
-
-        fps = config.pop('fps')
-        output_dir = config.pop('output_dir')
-        filename = config.pop('filename')
-        save_result = config.pop('save_result')
-        display = config.pop('display')
-        draw_trails = config.pop('draw_trails')
-        class_names = config.pop('class_names')
-
-        cap = cv2.VideoCapture(video_path)
-        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
-        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
-        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
-
-        if fps is None:
-            fps = cap.get(cv2.CAP_PROP_FPS)
-
-        if save_result:
-            os.makedirs(output_dir, exist_ok=True)
-            save_path = os.path.join(output_dir, filename)
-            logger.info(f"video save path is {save_path}")
 
-            video_writer = cv2.VideoWriter(
-                save_path,
-                cv2.VideoWriter_fourcc(*"mp4v"),
-                fps,
-                (int(width), int(height)),
-            )
-
-        frame_id = 1
-        tic = time.time()
-
-        prevTime = 0
-        frame_no = 0
-        while True:
-            start_time = time.time()
+        for (bbox_details, frame_details) in self._start_tracking(video_path, config):
+            # yeild bbox_details, frame_details to main script
+            yield self.format_output(bbox_details, frame_details)
 
-            ret, img = cap.read()
-            if not ret:
-                break
-            frame = img.copy()
+    def detect_video(self,
+                    video_path,
+                    **kwargs
+                    ):            
+        
+        # Emit the warning for DeprecationWarning
+        with warnings.catch_warnings():
+            warnings.simplefilter("always", DeprecationWarning)
+            warnings.warn("detect_video function is deprecated. Kindly use video_detecter instead", DeprecationWarning)
             
-            dets, img_info = self.detector.detect(img, conf_thres=0.25, iou_thres=0.45)
-            currTime = time.time()
-            fps = 1 / (currTime - prevTime)
-            prevTime = currTime
-
-            if dets is not None: 
-                bbox_xyxy = dets[:, :4]
-                scores = dets[:, 4]
-                class_ids = dets[:, 5]
-                img = utils.draw_boxes(img, bbox_xyxy, class_ids=class_ids, class_names=class_names)
-
-            cv2.line(img, (20, 25), (127, 25), [85, 45, 255], 30)
-            cv2.putText(img, f'FPS: {int(fps)}', (11, 35), 0, 1, [
-                        225, 255, 255], thickness=2, lineType=cv2.LINE_AA)
-
+        output_filename = os.path.basename(video_path)
+        kwargs['filename'] = output_filename
+        config = self._update_args(kwargs)
 
-            elapsed_time = time.time() - start_time
+        for (bbox_details, frame_details) in self._start_tracking(video_path, config):
+            # yeild bbox_details, frame_details to main script
+            yield bbox_details, frame_details
+    
+    def video_detecter(self,
+                    video_path,
+                    **kwargs
+                    ):            
+        output_filename = os.path.basename(video_path)
+        kwargs['filename'] = output_filename
+        config = self._update_args(kwargs)
 
-            logger.info(
-                'frame {}/{} ({:.2f} ms)'.format(frame_no, int(frame_count),
-                                                 elapsed_time * 1000))
-            frame_no+=1
-            if display:
-                cv2.imshow('Window', img)
+        for (bbox_details, frame_details) in self._start_tracking(video_path, config):
+            # yeild bbox_details, frame_details to main script
+            yield self.format_output(bbox_details, frame_details)
+    
+    def detect(self, source, **kwargs)->np.ndarray:
+        """ Function to perform detection on an img
 
-            if save_result:
-                video_writer.write(img)
+        Args:
+            source (_type_): if str read the image. if nd.array pass it directly to detect
 
-            if cv2.waitKey(25) & 0xFF == ord('q'):
-                break
+        Returns:
+            _type_: ndarray of detection
+        """
+        # Emit the warning for DeprecationWarning
+        with warnings.catch_warnings():
+            warnings.simplefilter("always", DeprecationWarning)
+            warnings.warn("detect function is deprecated. Kindly use detecter instead", DeprecationWarning)
             
-            yield (bbox_xyxy, scores, class_ids), (im0 if display else frame, frame_no-1, fps)
-
-        tac = time.time()
-        print(f'Total Time Taken: {tac - tic:.2f}')
-        # kwargs['filename'] = output_filename
-        # config = self._update_args(kwargs)
-        
-        # for (bbox_details, frame_details) in self._start_tracking(video_path, config):
-        #     # yeild bbox_details, frame_details to main script
-        #     yield bbox_details, frame_details
+        if isinstance(source, str):
+            source = cv2.imread(source)
+        return self.detector.detect(source, **kwargs)
     
-    def detect(self, source, **kwargs)->np.ndarray:
+    def detecter(self, source, **kwargs):
         """ Function to perform detection on an img
 
         Args:
             source (_type_): if str read the image. if nd.array pass it directly to detect
 
         Returns:
             _type_: ndarray of detection
         """
         if isinstance(source, str):
             source = cv2.imread(source)
-        return self.detector.detect(source, **kwargs)
+        dets, _ = self.detector.detect(source, **kwargs)
+        bboxes_xyxy = dets[:, :4]
+        scores = dets[:, 4]
+        class_ids = dets[:, 5]
+        ids = None
+        info = None
+        return self.format_output((bboxes_xyxy, ids, scores, class_ids), info)
+
+    def detect_and_track(self, frame, **kwargs):
+        if self.tracker:
+            bboxes_xyxy, ids, scores, class_ids = self.tracker.detect_and_track(
+                frame, kwargs)
+            info = None
+        else:
+            dets, info = self.detect(source=frame, **kwargs)
+            bboxes_xyxy = dets[:, :4]
+            scores = dets[:, 4]
+            class_ids = dets[:, 5]
+            ids = None
+
+        return (bboxes_xyxy, ids, scores, class_ids), info
     
+    def detect_track_manager(self, frame, **kwargs):
+        if self.tracker:
+            bboxes_xyxy, ids, scores, class_ids = self.tracker.detect_and_track(
+                frame, kwargs)
+            info = None
+        else:
+            model_output = self.detecter(source=frame, **kwargs)
+            
+            info = model_output.info            
+            bboxes_xyxy = model_output.dets.bbox
+            scores = model_output.dets.score
+            class_ids = model_output.dets.class_ids
+            ids = None
+
+        return (bboxes_xyxy, ids, scores, class_ids), info
+        
     def detect_text(self, image):
         horizontal_list, _ = self.detector.detect(image)
         if self.recognizer is None:
                 raise TypeError("Recognizer can not be None")
             
         return self.recognizer.recognize(image, horizontal_list=horizontal_list,
                             free_list=[])
 
     def track_webcam(self,
                      cam_id=0,
                      **kwargs):
+        # Emit the warning for DeprecationWarning
+        with warnings.catch_warnings():
+            warnings.simplefilter("always", DeprecationWarning)
+            warnings.warn("track_webcam function is deprecated. Kindly use webcam_tracker instead", DeprecationWarning)
+            
         output_filename = 'results.mp4'
 
         kwargs['filename'] = output_filename
         kwargs['fps'] = 29
         config = self._update_args(kwargs)
 
 
         for (bbox_details, frame_details) in self._start_tracking(cam_id, config):
             # yeild bbox_details, frame_details to main script
             yield bbox_details, frame_details
+    
+    def webcam_tracker(self,
+                     cam_id=0,
+                     **kwargs):
+        output_filename = 'results.mp4'
+
+        kwargs['filename'] = output_filename
+        kwargs['fps'] = 29
+        config = self._update_args(kwargs)
+
+
+        for (bbox_details, frame_details) in self._start_tracking(cam_id, config):
+            # yeild bbox_details, frame_details to main script
+            yield self.format_output(bbox_details, frame_details)
         
     def _start_tracking(self,
                         stream_path: str,
                         config: dict) -> tuple:
 
         if not self.tracker:
-            print(f'No tracker is selected. use detect() function perform detcetion or pass a tracker.')
-            exit()
+            warnings.warn(f'No tracker has been selected. Only the detector is operational.')
 
         fps = config.pop('fps')
         output_dir = config.pop('output_dir')
         filename = config.pop('filename')
         save_result = config.pop('save_result')
         display = config.pop('display')
         draw_trails = config.pop('draw_trails')
         class_names = config.pop('class_names')
 
-        cap = cv2.VideoCapture(stream_path)
-        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
-        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
-        frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
+        cap = self.read_video(stream_path)
+        width, height = cap.frame_size
+        frame_count = cap.frame_counts
 
         if fps is None:
-            fps = cap.get(cv2.CAP_PROP_FPS)
+            fps = cap.fps
 
         if save_result:
             os.makedirs(output_dir, exist_ok=True)
             save_path = os.path.join(output_dir, filename)
             logger.info(f"video save path is {save_path}")
 
             video_writer = cv2.VideoWriter(
@@ -248,68 +313,170 @@
                 cv2.VideoWriter_fourcc(*"mp4v"),
                 fps,
                 (int(width), int(height)),
             )
 
         frame_id = 1
         tic = time.time()
-
         prevTime = 0
 
-        while True:
+        for frame in cap:
             start_time = time.time()
 
-            ret, frame = cap.read()
-            if not ret:
-                break
             im0 = copy.deepcopy(frame)
+            try:
+                (bboxes_xyxy, ids, scores, class_ids), _ = self.detect_track_manager(frame, **config)
+            except:
+                (bboxes_xyxy, ids, scores, class_ids), _ = self.detect_and_track(frame, **config)
 
-            bboxes_xyxy, ids, scores, class_ids = self.tracker.detect_and_track(
-                frame, config)
             elapsed_time = time.time() - start_time
 
             logger.info(
                 'frame {}/{} ({:.2f} ms)'.format(frame_id, int(frame_count),
                                                  elapsed_time * 1000))
 
             if self.recognizer:
-                res = self.recognizer.recognize(im0, horizontal_list=bboxes_xyxy,
+                res = self.recognizer.recognize(frame, horizontal_list=bboxes_xyxy,
                             free_list=[])
                 im0 = utils.draw_text(im0, res)
             else:
-                im0 = utils.draw_boxes(im0,
-                                    bboxes_xyxy,
-                                    class_ids,
-                                    identities=ids,
+                im0 = self.draw((bboxes_xyxy, ids, scores, class_ids),
+                                    img=im0,
                                     draw_trails=draw_trails,
-                                    class_names=class_names)
+                                    class_names=class_names,
+                                    display=display)
 
             currTime = time.time()
             fps = 1 / (currTime - prevTime)
             prevTime = currTime
             cv2.line(im0, (20, 25), (127, 25), [85, 45, 255], 30)
             cv2.putText(im0, f'FPS: {int(fps)}', (11, 35), 0, 1, [
                         225, 255, 255], thickness=2, lineType=cv2.LINE_AA)
-
-            if display:
-                cv2.imshow(' Sample', im0)
+            
+            if self.use_segmentation:
+                if len(bboxes_xyxy) > 0: # Check if bounding box is present or not
+                    # Will generate mask using SAM
+                    masks = self.segmentor.create_mask(np.array(bboxes_xyxy), frame)
+                    im0 = self.draw_masks(masks, img=im0, display=display)
+                    bboxes_xyxy = (bboxes_xyxy, masks) 
+            
             if save_result:
                 video_writer.write(im0)
 
             frame_id += 1
 
             if cv2.waitKey(25) & 0xFF == ord('q'):
                 break
 
             # yeild required values in form of (bbox_details, frames_details)
             yield (bboxes_xyxy, ids, scores, class_ids), (im0 if display else frame, frame_id-1, fps)
 
         tac = time.time()
         print(f'Total Time Taken: {tac - tic:.2f}')
 
+    @staticmethod
+    def draw(dets, display=False, img=None, **kwargs):            
+        draw_trails = kwargs.get('draw_trails', False)
+        class_names = kwargs.get('class_names', None)
+        if isinstance(dets, tuple):
+            bboxes_xyxy, ids, scores, class_ids = dets
+            if isinstance(bboxes_xyxy, tuple):
+                bboxes_xyxy, _ = bboxes_xyxy    
+                
+        elif isinstance(dets, np.ndarray):
+            bboxes_xyxy = dets[:, :4]
+            scores = dets[:, 4]
+            class_ids = dets[:, 5]
+            ids = None
+        
+        elif isinstance(dets, ModelOutput):
+            bboxes_xyxy = dets.dets.bbox
+            ids = dets.dets.ids
+            score = dets.dets.score
+            class_ids = dets.dets.class_ids
+            img = dets.info.image if dets.info.image is not None else img
+            frame_no = dets.info.frame_no
+            fps = dets.info.fps
+        
+        img = utils.draw_boxes(img,
+                                bbox_xyxy=bboxes_xyxy,
+                                class_ids=class_ids,
+                                identities=ids,
+                                draw_trails=draw_trails,
+                                class_names=class_names)
+        
+        if display:
+            cv2.imshow(' Sample', img)
+        
+        return img
+    
+    @staticmethod      
+    def draw_masks(dets, display, img=None, **kwargs):
+        # Check if bounding box are present
+        if isinstance(dets, tuple) and len(dets) > 0 and len(dets[0]) == 0:
+            return img
+        
+        elif isinstance(dets, ModelOutput):
+            masks = dets.dets.bbox
+            ids = dets.dets.ids
+            score = dets.dets.score
+            class_ids = dets.dets.class_ids
+            img = dets.info.image if dets.info.image is not None else img
+            frame_no = dets.info.frame_no
+            fps = dets.info.fps
+            if isinstance(masks, tuple):
+                bboxes_xyxy, masks = masks
+            if isinstance(masks, np.ndarray):
+                return img
+        
+        elif isinstance(dets, tuple):
+            bboxes_xyxy, ids, scores, class_ids = dets
+            if isinstance(bboxes_xyxy, tuple):
+                bboxes_xyxy, masks = bboxes_xyxy
+        else:
+            masks = dets
+            class_ids = None
+                
+        color = [0, 255, 0]
+        masked_image = img.copy()
+        for idx in range(len(masks)):
+            mask = masks[idx].squeeze()  # Squeeze to remove singleton dimension
+            if class_ids is not None:
+                color = compute_color_for_labels(int(class_ids[idx]))
+            color = np.asarray(color, dtype='uint8')
+            mask_color = np.expand_dims(mask, axis=-1) * color  # Apply color to the mask
+            # Apply the mask to the image
+            masked_image = np.where(mask_color > 0, mask_color, masked_image)
+
+        masked_image = masked_image.astype(np.uint8)
+        img = cv2.addWeighted(img, 0.5, masked_image, 0.5, 0)
+        
+        if display:
+            cv2.imshow(' Sample', img)
+        return img
+
+    def read_video(self, video_path):
+        vid = VideoReader(video_path)
+        
+        return vid
+    
+    def format_output(self, bbox_details, frame_details):
 
+        # Set detections
+        self.model_output.dets.bbox = bbox_details[0]
+        self.model_output.dets.ids = bbox_details[1]
+        self.model_output.dets.score = bbox_details[2]
+        self.model_output.dets.class_ids = bbox_details[3]
+        if frame_details:
+            # Set image info
+            self.model_output.info.image = frame_details[0]
+            self.model_output.info.frame_no = frame_details[1]
+            self.model_output.info.fps = frame_details[2]
+
+        return self.model_output
+    
 if __name__ == '__main__':
     # asone = ASOne(tracker='norfair')
     asone = ASOne()
 
     asone.start_tracking('data/sample_videos/video2.mp4',
                          save_result=True, display=False)
```

## asone/demo_detector.py

```diff
@@ -33,15 +33,15 @@
                                 iou_thres=args.iou_thres,
                                 display=args.display,
                                 filter_classes=filter_classes,
                                 class_names=None) # class_names=['License Plate'] for custom weights
     
     # Loop over track_fn to retrieve outputs of each frame 
     for bbox_details, frame_details in track:
-        bbox_xyxy, scores, class_ids = bbox_details
+        bbox_xyxy, ids, scores, class_ids = bbox_details
         frame, frame_num, fps = frame_details
         print(frame_num)
         
 
 if __name__ == '__main__':
     parser = argparse.ArgumentParser()
```

## asone/pose_estimator.py

```diff
@@ -1,45 +1,108 @@
 import cv2
 import numpy as np
 import os
 from .utils import draw_kpts, plot_skeleton_kpts
 import cv2
 import time
+import warnings
 
 from asone.pose_estimators.yolov7_pose import Yolov7PoseEstimator
 from asone.pose_estimators.yolov8_pose import Yolov8PoseEstimator
 from asone.utils import get_weight_path, download_weights
+from asone.schemas.output_schemas import ModelOutput
 
 class PoseEstimator:
     def __init__(self, estimator_flag, weights: str=None, use_cuda=True):
 
         if weights:
             weights = weights
         else:
             weights = get_weight_path(estimator_flag)
             if not os.path.exists(weights):
                 download_weights(weights)
         self.estimator = self.get_estimator(estimator_flag, weights, use_cuda)
+        self.model_output = ModelOutput()
 
     def get_estimator(self, estimator_flag: int, weights: str, use_cuda: bool):
         
         if estimator_flag in range(149, 155):
             estimator = Yolov7PoseEstimator(weights=weights, use_cuda=use_cuda)
 
         elif estimator_flag in range(144, 149):
             estimator = Yolov8PoseEstimator(weights=weights,
                                        use_cuda=use_cuda)
         return estimator
     
     def estimate_image(self, frame):
     
         keypoints = self.estimator.estimate(frame)
-        return keypoints
+        return keypoints.cpu().numpy().xy
     
     def estimate_video(self, video_path, save=True, conf_thresh=0.5, display=True):
+       # Emit the warning for DeprecationWarning
+        with warnings.catch_warnings():
+            warnings.simplefilter("always", DeprecationWarning)
+            warnings.warn("estimate_video function is deprecated. Kindly use video_estimator instead", DeprecationWarning)
+            
+        if video_path == 0:
+            cap = cv2.VideoCapture(0)
+            video_path = 'webcam.mp4'
+        else:
+            cap = cv2.VideoCapture(video_path)
+        
+        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
+        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
+        FPS = cap.get(cv2.CAP_PROP_FPS)
+
+        if save:
+            video_writer = cv2.VideoWriter(
+                os.path.basename(video_path),
+                cv2.VideoWriter_fourcc(*"mp4v"),
+                FPS,
+                (int(width), int(height)),
+            )
+        
+        frame_no = 1
+        tic = time.time()
+        frame_id = 1
+        prevTime = 0
+        fframe_num = 0
+        while True:
+            start_time = time.time()
+
+            ret, img = cap.read()
+            if not ret:
+                break
+            frame = img.copy()
+            kpts = self.estimator.estimate(img)
+            currTime = time.time()
+            fps = 1 / (currTime - prevTime)
+            prevTime = currTime
+
+            if kpts is not None:
+                img = draw_kpts(kpts, image=img) 
+                
+            cv2.line(img, (20, 25), (127, 25), [85, 45, 255], 30)
+            cv2.putText(img, f'FPS: {int(fps)}', (11, 35), 0, 1, [
+                        225, 255, 255], thickness=2, lineType=cv2.LINE_AA)
+            frame_id += 1
+            frame_no+=1
+            if display:
+                cv2.imshow('Window', img)
+
+            if save:
+                video_writer.write(img)
+    
+            if cv2.waitKey(25) & 0xFF == ord('q'):
+                break
+
+            yield (kpts), (img if display else frame, frame_id-1, fps)
+    
+    def video_estimator(self, video_path, save=True, conf_thresh=0.5, display=True):
        
         if video_path == 0:
             cap = cv2.VideoCapture(0)
             video_path = 'webcam.mp4'
         else:
             cap = cv2.VideoCapture(video_path)
         
@@ -69,15 +132,15 @@
             frame = img.copy()
             kpts = self.estimator.estimate(img)
             currTime = time.time()
             fps = 1 / (currTime - prevTime)
             prevTime = currTime
 
             if kpts is not None:
-                img = draw_kpts(img, kpts) 
+                img = draw_kpts(kpts, image=img) 
                 
             cv2.line(img, (20, 25), (127, 25), [85, 45, 255], 30)
             cv2.putText(img, f'FPS: {int(fps)}', (11, 35), 0, 1, [
                         225, 255, 255], thickness=2, lineType=cv2.LINE_AA)
             frame_id += 1
             frame_no+=1
             if display:
@@ -85,8 +148,21 @@
 
             if save:
                 video_writer.write(img)
     
             if cv2.waitKey(25) & 0xFF == ord('q'):
                 break
 
-            yield (kpts), (img if display else frame, frame_id-1, fps)
+            yield self.format_output((kpts), (img if display else frame, frame_id-1, fps))
+    
+    
+    def format_output(self, bbox_details, frame_details):
+
+        # Set detections
+        self.model_output.dets.bbox = bbox_details
+        if frame_details:
+            # Set image info
+            self.model_output.info.image = frame_details[0]
+            self.model_output.info.frame_no = frame_details[1]
+            self.model_output.info.fps = frame_details[2]
+
+        return self.model_output
```

## asone/detectors/__init__.py

```diff
@@ -1,16 +1,18 @@
 from asone.detectors.yolov5 import YOLOv5Detector
 from asone.detectors.yolov6 import YOLOv6Detector
 from asone.detectors.yolov7 import YOLOv7Detector
+from asone.detectors.yolov9 import YOLOv9Detector
 from asone.detectors.yolor import YOLOrDetector
 from asone.detectors.yolox import YOLOxDetector
 from asone.detectors.easyocr_detector import TextDetector
 
 from asone.detectors.detector import Detector
 __all__ = ['Detector'
            'YOLOv5Detector',
            'YOLOv6Detector',
            'YOLOv7Detector',
+           'YOLOv9Detector',
            'YOLOrDetector',
            'YOLOxDetector',
            'TextDetector',
            'YOLOnasDetector']
```

## asone/detectors/detector.py

```diff
@@ -1,22 +1,12 @@
 import cv2
 
-from asone.detectors.yolov5 import YOLOv5Detector
-from asone.detectors.yolov6 import YOLOv6Detector
-from asone.detectors.yolov7 import YOLOv7Detector
-from asone.detectors.yolor import YOLOrDetector
-from asone.detectors.yolox import YOLOxDetector
-from asone.detectors.yolonas import YOLOnasDetector
-from asone.detectors.easyocr_detector import TextDetector
-
 from asone.detectors.utils.weights_path import get_weight_path
 from asone.detectors.utils.cfg_path import get_cfg_path
 from asone.detectors.utils.exp_name import get_exp__name
-from .yolov8 import YOLOv8Detector
-
 
 class Detector:
     def __init__(self,
                  model_flag: int,
                  weights: str = None,
                  use_cuda: bool = True,
                  recognizer:int = None,
@@ -35,83 +25,85 @@
             mlmodel = True    
         elif weights:
             onnx = False
             weight = weights
         else:
             mlmodel, onnx, weight = get_weight_path(model_flag)
         
-        if model_flag in range(0, 20):
+        if model_flag in range(0, 20) or model_flag in range(120, 131):
+            from asone.detectors.yolov5 import YOLOv5Detector
             _detector = YOLOv5Detector(weights=weight,
                                        use_onnx=onnx,
+                                       mlmodel=mlmodel,
                                        use_cuda=cuda)
         elif model_flag in range(20, 34):
+            from asone.detectors.yolov6 import YOLOv6Detector
             _detector = YOLOv6Detector(weights=weight,
                                        use_onnx=onnx,
                                        use_cuda=cuda)
-        elif model_flag in range(34, 48):
+        elif model_flag in range(34, 48) or model_flag in range(131, 139):
+            from asone.detectors.yolov7 import YOLOv7Detector
+            # Get exp file and corresponding model for coreml only
             _detector = YOLOv7Detector(weights=weight,
                                        use_onnx=onnx,
+                                       mlmodel=mlmodel,
                                        use_cuda=cuda)
         elif model_flag in range(48, 58):
+            from asone.detectors.yolor import YOLOrDetector
             # Get Configuration file for Yolor
             if model_flag in range(48, 57, 2):
                 cfg = get_cfg_path(model_flag)
             else:
                 cfg = None
             _detector = YOLOrDetector(weights=weight,
                                       cfg=cfg,
                                       use_onnx=onnx,
                                       use_cuda=cuda)
 
         elif model_flag in range(58, 72):
+            from asone.detectors.yolox import YOLOxDetector
             # Get exp file and corresponding model for pytorch only
             if model_flag in range(58, 71, 2):
                 exp, model_name = get_exp__name(model_flag)
             else:
                 exp = model_name = None
             _detector = YOLOxDetector(model_name=model_name,
                                       exp_file=exp,
                                       weights=weight,
                                       use_onnx=onnx,
                                       use_cuda=cuda)
-        elif model_flag in range(72, 82):
+        elif model_flag in range(72, 82) or model_flag in range(139, 144):
+            from asone.detectors.yolov8 import YOLOv8Detector
             # Get exp file and corresponding model for pytorch only
             _detector = YOLOv8Detector(weights=weight,
                                        use_onnx=onnx,
+                                       mlmodel=mlmodel,
                                        use_cuda=cuda)
         # Get TextDetector model
         elif model_flag  in range(82, 85):
+            from asone.detectors.easyocr_detector import TextDetector
             _detector = TextDetector(detect_network=weight, use_cuda=cuda)
-        
-        elif model_flag in range(120, 131):
-            # Get exp file and corresponding model for coreml only
-            _detector = YOLOv5Detector(weights=weight,
-                                       use_onnx=onnx,
-                                       mlmodel=mlmodel,
-                                       use_cuda=cuda)
-        elif model_flag in range(131, 139):
-            # Get exp file and corresponding model for coreml only
-            _detector = YOLOv7Detector(weights=weight,
-                                       use_onnx=onnx,
-                                       mlmodel=mlmodel,
-                                       use_cuda=cuda)
-        elif model_flag in range(139, 144):
-            # Get exp file and corresponding model for coreml only
-            _detector = YOLOv8Detector(weights=weight,
-                                       use_onnx=onnx,
-                                       mlmodel=mlmodel,
-                                       use_cuda=cuda)
+
         elif model_flag in range(160, 163):
+            from asone.detectors.yolonas import YOLOnasDetector
             # Get exp file and corresponding model for coreml only
             _detector = YOLOnasDetector(
                                     model_flag,
                                     weights=weight,
                                     use_onnx=onnx,
                                     use_cuda=cuda,
                                     num_classes=num_classes)
+        
+        elif model_flag in range(164, 170):
+            from asone.detectors.yolov9 import YOLOv9Detector
+            # Get exp file and corresponding model for pytorch only
+            _detector = YOLOv9Detector(
+                                    weights=weight,
+                                    use_onnx=onnx,
+                                    use_cuda=cuda)
             
         return _detector
 
     def get_detector(self):
         return self.model
 
     def detect(self,
```

## asone/detectors/utils/weights_path.py

```diff
@@ -116,15 +116,27 @@
             # Text Detectors
             '82': 'craft',
             '83': 'dbnet18',
             # YOLONAS_S_PYTORCH
             # YOLO NAS
             '160':os.path.join('yolonas','weights','yolo_nas_s.pth'),
             '161':os.path.join('yolonas','weights','yolo_nas_m.pth'),
-            '162':os.path.join('yolonas','weights','yolo_nas_l.pth') 
+            '162':os.path.join('yolonas','weights','yolo_nas_l.pth'),
+            
+            # YOLOv9
+            '164':os.path.join('yolov9','weights','yolov9-c-converted.pt'),
+            '165':os.path.join('yolov9','weights','yolov9-e-converted.pt'),
+            '166':os.path.join('yolov9','weights','yolov9-c.pt'),
+            '167':os.path.join('yolov9','weights','yolov9-e.pt'),
+            '168':os.path.join('yolov9','weights','gelan-c.pt'),
+            '169':os.path.join('yolov9','weights','gelan-e.pt'),
+            
+            
+            # Segmentor
+            '171':os.path.join('sam','weights','sam_vit_h_4b8939.pth'),
 }
 
 def get_weight_path(model_flag):
     coreml= False
     if model_flag in range(0, 20):
         onnx = False if (model_flag % 2 == 0) else True
         weight = weights[str(model_flag)]
@@ -159,9 +171,13 @@
         weight = weights[str(model_flag)]
         onnx=False
         coreml = True
     elif model_flag in range(160, 163):
         weight = weights[str(model_flag)]
         onnx=False
         coreml = True
+    elif model_flag in range(164, 170):
+        onnx = False
+        weight = weights[str(model_flag)]
+
     return coreml, onnx, weight
```

## asone/detectors/yolonas/yolonas.py

```diff
@@ -7,14 +7,16 @@
 from asone import utils
 import super_gradients
 import numpy as np
 from super_gradients.training.processing import DetectionCenterPadding, StandardizeImage, NormalizeImage, ImagePermute, ComposeProcessing, DetectionLongestMaxSizeRescale
 from super_gradients.training import models
 from super_gradients.common.object_names import Models
 
+from asone.utils.utils import PathResolver
+
 
 class_names = [""]
 
 
 class YOLOnasDetector:
     def __init__(self,
                  model_flag,
@@ -32,16 +34,17 @@
         if not os.path.exists(weights):
             utils.download_weights(weights)
         
         self.num_classes = num_classes
         self.device = 'cuda' if use_cuda and torch.cuda.is_available() else 'cpu'
         self.use_onnx = use_onnx
 
-        # Load Model
-        self.model = self.load_model(weights=weights)
+        with PathResolver():
+            # Load Model
+            self.model = self.load_model(weights=weights)
 
     def load_model(self, weights):
         
             # model = super_gradients.training.models.get(name, 
             #             checkpoint_path=weights, 
             #             checkpoint_num_classes=self.checkpoint_num_classes,
             #             num_classes=self.num_classes).to(self.device)
```

## asone/detectors/yolor/yolor_detector.py

```diff
@@ -2,20 +2,22 @@
 import os
 from asone.utils import get_names
 import numpy as np
 import warnings
 import torch
 import onnxruntime
 
-from .models.models import *
+from asone.detectors.yolor.models.models import *
 from asone import utils
 from asone.detectors.yolor.utils.yolor_utils import (non_max_suppression,
                                                      scale_coords,
                                                      letterbox)
 
+from asone.utils.utils import PathResolver
+
 
 class YOLOrDetector:
     def __init__(self,
                  weights=None,
                  cfg=None,
                  use_onnx=True,
                  use_cuda=True,
@@ -27,16 +29,17 @@
         if not os.path.exists(weights):
             utils.download_weights(weights)
 
         if cfg == None:
             cfg = os.path.join("cfg", "yolor_p6.cfg")
         # If incase weighst is a list of paths then select path at first index
         weights = str(weights[0] if isinstance(weights, list) else weights)
-        # Load Model
-        self.model = self.load_model(use_cuda, weights, cfg=cfg, img_size=640)
+        with PathResolver():
+            # Load Model
+            self.model = self.load_model(use_cuda, weights, cfg=cfg, img_size=640)
 
     def load_model(self, use_cuda, weights, cfg, img_size, fp16=False):
         # Device: CUDA and if fp16=True only then half precision floating point works
         self.fp16 = fp16 & (
             (not self.use_onnx or self.use_onnx) and self.device != 'cpu')
         # Load onnx
         if self.use_onnx:
```

## asone/detectors/yolor/utils/autoanchor.py

```diff
@@ -91,15 +91,15 @@
         for i, x in enumerate(k):
             print('%i,%i' % (round(x[0]), round(x[1])), end=',  ' if i < len(k) - 1 else '\n')  # use in *.cfg
         return k
 
     if isinstance(path, str):  # *.yaml file
         with open(path) as f:
             data_dict = yaml.load(f, Loader=yaml.FullLoader)  # model dict
-        from utils.datasets import LoadImagesAndLabels
+        from asone.detectors.yolor.utils.datasets import LoadImagesAndLabels
         dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)
     else:
         dataset = path  # dataset
 
     # Get label wh
     shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)
     wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh
```

## asone/detectors/yolov5/yolov5_detector.py

```diff
@@ -9,14 +9,16 @@
 from asone.detectors.yolov5.yolov5.utils.yolov5_utils import (non_max_suppression,
                                                               scale_coords,
                                                               letterbox)
 from asone.detectors.yolov5.yolov5.models.experimental import attempt_load
 from asone import utils
 from asone.detectors.utils.coreml_utils import yolo_to_xyxy, generalize_output_format, scale_bboxes
 
+from asone.utils.utils import PathResolver
+
 
 class YOLOv5Detector:
     def __init__(self,
                  weights=None,
                  use_onnx=False,
                  mlmodel=False,
                  use_cuda=True):
@@ -24,16 +26,17 @@
         self.use_onnx = use_onnx
         self.mlmodel = mlmodel
         self.device = 'cuda' if use_cuda else 'cpu'
 
         if not os.path.exists(weights):
             utils.download_weights(weights)
         
-        # Load Model
-        self.model = self.load_model(use_cuda, weights)
+        with PathResolver():
+            # Load Model
+            self.model = self.load_model(use_cuda, weights)
         
     def load_model(self, use_cuda, weights, fp16=False):
         # Device: CUDA and if fp16=True only then half precision floating point works  
         self.fp16 = fp16 & ((not self.use_onnx or self.use_onnx) and self.device != 'cpu')
         # Load onnx 
         if self.use_onnx:
             if use_cuda:
```

## asone/detectors/yolov5/yolov5/models/__init__.py

```diff
@@ -1,3 +1,3 @@
-import os
-import sys
-sys.path.append(os.path.dirname(__file__))
+# import os
+# import sys
+# sys.path.append(os.path.dirname(__file__))
```

## asone/detectors/yolov5/yolov5/models/common.py

```diff
@@ -311,15 +311,15 @@
         #   OpenVINO:                       *.xml
         #   CoreML:                         *.mlmodel
         #   TensorRT:                       *.engine
         #   TensorFlow SavedModel:          *_saved_model
         #   TensorFlow GraphDef:            *.pb
         #   TensorFlow Lite:                *.tflite
         #   TensorFlow Edge TPU:            *_edgetpu.tflite
-        from asone.detectors.yolov5.utils.experimental import attempt_download, attempt_load  # scoped to avoid circular import
+        from asone.detectors.yolov5.yolov5.models.experimental import attempt_download, attempt_load  # scoped to avoid circular import
 
         super().__init__()
         w = str(weights[0] if isinstance(weights, list) else weights)
         pt, jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs = self.model_type(w)  # get backend
         w = attempt_download(w)  # download if not local
         fp16 &= (pt or jit or onnx or engine) and device.type != 'cpu'  # FP16
         stride, names = 32, [f'class{i}' for i in range(1000)]  # assign defaults
@@ -521,15 +521,15 @@
             im = torch.zeros(*imgsz, dtype=torch.half if self.fp16 else torch.float, device=self.device)  # input
             for _ in range(2 if self.jit else 1):  #
                 self.forward(im)  # warmup
 
     @staticmethod
     def model_type(p='path/to/model.pt'):
         # Return model type from model path, i.e. path='path/to/model.onnx' -> type=onnx
-        from export import export_formats
+        from asone.detectors.yolov5.yolov5.export import export_formats
         suffixes = list(export_formats().Suffix) + ['.xml']  # export suffixes
         check_suffix(p, suffixes)  # checks
         p = Path(p).name  # eliminate trailing separators
         pt, jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs, xml2 = (s in p for s in suffixes)
         xml |= xml2  # *_openvino_model or *.xml
         tflite &= not edgetpu  # *.tflite
         return pt, jit, onnx, xml, engine, coreml, saved_model, pb, tflite, edgetpu, tfjs
```

## asone/detectors/yolov5/yolov5/models/general.py

```diff
@@ -523,15 +523,15 @@
             LOGGER.info(emojis(f"Dataset download {s}"))
     check_font('Arial.ttf' if is_ascii(data['names']) else 'Arial.Unicode.ttf', progress=True)  # download fonts
     return data  # dictionary
 
 
 def check_amp(model):
     # Check PyTorch Automatic Mixed Precision (AMP) functionality. Return True on correct operation
-    from asone.detectors.yolov5.utils.common import AutoShape, DetectMultiBackend
+    from asone.detectors.yolov5.yolov5.models.common import AutoShape, DetectMultiBackend
 
     def amp_allclose(model, im):
         # All close FP32 vs AMP results
         m = AutoShape(model, verbose=False)  # model
         a = m(im).xywhn[0]  # FP32 inference
         m.amp = True
         b = m(im).xywhn[0]  # AMP inference
```

## asone/detectors/yolov6/yolov6_detector.py

```diff
@@ -5,15 +5,17 @@
 import warnings
 import torch
 import onnxruntime
 
 from asone import utils
 from asone.detectors.yolov6.yolov6.utils.yolov6_utils import (prepare_input, load_pytorch,
                                                               non_max_suppression, process_and_scale_boxes) 
-sys.path.append(os.path.dirname(__file__))  
+# sys.path.append(os.path.dirname(__file__))
+from asone.utils.utils import PathResolver
+  
 
 class YOLOv6Detector:
     def __init__(self,
                  weights=None,
                  use_onnx=False,
                  use_cuda=True):
 
@@ -21,16 +23,17 @@
         self.device = 'cuda' if use_cuda else 'cpu'
 
         if not os.path.exists(weights):
             utils.download_weights(weights)
         #If incase weighst is a list of paths then select path at first index
         weights = str(weights[0] if isinstance(weights, list) else weights)
         
-        # Load Model
-        self.model = self.load_model(use_cuda, weights)
+        with PathResolver():
+            # Load Model
+            self.model = self.load_model(use_cuda, weights)
         
         if use_onnx:
             # Get Some ONNX model details 
             self.input_shape, self.input_height, self.input_width = self.ONNXModel_detail(self.model)
             self.input_names, self.output_names = self.ONNXModel_names(self.model)
```

## asone/detectors/yolov6/yolov6/assigners/atss_assigner.py

```diff
@@ -1,12 +1,12 @@
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
-from yolov6.assigners.iou2d_calculator import iou2d_calculator
-from yolov6.assigners.assigner_utils import dist_calculator, select_candidates_in_gts, select_highest_overlaps, iou_calculator
+from asone.detectors.yolov6.yolov6.assigners.iou2d_calculator import iou2d_calculator
+from asone.detectors.yolov6.yolov6.assigners.assigner_utils import dist_calculator, select_candidates_in_gts, select_highest_overlaps, iou_calculator
 
 class ATSSAssigner(nn.Module):
     '''Adaptive Training Sample Selection Assigner'''
     def __init__(self,
                  topk=9,
                  num_classes=80):
         super(ATSSAssigner, self).__init__()
```

## asone/detectors/yolov6/yolov6/assigners/tal_assigner.py

```diff
@@ -1,11 +1,11 @@
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
-from yolov6.assigners.assigner_utils import select_candidates_in_gts, select_highest_overlaps, iou_calculator
+from asone.detectors.yolov6.yolov6.assigners.assigner_utils import select_candidates_in_gts, select_highest_overlaps, iou_calculator
 
 class TaskAlignedAssigner(nn.Module):
     def __init__(self, 
                  topk=13,
                  num_classes=80, 
                  alpha=1.0, 
                  beta=6.0,
```

## asone/detectors/yolov6/yolov6/layers/common.py

```diff
@@ -347,15 +347,15 @@
 
 
 class DetectBackend(nn.Module):
     def __init__(self, weights='yolov6s.pt', device=None, dnn=True):
 
         super().__init__()
         assert isinstance(weights, str) and Path(weights).suffix == '.pt', f'{Path(weights).suffix} format is not supported.'
-        from yolov6.utils.checkpoint import load_checkpoint
+        from asone.detectors.yolov6.yolov6.utils.checkpoint import load_checkpoint
         model = load_checkpoint(weights, map_location=device)
         stride = int(model.stride.max())
         self.__dict__.update(locals())  # assign all variables to self
 
     def forward(self, im, val=False):
         y, _ = self.model(im)
         if isinstance(y, np.ndarray):
```

## asone/detectors/yolov6/yolov6/models/efficientrep.py

```diff
@@ -1,9 +1,9 @@
 from torch import nn
-from yolov6.layers.common import BottleRep, RepVGGBlock, RepBlock, BepC3, SimSPPF, SPPF, ConvWrapper
+from asone.detectors.yolov6.yolov6.layers.common import BottleRep, RepVGGBlock, RepBlock, BepC3, SimSPPF, SPPF, ConvWrapper
 
 
 class EfficientRep(nn.Module):
     '''EfficientRep Backbone
     EfficientRep is handcrafted by hardware-aware neural network design.
     With rep-style struct, EfficientRep is friendly to high-computation hardware(e.g. GPU).
     '''
```

## asone/detectors/yolov6/yolov6/models/effidehead.py

```diff
@@ -1,14 +1,14 @@
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import math
-from yolov6.layers.common import *
-from yolov6.assigners.anchor_generator import generate_anchors
-from yolov6.utils.general import dist2bbox
+from asone.detectors.yolov6.yolov6.layers.common import *
+from asone.detectors.yolov6.yolov6.assigners.anchor_generator import generate_anchors
+from asone.detectors.yolov6.yolov6.utils.general import dist2bbox
 
 
 class Detect(nn.Module):
     '''Efficient Decoupled Head
     With hardware-aware degisn, the decoupled head is optimized with
     hybridchannels methods.
     '''
```

## asone/detectors/yolov6/yolov6/models/loss.py

```diff
@@ -1,19 +1,19 @@
 #!/usr/bin/env python3
 # -*- coding:utf-8 -*-
 
 import torch
 import torch.nn as nn
 import numpy as np
 import torch.nn.functional as F
-from yolov6.assigners.anchor_generator import generate_anchors
-from yolov6.utils.general import dist2bbox, bbox2dist, xywh2xyxy
-from yolov6.utils.figure_iou import IOUloss
-from yolov6.assigners.atss_assigner import ATSSAssigner
-from yolov6.assigners.tal_assigner import TaskAlignedAssigner
+from asone.detectors.yolov6.yolov6.assigners.anchor_generator import generate_anchors
+from asone.detectors.yolov6.yolov6.utils.general import dist2bbox, bbox2dist, xywh2xyxy
+from asone.detectors.yolov6.yolov6.utils.figure_iou import IOUloss
+from asone.detectors.yolov6.yolov6.assigners.atss_assigner import ATSSAssigner
+from asone.detectors.yolov6.yolov6.assigners.tal_assigner import TaskAlignedAssigner
 
 
 class ComputeLoss:
     '''Loss computation func.'''
     def __init__(self, 
                  fpn_strides=[8, 16, 32],
                  grid_cell_size=5.0,
```

## asone/detectors/yolov6/yolov6/models/loss_distill.py

```diff
@@ -1,19 +1,19 @@
 #!/usr/bin/env python3
 # -*- coding:utf-8 -*-
 
 import torch
 import torch.nn as nn
 import numpy as np
 import torch.nn.functional as F
-from yolov6.assigners.anchor_generator import generate_anchors
-from yolov6.utils.general import dist2bbox, bbox2dist, xywh2xyxy
-from yolov6.utils.figure_iou import IOUloss
-from yolov6.assigners.atss_assigner import ATSSAssigner
-from yolov6.assigners.tal_assigner import TaskAlignedAssigner
+from asone.detectors.yolov6.yolov6.assigners.anchor_generator import generate_anchors
+from asone.detectors.yolov6.yolov6.utils.general import dist2bbox, bbox2dist, xywh2xyxy
+from asone.detectors.yolov6.yolov6.utils.figure_iou import IOUloss
+from asone.detectors.yolov6.yolov6.assigners.atss_assigner import ATSSAssigner
+from asone.detectors.yolov6.yolov6.assigners.tal_assigner import TaskAlignedAssigner
 
 
 class ComputeLoss:
     '''Loss computation func.'''
     def __init__(self, 
                  fpn_strides=[8, 16, 32],
                  grid_cell_size=5.0,
```

## asone/detectors/yolov6/yolov6/models/reppan.py

```diff
@@ -1,10 +1,10 @@
 import torch
 from torch import nn
-from yolov6.layers.common import RepBlock, RepVGGBlock, BottleRep, BepC3, SimConv, Transpose
+from asone.detectors.yolov6.yolov6.layers.common import RepBlock, RepVGGBlock, BottleRep, BepC3, SimConv, Transpose
 
 _QUANT=False
 class RepPANNeck(nn.Module):
     """RepPANNeck Module
     EfficientRep is the default backbone of this model.
     RepPANNeck has the balance of feature fusion ability and hardware efficiency.
     """
```

## asone/detectors/yolov6/yolov6/models/yolo.py

```diff
@@ -1,18 +1,18 @@
 #!/usr/bin/env python3
 # -*- coding:utf-8 -*-
 import math
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
-from yolov6.layers.common import *
-from yolov6.utils.torch_utils import initialize_weights
-from yolov6.models.efficientrep import *
-from yolov6.models.reppan import *
-from yolov6.models.effidehead import Detect, build_effidehead_layer
+from asone.detectors.yolov6.yolov6.layers.common import *
+from asone.detectors.yolov6.yolov6.utils.torch_utils import initialize_weights
+from asone.detectors.yolov6.yolov6.models.efficientrep import *
+from asone.detectors.yolov6.yolov6.models.reppan import *
+from asone.detectors.yolov6.yolov6.models.effidehead import Detect, build_effidehead_layer
 
 
 class Model(nn.Module):
     '''YOLOv6 model with backbone, neck and head.
     The default parts are EfficientRep Backbone, Rep-PAN and
     Efficient Decoupled Head.
     '''
```

## asone/detectors/yolov6/yolov6/utils/torch_utils.py

```diff
@@ -4,15 +4,15 @@
 import time
 from contextlib import contextmanager
 from copy import deepcopy
 import torch
 import torch.distributed as dist
 import torch.nn as nn
 import torch.nn.functional as F
-from yolov6.utils.events import LOGGER
+from asone.detectors.yolov6.yolov6.utils.events import LOGGER
 
 try:
     import thop  # for FLOPs computation
 except ImportError:
     thop = None
 
 
@@ -79,15 +79,15 @@
     )
     fusedconv.bias.copy_(torch.mm(w_bn, b_conv.reshape(-1, 1)).reshape(-1) + b_bn)
 
     return fusedconv
 
 
 def fuse_model(model):
-    from yolov6.layers.common import Conv
+    from asone.detectors.yolov6.yolov6.layers.common import Conv
 
     for m in model.modules():
         if type(m) is Conv and hasattr(m, "bn"):
             m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv
             delattr(m, "bn")  # remove batchnorm
             m.forward = m.forward_fuse  # update forward
     return model
```

## asone/detectors/yolov7/yolov7_detector.py

```diff
@@ -10,25 +10,26 @@
                                  process_output,
                                  non_max_suppression)
 from asone.detectors.yolov7.yolov7.models.experimental import attempt_load
 from asone import utils
 from PIL import Image
 from asone.detectors.utils.coreml_utils import yolo_to_xyxy, generalize_output_format, scale_bboxes
 
+from asone.utils.utils import PathResolver
+
 def xywh2xyxy(x):
     # Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right
     y = x.clone() if isinstance(x, torch.Tensor) else np.copy(x)
     y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x
     y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y
     y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x
     y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y
     return y
 
 
-sys.path.append(os.path.join(os.path.dirname(__file__), 'yolov7'))
 class YOLOv7Detector:
     def __init__(self,
                  weights=None,
                  use_onnx=False,
                  mlmodel=False,
                  use_cuda=True):
         self.use_onnx = use_onnx
@@ -38,17 +39,17 @@
         #If incase weighst is a list of paths then select path at first index
 
         weights = str(weights[0] if isinstance(weights, list) else weights)
 
         if not os.path.exists(weights):
             utils.download_weights(weights)
             
-
-        # Load Model
-        self.model = self.load_model(use_cuda, weights)
+        with PathResolver():
+            # Load Model
+            self.model = self.load_model(use_cuda, weights)
     
     def load_model(self, use_cuda, weights, fp16=False):
         # Device: CUDA and if fp16=True only then half precision floating point works  
         self.fp16 = fp16 & ((not self.use_onnx or self.use_onnx) and self.device != 'cpu')
         # Load onnx 
         if self.use_onnx:            
             if use_cuda:
```

## asone/detectors/yolov7/yolov7/models/__init__.py

```diff
@@ -1,4 +0,0 @@
-00000000: 696d 706f 7274 206f 730a 696d 706f 7274  import os.import
-00000010: 2073 7973 0a73 7973 2e70 6174 682e 6170   sys.sys.path.ap
-00000020: 7065 6e64 286f 732e 7061 7468 2e64 6972  pend(os.path.dir
-00000030: 6e61 6d65 285f 5f66 696c 655f 5f29 290a  name(__file__)).
```

## asone/detectors/yolov7/yolov7/models/experimental.py

```diff
@@ -1,11 +1,11 @@
 import torch
 import torch.nn as nn
 
-from .common import Conv
+from asone.detectors.yolov7.yolov7.models.common import Conv
 
 class Ensemble(nn.ModuleList):
     # Ensemble of models
     def __init__(self):
         super(Ensemble, self).__init__()
 
     def forward(self, x, augment=False):
```

## asone/detectors/yolov8/yolov8_detector.py

```diff
@@ -1,21 +1,23 @@
 import os
 from asone import utils
 from asone.utils import get_names
 import onnxruntime
 import torch
-from .utils.yolov8_utils import prepare_input, process_output
+from asone.detectors.yolov8.utils.yolov8_utils import prepare_input, process_output
 import numpy as np
 import warnings
 from ultralytics.nn.autobackend import AutoBackend
 from ultralytics.nn.tasks import DetectionModel, attempt_load_one_weight
 import coremltools as ct
 from PIL import Image
 from asone.detectors.utils.coreml_utils import yolo_to_xyxy, generalize_output_format, scale_bboxes
 
+from asone.utils.utils import PathResolver
+
 
 class YOLOv8Detector:
     def __init__(self,
                  weights=None,
                  use_onnx=False,
                  mlmodel=False,
                  use_cuda=True):
@@ -26,16 +28,17 @@
 
         # If incase weighst is a list of paths then select path at first index
         weights = str(weights[0] if isinstance(weights, list) else weights)
 
         if not os.path.exists(weights):
             utils.download_weights(weights)
 
-        # Load Model
-        self.model = self.load_model(use_cuda, weights)
+        with PathResolver():
+            # Load Model
+            self.model = self.load_model(use_cuda, weights)
 
     def load_model(self, use_cuda, weights, fp16=False):
 
         # Device: CUDA and if fp16=True only then half precision floating point works
         self.fp16 = fp16 & (
             (not self.use_onnx or self.use_onnx) and self.device != 'cpu')
```

## asone/detectors/yolov8/utils/yolov8_utils.py

```diff
@@ -1,12 +1,12 @@
 import cv2
 import numpy as np
-from ultralytics.yolo.utils import ops
+from ultralytics.utils import ops
 import torch
-from ultralytics.yolo.data.augment import LetterBox
+from ultralytics.data.augment import LetterBox
 
 def prepare_input(image, input_shape, stride, pt):
     input_tensor = LetterBox(input_shape, auto=pt, stride=stride)(image=image)
     input_tensor = input_tensor.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
     input_tensor = np.ascontiguousarray(input_tensor).astype(np.float32)  # contiguous
     input_tensor /= 255.0  # 0 - 255 to 0.0 - 1.0
     input_tensor = input_tensor[None].astype(np.float32)
```

## asone/detectors/yolox/yolox_detector.py

```diff
@@ -8,14 +8,16 @@
 import onnxruntime
 
 from asone import utils
 from asone.detectors.yolox.yolox.utils import fuse_model, postprocess
 from asone.detectors.yolox.yolox.exp import get_exp
 from asone.detectors.yolox.yolox_utils import preprocess, multiclass_nms, demo_postprocess
 
+from asone.utils.utils import PathResolver
+
 
 class YOLOxDetector:
     def __init__(self,
                  model_name=None,
                  exp_file=None,
                  weights=None,
                  use_onnx=False,
@@ -31,19 +33,20 @@
         self.weights_name = os.path.basename(weights)
 
         if model_name is None:
             model_name = 'yolox-s'
 
         if exp_file is None:
             exp_file = os.path.join("exps", "default", "yolox_s.py")
-        # Load Model
-        if self.use_onnx:
-            self.model = self.load_onnx_model(use_cuda, weights)
-        else:
-            self.model = self.load_torch_model(weights, exp_file, model_name)
+        with PathResolver():
+            # Load Model
+            if self.use_onnx:
+                self.model = self.load_onnx_model(use_cuda, weights)
+            else:
+                self.model = self.load_torch_model(weights, exp_file, model_name)
 
     def load_onnx_model(self, use_cuda, weights):
         # Load onnx
         if use_cuda:
             providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
         else:
             providers = ['CPUExecutionProvider']
```

## asone/detectors/yolox/yolox/exp/yolox_base.py

```diff
@@ -5,15 +5,15 @@
 import os
 import random
 
 import torch
 import torch.distributed as dist
 import torch.nn as nn
 
-from .base_exp import BaseExp
+from asone.detectors.yolox.yolox.exp.base_exp import BaseExp
 
 
 class Exp(BaseExp):
     def __init__(self):
         super().__init__()
 
         # ---------------- model config ---------------- #
@@ -124,24 +124,24 @@
 
         self.model.apply(init_yolo)
         self.model.head.initialize_biases(1e-2)
         self.model.train()
         return self.model
 
     def get_data_loader(self, batch_size, is_distributed, no_aug=False, cache_img=False):
-        from yolox.data import (
+        from asone.detectors.yolox.yolox.data import (
             COCODataset,
             TrainTransform,
             YoloBatchSampler,
             DataLoader,
             InfiniteSampler,
             MosaicDetection,
             worker_init_reset_seed,
         )
-        from yolox.utils import wait_for_the_master
+        from asone.detectors.yolox.yolox.utils import wait_for_the_master
 
         with wait_for_the_master():
             dataset = COCODataset(
                 data_dir=self.data_dir,
                 json_file=self.train_ann,
                 img_size=self.input_size,
                 preproc=TrainTransform(
@@ -251,30 +251,30 @@
             )  # add pg1 with weight_decay
             optimizer.add_param_group({"params": pg2})
             self.optimizer = optimizer
 
         return self.optimizer
 
     def get_lr_scheduler(self, lr, iters_per_epoch):
-        from yolox.utils import LRScheduler
+        from asone.detectors.yolox.yolox.utils import LRScheduler
 
         scheduler = LRScheduler(
             self.scheduler,
             lr,
             iters_per_epoch,
             self.max_epoch,
             warmup_epochs=self.warmup_epochs,
             warmup_lr_start=self.warmup_lr,
             no_aug_epochs=self.no_aug_epochs,
             min_lr_ratio=self.min_lr_ratio,
         )
         return scheduler
 
     def get_eval_loader(self, batch_size, is_distributed, testdev=False, legacy=False):
-        from yolox.data import COCODataset, ValTransform
+        from asone.detectors.yolox.yolox.data import COCODataset, ValTransform
 
         valdataset = COCODataset(
             data_dir=self.data_dir,
             json_file=self.val_ann if not testdev else self.test_ann,
             name="val2017" if not testdev else "test2017",
             img_size=self.test_size,
             preproc=ValTransform(legacy=legacy),
@@ -295,28 +295,28 @@
         }
         dataloader_kwargs["batch_size"] = batch_size
         val_loader = torch.utils.data.DataLoader(valdataset, **dataloader_kwargs)
 
         return val_loader
 
     def get_evaluator(self, batch_size, is_distributed, testdev=False, legacy=False):
-        from yolox.evaluators import COCOEvaluator
+        from asone.detectors.yolox.yolox.evaluators import COCOEvaluator
 
         val_loader = self.get_eval_loader(batch_size, is_distributed, testdev, legacy)
         evaluator = COCOEvaluator(
             dataloader=val_loader,
             img_size=self.test_size,
             confthre=self.test_conf,
             nmsthre=self.nmsthre,
             num_classes=self.num_classes,
             testdev=testdev,
         )
         return evaluator
 
     def get_trainer(self, args):
-        from yolox.core import Trainer
+        from asone.detectors.yolox.yolox.core import Trainer
         trainer = Trainer(self, args)
         # NOTE: trainer shouldn't be an attribute of exp object
         return trainer
 
     def eval(self, model, evaluator, is_distributed, half=False, return_outputs=False):
         return evaluator.evaluate(model, is_distributed, half, return_outputs=return_outputs)
```

## asone/detectors/yolox/yolox/models/build.py

```diff
@@ -43,15 +43,15 @@
         ckpt_path (str): path to your own ckpt. Required if name="yolox_custom" and you want to
             load a pretrained model
 
 
     Returns:
         YOLOX model (nn.Module)
     """
-    from yolox.exp import get_exp, Exp
+    from asone.detectors.yolox.yolox.exp import get_exp, Exp
 
     if device is None:
         device = "cuda:0" if torch.cuda.is_available() else "cpu"
     device = torch.device(device)
 
     assert name in _CKPT_FULL_PATH or name == "yolox_custom", \
         f"user should use one of value in {_CKPT_FULL_PATH.keys()} or \"yolox_custom\""
```

## asone/detectors/yolox/yolox/models/darknet.py

```diff
@@ -1,14 +1,14 @@
 #!/usr/bin/env python
 # -*- encoding: utf-8 -*-
 # Copyright (c) Megvii Inc. All rights reserved.
 
 from torch import nn
 
-from .network_blocks import BaseConv, CSPLayer, DWConv, Focus, ResLayer, SPPBottleneck
+from asone.detectors.yolox.yolox.models.network_blocks import BaseConv, CSPLayer, DWConv, Focus, ResLayer, SPPBottleneck
 
 
 class Darknet(nn.Module):
     # number of blocks from dark2 to dark5.
     depth2blocks = {21: [1, 2, 2, 1], 53: [2, 8, 8, 4]}
 
     def __init__(
```

## asone/detectors/yolox/yolox/models/yolo_fpn.py

```diff
@@ -1,16 +1,16 @@
 #!/usr/bin/env python
 # -*- encoding: utf-8 -*-
 # Copyright (c) Megvii Inc. All rights reserved.
 
 import torch
 import torch.nn as nn
 
-from .darknet import Darknet
-from .network_blocks import BaseConv
+from asone.detectors.yolox.yolox.models.darknet import Darknet
+from asone.detectors.yolox.yolox.models.network_blocks import BaseConv
 
 
 class YOLOFPN(nn.Module):
     """
     YOLOFPN module. Darknet 53 is the default backbone of this model.
     """
```

## asone/detectors/yolox/yolox/models/yolo_head.py

```diff
@@ -7,16 +7,16 @@
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
 from asone.detectors.yolox.yolox.utils import bboxes_iou, meshgrid
 
-from .losses import IOUloss
-from .network_blocks import BaseConv, DWConv
+from asone.detectors.yolox.yolox.models.losses import IOUloss
+from asone.detectors.yolox.yolox.models.network_blocks import BaseConv, DWConv
 
 
 class YOLOXHead(nn.Module):
     def __init__(
         self,
         num_classes,
         width=1.0,
```

## asone/detectors/yolox/yolox/models/yolo_pafpn.py

```diff
@@ -1,16 +1,16 @@
 #!/usr/bin/env python
 # -*- encoding: utf-8 -*-
 # Copyright (c) Megvii Inc. All rights reserved.
 
 import torch
 import torch.nn as nn
 
-from .darknet import CSPDarknet
-from .network_blocks import BaseConv, CSPLayer, DWConv
+from asone.detectors.yolox.yolox.models.darknet import CSPDarknet
+from asone.detectors.yolox.yolox.models.network_blocks import BaseConv, CSPLayer, DWConv
 
 
 class YOLOPAFPN(nn.Module):
     """
     YOLOv3 model. Darknet 53 is the default backbone of this model.
     """
```

## asone/detectors/yolox/yolox/models/yolox.py

```diff
@@ -1,15 +1,15 @@
 #!/usr/bin/env python
 # -*- encoding: utf-8 -*-
 # Copyright (c) Megvii Inc. All rights reserved.
 
 import torch.nn as nn
 
-from .yolo_head import YOLOXHead
-from .yolo_pafpn import YOLOPAFPN
+from asone.detectors.yolox.yolox.models.yolo_head import YOLOXHead
+from asone.detectors.yolox.yolox.models.yolo_pafpn import YOLOPAFPN
 
 
 class YOLOX(nn.Module):
     """
     YOLOX model module. The module list is defined by create_yolov3_modules function.
     The network returns loss values from three YOLO layers during training
     and detection results during test.
```

## asone/detectors/yolox/yolox/utils/allreduce_norm.py

```diff
@@ -5,15 +5,15 @@
 import pickle
 from collections import OrderedDict
 
 import torch
 from torch import distributed as dist
 from torch import nn
 
-from .dist import _get_global_gloo_group, get_world_size
+from asone.detectors.yolox.yolox.utils.dist import _get_global_gloo_group, get_world_size
 
 ASYNC_NORM = (
     nn.BatchNorm1d,
     nn.BatchNorm2d,
     nn.BatchNorm3d,
     nn.InstanceNorm1d,
     nn.InstanceNorm2d,
```

## asone/detectors/yolox/yolox/utils/model_utils.py

```diff
@@ -82,15 +82,15 @@
 
     Args:
         model (nn.Module): model to fuse
 
     Returns:
         nn.Module: fused model
     """
-    from yolox.models.network_blocks import BaseConv
+    from asone.detectors.yolox.yolox.models.network_blocks import BaseConv
 
     for m in model.modules():
         if type(m) is BaseConv and hasattr(m, "bn"):
             m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv
             delattr(m, "bn")  # remove batchnorm
             m.forward = m.fuseforward  # update forward
     return model
```

## asone/detectors/yolox/yolox/utils/setup_env.py

```diff
@@ -4,15 +4,15 @@
 
 import os
 import subprocess
 from loguru import logger
 
 import cv2
 
-from .dist import get_world_size, is_main_process
+from asone.detectors.yolox.yolox.utils.dist import get_world_size, is_main_process
 
 __all__ = ["configure_nccl", "configure_module", "configure_omp"]
 
 
 def configure_nccl():
     """Configure multi-machine environment variables of NCCL."""
     os.environ["NCCL_LAUNCH_MODE"] = "PARALLEL"
```

## asone/pose_estimators/yolov7_pose/yolov7.py

```diff
@@ -1,18 +1,18 @@
 import cv2
 import time
 import torch
 import numpy as np
 import matplotlib.pyplot as plt
 from torchvision import transforms
-from .utils.datasets import letterbox
-from .utils.torch_utils import select_device
-from .models.experimental import attempt_load
-from .utils.general import non_max_suppression_kpt,strip_optimizer,xyxy2xywh
-from .utils.plots import output_to_keypoint, plot_skeleton_kpts,colors,plot_one_box_kpt
+from asone.pose_estimators.yolov7_pose.utils.datasets import letterbox
+from asone.pose_estimators.yolov7_pose.utils.torch_utils import select_device
+from asone.pose_estimators.yolov7_pose.models.experimental import attempt_load
+from asone.pose_estimators.yolov7_pose.utils.general import non_max_suppression_kpt,strip_optimizer,xyxy2xywh
+from asone.pose_estimators.yolov7_pose.utils.plots import output_to_keypoint, plot_skeleton_kpts,colors,plot_one_box_kpt
 import os
 import sys
 
 
 class Yolov7PoseEstimator:
     def __init__(self, weights="yolov7-w6-pose.pt", use_cuda=True): 
         self.weights=weights
```

## asone/pose_estimators/yolov7_pose/models/experimental.py

```diff
@@ -1,13 +1,13 @@
 import numpy as np
 import random
 import torch
 import torch.nn as nn
 
-from .common import Conv, DWConv
+from asone.pose_estimators.yolov7_pose.models.common import Conv, DWConv
 from asone.pose_estimators.yolov7_pose.utils.google_utils import attempt_download
 from asone.pose_estimators.yolov7_pose.utils.yolov7_pose_utils import yolov7_in_syspath
 
 class CrossConv(nn.Module):
     # Cross Convolution Downsample
     def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):
         # ch_in, ch_out, kernel, stride, groups, expansion, shortcut
```

## asone/pose_estimators/yolov7_pose/models/yolo.py

```diff
@@ -1,22 +1,22 @@
 import argparse
 import logging
 import sys
 from copy import deepcopy
 
-sys.path.append('./')  # to run '$ python *.py' files in subdirectories
+# sys.path.append('./')  # to run '$ python *.py' files in subdirectories
 logger = logging.getLogger(__name__)
 import torch
-from models.common import *
-from models.experimental import *
-from utils.autoanchor import check_anchor_order
-from utils.general import make_divisible, check_file, set_logging
-from utils.torch_utils import time_synchronized, fuse_conv_and_bn, model_info, scale_img, initialize_weights, \
+from asone.pose_estimators.yolov7_pose.models.common import *
+from asone.pose_estimators.yolov7_pose.models.experimental import *
+from asone.pose_estimators.yolov7_pose.utils.autoanchor import check_anchor_order
+from asone.pose_estimators.yolov7_pose.utils.general import make_divisible, check_file, set_logging
+from asone.pose_estimators.yolov7_pose.utils.torch_utils import time_synchronized, fuse_conv_and_bn, model_info, scale_img, initialize_weights, \
     select_device, copy_attr
-from utils.loss import SigmoidBin
+from asone.pose_estimators.yolov7_pose.utils.loss import SigmoidBin
 
 try:
     import thop  # for FLOPS computation
 except ImportError:
     thop = None
```

## asone/pose_estimators/yolov7_pose/utils/autoanchor.py

```diff
@@ -2,15 +2,15 @@
 
 import numpy as np
 import torch
 import yaml
 from scipy.cluster.vq import kmeans
 from tqdm import tqdm
 
-from utils.general import colorstr
+from asone.pose_estimators.yolov7_pose.utils.general import colorstr
 
 
 def check_anchor_order(m):
     # Check anchor order against stride order for YOLO Detect() module m, and correct if necessary
     a = m.anchor_grid.prod(-1).view(-1)  # anchor area
     da = a[-1] - a[0]  # delta a
     ds = m.stride[-1] - m.stride[0]  # delta s
@@ -99,15 +99,15 @@
         for i, x in enumerate(k):
             print('%i,%i' % (round(x[0]), round(x[1])), end=',  ' if i < len(k) - 1 else '\n')  # use in *.cfg
         return k
 
     if isinstance(path, str):  # *.yaml file
         with open(path) as f:
             data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # model dict
-        from utils.datasets import LoadImagesAndLabels
+        from asone.pose_estimators.yolov7_pose.utils.datasets import LoadImagesAndLabels
         dataset = LoadImagesAndLabels(data_dict['train'], augment=True, rect=True)
     else:
         dataset = path  # dataset
 
     # Get label wh
     shapes = img_size * dataset.shapes / dataset.shapes.max(1, keepdims=True)
     wh0 = np.concatenate([l[:, 3:5] * s for s, l in zip(shapes, dataset.labels)])  # wh
```

## asone/pose_estimators/yolov7_pose/utils/datasets.py

```diff
@@ -22,17 +22,17 @@
 
 import pickle
 from copy import deepcopy
 #from pycocotools import mask as maskUtils
 from torchvision.utils import save_image
 from torchvision.ops import roi_pool, roi_align, ps_roi_pool, ps_roi_align
 
-from .general import check_requirements, xyxy2xywh, xywh2xyxy, xywhn2xyxy, xyn2xy, segment2box, segments2boxes, \
+from asone.pose_estimators.yolov7_pose.utils.general import check_requirements, xyxy2xywh, xywh2xyxy, xywhn2xyxy, xyn2xy, segment2box, segments2boxes, \
     resample_segments, clean_str
-from .torch_utils import torch_distributed_zero_first
+from asone.pose_estimators.yolov7_pose.utils.torch_utils import torch_distributed_zero_first
 
 # Parameters
 help_url = 'https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'
 img_formats = ['bmp', 'jpg', 'jpeg', 'png', 'tif', 'tiff', 'dng', 'webp', 'mpo']  # acceptable image suffixes
 vid_formats = ['mov', 'avi', 'mp4', 'mpg', 'mpeg', 'm4v', 'wmv', 'mkv']  # acceptable video suffixes
 logger = logging.getLogger(__name__)
```

## asone/pose_estimators/yolov7_pose/utils/general.py

```diff
@@ -14,17 +14,17 @@
 import cv2
 import numpy as np
 import pandas as pd
 import torch
 import torchvision
 import yaml
 
-from .google_utils import gsutil_getsize
-from .metrics import fitness
-from .torch_utils import init_torch_seeds
+from asone.pose_estimators.yolov7_pose.utils.google_utils import gsutil_getsize
+from asone.pose_estimators.yolov7_pose.utils.metrics import fitness
+from asone.pose_estimators.yolov7_pose.utils.torch_utils import init_torch_seeds
 
 # Settings
 torch.set_printoptions(linewidth=320, precision=5, profile='long')
 np.set_printoptions(linewidth=320, formatter={'float_kind': '{:11.5g}'.format})  # format short g, %precision=5
 pd.options.display.max_columns = 10
 cv2.setNumThreads(0)  # prevent OpenCV from multithreading (incompatible with PyTorch DataLoader)
 os.environ['NUMEXPR_MAX_THREADS'] = str(min(os.cpu_count(), 8))  # NumExpr max threads
```

## asone/pose_estimators/yolov7_pose/utils/loss.py

```diff
@@ -1,15 +1,15 @@
 # Loss functions
 
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 
-from utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy
-from utils.torch_utils import is_parallel
+from asone.pose_estimators.yolov7_pose.utils.general import bbox_iou, bbox_alpha_iou, box_iou, box_giou, box_diou, box_ciou, xywh2xyxy
+from asone.pose_estimators.yolov7_pose.utils.torch_utils import is_parallel
 
 
 def smooth_BCE(eps=0.1):  # https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441
     # return positive, negative label smoothing BCE targets
     return 1.0 - 0.5 * eps, 0.5 * eps
```

## asone/pose_estimators/yolov7_pose/utils/metrics.py

```diff
@@ -2,15 +2,15 @@
 
 from pathlib import Path
 
 import matplotlib.pyplot as plt
 import numpy as np
 import torch
 
-from . import general
+from asone.pose_estimators.yolov7_pose.utils import general
 
 
 def fitness(x):
     # Model fitness as a weighted combination of metrics
     w = [0.0, 0.0, 0.1, 0.9]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]
     return (x[:, :4] * w).sum(1)
```

## asone/pose_estimators/yolov7_pose/utils/plots.py

```diff
@@ -14,16 +14,16 @@
 import pandas as pd
 import seaborn as sns
 import torch
 import yaml
 from PIL import Image, ImageDraw, ImageFont
 from scipy.signal import butter, filtfilt
 
-from .general import xywh2xyxy, xyxy2xywh
-from .metrics import fitness
+from asone.pose_estimators.yolov7_pose.utils.general import xywh2xyxy, xyxy2xywh
+from asone.pose_estimators.yolov7_pose.utils.metrics import fitness
 
 # Settings
 matplotlib.rc('font', **{'size': 11})
 matplotlib.use('Agg')  # for writing to files only
 
 class Colors:
     # Ultralytics color palette https://ultralytics.com/
```

## asone/pose_estimators/yolov7_pose/utils/wandb_logging/wandb_utils.py

```diff
@@ -2,15 +2,15 @@
 import sys
 from pathlib import Path
 
 import torch
 import yaml
 from tqdm import tqdm
 
-sys.path.append(str(Path(__file__).parent.parent.parent))  # add utils/ to path
+# sys.path.append(str(Path(__file__).parent.parent.parent))  # add utils/ to path
 from utils.datasets import LoadImagesAndLabels
 from utils.datasets import img2label_paths
 from utils.general import colorstr, xywh2xyxy, check_dataset
 
 try:
     import wandb
     from wandb import init, finish
```

## asone/utils/default_cfg.py

```diff
@@ -1,13 +1,13 @@
 config = {
     "output_dir": "results",
     "filename": None,
     "fps": None,
     "save_result": True,
-    "display": True,
+    "display": False,
     "draw_trails": False,
     "filter_classes": None,
     "class_names": None,
     "input_shape" : (640, 640),
     "conf_thres": 0.25,
     "iou_thres" : 0.45,
     "max_det" : 1000,
```

## asone/utils/download.py

```diff
@@ -113,14 +113,30 @@
         model_key = '1R_7QH-Y9TJ0jnDn3STfZvZzbx1fqs1mZ'
     elif model == 'yolo_nas_l':
         model_key = '1FYDcp-LNxlVfxvKU2kG8FmkqZNIOSAnN'
     elif model == 'yolo_nas_m':
         model_key = '1wHf3q5Jl5Uk1iGgRjm6TYChInAoYGNhf'
     elif model == 'yolo_nas_s':
         model_key = '1jtI-L9J8G7sRBa-sziqryMp11vlFKWyh'
+        
+    elif model == 'yolov9-c-converted':
+        model_key = '1PCT4dCKosBB0B26sLdQ5xdjQ2vTPjWaH'
+    elif model == 'yolov9-e-converted':
+        model_key = '16rNqbrlmN3YgsaxOsYLad1IRK2eo_3AL'
+    elif model == 'yolov9-c':
+        model_key = '1FRnyftVwTYyH2Or8BkMWE7HB_08dsNkA'
+    elif model == 'yolov9-e':
+        model_key = '1ayY7dJH6r9hzl1MSOdVFx0UqmWixhEJu'
+    elif model == 'gelan-c':
+        model_key = '1AhGd8Ex0Kr1iXiSytu-OBpyvLykL9tMF'
+    elif model == 'gelan-e':
+        model_key = '1vc7nBJTMm3tt_gLD-zJSbmFAaWoP8ZbS'
+        
+    elif model == "sam_vit_h_4b8939":
+        model_key = '1-QSw_IqF4WczsC3pdbiIpmjTEaxPc5nO'
     else:
         raise ValueError(f'No model named {model} found.')
 
     url = f'https://drive.google.com/uc?id={model_key}&confirm=t'
     gdown.download(url, output=filename, quiet=False)
 
     if not os.path.exists(outputpath):
```

## asone/utils/draw.py

```diff
@@ -1,13 +1,14 @@
 import cv2
 from numpy import random
 import numpy as np
 from asone.utils import compute_color_for_labels
 from asone.utils import get_names
 from collections import deque
+from asone.schemas.output_schemas import ModelOutput
 
 names = get_names()
 data_deque = {}
 
 
 def draw_ui_box(x, img, label=None, color=None, line_thickness=None):
     # Plots one bounding box on image img
@@ -24,15 +25,15 @@
         img = draw_border(img, (c1[0], c1[1] - t_size[1] - 3),
                           (c1[0] + t_size[0], c1[1]+3), color, 1, 8, 2)
 
         # cv2.line(img, c1, c2, color, 30)
         # cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled
         cv2.putText(img, str(label), (c1[0], c1[1] - 2), 0, tl / 3,
                     [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)
-
+    return img
 
 def draw_border(img, pt1, pt2, color, thickness, r, d):
     x1, y1 = pt1
     x2, y2 = pt2
     # Top leftfrom collections import deque (x1, y1 + r + d), color, thickness)
     cv2.ellipse(img, (x1 + r, y1 + r), (r, r), 180, 0, 90, color, thickness)
 
@@ -115,29 +116,31 @@
 
         # generate dynamic thickness of trails
         thickness = int(np.sqrt(64 / float(i + i)) * 1.5)
         
         # draw trails
         cv2.line(img, data_deque[id][i - 1], data_deque[id][i], color, thickness)
 
-def draw_text(img, results, offset=(0, 0)):
+def draw_text(img, results, offset=(0, 0), display: bool = False):
     color = compute_color_for_labels(int(0))
     for res in results:
         box = res[:4]
         text = res[4]
         x1, y1, x2, y2 = box
         x1 += offset[0]
         x2 += offset[0]
         y1 += offset[1]
         y2 += offset[1]
         label = text
 
-        draw_ui_box(box, img, label=label, color=color, line_thickness=2)
+        img = draw_ui_box(box, img, label=label, color=color, line_thickness=2)
         center = (int((x2+x1) / 2), int((y2+y2)/2))
- 
+    if display:
+        cv2.imshow(' Sample', img)
+        
     return img
 
 # Utils for code estimation 
 
 class Colors:
     # Ultralytics color palette https://ultralytics.com/
     def __init__(self):
@@ -161,36 +164,40 @@
     def hex2rgb(h):  # rgb order (PIL)
         return tuple(int(h[1 + i:1 + i + 2], 16) for i in (0, 2, 4))
 
 
 colors = Colors()  # create instance for 'from utils.plots import colors'
 
 
-def draw_kpts(image ,keypoints, shape=(640, 640), radius=5, kpt_line=True):
+def draw_kpts(keypoints, image=None, shape=(640, 640), radius=5, kpt_line=True,
+              display: bool=True):
         """Plot keypoints on the image.
         Args:
             kpts (tensor): Predicted keypoints with shape [17, 3]. Each keypoint has (x, y, confidence).
             shape (tuple): Image shape as a tuple (h, w), where h is the height and w is the width.
             radius (int, optional): Radius of the drawn keypoints. Default is 5.
             kpt_line (bool, optional): If True, the function will draw lines connecting keypoints
                                        for human pose. Default is True.
         Note: `kpt_line=True` currently only supports human pose plotting.
         """
         # if self.pil:
         #     # Convert to numpy first
         #     self.im = np.asarray(self.im).copy()
+        if isinstance(keypoints, ModelOutput):
+            image = keypoints.info.image
+            keypoints = keypoints.dets.bbox
         if keypoints is not None:
             for kpts in reversed(keypoints):
                 
                 limb_color = colors.pose_palette[[9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16]]
                 kpt_color = colors.pose_palette[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]
                 skeleton = [[16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12], [7, 13], [6, 7], [6, 8], [7, 9],
                                 [8, 10], [9, 11], [2, 3], [1, 2], [1, 3], [2, 4], [3, 5], [4, 6], [5, 7]]
                 nkpt, ndim = kpts.shape
-                is_pose = nkpt == 17 and ndim == 3
+                is_pose = nkpt == 17 and ndim in [2, 3]
                 kpt_line &= is_pose  # `kpt_line=True` for now only supports human pose plotting
                 for i, k in enumerate(kpts):
                     color_k = [int(x) for x in kpt_color[i]] if is_pose else colors(i)
                     x_coord, y_coord = k[0], k[1]
                     if x_coord % shape[1] != 0 and y_coord % shape[0] != 0:
                         if len(k) == 3:
                             conf = k[2]
@@ -209,15 +216,16 @@
                             if conf1 < 0.5 or conf2 < 0.5:
                                 continue
                         if pos1[0] % shape[1] == 0 or pos1[1] % shape[0] == 0 or pos1[0] < 0 or pos1[1] < 0:
                             continue
                         if pos2[0] % shape[1] == 0 or pos2[1] % shape[0] == 0 or pos2[0] < 0 or pos2[1] < 0:
                             continue
                         cv2.line(image, pos1, pos2, [int(x) for x in limb_color[i]], thickness=2, lineType=cv2.LINE_AA)
-                
+        if display:
+            cv2.imshow(' Sample', image)
         return image
 
 def plot_skeleton_kpts(im, kpts, steps, orig_shape=None):
     #Plot the skeleton and keypointsfor coco datatset
     palette = np.array([[255, 128, 0], [255, 153, 51], [255, 178, 102],
                         [230, 230, 0], [255, 153, 255], [153, 204, 255],
                         [255, 102, 255], [255, 51, 255], [102, 178, 255],
```

## Comparing `asone-0.3.3.dist-info/LICENCE` & `asone-2.0.0.dist-info/LICENCE`

 * *Files identical despite different names*

## Comparing `asone-0.3.3.dist-info/METADATA` & `asone-2.0.0.dist-info/METADATA`

 * *Files 26% similar despite different names*

```diff
@@ -1,899 +1,870 @@
 00000000: 4d65 7461 6461 7461 2d56 6572 7369 6f6e  Metadata-Version
 00000010: 3a20 322e 310a 4e61 6d65 3a20 6173 6f6e  : 2.1.Name: ason
-00000020: 650a 5665 7273 696f 6e3a 2030 2e33 2e33  e.Version: 0.3.3
+00000020: 650a 5665 7273 696f 6e3a 2032 2e30 2e30  e.Version: 2.0.0
 00000030: 0a53 756d 6d61 7279 3a20 554e 4b4e 4f57  .Summary: UNKNOW
 00000040: 4e0a 486f 6d65 2d70 6167 653a 2068 7474  N.Home-page: htt
 00000050: 7073 3a2f 2f67 6974 6875 622e 636f 6d2f  ps://github.com/
-00000060: 6178 6365 6c65 7261 7465 6169 2f61 736f  axcelerateai/aso
-00000070: 6e65 0a41 7574 686f 723a 2041 7863 656c  ne.Author: Axcel
-00000080: 6572 6174 6541 490a 4175 7468 6f72 2d65  erateAI.Author-e
-00000090: 6d61 696c 3a20 756d 6169 722e 696d 7261  mail: umair.imra
-000000a0: 6e40 6178 6365 6c65 7261 7465 2e61 690a  n@axcelerate.ai.
-000000b0: 4c69 6365 6e73 653a 2042 5344 2032 2d63  License: BSD 2-c
-000000c0: 6c61 7573 650a 4b65 7977 6f72 6473 3a20  lause.Keywords: 
-000000d0: 6173 6f6e 6520 6279 7465 7472 6163 6b20  asone bytetrack 
-000000e0: 6465 6570 736f 7274 206e 6f72 6661 6972  deepsort norfair
-000000f0: 2079 6f6c 6f20 796f 6c6f 7820 796f 6c6f   yolo yolox yolo
-00000100: 7220 796f 6c6f 7635 2079 6f6c 6f76 3720  r yolov5 yolov7 
-00000110: 696e 7374 616c 6c61 7469 6f6e 2069 6e66  installation inf
-00000120: 6572 656e 6369 6e67 0a50 6c61 7466 6f72  erencing.Platfor
-00000130: 6d3a 2055 4e4b 4e4f 574e 0a43 6c61 7373  m: UNKNOWN.Class
-00000140: 6966 6965 723a 2044 6576 656c 6f70 6d65  ifier: Developme
-00000150: 6e74 2053 7461 7475 7320 3a3a 2031 202d  nt Status :: 1 -
-00000160: 2050 6c61 6e6e 696e 670a 436c 6173 7369   Planning.Classi
-00000170: 6669 6572 3a20 496e 7465 6e64 6564 2041  fier: Intended A
-00000180: 7564 6965 6e63 6520 3a3a 2053 6369 656e  udience :: Scien
-00000190: 6365 2f52 6573 6561 7263 680a 436c 6173  ce/Research.Clas
-000001a0: 7369 6669 6572 3a20 4c69 6365 6e73 6520  sifier: License 
-000001b0: 3a3a 204f 5349 2041 7070 726f 7665 6420  :: OSI Approved 
-000001c0: 3a3a 204d 4954 204c 6963 656e 7365 0a43  :: MIT License.C
-000001d0: 6c61 7373 6966 6965 723a 204f 7065 7261  lassifier: Opera
-000001e0: 7469 6e67 2053 7973 7465 6d20 3a3a 2050  ting System :: P
-000001f0: 4f53 4958 203a 3a20 4c69 6e75 780a 436c  OSIX :: Linux.Cl
-00000200: 6173 7369 6669 6572 3a20 4f70 6572 6174  assifier: Operat
-00000210: 696e 6720 5379 7374 656d 203a 3a20 4d69  ing System :: Mi
-00000220: 6372 6f73 6f66 7420 3a3a 2057 696e 646f  crosoft :: Windo
-00000230: 7773 203a 3a20 5769 6e64 6f77 7320 3130  ws :: Windows 10
-00000240: 0a43 6c61 7373 6966 6965 723a 2050 726f  .Classifier: Pro
-00000250: 6772 616d 6d69 6e67 204c 616e 6775 6167  gramming Languag
-00000260: 6520 3a3a 2050 7974 686f 6e20 3a3a 2033  e :: Python :: 3
-00000270: 0a43 6c61 7373 6966 6965 723a 2050 726f  .Classifier: Pro
-00000280: 6772 616d 6d69 6e67 204c 616e 6775 6167  gramming Languag
-00000290: 6520 3a3a 2050 7974 686f 6e20 3a3a 2033  e :: Python :: 3
-000002a0: 2e38 0a43 6c61 7373 6966 6965 723a 2050  .8.Classifier: P
-000002b0: 726f 6772 616d 6d69 6e67 204c 616e 6775  rogramming Langu
-000002c0: 6167 6520 3a3a 2050 7974 686f 6e20 3a3a  age :: Python ::
-000002d0: 2033 2e39 0a43 6c61 7373 6966 6965 723a   3.9.Classifier:
-000002e0: 2050 726f 6772 616d 6d69 6e67 204c 616e   Programming Lan
-000002f0: 6775 6167 6520 3a3a 2050 7974 686f 6e20  guage :: Python 
-00000300: 3a3a 2033 2e31 300a 4465 7363 7269 7074  :: 3.10.Descript
-00000310: 696f 6e2d 436f 6e74 656e 742d 5479 7065  ion-Content-Type
-00000320: 3a20 7465 7874 2f6d 6172 6b64 6f77 6e0a  : text/markdown.
-00000330: 5265 7175 6972 6573 2d44 6973 743a 2061  Requires-Dist: a
-00000340: 736f 6e65 2d6f 6372 0a52 6571 7569 7265  sone-ocr.Require
-00000350: 732d 4469 7374 3a20 636f 7265 6d6c 746f  s-Dist: coremlto
-00000360: 6f6c 730a 5265 7175 6972 6573 2d44 6973  ols.Requires-Dis
-00000370: 743a 2065 6173 7964 6963 740a 5265 7175  t: easydict.Requ
-00000380: 6972 6573 2d44 6973 743a 2067 646f 776e  ires-Dist: gdown
-00000390: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
-000003a0: 6c61 700a 5265 7175 6972 6573 2d44 6973  lap.Requires-Dis
-000003b0: 743a 206c 6f67 7572 750a 5265 7175 6972  t: loguru.Requir
-000003c0: 6573 2d44 6973 743a 206d 6f74 7079 0a52  es-Dist: motpy.R
-000003d0: 6571 7569 7265 732d 4469 7374 3a20 6e6f  equires-Dist: no
-000003e0: 7266 6169 720a 5265 7175 6972 6573 2d44  rfair.Requires-D
-000003f0: 6973 743a 206e 756d 7079 2028 3d3d 312e  ist: numpy (==1.
-00000400: 3233 2e33 290a 5265 7175 6972 6573 2d44  23.3).Requires-D
-00000410: 6973 743a 206f 6e6e 7872 756e 7469 6d65  ist: onnxruntime
-00000420: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
-00000430: 6f70 656e 6376 2d70 7974 686f 6e0a 5265  opencv-python.Re
-00000440: 7175 6972 6573 2d44 6973 743a 2070 616e  quires-Dist: pan
-00000450: 6461 730a 5265 7175 6972 6573 2d44 6973  das.Requires-Dis
-00000460: 743a 2070 726f 746f 6275 6620 283d 3d33  t: protobuf (==3
-00000470: 2e32 3029 0a52 6571 7569 7265 732d 4469  .20).Requires-Di
-00000480: 7374 3a20 7079 7961 6d6c 0a52 6571 7569  st: pyyaml.Requi
-00000490: 7265 732d 4469 7374 3a20 7363 6970 790a  res-Dist: scipy.
-000004a0: 5265 7175 6972 6573 2d44 6973 743a 2074  Requires-Dist: t
-000004b0: 6162 756c 6174 650a 5265 7175 6972 6573  abulate.Requires
-000004c0: 2d44 6973 743a 2074 656e 736f 7262 6f61  -Dist: tensorboa
-000004d0: 7264 0a52 6571 7569 7265 732d 4469 7374  rd.Requires-Dist
-000004e0: 3a20 746f 7263 6872 6569 6420 283d 3d30  : torchreid (==0
-000004f0: 2e32 2e35 290a 5265 7175 6972 6573 2d44  .2.5).Requires-D
-00000500: 6973 743a 2074 7970 696e 672d 6578 7465  ist: typing-exte
-00000510: 6e73 696f 6e73 2028 3d3d 332e 3130 2e30  nsions (==3.10.0
-00000520: 2e32 290a 5265 7175 6972 6573 2d44 6973  .2).Requires-Dis
-00000530: 743a 2075 6c74 7261 6c79 7469 6373 2028  t: ultralytics (
-00000540: 3d3d 382e 302e 3130 3929 0a52 6571 7569  ==8.0.109).Requi
-00000550: 7265 732d 4469 7374 3a20 7768 6565 6c0a  res-Dist: wheel.
-00000560: 0a23 2041 532d 4f6e 6520 3a20 4120 4d6f  .# AS-One : A Mo
-00000570: 6475 6c61 7220 4c69 6272 6172 7920 666f  dular Library fo
-00000580: 7220 594f 4c4f 204f 626a 6563 7420 4465  r YOLO Object De
-00000590: 7465 6374 696f 6e20 616e 6420 4f62 6a65  tection and Obje
-000005a0: 6374 2054 7261 636b 696e 670a 0a5b 3c69  ct Tracking..[<i
-000005b0: 6d67 2073 7263 3d22 6874 7470 733a 2f2f  mg src="https://
-000005c0: 6b61 6a61 6269 2d73 746f 7265 6672 6f6e  kajabi-storefron
-000005d0: 7473 2d70 726f 6475 6374 696f 6e2e 6b61  ts-production.ka
-000005e0: 6a61 6269 2d63 646e 2e63 6f6d 2f6b 616a  jabi-cdn.com/kaj
-000005f0: 6162 692d 7374 6f72 6566 726f 6e74 732d  abi-storefronts-
-00000600: 7072 6f64 7563 7469 6f6e 2f66 696c 652d  production/file-
-00000610: 7570 6c6f 6164 732f 7468 656d 6573 2f32  uploads/themes/2
-00000620: 3135 3134 3736 3934 312f 7365 7474 696e  151476941/settin
-00000630: 6773 5f69 6d61 6765 732f 3635 6438 322d  gs_images/65d82-
-00000640: 3064 3834 2d36 3137 312d 6137 6530 2d35  0d84-6171-a7e0-5
-00000650: 6161 3138 3062 3635 3764 355f 426c 6163  aa180b657d5_Blac
-00000660: 6b5f 7769 7468 5f4c 6f67 6f2e 6a70 6722  k_with_Logo.jpg"
-00000670: 2077 6964 7468 3d22 3130 3025 223e 5d28   width="100%">](
-00000680: 6874 7470 733a 2f2f 7777 772e 796f 7574  https://www.yout
-00000690: 7562 652e 636f 6d2f 7761 7463 683f 763d  ube.com/watch?v=
-000006a0: 4b2d 5663 7050 7763 4d38 6b29 0a0a 0a0a  K-VcpPwcM8k)....
-000006b0: 0a0a 2323 2323 2054 6162 6c65 206f 6620  ..#### Table of 
-000006c0: 436f 6e74 656e 7473 0a31 2e20 496e 7472  Contents.1. Intr
-000006d0: 6f64 7563 7469 6f6e 0a32 2e20 5072 6572  oduction.2. Prer
-000006e0: 6571 7569 7369 7465 730a 332e 2043 6c6f  equisites.3. Clo
-000006f0: 6e65 2074 6865 2052 6570 6f0a 342e 2049  ne the Repo.4. I
-00000700: 6e73 7461 6c6c 6174 696f 6e0a 2020 2020  nstallation.    
-00000710: 2d20 5b4c 696e 7578 5d28 2334 2d69 6e73  - [Linux](#4-ins
-00000720: 7461 6c6c 6174 696f 6e29 0a20 2020 202d  tallation).    -
-00000730: 205b 5769 6e64 6f77 7320 3130 2f31 315d   [Windows 10/11]
-00000740: 2823 342d 696e 7374 616c 6c61 7469 6f6e  (#4-installation
-00000750: 2920 0a20 2020 202d 205b 4d61 634f 535d  ) .    - [MacOS]
-00000760: 2823 342d 696e 7374 616c 6c61 7469 6f6e  (#4-installation
-00000770: 2920 0a35 2e20 5275 6e6e 696e 6720 4153  ) .5. Running AS
-00000780: 2d4f 6e65 0a36 2e20 5b53 616d 706c 6520  -One.6. [Sample 
-00000790: 436f 6465 2053 6e69 7070 6574 735d 2823  Code Snippets](#
-000007a0: 362d 7361 6d70 6c65 2d63 6f64 652d 736e  6-sample-code-sn
-000007b0: 6970 7065 7473 290a 372e 205b 4d6f 6465  ippets).7. [Mode
-000007c0: 6c20 5a6f 6f5d 2861 736f 6e65 2f6c 696e  l Zoo](asone/lin
-000007d0: 7578 2f49 6e73 7472 7563 7469 6f6e 732f  ux/Instructions/
-000007e0: 4265 6e63 686d 6172 6b69 6e67 2e6d 6429  Benchmarking.md)
-000007f0: 0a0a 2323 2031 2e20 496e 7472 6f64 7563  ..## 1. Introduc
-00000800: 7469 6f6e 0a3d 3d55 5044 4154 453a 2059  tion.==UPDATE: Y
-00000810: 4f4c 4f2d 4e41 5320 6973 204f 5554 3d3d  OLO-NAS is OUT==
-00000820: 0a0a 4153 2d4f 6e65 2069 7320 6120 7079  ..AS-One is a py
-00000830: 7468 6f6e 2077 7261 7070 6572 2066 6f72  thon wrapper for
-00000840: 206d 756c 7469 706c 6520 6465 7465 6374   multiple detect
-00000850: 696f 6e20 616e 6420 7472 6163 6b69 6e67  ion and tracking
-00000860: 2061 6c67 6f72 6974 686d 7320 616c 6c20   algorithms all 
-00000870: 6174 206f 6e65 2070 6c61 6365 2e20 4469  at one place. Di
-00000880: 6666 6572 656e 7420 7472 6163 6b65 7273  fferent trackers
-00000890: 2073 7563 6820 6173 2060 4279 7465 5472   such as `ByteTr
-000008a0: 6163 6b60 2c20 6044 6565 7053 4f52 5460  ack`, `DeepSORT`
-000008b0: 206f 7220 604e 6f72 4661 6972 6020 6361   or `NorFair` ca
-000008c0: 6e20 6265 2069 6e74 6567 7261 7465 6420  n be integrated 
-000008d0: 7769 7468 2064 6966 6665 7265 6e74 2076  with different v
-000008e0: 6572 7369 6f6e 7320 6f66 2060 594f 4c4f  ersions of `YOLO
-000008f0: 6020 7769 7468 206d 696e 696d 756d 206c  ` with minimum l
-00000900: 696e 6573 206f 6620 636f 6465 2e0a 5468  ines of code..Th
-00000910: 6973 2070 7974 686f 6e20 7772 6170 7065  is python wrappe
-00000920: 7220 7072 6f76 6964 6573 2059 4f4c 4f20  r provides YOLO 
-00000930: 6d6f 6465 6c73 2069 6e20 604f 4e4e 5860  models in `ONNX`
-00000940: 2c20 6050 7954 6f72 6368 6020 2620 6043  , `PyTorch` & `C
-00000950: 6f72 654d 4c60 2020 666c 6176 6f72 732e  oreML`  flavors.
-00000960: 2057 6520 706c 616e 2074 6f20 6f66 6665   We plan to offe
-00000970: 7220 7375 7070 6f72 7420 666f 7220 6675  r support for fu
-00000980: 7475 7265 2076 6572 7369 6f6e 7320 6f66  ture versions of
-00000990: 2059 4f4c 4f20 7768 656e 2074 6865 7920   YOLO when they 
-000009a0: 6765 7420 7265 6c65 6173 6564 2e0a 0a54  get released...T
-000009b0: 6869 7320 6973 204f 6e65 204c 6962 7261  his is One Libra
-000009c0: 7279 2066 6f72 206d 6f73 7420 6f66 2079  ry for most of y
-000009d0: 6f75 7220 636f 6d70 7574 6572 2076 6973  our computer vis
-000009e0: 696f 6e20 6e65 6564 732e 0a0a 4966 2079  ion needs...If y
-000009f0: 6f75 2077 6f75 6c64 206c 696b 6520 746f  ou would like to
-00000a00: 2064 6976 6520 6465 6570 6572 2069 6e74   dive deeper int
-00000a10: 6f20 594f 4c4f 204f 626a 6563 7420 4465  o YOLO Object De
-00000a20: 7465 6374 696f 6e20 616e 6420 5472 6163  tection and Trac
-00000a30: 6b69 6e67 2c20 7468 656e 2063 6865 636b  king, then check
-00000a40: 206f 7574 206f 7572 205b 636f 7572 7365   out our [course
-00000a50: 735d 2868 7474 7073 3a2f 2f77 7777 2e61  s](https://www.a
-00000a60: 7567 6d65 6e74 6564 7374 6172 7475 7073  ugmentedstartups
-00000a70: 2e63 6f6d 2f73 746f 7265 2920 616e 6420  .com/store) and 
-00000a80: 5b70 726f 6a65 6374 735d 2868 7474 7073  [projects](https
-00000a90: 3a2f 2f73 746f 7265 2e61 7567 6d65 6e74  ://store.augment
-00000aa0: 6564 7374 6172 7475 7073 2e63 6f6d 290a  edstartups.com).
-00000ab0: 0a5b 3c69 6d67 2073 7263 3d22 6874 7470  .[<img src="http
-00000ac0: 733a 2f2f 7333 2e61 6d61 7a6f 6e61 7773  s://s3.amazonaws
-00000ad0: 2e63 6f6d 2f6b 616a 6162 692d 7374 6f72  .com/kajabi-stor
-00000ae0: 6566 726f 6e74 732d 7072 6f64 7563 7469  efronts-producti
-00000af0: 6f6e 2f62 6c6f 6773 2f32 3236 3036 2f69  on/blogs/22606/i
-00000b00: 6d61 6765 732f 3046 4478 3833 5658 5359  mages/0FDx83VXSY
-00000b10: 4f59 304e 414f 326b 4d63 5f41 534f 6e65  OY0NAO2kMc_ASOne
-00000b20: 5f57 696e 646f 7773 5f50 6c61 792e 6a70  _Windows_Play.jp
-00000b30: 6722 2077 6964 7468 3d22 3530 2522 3e5d  g" width="50%">]
-00000b40: 2868 7474 7073 3a2f 2f77 7777 2e79 6f75  (https://www.you
-00000b50: 7475 6265 2e63 6f6d 2f77 6174 6368 3f76  tube.com/watch?v
-00000b60: 3d4b 2d56 6370 5077 634d 386b 290a 0a57  =K-VcpPwcM8k)..W
-00000b70: 6174 6368 2074 6865 2073 7465 702d 6279  atch the step-by
-00000b80: 2d73 7465 7020 7475 746f 7269 616c 0a0a  -step tutorial..
-00000b90: 2323 2032 2e20 5072 6572 6571 7569 7369  ## 2. Prerequisi
-00000ba0: 7465 730a 0a2d 204d 616b 6520 7375 7265  tes..- Make sure
-00000bb0: 2074 6f20 696e 7374 616c 6c20 6047 5055   to install `GPU
-00000bc0: 6020 6472 6976 6572 7320 696e 2079 6f75  ` drivers in you
-00000bd0: 7220 7379 7374 656d 2069 6620 796f 7520  r system if you 
-00000be0: 7761 6e74 2074 6f20 7573 6520 6047 5055  want to use `GPU
-00000bf0: 6020 2e20 466f 6c6c 6f77 205b 6472 6976  ` . Follow [driv
-00000c00: 6572 2069 6e73 7461 6c6c 6174 696f 6e5d  er installation]
-00000c10: 2861 736f 6e65 2f6c 696e 7578 2f49 6e73  (asone/linux/Ins
-00000c20: 7472 7563 7469 6f6e 732f 4472 6976 6572  tructions/Driver
-00000c30: 2d49 6e73 7461 6c6c 6174 696f 6e73 2e6d  -Installations.m
-00000c40: 6429 2066 6f72 2066 7572 7468 6572 2069  d) for further i
-00000c50: 6e73 7472 7563 7469 6f6e 732e 0a2d 204d  nstructions..- M
-00000c60: 616b 6520 7375 7265 2079 6f75 2068 6176  ake sure you hav
-00000c70: 6520 5b4d 5320 4275 696c 6420 746f 6f6c  e [MS Build tool
-00000c80: 735d 2868 7474 7073 3a2f 2f61 6b61 2e6d  s](https://aka.m
-00000c90: 732f 7673 2f31 372f 7265 6c65 6173 652f  s/vs/17/release/
-00000ca0: 7673 5f42 7569 6c64 546f 6f6c 732e 6578  vs_BuildTools.ex
-00000cb0: 6529 2069 6e73 7461 6c6c 6564 2069 6e20  e) installed in 
-00000cc0: 7379 7374 656d 2069 6620 7573 696e 6720  system if using 
-00000cd0: 7769 6e64 6f77 732e 200a 2d20 5b44 6f77  windows. .- [Dow
-00000ce0: 6e6c 6f61 6420 6769 7420 666f 7220 7769  nload git for wi
-00000cf0: 6e64 6f77 735d 2868 7474 7073 3a2f 2f67  ndows](https://g
-00000d00: 6974 2d73 636d 2e63 6f6d 2f64 6f77 6e6c  it-scm.com/downl
-00000d10: 6f61 642f 7769 6e29 2069 6620 6e6f 7420  oad/win) if not 
-00000d20: 696e 7374 616c 6c65 642e 0a0a 2323 2033  installed...## 3
-00000d30: 2e20 436c 6f6e 6520 7468 6520 5265 706f  . Clone the Repo
-00000d40: 0a0a 4e61 7669 6761 7465 2074 6f20 616e  ..Navigate to an
-00000d50: 2065 6d70 7479 2066 6f6c 6465 7220 6f66   empty folder of
-00000d60: 2079 6f75 7220 6368 6f69 6365 2e0a 0a60   your choice...`
-00000d70: 6060 6769 7420 636c 6f6e 6520 6874 7470  ``git clone http
-00000d80: 733a 2f2f 6769 7468 7562 2e63 6f6d 2f61  s://github.com/a
-00000d90: 7567 6d65 6e74 6564 7374 6172 7475 7073  ugmentedstartups
-00000da0: 2f41 532d 4f6e 652e 6769 7460 6060 0a0a  /AS-One.git```..
-00000db0: 4368 616e 6765 2044 6972 6563 746f 7279  Change Directory
-00000dc0: 2074 6f20 4153 2d4f 6e65 0a0a 6060 6063   to AS-One..```c
-00000dd0: 6420 4153 2d4f 6e65 6060 600a 0a23 2320  d AS-One```..## 
-00000de0: 342e 2049 6e73 7461 6c6c 6174 696f 6e0a  4. Installation.
-00000df0: 3c64 6574 6169 6c73 206f 7065 6e3e 0a3c  <details open>.<
-00000e00: 7375 6d6d 6172 793e 466f 7220 4c69 6e75  summary>For Linu
-00000e10: 783c 2f73 756d 6d61 7279 3e0a 0a60 6060  x</summary>..```
-00000e20: 7368 656c 6c0a 7079 7468 6f6e 3320 2d6d  shell.python3 -m
-00000e30: 2076 656e 7620 2e65 6e76 0a73 6f75 7263   venv .env.sourc
-00000e40: 6520 2e65 6e76 2f62 696e 2f61 6374 6976  e .env/bin/activ
-00000e50: 6174 650a 0a70 6970 2069 6e73 7461 6c6c  ate..pip install
-00000e60: 206e 756d 7079 2043 7974 686f 6e0a 7069   numpy Cython.pi
-00000e70: 7020 696e 7374 616c 6c20 6379 7468 6f6e  p install cython
-00000e80: 2d62 626f 7820 6173 6f6e 6520 6f6e 6e78  -bbox asone onnx
-00000e90: 7275 6e74 696d 652d 6770 753d 3d31 2e31  runtime-gpu==1.1
-00000ea0: 322e 310a 7069 7020 696e 7374 616c 6c20  2.1.pip install 
-00000eb0: 7375 7065 722d 6772 6164 6965 6e74 733d  super-gradients=
-00000ec0: 3d33 2e31 2e31 0a23 2066 6f72 2043 5055  =3.1.1.# for CPU
-00000ed0: 0a70 6970 2069 6e73 7461 6c6c 2074 6f72  .pip install tor
-00000ee0: 6368 2074 6f72 6368 7669 7369 6f6e 0a23  ch torchvision.#
-00000ef0: 2066 6f72 2047 5055 0a70 6970 2069 6e73   for GPU.pip ins
-00000f00: 7461 6c6c 2074 6f72 6368 2074 6f72 6368  tall torch torch
-00000f10: 7669 7369 6f6e 202d 2d65 7874 7261 2d69  vision --extra-i
-00000f20: 6e64 6578 2d75 726c 2068 7474 7073 3a2f  ndex-url https:/
-00000f30: 2f64 6f77 6e6c 6f61 642e 7079 746f 7263  /download.pytorc
-00000f40: 682e 6f72 672f 7768 6c2f 6375 3131 330a  h.org/whl/cu113.
-00000f50: 6060 600a 3c2f 6465 7461 696c 733e 0a0a  ```.</details>..
-00000f60: 3c64 6574 6169 6c73 3e0a 3c73 756d 6d61  <details>.<summa
-00000f70: 7279 3e20 466f 7220 5769 6e64 6f77 7320  ry> For Windows 
-00000f80: 3130 2f31 313c 2f73 756d 6d61 7279 3e0a  10/11</summary>.
-00000f90: 0a60 6060 7368 656c 6c0a 7079 7468 6f6e  .```shell.python
-00000fa0: 202d 6d20 7665 6e76 202e 656e 760a 2e65   -m venv .env..e
-00000fb0: 6e76 5c53 6372 6970 7473 5c61 6374 6976  nv\Scripts\activ
-00000fc0: 6174 650a 7069 7020 696e 7374 616c 6c20  ate.pip install 
-00000fd0: 6e75 6d70 7920 4379 7468 6f6e 200a 7069  numpy Cython .pi
-00000fe0: 7020 696e 7374 616c 6c20 6c61 700a 7069  p install lap.pi
-00000ff0: 7020 696e 7374 616c 6c20 2d65 2067 6974  p install -e git
-00001000: 2b68 7474 7073 3a2f 2f67 6974 6875 622e  +https://github.
-00001010: 636f 6d2f 7361 6d73 6f6e 2d77 616e 672f  com/samson-wang/
-00001020: 6379 7468 6f6e 5f62 626f 782e 6769 7423  cython_bbox.git#
-00001030: 6567 673d 6379 7468 6f6e 2d62 626f 780a  egg=cython-bbox.
-00001040: 0a70 6970 2069 6e73 7461 6c6c 2061 736f  .pip install aso
-00001050: 6e65 206f 6e6e 7872 756e 7469 6d65 2d67  ne onnxruntime-g
-00001060: 7075 3d3d 312e 3132 2e31 0a70 6970 2069  pu==1.12.1.pip i
-00001070: 6e73 7461 6c6c 2073 7570 6572 2d67 7261  nstall super-gra
-00001080: 6469 656e 7473 3d3d 332e 312e 310a 2320  dients==3.1.1.# 
-00001090: 666f 7220 4350 550a 7069 7020 696e 7374  for CPU.pip inst
-000010a0: 616c 6c20 746f 7263 6820 746f 7263 6876  all torch torchv
-000010b0: 6973 696f 6e0a 0a23 2066 6f72 2047 5055  ision..# for GPU
-000010c0: 0a70 6970 2069 6e73 7461 6c6c 2074 6f72  .pip install tor
-000010d0: 6368 2074 6f72 6368 7669 7369 6f6e 202d  ch torchvision -
-000010e0: 2d65 7874 7261 2d69 6e64 6578 2d75 726c  -extra-index-url
-000010f0: 2068 7474 7073 3a2f 2f64 6f77 6e6c 6f61   https://downloa
-00001100: 642e 7079 746f 7263 682e 6f72 672f 7768  d.pytorch.org/wh
-00001110: 6c2f 6375 3131 330a 6f72 0a70 6970 2069  l/cu113.or.pip i
-00001120: 6e73 7461 6c6c 2074 6f72 6368 3d3d 312e  nstall torch==1.
-00001130: 3130 2e31 2b63 7531 3133 2074 6f72 6368  10.1+cu113 torch
-00001140: 7669 7369 6f6e 3d3d 302e 3131 2e32 2b63  vision==0.11.2+c
-00001150: 7531 3133 2074 6f72 6368 6175 6469 6f3d  u113 torchaudio=
-00001160: 3d3d 302e 3130 2e31 2b63 7531 3133 202d  ==0.10.1+cu113 -
-00001170: 6620 6874 7470 733a 2f2f 646f 776e 6c6f  f https://downlo
-00001180: 6164 2e70 7974 6f72 6368 2e6f 7267 2f77  ad.pytorch.org/w
-00001190: 686c 2f63 7531 3133 2f74 6f72 6368 5f73  hl/cu113/torch_s
-000011a0: 7461 626c 652e 6874 6d6c 0a60 6060 0a3c  table.html.```.<
-000011b0: 2f64 6574 6169 6c73 3e0a 3c64 6574 6169  /details>.<detai
-000011c0: 6c73 3e0a 3c73 756d 6d61 7279 3e46 6f72  ls>.<summary>For
-000011d0: 204d 6163 4f53 3c2f 7375 6d6d 6172 793e   MacOS</summary>
-000011e0: 0a0a 6060 6073 6865 6c6c 0a70 7974 686f  ..```shell.pytho
-000011f0: 6e33 202d 6d20 7665 6e76 202e 656e 760a  n3 -m venv .env.
-00001200: 736f 7572 6365 202e 656e 762f 6269 6e2f  source .env/bin/
-00001210: 6163 7469 7661 7465 0a0a 7069 7020 696e  activate..pip in
-00001220: 7374 616c 6c20 6e75 6d70 7920 4379 7468  stall numpy Cyth
-00001230: 6f6e 0a70 6970 2069 6e73 7461 6c6c 2063  on.pip install c
-00001240: 7974 686f 6e2d 6262 6f78 2061 736f 6e65  ython-bbox asone
-00001250: 0a70 6970 2069 6e73 7461 6c6c 2073 7570  .pip install sup
-00001260: 6572 2d67 7261 6469 656e 7473 3d3d 332e  er-gradients==3.
-00001270: 312e 310a 2320 666f 7220 4350 550a 7069  1.1.# for CPU.pi
-00001280: 7020 696e 7374 616c 6c20 746f 7263 6820  p install torch 
-00001290: 746f 7263 6876 6973 696f 6e0a 6060 600a  torchvision.```.
-000012a0: 3c2f 6465 7461 696c 733e 0a0a 2323 2035  </details>..## 5
-000012b0: 2e20 5275 6e6e 696e 6720 4153 2d4f 6e65  . Running AS-One
-000012c0: 0a0a 5275 6e20 606d 6169 6e2e 7079 6020  ..Run `main.py` 
-000012d0: 746f 2074 6573 7420 7472 6163 6b65 7220  to test tracker 
-000012e0: 6f6e 2060 6461 7461 2f73 616d 706c 655f  on `data/sample_
-000012f0: 7669 6465 6f73 2f74 6573 742e 6d70 3460  videos/test.mp4`
-00001300: 2076 6964 656f 0a0a 6060 600a 7079 7468   video..```.pyth
-00001310: 6f6e 206d 6169 6e2e 7079 2064 6174 612f  on main.py data/
-00001320: 7361 6d70 6c65 5f76 6964 656f 732f 7465  sample_videos/te
-00001330: 7374 2e6d 7034 0a60 6060 0a0a 2323 2320  st.mp4.```..### 
-00001340: 5275 6e20 696e 2060 476f 6f67 6c65 2043  Run in `Google C
-00001350: 6f6c 6162 600a 0a20 3c61 2068 7265 663d  olab`.. <a href=
-00001360: 2268 7474 7073 3a2f 2f64 7269 7665 2e67  "https://drive.g
-00001370: 6f6f 676c 652e 636f 6d2f 6669 6c65 2f64  oogle.com/file/d
-00001380: 2f31 7879 3550 3957 4749 3139 2d50 7a52  /1xy5P9WGI19-PzR
-00001390: 4833 6365 4f6d 6f43 6770 3633 4b36 4a5f  H3ceOmoCgp63K6J_
-000013a0: 4c73 2f76 6965 773f 7573 703d 7368 6172  Ls/view?usp=shar
-000013b0: 696e 6722 3e3c 696d 6720 7372 633d 2268  ing"><img src="h
-000013c0: 7474 7073 3a2f 2f63 6f6c 6162 2e72 6573  ttps://colab.res
-000013d0: 6561 7263 682e 676f 6f67 6c65 2e63 6f6d  earch.google.com
-000013e0: 2f61 7373 6574 732f 636f 6c61 622d 6261  /assets/colab-ba
-000013f0: 6467 652e 7376 6722 2061 6c74 3d22 4f70  dge.svg" alt="Op
-00001400: 656e 2049 6e20 436f 6c61 6222 3e3c 2f61  en In Colab"></a
-00001410: 3e0a 0a0a 2323 2036 2e20 5361 6d70 6c65  >...## 6. Sample
-00001420: 2043 6f64 6520 536e 6970 7065 7473 0a3c   Code Snippets.<
-00001430: 6465 7461 696c 733e 0a3c 7375 6d6d 6172  details>.<summar
-00001440: 793e 362e 312e 204f 626a 6563 7420 4465  y>6.1. Object De
-00001450: 7465 6374 696f 6e3c 2f73 756d 6d61 7279  tection</summary
-00001460: 3e0a 0a60 6060 7079 7468 6f6e 0a69 6d70  >..```python.imp
-00001470: 6f72 7420 6173 6f6e 650a 6672 6f6d 2061  ort asone.from a
-00001480: 736f 6e65 2069 6d70 6f72 7420 7574 696c  sone import util
-00001490: 730a 6672 6f6d 2061 736f 6e65 2069 6d70  s.from asone imp
-000014a0: 6f72 7420 4153 4f6e 650a 696d 706f 7274  ort ASOne.import
-000014b0: 2063 7632 0a0a 7669 6465 6f5f 7061 7468   cv2..video_path
-000014c0: 203d 2027 6461 7461 2f73 616d 706c 655f   = 'data/sample_
-000014d0: 7669 6465 6f73 2f74 6573 742e 6d70 3427  videos/test.mp4'
-000014e0: 0a64 6574 6563 746f 7220 3d20 4153 4f6e  .detector = ASOn
-000014f0: 6528 6465 7465 6374 6f72 3d61 736f 6e65  e(detector=asone
-00001500: 2e59 4f4c 4f56 375f 5059 544f 5243 482c  .YOLOV7_PYTORCH,
-00001510: 2075 7365 5f63 7564 613d 5472 7565 2920   use_cuda=True) 
-00001520: 2320 5365 7420 7573 655f 6375 6461 2074  # Set use_cuda t
-00001530: 6f20 4661 6c73 6520 666f 7220 6370 750a  o False for cpu.
-00001540: 0a66 696c 7465 725f 636c 6173 7365 7320  .filter_classes 
-00001550: 3d20 5b27 6361 7227 5d20 2320 5365 7420  = ['car'] # Set 
-00001560: 746f 204e 6f6e 6520 746f 2064 6574 6563  to None to detec
-00001570: 7420 616c 6c20 636c 6173 7365 730a 0a63  t all classes..c
-00001580: 6170 203d 2063 7632 2e56 6964 656f 4361  ap = cv2.VideoCa
-00001590: 7074 7572 6528 7669 6465 6f5f 7061 7468  pture(video_path
-000015a0: 290a 0a77 6869 6c65 2054 7275 653a 0a20  )..while True:. 
-000015b0: 2020 205f 2c20 6672 616d 6520 3d20 6361     _, frame = ca
-000015c0: 702e 7265 6164 2829 0a20 2020 2069 6620  p.read().    if 
-000015d0: 6e6f 7420 5f3a 0a20 2020 2020 2020 2062  not _:.        b
-000015e0: 7265 616b 0a0a 2020 2020 6465 7473 2c20  reak..    dets, 
-000015f0: 696d 675f 696e 666f 203d 2064 6574 6563  img_info = detec
-00001600: 746f 722e 6465 7465 6374 2866 7261 6d65  tor.detect(frame
-00001610: 2c20 6669 6c74 6572 5f63 6c61 7373 6573  , filter_classes
-00001620: 3d66 696c 7465 725f 636c 6173 7365 7329  =filter_classes)
-00001630: 0a0a 2020 2020 6262 6f78 5f78 7978 7920  ..    bbox_xyxy 
-00001640: 3d20 6465 7473 5b3a 2c20 3a34 5d0a 2020  = dets[:, :4].  
-00001650: 2020 7363 6f72 6573 203d 2064 6574 735b    scores = dets[
-00001660: 3a2c 2034 5d0a 2020 2020 636c 6173 735f  :, 4].    class_
-00001670: 6964 7320 3d20 6465 7473 5b3a 2c20 355d  ids = dets[:, 5]
-00001680: 0a0a 2020 2020 6672 616d 6520 3d20 7574  ..    frame = ut
-00001690: 696c 732e 6472 6177 5f62 6f78 6573 2866  ils.draw_boxes(f
-000016a0: 7261 6d65 2c20 6262 6f78 5f78 7978 792c  rame, bbox_xyxy,
-000016b0: 2063 6c61 7373 5f69 6473 3d63 6c61 7373   class_ids=class
-000016c0: 5f69 6473 290a 0a20 2020 2063 7632 2e69  _ids)..    cv2.i
-000016d0: 6d73 686f 7728 2772 6573 756c 7427 2c20  mshow('result', 
-000016e0: 6672 616d 6529 0a0a 2020 2020 6966 2063  frame)..    if c
-000016f0: 7632 2e77 6169 744b 6579 2832 3529 2026  v2.waitKey(25) &
-00001700: 2030 7846 4620 3d3d 206f 7264 2827 7127   0xFF == ord('q'
-00001710: 293a 0a20 2020 2020 2020 2062 7265 616b  ):.        break
-00001720: 0a60 6060 0a0a 5275 6e20 7468 6520 6061  .```..Run the `a
-00001730: 736f 6e65 2f64 656d 6f5f 6465 7465 6374  sone/demo_detect
-00001740: 6f72 2e70 7960 2074 6f20 7465 7374 2064  or.py` to test d
-00001750: 6574 6563 746f 722e 0a0a 6060 6073 6865  etector...```she
-00001760: 6c6c 0a23 2072 756e 206f 6e20 6770 750a  ll.# run on gpu.
-00001770: 7079 7468 6f6e 202d 6d20 6173 6f6e 652e  python -m asone.
-00001780: 6465 6d6f 5f64 6574 6563 746f 7220 6461  demo_detector da
-00001790: 7461 2f73 616d 706c 655f 7669 6465 6f73  ta/sample_videos
-000017a0: 2f74 6573 742e 6d70 340a 0a23 2072 756e  /test.mp4..# run
-000017b0: 206f 6e20 6370 750a 7079 7468 6f6e 202d   on cpu.python -
-000017c0: 6d20 6173 6f6e 652e 6465 6d6f 5f64 6574  m asone.demo_det
-000017d0: 6563 746f 7220 6461 7461 2f73 616d 706c  ector data/sampl
-000017e0: 655f 7669 6465 6f73 2f74 6573 742e 6d70  e_videos/test.mp
-000017f0: 3420 2d2d 6370 750a 6060 600a 0a3c 6465  4 --cpu.```..<de
-00001800: 7461 696c 733e 0a3c 7375 6d6d 6172 793e  tails>.<summary>
-00001810: 362e 312e 3120 5573 6520 4375 7374 6f6d  6.1.1 Use Custom
-00001820: 2054 7261 696e 6564 2057 6569 6768 7473   Trained Weights
-00001830: 2066 6f72 2044 6574 6563 746f 723c 2f73   for Detector</s
-00001840: 756d 6d61 7279 3e0a 0a3c 212d 2d20 2323  ummary>..<!-- ##
-00001850: 2320 362e 312e 3220 5573 6520 4375 7374  # 6.1.2 Use Cust
-00001860: 6f6d 2054 7261 696e 6564 2057 6569 6768  om Trained Weigh
-00001870: 7473 202d 2d3e 0a0a 5573 6520 796f 7572  ts -->..Use your
-00001880: 2063 7573 746f 6d20 7765 6967 6874 7320   custom weights 
-00001890: 6f66 2061 2064 6574 6563 746f 7220 6d6f  of a detector mo
-000018a0: 6465 6c20 7472 6169 6e65 6420 6f6e 2063  del trained on c
-000018b0: 7573 746f 6d20 6461 7461 2062 7920 7369  ustom data by si
-000018c0: 6d70 6c79 2070 726f 7669 6469 6e67 2070  mply providing p
-000018d0: 6174 6820 6f66 2074 6865 2077 6569 6768  ath of the weigh
-000018e0: 7473 2066 696c 652e 0a0a 6060 6070 7974  ts file...```pyt
-000018f0: 686f 6e0a 696d 706f 7274 2061 736f 6e65  hon.import asone
-00001900: 0a66 726f 6d20 6173 6f6e 6520 696d 706f  .from asone impo
-00001910: 7274 2075 7469 6c73 0a66 726f 6d20 6173  rt utils.from as
-00001920: 6f6e 6520 696d 706f 7274 2041 534f 6e65  one import ASOne
-00001930: 0a69 6d70 6f72 7420 6376 320a 0a76 6964  .import cv2..vid
-00001940: 656f 5f70 6174 6820 3d20 2764 6174 612f  eo_path = 'data/
-00001950: 7361 6d70 6c65 5f76 6964 656f 732f 6c69  sample_videos/li
-00001960: 6365 6e73 655f 7669 6465 6f2e 7765 626d  cense_video.webm
-00001970: 270a 6465 7465 6374 6f72 203d 2041 534f  '.detector = ASO
-00001980: 6e65 2864 6574 6563 746f 723d 6173 6f6e  ne(detector=ason
-00001990: 652e 594f 4c4f 5637 5f50 5954 4f52 4348  e.YOLOV7_PYTORCH
-000019a0: 2c20 7765 6967 6874 733d 2764 6174 612f  , weights='data/
-000019b0: 6375 7374 6f6d 5f77 6569 6768 7473 2f79  custom_weights/y
-000019c0: 6f6c 6f76 375f 6375 7374 6f6d 2e70 7427  olov7_custom.pt'
-000019d0: 2c20 7573 655f 6375 6461 3d54 7275 6529  , use_cuda=True)
-000019e0: 2023 2053 6574 2075 7365 5f63 7564 6120   # Set use_cuda 
-000019f0: 746f 2046 616c 7365 2066 6f72 2063 7075  to False for cpu
-00001a00: 0a0a 636c 6173 735f 6e61 6d65 7320 3d20  ..class_names = 
-00001a10: 5b27 6c69 6365 6e73 655f 706c 6174 6527  ['license_plate'
-00001a20: 5d20 2320 796f 7572 2063 7573 746f 6d20  ] # your custom 
-00001a30: 636c 6173 7365 7320 6c69 7374 0a0a 6361  classes list..ca
-00001a40: 7020 3d20 6376 322e 5669 6465 6f43 6170  p = cv2.VideoCap
-00001a50: 7475 7265 2876 6964 656f 5f70 6174 6829  ture(video_path)
-00001a60: 0a0a 7768 696c 6520 5472 7565 3a0a 2020  ..while True:.  
-00001a70: 2020 5f2c 2066 7261 6d65 203d 2063 6170    _, frame = cap
-00001a80: 2e72 6561 6428 290a 2020 2020 6966 206e  .read().    if n
-00001a90: 6f74 205f 3a0a 2020 2020 2020 2020 6272  ot _:.        br
-00001aa0: 6561 6b0a 0a20 2020 2064 6574 732c 2069  eak..    dets, i
-00001ab0: 6d67 5f69 6e66 6f20 3d20 6465 7465 6374  mg_info = detect
-00001ac0: 6f72 2e64 6574 6563 7428 6672 616d 6529  or.detect(frame)
-00001ad0: 0a0a 2020 2020 6262 6f78 5f78 7978 7920  ..    bbox_xyxy 
-00001ae0: 3d20 6465 7473 5b3a 2c20 3a34 5d0a 2020  = dets[:, :4].  
-00001af0: 2020 7363 6f72 6573 203d 2064 6574 735b    scores = dets[
-00001b00: 3a2c 2034 5d0a 2020 2020 636c 6173 735f  :, 4].    class_
-00001b10: 6964 7320 3d20 6465 7473 5b3a 2c20 355d  ids = dets[:, 5]
-00001b20: 0a0a 2020 2020 6672 616d 6520 3d20 7574  ..    frame = ut
-00001b30: 696c 732e 6472 6177 5f62 6f78 6573 2866  ils.draw_boxes(f
-00001b40: 7261 6d65 2c20 6262 6f78 5f78 7978 792c  rame, bbox_xyxy,
-00001b50: 2063 6c61 7373 5f69 6473 3d63 6c61 7373   class_ids=class
-00001b60: 5f69 6473 2c20 636c 6173 735f 6e61 6d65  _ids, class_name
-00001b70: 733d 636c 6173 735f 6e61 6d65 7329 2023  s=class_names) #
-00001b80: 2073 696d 706c 7920 7061 7373 2063 7573   simply pass cus
-00001b90: 746f 6d20 636c 6173 7365 7320 6c69 7374  tom classes list
-00001ba0: 2074 6f20 7772 6974 6520 796f 7572 2063   to write your c
-00001bb0: 6c61 7373 6573 206f 6e20 7265 7375 6c74  lasses on result
-00001bc0: 2076 6964 656f 0a0a 2020 2020 6376 322e   video..    cv2.
-00001bd0: 696d 7368 6f77 2827 7265 7375 6c74 272c  imshow('result',
-00001be0: 2066 7261 6d65 290a 0a20 2020 2069 6620   frame)..    if 
-00001bf0: 6376 322e 7761 6974 4b65 7928 3235 2920  cv2.waitKey(25) 
-00001c00: 2620 3078 4646 203d 3d20 6f72 6428 2771  & 0xFF == ord('q
-00001c10: 2729 3a0a 2020 2020 2020 2020 6272 6561  '):.        brea
-00001c20: 6b0a 6060 600a 3c2f 6465 7461 696c 733e  k.```.</details>
-00001c30: 0a0a 3c64 6574 6169 6c73 3e0a 3c73 756d  ..<details>.<sum
-00001c40: 6d61 7279 3e36 2e31 2e32 2e20 4368 616e  mary>6.1.2. Chan
-00001c50: 6769 6e67 2044 6574 6563 746f 7220 4d6f  ging Detector Mo
-00001c60: 6465 6c73 203c 2f73 756d 6d61 7279 3e0a  dels </summary>.
-00001c70: 0a43 6861 6e67 6520 6465 7465 6374 6f72  .Change detector
-00001c80: 2062 7920 7369 6d70 6c79 2063 6861 6e67   by simply chang
-00001c90: 696e 6720 6465 7465 6374 6f72 2066 6c61  ing detector fla
-00001ca0: 672e 2054 6865 2066 6c61 6773 2061 7265  g. The flags are
-00001cb0: 2070 726f 7669 6465 6420 696e 205b 6265   provided in [be
-00001cc0: 6e63 686d 6172 6b5d 2861 736f 6e65 2f6c  nchmark](asone/l
-00001cd0: 696e 7578 2f49 6e73 7472 7563 7469 6f6e  inux/Instruction
-00001ce0: 732f 4265 6e63 686d 6172 6b69 6e67 2e6d  s/Benchmarking.m
-00001cf0: 6429 2074 6162 6c65 732e 0a2a 204f 7572  d) tables..* Our
-00001d00: 206c 6962 7261 7279 206e 6f77 2073 7570   library now sup
-00001d10: 706f 7274 7320 594f 4c4f 7635 2c20 594f  ports YOLOv5, YO
-00001d20: 4c4f 7637 2c20 616e 6420 594f 4c4f 7638  LOv7, and YOLOv8
-00001d30: 206f 6e20 6d61 634f 532e 0a60 6060 7079   on macOS..```py
-00001d40: 7468 6f6e 0a23 2043 6861 6e67 6520 6465  thon.# Change de
-00001d50: 7465 6374 6f72 0a64 6574 6563 746f 7220  tector.detector 
-00001d60: 3d20 4153 4f6e 6528 6465 7465 6374 6f72  = ASOne(detector
-00001d70: 3d61 736f 6e65 2e59 4f4c 4f58 5f53 5f50  =asone.YOLOX_S_P
-00001d80: 5954 4f52 4348 2c20 7573 655f 6375 6461  YTORCH, use_cuda
-00001d90: 3d54 7275 6529 0a0a 2320 466f 7220 6d61  =True)..# For ma
-00001da0: 634f 730a 2320 594f 4c4f 350a 6465 7465  cOs.# YOLO5.dete
-00001db0: 6374 6f72 203d 2041 534f 6e65 2864 6574  ctor = ASOne(det
-00001dc0: 6563 746f 723d 6173 6f6e 652e 594f 4c4f  ector=asone.YOLO
-00001dd0: 5635 585f 4d4c 4d4f 4445 4c29 0a23 2059  V5X_MLMODEL).# Y
-00001de0: 4f4c 4f37 0a64 6574 6563 746f 7220 3d20  OLO7.detector = 
-00001df0: 4153 4f6e 6528 6465 7465 6374 6f72 3d61  ASOne(detector=a
-00001e00: 736f 6e65 2e59 4f4c 4f56 375f 4d4c 4d4f  sone.YOLOV7_MLMO
-00001e10: 4445 4c29 0a23 2059 4f4c 4f38 0a64 6574  DEL).# YOLO8.det
-00001e20: 6563 746f 7220 3d20 4153 4f6e 6528 6465  ector = ASOne(de
-00001e30: 7465 6374 6f72 3d61 736f 6e65 2e59 4f4c  tector=asone.YOL
-00001e40: 4f56 384c 5f4d 4c4d 4f44 454c 290a 6060  OV8L_MLMODEL).``
-00001e50: 600a 0a3c 2f64 6574 6169 6c73 3e0a 0a3c  `..</details>..<
-00001e60: 2f64 6574 6169 6c73 3e0a 0a3c 6465 7461  /details>..<deta
-00001e70: 696c 733e 0a3c 7375 6d6d 6172 793e 362e  ils>.<summary>6.
-00001e80: 322e 204f 626a 6563 7420 5472 6163 6b69  2. Object Tracki
-00001e90: 6e67 203c 2f73 756d 6d61 7279 3e0a 0a55  ng </summary>..U
-00001ea0: 7365 2074 7261 636b 6572 206f 6e20 7361  se tracker on sa
-00001eb0: 6d70 6c65 2076 6964 656f 2e20 0a0a 6060  mple video. ..``
-00001ec0: 6070 7974 686f 6e0a 696d 706f 7274 2061  `python.import a
-00001ed0: 736f 6e65 0a66 726f 6d20 6173 6f6e 6520  sone.from asone 
-00001ee0: 696d 706f 7274 2041 534f 6e65 0a0a 2320  import ASOne..# 
-00001ef0: 496e 7374 616e 7469 6174 6520 4173 6f6e  Instantiate Ason
-00001f00: 6520 6f62 6a65 6374 0a64 6574 6563 7420  e object.detect 
-00001f10: 3d20 4153 4f6e 6528 7472 6163 6b65 723d  = ASOne(tracker=
-00001f20: 6173 6f6e 652e 4259 5445 5452 4143 4b2c  asone.BYTETRACK,
-00001f30: 2064 6574 6563 746f 723d 6173 6f6e 652e   detector=asone.
-00001f40: 594f 4c4f 5637 5f50 5954 4f52 4348 2c20  YOLOV7_PYTORCH, 
-00001f50: 7573 655f 6375 6461 3d54 7275 6529 2023  use_cuda=True) #
-00001f60: 7365 7420 7573 655f 6375 6461 3d46 616c  set use_cuda=Fal
-00001f70: 7365 2074 6f20 7573 6520 6370 750a 0a66  se to use cpu..f
-00001f80: 696c 7465 725f 636c 6173 7365 7320 3d20  ilter_classes = 
-00001f90: 5b27 7065 7273 6f6e 275d 2023 2073 6574  ['person'] # set
-00001fa0: 2074 6f20 4e6f 6e65 2074 6f20 7472 6163   to None to trac
-00001fb0: 6b20 616c 6c20 636c 6173 7365 730a 0a23  k all classes..#
-00001fc0: 2023 2323 2323 2323 2323 2323 2323 2323   ###############
-00001fd0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00001fe0: 2323 2323 2323 2323 2323 2323 2323 230a  ###############.
-00001ff0: 2320 2020 2020 2020 2020 2020 546f 2074  #           To t
-00002000: 7261 636b 2075 7369 6e67 2076 6964 656f  rack using video
-00002010: 2066 696c 650a 2320 2323 2323 2323 2323   file.# ########
-00002020: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002030: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002040: 2323 2323 2323 0a23 2047 6574 2074 7261  ######.# Get tra
-00002050: 636b 696e 6720 6675 6e63 7469 6f6e 0a74  cking function.t
-00002060: 7261 636b 203d 2064 6574 6563 742e 7472  rack = detect.tr
-00002070: 6163 6b5f 7669 6465 6f28 2764 6174 612f  ack_video('data/
-00002080: 7361 6d70 6c65 5f76 6964 656f 732f 7465  sample_videos/te
-00002090: 7374 2e6d 7034 272c 206f 7574 7075 745f  st.mp4', output_
-000020a0: 6469 723d 2764 6174 612f 7265 7375 6c74  dir='data/result
-000020b0: 7327 2c20 7361 7665 5f72 6573 756c 743d  s', save_result=
-000020c0: 5472 7565 2c20 6469 7370 6c61 793d 5472  True, display=Tr
-000020d0: 7565 2c20 6669 6c74 6572 5f63 6c61 7373  ue, filter_class
-000020e0: 6573 3d66 696c 7465 725f 636c 6173 7365  es=filter_classe
-000020f0: 7329 0a0a 2320 4c6f 6f70 206f 7665 7220  s)..# Loop over 
-00002100: 7472 6163 6b20 746f 2072 6574 7269 6576  track to retriev
-00002110: 6520 6f75 7470 7574 7320 6f66 2065 6163  e outputs of eac
-00002120: 6820 6672 616d 6520 0a66 6f72 2062 626f  h frame .for bbo
-00002130: 785f 6465 7461 696c 732c 2066 7261 6d65  x_details, frame
-00002140: 5f64 6574 6169 6c73 2069 6e20 7472 6163  _details in trac
-00002150: 6b3a 0a20 2020 2062 626f 785f 7879 7879  k:.    bbox_xyxy
-00002160: 2c20 6964 732c 2073 636f 7265 732c 2063  , ids, scores, c
-00002170: 6c61 7373 5f69 6473 203d 2062 626f 785f  lass_ids = bbox_
-00002180: 6465 7461 696c 730a 2020 2020 6672 616d  details.    fram
-00002190: 652c 2066 7261 6d65 5f6e 756d 2c20 6670  e, frame_num, fp
-000021a0: 7320 3d20 6672 616d 655f 6465 7461 696c  s = frame_detail
-000021b0: 730a 2020 2020 2320 446f 2061 6e79 7468  s.    # Do anyth
-000021c0: 696e 6720 7769 7468 2062 626f 7865 7320  ing with bboxes 
-000021d0: 6865 7265 0a0a 2320 2323 2323 2323 2323  here..# ########
-000021e0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-000021f0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002200: 2323 2323 2323 0a23 2020 2020 2020 2020  ######.#        
-00002210: 2020 2054 6f20 7472 6163 6b20 7573 696e     To track usin
-00002220: 6720 7765 6263 616d 0a23 2023 2323 2323  g webcam.# #####
-00002230: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002240: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002250: 2323 2323 2323 2323 230a 2320 4765 7420  #########.# Get 
-00002260: 7472 6163 6b69 6e67 2066 756e 6374 696f  tracking functio
-00002270: 6e0a 7472 6163 6b20 3d20 6465 7465 6374  n.track = detect
-00002280: 2e74 7261 636b 5f77 6562 6361 6d28 6361  .track_webcam(ca
-00002290: 6d5f 6964 3d30 2c20 6f75 7470 7574 5f64  m_id=0, output_d
-000022a0: 6972 3d27 6461 7461 2f72 6573 756c 7473  ir='data/results
-000022b0: 272c 2073 6176 655f 7265 7375 6c74 3d54  ', save_result=T
-000022c0: 7275 652c 2064 6973 706c 6179 3d54 7275  rue, display=Tru
-000022d0: 652c 2066 696c 7465 725f 636c 6173 7365  e, filter_classe
-000022e0: 733d 6669 6c74 6572 5f63 6c61 7373 6573  s=filter_classes
-000022f0: 290a 0a23 204c 6f6f 7020 6f76 6572 2074  )..# Loop over t
-00002300: 7261 636b 2074 6f20 7265 7472 6965 7665  rack to retrieve
-00002310: 206f 7574 7075 7473 206f 6620 6561 6368   outputs of each
-00002320: 2066 7261 6d65 200a 666f 7220 6262 6f78   frame .for bbox
-00002330: 5f64 6574 6169 6c73 2c20 6672 616d 655f  _details, frame_
-00002340: 6465 7461 696c 7320 696e 2074 7261 636b  details in track
-00002350: 3a0a 2020 2020 6262 6f78 5f78 7978 792c  :.    bbox_xyxy,
-00002360: 2069 6473 2c20 7363 6f72 6573 2c20 636c   ids, scores, cl
-00002370: 6173 735f 6964 7320 3d20 6262 6f78 5f64  ass_ids = bbox_d
-00002380: 6574 6169 6c73 0a20 2020 2066 7261 6d65  etails.    frame
-00002390: 2c20 6672 616d 655f 6e75 6d2c 2066 7073  , frame_num, fps
-000023a0: 203d 2066 7261 6d65 5f64 6574 6169 6c73   = frame_details
-000023b0: 0a20 2020 2023 2044 6f20 616e 7974 6869  .    # Do anythi
-000023c0: 6e67 2077 6974 6820 6262 6f78 6573 2068  ng with bboxes h
-000023d0: 6572 650a 0a23 2023 2323 2323 2323 2323  ere..# #########
-000023e0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-000023f0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002400: 2323 2323 230a 2320 2020 2020 2020 2020  #####.#         
-00002410: 2020 546f 2074 7261 636b 2075 7369 6e67    To track using
-00002420: 2077 6562 2073 7472 6561 6d0a 2320 2323   web stream.# ##
-00002430: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002440: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002450: 2323 2323 2323 2323 2323 2323 0a23 2047  ############.# G
-00002460: 6574 2074 7261 636b 696e 6720 6675 6e63  et tracking func
-00002470: 7469 6f6e 0a73 7472 6561 6d5f 7572 6c20  tion.stream_url 
-00002480: 3d20 2772 7473 703a 2f2f 776f 777a 6165  = 'rtsp://wowzae
-00002490: 6332 6465 6d6f 2e73 7472 6561 6d6c 6f63  c2demo.streamloc
-000024a0: 6b2e 6e65 742f 766f 642f 6d70 343a 4269  k.net/vod/mp4:Bi
-000024b0: 6742 7563 6b42 756e 6e79 5f31 3135 6b2e  gBuckBunny_115k.
-000024c0: 6d70 3427 0a74 7261 636b 203d 2064 6574  mp4'.track = det
-000024d0: 6563 742e 7472 6163 6b5f 7374 7265 616d  ect.track_stream
-000024e0: 2873 7472 6561 6d5f 7572 6c2c 206f 7574  (stream_url, out
-000024f0: 7075 745f 6469 723d 2764 6174 612f 7265  put_dir='data/re
-00002500: 7375 6c74 7327 2c20 7361 7665 5f72 6573  sults', save_res
-00002510: 756c 743d 5472 7565 2c20 6469 7370 6c61  ult=True, displa
-00002520: 793d 5472 7565 2c20 6669 6c74 6572 5f63  y=True, filter_c
-00002530: 6c61 7373 6573 3d66 696c 7465 725f 636c  lasses=filter_cl
-00002540: 6173 7365 7329 0a0a 2320 4c6f 6f70 206f  asses)..# Loop o
-00002550: 7665 7220 7472 6163 6b20 746f 2072 6574  ver track to ret
-00002560: 7269 6576 6520 6f75 7470 7574 7320 6f66  rieve outputs of
-00002570: 2065 6163 6820 6672 616d 6520 0a66 6f72   each frame .for
-00002580: 2062 626f 785f 6465 7461 696c 732c 2066   bbox_details, f
-00002590: 7261 6d65 5f64 6574 6169 6c73 2069 6e20  rame_details in 
-000025a0: 7472 6163 6b3a 0a20 2020 2062 626f 785f  track:.    bbox_
-000025b0: 7879 7879 2c20 6964 732c 2073 636f 7265  xyxy, ids, score
-000025c0: 732c 2063 6c61 7373 5f69 6473 203d 2062  s, class_ids = b
-000025d0: 626f 785f 6465 7461 696c 730a 2020 2020  box_details.    
-000025e0: 6672 616d 652c 2066 7261 6d65 5f6e 756d  frame, frame_num
-000025f0: 2c20 6670 7320 3d20 6672 616d 655f 6465  , fps = frame_de
-00002600: 7461 696c 730a 2020 2020 2320 446f 2061  tails.    # Do a
-00002610: 6e79 7468 696e 6720 7769 7468 2062 626f  nything with bbo
-00002620: 7865 7320 6865 7265 0a60 6060 0a0a 5b4e  xes here.```..[N
-00002630: 6f74 655d 2055 7365 2063 616e 2075 7365  ote] Use can use
-00002640: 2063 7573 746f 6d20 7765 6967 6874 7320   custom weights 
-00002650: 666f 7220 6120 6465 7465 6374 6f72 206d  for a detector m
-00002660: 6f64 656c 2062 7920 7369 6d70 6c79 2070  odel by simply p
-00002670: 726f 7669 6469 6e67 2070 6174 6820 6f66  roviding path of
-00002680: 2074 6865 2077 6569 6768 7473 2066 696c   the weights fil
-00002690: 652e 2069 6e20 6041 534f 6e65 6020 636c  e. in `ASOne` cl
-000026a0: 6173 732e 0a0a 3c64 6574 6169 6c73 3e0a  ass...<details>.
-000026b0: 3c73 756d 6d61 7279 3e36 2e32 2e31 2043  <summary>6.2.1 C
-000026c0: 6861 6e67 696e 6720 4465 7465 6374 6f72  hanging Detector
-000026d0: 2061 6e64 2054 7261 636b 696e 6720 4d6f   and Tracking Mo
-000026e0: 6465 6c73 3c2f 7375 6d6d 6172 793e 0a0a  dels</summary>..
-000026f0: 3c21 2d2d 2023 2323 2043 6861 6e67 696e  <!-- ### Changin
-00002700: 6720 4465 7465 6374 6f72 2061 6e64 2054  g Detector and T
-00002710: 7261 636b 696e 6720 4d6f 6465 6c73 202d  racking Models -
-00002720: 2d3e 0a0a 4368 616e 6765 2054 7261 636b  ->..Change Track
-00002730: 6572 2062 7920 7369 6d70 6c79 2063 6861  er by simply cha
-00002740: 6e67 696e 6720 7468 6520 7472 6163 6b65  nging the tracke
-00002750: 7220 666c 6167 2e0a 0a54 6865 2066 6c61  r flag...The fla
-00002760: 6773 2061 7265 2070 726f 7669 6465 6420  gs are provided 
-00002770: 696e 205b 6265 6e63 686d 6172 6b5d 2861  in [benchmark](a
-00002780: 736f 6e65 2f6c 696e 7578 2f49 6e73 7472  sone/linux/Instr
-00002790: 7563 7469 6f6e 732f 4265 6e63 686d 6172  uctions/Benchmar
-000027a0: 6b69 6e67 2e6d 6429 2074 6162 6c65 732e  king.md) tables.
-000027b0: 0a0a 6060 6070 7974 686f 6e0a 6465 7465  ..```python.dete
-000027c0: 6374 203d 2041 534f 6e65 2874 7261 636b  ct = ASOne(track
-000027d0: 6572 3d61 736f 6e65 2e42 5954 4554 5241  er=asone.BYTETRA
-000027e0: 434b 2c20 6465 7465 6374 6f72 3d61 736f  CK, detector=aso
-000027f0: 6e65 2e59 4f4c 4f56 375f 5059 544f 5243  ne.YOLOV7_PYTORC
-00002800: 482c 2075 7365 5f63 7564 613d 5472 7565  H, use_cuda=True
-00002810: 290a 2320 4368 616e 6765 2074 7261 636b  ).# Change track
-00002820: 6572 0a64 6574 6563 7420 3d20 4153 4f6e  er.detect = ASOn
-00002830: 6528 7472 6163 6b65 723d 6173 6f6e 652e  e(tracker=asone.
-00002840: 4445 4550 534f 5254 2c20 6465 7465 6374  DEEPSORT, detect
-00002850: 6f72 3d61 736f 6e65 2e59 4f4c 4f56 375f  or=asone.YOLOV7_
-00002860: 5059 544f 5243 482c 2075 7365 5f63 7564  PYTORCH, use_cud
-00002870: 613d 5472 7565 290a 6060 600a 0a60 6060  a=True).```..```
-00002880: 7079 7468 6f6e 0a23 2043 6861 6e67 6520  python.# Change 
-00002890: 4465 7465 6374 6f72 0a64 6574 6563 7420  Detector.detect 
-000028a0: 3d20 4153 4f6e 6528 7472 6163 6b65 723d  = ASOne(tracker=
-000028b0: 6173 6f6e 652e 4445 4550 534f 5254 2c20  asone.DEEPSORT, 
-000028c0: 6465 7465 6374 6f72 3d61 736f 6e65 2e59  detector=asone.Y
-000028d0: 4f4c 4f58 5f53 5f50 5954 4f52 4348 2c20  OLOX_S_PYTORCH, 
-000028e0: 7573 655f 6375 6461 3d54 7275 6529 0a60  use_cuda=True).`
-000028f0: 6060 0a3c 2f64 6574 6169 6c73 3e0a 0a0a  ``.</details>...
-00002900: 5275 6e20 7468 6520 6061 736f 6e65 2f64  Run the `asone/d
-00002910: 656d 6f5f 6465 7465 6374 6f72 2e70 7960  emo_detector.py`
-00002920: 2074 6f20 7465 7374 2064 6574 6563 746f   to test detecto
-00002930: 722e 0a0a 6060 6073 6865 6c6c 0a23 2072  r...```shell.# r
-00002940: 756e 206f 6e20 6770 750a 7079 7468 6f6e  un on gpu.python
-00002950: 202d 6d20 6173 6f6e 652e 6465 6d6f 5f64   -m asone.demo_d
-00002960: 6574 6563 746f 7220 6461 7461 2f73 616d  etector data/sam
-00002970: 706c 655f 7669 6465 6f73 2f74 6573 742e  ple_videos/test.
-00002980: 6d70 340a 0a23 2072 756e 206f 6e20 6370  mp4..# run on cp
-00002990: 750a 7079 7468 6f6e 202d 6d20 6173 6f6e  u.python -m ason
-000029a0: 652e 6465 6d6f 5f64 6574 6563 746f 7220  e.demo_detector 
-000029b0: 6461 7461 2f73 616d 706c 655f 7669 6465  data/sample_vide
-000029c0: 6f73 2f74 6573 742e 6d70 3420 2d2d 6370  os/test.mp4 --cp
-000029d0: 750a 6060 600a 3c2f 6465 7461 696c 733e  u.```.</details>
-000029e0: 0a3c 6465 7461 696c 733e 0a3c 7375 6d6d  .<details>.<summ
-000029f0: 6172 793e 362e 332e 2054 6578 7420 4465  ary>6.3. Text De
-00002a00: 7465 6374 696f 6e3c 2f73 756d 6d61 7279  tection</summary
-00002a10: 3e0a 0a53 616d 706c 6520 636f 6465 2074  >..Sample code t
-00002a20: 6f20 6465 7465 6374 2074 6578 7420 6f6e  o detect text on
-00002a30: 2061 6e20 696d 6167 650a 0a60 6060 7079   an image..```py
-00002a40: 7468 6f6e 0a23 2044 6574 6563 7420 616e  thon.# Detect an
-00002a50: 6420 7265 636f 676e 697a 6520 7465 7874  d recognize text
-00002a60: 0a69 6d70 6f72 7420 6173 6f6e 650a 6672  .import asone.fr
-00002a70: 6f6d 2061 736f 6e65 2069 6d70 6f72 7420  om asone import 
-00002a80: 7574 696c 730a 6672 6f6d 2061 736f 6e65  utils.from asone
-00002a90: 2069 6d70 6f72 7420 4153 4f6e 650a 696d   import ASOne.im
-00002aa0: 706f 7274 2063 7632 0a0a 0a69 6d67 5f70  port cv2...img_p
-00002ab0: 6174 6820 3d20 2764 6174 612f 7361 6d70  ath = 'data/samp
-00002ac0: 6c65 5f69 6d67 732f 7361 6d70 6c65 5f74  le_imgs/sample_t
-00002ad0: 6578 742e 6a70 6567 270a 6f63 7220 3d20  ext.jpeg'.ocr = 
-00002ae0: 4153 4f6e 6528 6465 7465 6374 6f72 3d61  ASOne(detector=a
-00002af0: 736f 6e65 2e43 5241 4654 2c20 7265 636f  sone.CRAFT, reco
-00002b00: 676e 697a 6572 3d61 736f 6e65 2e45 4153  gnizer=asone.EAS
-00002b10: 594f 4352 2c20 7573 655f 6375 6461 3d54  YOCR, use_cuda=T
-00002b20: 7275 6529 2023 2053 6574 2075 7365 5f63  rue) # Set use_c
-00002b30: 7564 6120 746f 2046 616c 7365 2066 6f72  uda to False for
-00002b40: 2063 7075 0a69 6d67 203d 2063 7632 2e69   cpu.img = cv2.i
-00002b50: 6d72 6561 6428 696d 675f 7061 7468 290a  mread(img_path).
-00002b60: 7265 7375 6c74 7320 3d20 6f63 722e 6465  results = ocr.de
-00002b70: 7465 6374 5f74 6578 7428 696d 6729 200a  tect_text(img) .
-00002b80: 696d 6720 3d20 7574 696c 732e 6472 6177  img = utils.draw
-00002b90: 5f74 6578 7428 696d 672c 2072 6573 756c  _text(img, resul
-00002ba0: 7473 290a 6376 322e 696d 7772 6974 6528  ts).cv2.imwrite(
-00002bb0: 2264 6174 612f 7265 7375 6c74 732f 7265  "data/results/re
-00002bc0: 7375 6c74 732e 6a70 6722 2c20 696d 6729  sults.jpg", img)
-00002bd0: 0a60 6060 0a0a 5573 6520 5472 6163 6b65  .```..Use Tracke
-00002be0: 7220 6f6e 2054 6578 740a 6060 6070 7974  r on Text.```pyt
-00002bf0: 686f 6e0a 696d 706f 7274 2061 736f 6e65  hon.import asone
-00002c00: 0a66 726f 6d20 6173 6f6e 6520 696d 706f  .from asone impo
-00002c10: 7274 2041 534f 6e65 0a0a 2320 496e 7374  rt ASOne..# Inst
-00002c20: 616e 7469 6174 6520 4173 6f6e 6520 6f62  antiate Asone ob
-00002c30: 6a65 6374 0a64 6574 6563 7420 3d20 4153  ject.detect = AS
-00002c40: 4f6e 6528 7472 6163 6b65 723d 6173 6f6e  One(tracker=ason
-00002c50: 652e 4445 4550 534f 5254 2c20 6465 7465  e.DEEPSORT, dete
-00002c60: 6374 6f72 3d61 736f 6e65 2e43 5241 4654  ctor=asone.CRAFT
-00002c70: 2c20 7265 636f 676e 697a 6572 3d61 736f  , recognizer=aso
-00002c80: 6e65 2e45 4153 594f 4352 2c20 7573 655f  ne.EASYOCR, use_
-00002c90: 6375 6461 3d54 7275 6529 2023 7365 7420  cuda=True) #set 
-00002ca0: 7573 655f 6375 6461 3d46 616c 7365 2074  use_cuda=False t
-00002cb0: 6f20 7573 6520 6370 750a 0a23 2023 2323  o use cpu..# ###
-00002cc0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002cd0: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002ce0: 2323 2323 2323 2323 2323 230a 2320 2020  ###########.#   
-00002cf0: 2020 2020 2020 2020 546f 2074 7261 636b          To track
-00002d00: 2075 7369 6e67 2076 6964 656f 2066 696c   using video fil
-00002d10: 650a 2320 2323 2323 2323 2323 2323 2323  e.# ############
-00002d20: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002d30: 2323 2323 2323 2323 2323 2323 2323 2323  ################
-00002d40: 2323 0a23 2047 6574 2074 7261 636b 696e  ##.# Get trackin
-00002d50: 6720 6675 6e63 7469 6f6e 0a74 7261 636b  g function.track
-00002d60: 203d 2064 6574 6563 742e 7472 6163 6b5f   = detect.track_
-00002d70: 7669 6465 6f28 2764 6174 612f 7361 6d70  video('data/samp
-00002d80: 6c65 5f76 6964 656f 732f 4754 415f 352d  le_videos/GTA_5-
-00002d90: 556e 6971 7565 5f4c 6963 656e 7365 5f50  Unique_License_P
-00002da0: 6c61 7465 2e6d 7034 272c 206f 7574 7075  late.mp4', outpu
-00002db0: 745f 6469 723d 2764 6174 612f 7265 7375  t_dir='data/resu
-00002dc0: 6c74 7327 2c20 7361 7665 5f72 6573 756c  lts', save_resul
-00002dd0: 743d 5472 7565 2c20 6469 7370 6c61 793d  t=True, display=
-00002de0: 5472 7565 290a 0a23 204c 6f6f 7020 6f76  True)..# Loop ov
-00002df0: 6572 2074 7261 636b 2074 6f20 7265 7472  er track to retr
-00002e00: 6965 7665 206f 7574 7075 7473 206f 6620  ieve outputs of 
-00002e10: 6561 6368 2066 7261 6d65 200a 666f 7220  each frame .for 
-00002e20: 6262 6f78 5f64 6574 6169 6c73 2c20 6672  bbox_details, fr
-00002e30: 616d 655f 6465 7461 696c 7320 696e 2074  ame_details in t
-00002e40: 7261 636b 3a0a 2020 2020 6262 6f78 5f78  rack:.    bbox_x
-00002e50: 7978 792c 2069 6473 2c20 7363 6f72 6573  yxy, ids, scores
-00002e60: 2c20 636c 6173 735f 6964 7320 3d20 6262  , class_ids = bb
-00002e70: 6f78 5f64 6574 6169 6c73 0a20 2020 2066  ox_details.    f
-00002e80: 7261 6d65 2c20 6672 616d 655f 6e75 6d2c  rame, frame_num,
-00002e90: 2066 7073 203d 2066 7261 6d65 5f64 6574   fps = frame_det
-00002ea0: 6169 6c73 0a20 2020 2023 2044 6f20 616e  ails.    # Do an
-00002eb0: 7974 6869 6e67 2077 6974 6820 6262 6f78  ything with bbox
-00002ec0: 6573 2068 6572 650a 6060 600a 0a52 756e  es here.```..Run
-00002ed0: 2074 6865 2060 6173 6f6e 652f 6465 6d6f   the `asone/demo
-00002ee0: 5f6f 6372 2e70 7960 2074 6f20 7465 7374  _ocr.py` to test
-00002ef0: 206f 6372 2e0a 0a60 6060 7368 656c 6c0a   ocr...```shell.
-00002f00: 2320 7275 6e20 6f6e 2067 7075 0a20 7079  # run on gpu. py
-00002f10: 7468 6f6e 202d 6d20 6173 6f6e 652e 6465  thon -m asone.de
-00002f20: 6d6f 5f6f 6372 2064 6174 612f 7361 6d70  mo_ocr data/samp
-00002f30: 6c65 5f76 6964 656f 732f 4754 415f 352d  le_videos/GTA_5-
-00002f40: 556e 6971 7565 5f4c 6963 656e 7365 5f50  Unique_License_P
-00002f50: 6c61 7465 2e6d 7034 0a0a 2320 7275 6e20  late.mp4..# run 
-00002f60: 6f6e 2063 7075 0a20 7079 7468 6f6e 202d  on cpu. python -
-00002f70: 6d20 6173 6f6e 652e 6465 6d6f 5f6f 6372  m asone.demo_ocr
-00002f80: 2064 6174 612f 7361 6d70 6c65 5f76 6964   data/sample_vid
-00002f90: 656f 732f 4754 415f 352d 556e 6971 7565  eos/GTA_5-Unique
-00002fa0: 5f4c 6963 656e 7365 5f50 6c61 7465 2e6d  _License_Plate.m
-00002fb0: 7034 202d 2d63 7075 0a60 6060 0a0a 3c2f  p4 --cpu.```..</
-00002fc0: 6465 7461 696c 733e 0a0a 3c64 6574 6169  details>..<detai
-00002fd0: 6c73 3e0a 3c73 756d 6d61 7279 3e36 2e34  ls>.<summary>6.4
-00002fe0: 2e20 506f 7365 2045 7374 696d 6174 696f  . Pose Estimatio
-00002ff0: 6e3c 2f73 756d 6d61 7279 3e0a 0a53 616d  n</summary>..Sam
-00003000: 706c 6520 636f 6465 2074 6f20 6573 7469  ple code to esti
-00003010: 6d61 7465 2070 6f73 6520 6f6e 2061 6e20  mate pose on an 
-00003020: 696d 6167 650a 0a60 6060 7079 7468 6f6e  image..```python
-00003030: 0a23 2050 6f73 6520 4573 7469 6d61 7469  .# Pose Estimati
-00003040: 6f6e 0a69 6d70 6f72 7420 6173 6f6e 650a  on.import asone.
-00003050: 6672 6f6d 2061 736f 6e65 2069 6d70 6f72  from asone impor
-00003060: 7420 7574 696c 730a 6672 6f6d 2061 736f  t utils.from aso
-00003070: 6e65 2069 6d70 6f72 7420 506f 7365 4573  ne import PoseEs
-00003080: 7469 6d61 746f 720a 696d 706f 7274 2063  timator.import c
-00003090: 7632 0a0a 696d 675f 7061 7468 203d 2027  v2..img_path = '
-000030a0: 6461 7461 2f73 616d 706c 655f 696d 6773  data/sample_imgs
-000030b0: 2f74 6573 7432 2e6a 7067 270a 706f 7365  /test2.jpg'.pose
-000030c0: 5f65 7374 696d 6174 6f72 203d 2050 6f73  _estimator = Pos
-000030d0: 6545 7374 696d 6174 6f72 2865 7374 696d  eEstimator(estim
-000030e0: 6174 6f72 5f66 6c61 673d 6173 6f6e 652e  ator_flag=asone.
-000030f0: 594f 4c4f 5638 4d5f 504f 5345 2c20 7573  YOLOV8M_POSE, us
-00003100: 655f 6375 6461 3d54 7275 6529 2023 7365  e_cuda=True) #se
-00003110: 7420 7573 655f 6375 6461 3d46 616c 7365  t use_cuda=False
-00003120: 2074 6f20 7573 6520 6370 750a 696d 6720   to use cpu.img 
-00003130: 3d20 6376 322e 696d 7265 6164 2869 6d67  = cv2.imread(img
-00003140: 5f70 6174 6829 0a6b 7074 7320 3d20 706f  _path).kpts = po
-00003150: 7365 5f65 7374 696d 6174 6f72 2e65 7374  se_estimator.est
-00003160: 696d 6174 655f 696d 6167 6528 696d 6729  imate_image(img)
-00003170: 200a 696d 6720 3d20 7574 696c 732e 6472   .img = utils.dr
-00003180: 6177 5f6b 7074 7328 696d 672c 206b 7074  aw_kpts(img, kpt
-00003190: 7329 0a63 7632 2e69 6d77 7269 7465 2822  s).cv2.imwrite("
-000031a0: 6461 7461 2f72 6573 756c 7473 2f72 6573  data/results/res
-000031b0: 756c 7473 2e6a 7067 222c 2069 6d67 290a  ults.jpg", img).
-000031c0: 6060 600a 2a20 4e6f 7720 796f 7520 6361  ```.* Now you ca
-000031d0: 6e20 7573 6520 596f 6c6f 7638 2061 6e64  n use Yolov8 and
-000031e0: 2059 6f6c 6f76 372d 7736 2066 6f72 2070   Yolov7-w6 for p
-000031f0: 6f73 6520 6573 7469 6d61 7469 6f6e 2e20  ose estimation. 
-00003200: 5468 6520 666c 6167 7320 6172 6520 7072  The flags are pr
-00003210: 6f76 6964 6564 2069 6e20 5b62 656e 6368  ovided in [bench
-00003220: 6d61 726b 5d28 6173 6f6e 652f 6c69 6e75  mark](asone/linu
-00003230: 782f 496e 7374 7275 6374 696f 6e73 2f42  x/Instructions/B
-00003240: 656e 6368 6d61 726b 696e 672e 6d64 2920  enchmarking.md) 
-00003250: 7461 626c 6573 2e0a 0a60 6060 7079 7468  tables...```pyth
-00003260: 6f6e 0a23 2050 6f73 6520 4573 7469 6d61  on.# Pose Estima
-00003270: 7469 6f6e 206f 6e20 7669 6465 6f0a 696d  tion on video.im
-00003280: 706f 7274 2061 736f 6e65 0a66 726f 6d20  port asone.from 
-00003290: 6173 6f6e 6520 696d 706f 7274 2050 6f73  asone import Pos
-000032a0: 6545 7374 696d 6174 6f72 0a0a 7669 6465  eEstimator..vide
-000032b0: 6f5f 7061 7468 203d 2027 6461 7461 2f73  o_path = 'data/s
-000032c0: 616d 706c 655f 7669 6465 6f73 2f66 6f6f  ample_videos/foo
-000032d0: 7462 616c 6c31 2e6d 7034 270a 706f 7365  tball1.mp4'.pose
-000032e0: 5f65 7374 696d 6174 6f72 203d 2050 6f73  _estimator = Pos
-000032f0: 6545 7374 696d 6174 6f72 2865 7374 696d  eEstimator(estim
-00003300: 6174 6f72 5f66 6c61 673d 6173 6f6e 652e  ator_flag=asone.
-00003310: 594f 4c4f 5637 5f57 365f 504f 5345 2c20  YOLOV7_W6_POSE, 
-00003320: 7573 655f 6375 6461 3d54 7275 6529 2023  use_cuda=True) #
-00003330: 7365 7420 7573 655f 6375 6461 3d46 616c  set use_cuda=Fal
-00003340: 7365 2074 6f20 7573 6520 6370 750a 6573  se to use cpu.es
-00003350: 7469 6d61 746f 7220 3d20 706f 7365 5f65  timator = pose_e
-00003360: 7374 696d 6174 6f72 2e65 7374 696d 6174  stimator.estimat
-00003370: 655f 7669 6465 6f28 7669 6465 6f5f 7061  e_video(video_pa
-00003380: 7468 2c20 7361 7665 3d54 7275 652c 2064  th, save=True, d
-00003390: 6973 706c 6179 3d54 7275 6529 0a66 6f72  isplay=True).for
-000033a0: 206b 7074 732c 2066 7261 6d65 5f64 6574   kpts, frame_det
-000033b0: 6169 6c73 2069 6e20 6573 7469 6d61 746f  ails in estimato
-000033c0: 723a 0a20 2020 2066 7261 6d65 2c20 6672  r:.    frame, fr
-000033d0: 616d 655f 6e75 6d2c 2066 7073 203d 2066  ame_num, fps = f
-000033e0: 7261 6d65 5f64 6574 6169 6c73 0a20 2020  rame_details.   
-000033f0: 2070 7269 6e74 2866 7261 6d65 5f6e 756d   print(frame_num
-00003400: 290a 2020 2020 2320 446f 2061 6e79 7468  ).    # Do anyth
-00003410: 696e 6720 7769 7468 206b 7074 7320 6865  ing with kpts he
-00003420: 7265 0a60 6060 0a0a 5275 6e20 7468 6520  re.```..Run the 
-00003430: 6061 736f 6e65 2f64 656d 6f5f 706f 7365  `asone/demo_pose
-00003440: 5f65 7374 696d 6174 6f72 2e70 7960 2074  _estimator.py` t
-00003450: 6f20 7465 7374 2050 6f73 6520 6573 7469  o test Pose esti
-00003460: 6d61 7469 6f6e 2e0a 0a60 6060 7368 656c  mation...```shel
-00003470: 6c0a 2320 7275 6e20 6f6e 2067 7075 0a20  l.# run on gpu. 
-00003480: 7079 7468 6f6e 202d 6d20 6173 6f6e 652e  python -m asone.
-00003490: 6465 6d6f 5f70 6f73 655f 6573 7469 6d61  demo_pose_estima
-000034a0: 746f 7220 6461 7461 2f73 616d 706c 655f  tor data/sample_
-000034b0: 7669 6465 6f73 2f66 6f6f 7462 616c 6c31  videos/football1
-000034c0: 2e6d 7034 0a0a 2320 7275 6e20 6f6e 2063  .mp4..# run on c
-000034d0: 7075 0a20 7079 7468 6f6e 202d 6d20 6173  pu. python -m as
-000034e0: 6f6e 652e 6465 6d6f 5f70 6f73 655f 6573  one.demo_pose_es
-000034f0: 7469 6d61 746f 7220 6461 7461 2f73 616d  timator data/sam
-00003500: 706c 655f 7669 6465 6f73 2f66 6f6f 7462  ple_videos/footb
-00003510: 616c 6c31 2e6d 7034 202d 2d63 7075 0a60  all1.mp4 --cpu.`
-00003520: 6060 0a0a 3c2f 6465 7461 696c 733e 0a0a  ``..</details>..
-00003530: 546f 2073 6574 7570 2041 534f 6e65 2075  To setup ASOne u
-00003540: 7369 6e67 2044 6f63 6b65 7220 666f 6c6c  sing Docker foll
-00003550: 6f77 2069 6e73 7472 7563 7469 6f6e 7320  ow instructions 
-00003560: 6769 7665 6e20 696e 205b 646f 636b 6572  given in [docker
-00003570: 2073 6574 7570 5d28 6173 6f6e 652f 6c69   setup](asone/li
-00003580: 6e75 782f 496e 7374 7275 6374 696f 6e73  nux/Instructions
-00003590: 2f44 6f63 6b65 722d 5365 7475 702e 6d64  /Docker-Setup.md
-000035a0: 2920 0a0a 2320 546f 446f 0a2d 205b 785d  ) ..# ToDo.- [x]
-000035b0: 2046 6972 7374 2052 656c 6561 7365 0a2d   First Release.-
-000035c0: 205b 785d 2049 6d70 6f72 7420 7472 6169   [x] Import trai
-000035d0: 6e65 6420 6d6f 6465 6c73 0a2d 205b 785d  ned models.- [x]
-000035e0: 2053 696d 706c 6966 7920 636f 6465 2065   Simplify code e
-000035f0: 7665 6e20 6675 7274 6865 720a 2d20 5b78  ven further.- [x
-00003600: 5d20 5570 6461 7465 6420 666f 7220 594f  ] Updated for YO
-00003610: 4c4f 7638 0a2d 205b 785d 204f 4352 2061  LOv8.- [x] OCR a
-00003620: 6e64 2043 6f75 6e74 696e 670a 2d20 5b78  nd Counting.- [x
-00003630: 5d20 4f43 534f 5254 2c20 5374 726f 6e67  ] OCSORT, Strong
-00003640: 534f 5254 2c20 4d6f 5450 790a 2d20 5b78  SORT, MoTPy.- [x
-00003650: 5d20 4d31 2f32 2041 7070 6c65 2053 696c  ] M1/2 Apple Sil
-00003660: 6963 6f6e 2043 6f6d 7061 7469 6269 6c69  icon Compatibili
-00003670: 7479 0a2d 205b 785d 2050 6f73 6520 4573  ty.- [x] Pose Es
-00003680: 7469 6d61 7469 6f6e 2059 4f4c 4f76 372f  timation YOLOv7/
-00003690: 7638 0a2d 205b 785d 2059 4f4c 4f2d 4e41  v8.- [x] YOLO-NA
-000036a0: 530a 2d20 5b20 5d20 5341 4d20 496e 7465  S.- [ ] SAM Inte
-000036b0: 6772 6174 696f 6e0a 0a7c 4f66 6665 7265  gration..|Offere
-000036c0: 6420 4279 3a20 7c4d 6169 6e74 6169 6e65  d By: |Maintaine
-000036d0: 6420 4279 3a7c 0a7c 2d2d 2d2d 2d2d 2d2d  d By:|.|--------
-000036e0: 2d2d 2d2d 2d7c 2d2d 2d2d 2d2d 2d2d 2d2d  -----|----------
-000036f0: 2d2d 2d7c 0a7c 5b21 5b41 7567 6d65 6e74  ---|.|[![Augment
-00003700: 6564 5374 6172 7570 735d 2868 7474 7073  edStarups](https
-00003710: 3a2f 2f75 7365 722d 696d 6167 6573 2e67  ://user-images.g
-00003720: 6974 6875 6275 7365 7263 6f6e 7465 6e74  ithubusercontent
-00003730: 2e63 6f6d 2f31 3037 3033 3534 3534 2f31  .com/107035454/1
-00003740: 3935 3131 3532 3633 2d64 3332 3731 6566  95115263-d3271ef
-00003750: 332d 3937 3362 2d34 3061 342d 3833 6338  3-973b-40a4-83c8
-00003760: 2d30 6164 6538 3732 3764 6434 302e 706e  -0ade8727dd40.pn
-00003770: 6729 5d28 6874 7470 733a 2f2f 6175 676d  g)](https://augm
-00003780: 656e 7465 6473 7461 7274 7570 732e 636f  entedstartups.co
-00003790: 6d29 7c5b 215b 4178 6365 6c65 7261 7465  m)|[![Axcelerate
-000037a0: 4149 5d28 6874 7470 733a 2f2f 7573 6572  AI](https://user
-000037b0: 2d69 6d61 6765 732e 6769 7468 7562 7573  -images.githubus
-000037c0: 6572 636f 6e74 656e 742e 636f 6d2f 3130  ercontent.com/10
-000037d0: 3730 3335 3435 342f 3139 3531 3134 3837  7035454/19511487
-000037e0: 302d 3639 3163 3861 3532 2d66 6366 302d  0-691c8a52-fcf0-
-000037f0: 3436 3265 2d39 6530 322d 6137 3230 6663  462e-9e02-a720fc
-00003800: 3833 6239 3366 2e70 6e67 295d 2868 7474  83b93f.png)](htt
-00003810: 7073 3a2f 2f61 7863 656c 6572 6174 652e  ps://axcelerate.
-00003820: 6169 2f29 7c0a 0a0a                      ai/)|...
+00000060: 6175 676d 656e 7465 6473 7461 7274 7570  augmentedstartup
+00000070: 732f 4153 2d4f 6e65 0a41 7574 686f 723a  s/AS-One.Author:
+00000080: 2041 7863 656c 6572 6174 6541 490a 4175   AxcelerateAI.Au
+00000090: 7468 6f72 2d65 6d61 696c 3a20 6465 7640  thor-email: dev@
+000000a0: 6178 6365 6c65 7261 7465 2e61 690a 4c69  axcelerate.ai.Li
+000000b0: 6365 6e73 653a 2042 5344 2032 2d63 6c61  cense: BSD 2-cla
+000000c0: 7573 650a 4b65 7977 6f72 6473 3a20 6173  use.Keywords: as
+000000d0: 6f6e 6520 6279 7465 7472 6163 6b20 6465  one bytetrack de
+000000e0: 6570 736f 7274 206e 6f72 6661 6972 2079  epsort norfair y
+000000f0: 6f6c 6f20 796f 6c6f 7820 796f 6c6f 7220  olo yolox yolor 
+00000100: 796f 6c6f 7635 2079 6f6c 6f76 3720 796f  yolov5 yolov7 yo
+00000110: 6c6f 7638 2079 6f6c 6f76 3920 7361 6d20  lov8 yolov9 sam 
+00000120: 7365 676d 656e 742d 616e 7974 6869 6e67  segment-anything
+00000130: 2069 6e73 7461 6c6c 6174 696f 6e20 696e   installation in
+00000140: 6665 7265 6e63 696e 670a 506c 6174 666f  ferencing.Platfo
+00000150: 726d 3a20 554e 4b4e 4f57 4e0a 436c 6173  rm: UNKNOWN.Clas
+00000160: 7369 6669 6572 3a20 4465 7665 6c6f 706d  sifier: Developm
+00000170: 656e 7420 5374 6174 7573 203a 3a20 3120  ent Status :: 1 
+00000180: 2d20 506c 616e 6e69 6e67 0a43 6c61 7373  - Planning.Class
+00000190: 6966 6965 723a 2049 6e74 656e 6465 6420  ifier: Intended 
+000001a0: 4175 6469 656e 6365 203a 3a20 5363 6965  Audience :: Scie
+000001b0: 6e63 652f 5265 7365 6172 6368 0a43 6c61  nce/Research.Cla
+000001c0: 7373 6966 6965 723a 204c 6963 656e 7365  ssifier: License
+000001d0: 203a 3a20 4f53 4920 4170 7072 6f76 6564   :: OSI Approved
+000001e0: 203a 3a20 4d49 5420 4c69 6365 6e73 650a   :: MIT License.
+000001f0: 436c 6173 7369 6669 6572 3a20 4f70 6572  Classifier: Oper
+00000200: 6174 696e 6720 5379 7374 656d 203a 3a20  ating System :: 
+00000210: 504f 5349 5820 3a3a 204c 696e 7578 0a43  POSIX :: Linux.C
+00000220: 6c61 7373 6966 6965 723a 204f 7065 7261  lassifier: Opera
+00000230: 7469 6e67 2053 7973 7465 6d20 3a3a 204d  ting System :: M
+00000240: 6963 726f 736f 6674 203a 3a20 5769 6e64  icrosoft :: Wind
+00000250: 6f77 7320 3a3a 2057 696e 646f 7773 2031  ows :: Windows 1
+00000260: 300a 436c 6173 7369 6669 6572 3a20 5072  0.Classifier: Pr
+00000270: 6f67 7261 6d6d 696e 6720 4c61 6e67 7561  ogramming Langua
+00000280: 6765 203a 3a20 5079 7468 6f6e 203a 3a20  ge :: Python :: 
+00000290: 330a 436c 6173 7369 6669 6572 3a20 5072  3.Classifier: Pr
+000002a0: 6f67 7261 6d6d 696e 6720 4c61 6e67 7561  ogramming Langua
+000002b0: 6765 203a 3a20 5079 7468 6f6e 203a 3a20  ge :: Python :: 
+000002c0: 332e 380a 436c 6173 7369 6669 6572 3a20  3.8.Classifier: 
+000002d0: 5072 6f67 7261 6d6d 696e 6720 4c61 6e67  Programming Lang
+000002e0: 7561 6765 203a 3a20 5079 7468 6f6e 203a  uage :: Python :
+000002f0: 3a20 332e 390a 436c 6173 7369 6669 6572  : 3.9.Classifier
+00000300: 3a20 5072 6f67 7261 6d6d 696e 6720 4c61  : Programming La
+00000310: 6e67 7561 6765 203a 3a20 5079 7468 6f6e  nguage :: Python
+00000320: 203a 3a20 332e 3130 0a44 6573 6372 6970   :: 3.10.Descrip
+00000330: 7469 6f6e 2d43 6f6e 7465 6e74 2d54 7970  tion-Content-Typ
+00000340: 653a 2074 6578 742f 6d61 726b 646f 776e  e: text/markdown
+00000350: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+00000360: 4379 7468 6f6e 203d 3d33 2e30 2e39 0a52  Cython ==3.0.9.R
+00000370: 6571 7569 7265 732d 4469 7374 3a20 4950  equires-Dist: IP
+00000380: 7974 686f 6e0a 5265 7175 6972 6573 2d44  ython.Requires-D
+00000390: 6973 743a 2061 736f 6e65 2d6f 6372 0a52  ist: asone-ocr.R
+000003a0: 6571 7569 7265 732d 4469 7374 3a20 636f  equires-Dist: co
+000003b0: 7265 6d6c 746f 6f6c 730a 5265 7175 6972  remltools.Requir
+000003c0: 6573 2d44 6973 743a 2063 7974 686f 6e2d  es-Dist: cython-
+000003d0: 6262 6f78 0a52 6571 7569 7265 732d 4469  bbox.Requires-Di
+000003e0: 7374 3a20 6561 7379 6469 6374 0a52 6571  st: easydict.Req
+000003f0: 7569 7265 732d 4469 7374 3a20 6764 6f77  uires-Dist: gdow
+00000400: 6e0a 5265 7175 6972 6573 2d44 6973 743a  n.Requires-Dist:
+00000410: 206c 6170 0a52 6571 7569 7265 732d 4469   lap.Requires-Di
+00000420: 7374 3a20 6c6f 6775 7275 0a52 6571 7569  st: loguru.Requi
+00000430: 7265 732d 4469 7374 3a20 6d6f 7470 790a  res-Dist: motpy.
+00000440: 5265 7175 6972 6573 2d44 6973 743a 206e  Requires-Dist: n
+00000450: 6f72 6661 6972 0a52 6571 7569 7265 732d  orfair.Requires-
+00000460: 4469 7374 3a20 6e75 6d70 7920 3d3d 312e  Dist: numpy ==1.
+00000470: 3233 2e33 0a52 6571 7569 7265 732d 4469  23.3.Requires-Di
+00000480: 7374 3a20 6f6e 6e78 7275 6e74 696d 650a  st: onnxruntime.
+00000490: 5265 7175 6972 6573 2d44 6973 743a 206f  Requires-Dist: o
+000004a0: 7065 6e63 762d 7079 7468 6f6e 0a52 6571  pencv-python.Req
+000004b0: 7569 7265 732d 4469 7374 3a20 7061 6e64  uires-Dist: pand
+000004c0: 6173 0a52 6571 7569 7265 732d 4469 7374  as.Requires-Dist
+000004d0: 3a20 7069 6c6c 6f77 203d 3d39 2e35 2e30  : pillow ==9.5.0
+000004e0: 0a52 6571 7569 7265 732d 4469 7374 3a20  .Requires-Dist: 
+000004f0: 7072 6f74 6f62 7566 203d 3d33 2e32 302e  protobuf ==3.20.
+00000500: 2a0a 5265 7175 6972 6573 2d44 6973 743a  *.Requires-Dist:
+00000510: 2070 7979 616d 6c0a 5265 7175 6972 6573   pyyaml.Requires
+00000520: 2d44 6973 743a 2073 6369 7079 0a52 6571  -Dist: scipy.Req
+00000530: 7569 7265 732d 4469 7374 3a20 7365 676d  uires-Dist: segm
+00000540: 656e 742d 616e 7974 6869 6e67 0a52 6571  ent-anything.Req
+00000550: 7569 7265 732d 4469 7374 3a20 7375 7065  uires-Dist: supe
+00000560: 722d 6772 6164 6965 6e74 730a 5265 7175  r-gradients.Requ
+00000570: 6972 6573 2d44 6973 743a 2074 6162 756c  ires-Dist: tabul
+00000580: 6174 650a 5265 7175 6972 6573 2d44 6973  ate.Requires-Dis
+00000590: 743a 2074 656e 736f 7262 6f61 7264 0a52  t: tensorboard.R
+000005a0: 6571 7569 7265 732d 4469 7374 3a20 7468  equires-Dist: th
+000005b0: 6f70 0a52 6571 7569 7265 732d 4469 7374  op.Requires-Dist
+000005c0: 3a20 746f 7263 680a 5265 7175 6972 6573  : torch.Requires
+000005d0: 2d44 6973 743a 2074 6f72 6368 7265 6964  -Dist: torchreid
+000005e0: 203d 3d30 2e32 2e35 0a52 6571 7569 7265   ==0.2.5.Require
+000005f0: 732d 4469 7374 3a20 746f 7263 6876 6973  s-Dist: torchvis
+00000600: 696f 6e0a 5265 7175 6972 6573 2d44 6973  ion.Requires-Dis
+00000610: 743a 2074 7970 696e 672d 6578 7465 6e73  t: typing-extens
+00000620: 696f 6e73 0a52 6571 7569 7265 732d 4469  ions.Requires-Di
+00000630: 7374 3a20 756c 7472 616c 7974 6963 7320  st: ultralytics 
+00000640: 3d3d 382e 312e 3330 0a52 6571 7569 7265  ==8.1.30.Require
+00000650: 732d 4469 7374 3a20 7768 6565 6c0a 0a23  s-Dist: wheel..#
+00000660: 2041 532d 4f6e 6520 7632 203a 2041 204d   AS-One v2 : A M
+00000670: 6f64 756c 6172 204c 6962 7261 7279 2066  odular Library f
+00000680: 6f72 2059 4f4c 4f20 4f62 6a65 6374 2044  or YOLO Object D
+00000690: 6574 6563 7469 6f6e 2c20 5365 676d 656e  etection, Segmen
+000006a0: 7461 7469 6f6e 2c20 5472 6163 6b69 6e67  tation, Tracking
+000006b0: 2026 2050 6f73 650a 0a0a 0a3c 6469 7620   & Pose....<div 
+000006c0: 616c 6967 6e3d 2263 656e 7465 7222 3e0a  align="center">.
+000006d0: 2020 3c70 3e0a 2020 2020 3c61 2061 6c69    <p>.    <a ali
+000006e0: 676e 3d22 6365 6e74 6572 2220 6872 6566  gn="center" href
+000006f0: 3d22 2220 7461 7267 6574 3d22 6874 7470  ="" target="http
+00000700: 733a 2f2f 6261 6467 652e 6675 7279 2e69  s://badge.fury.i
+00000710: 6f2f 7079 2f61 736f 6e65 223e 0a20 2020  o/py/asone">.   
+00000720: 2020 203c 696d 670a 2020 2020 2020 2020     <img.        
+00000730: 7769 6474 683d 2231 3030 2522 0a20 2020  width="100%".   
+00000740: 2020 2020 2073 7263 3d22 6874 7470 733a       src="https:
+00000750: 2f2f 6b61 6a61 6269 2d73 746f 7265 6672  //kajabi-storefr
+00000760: 6f6e 7473 2d70 726f 6475 6374 696f 6e2e  onts-production.
+00000770: 6b61 6a61 6269 2d63 646e 2e63 6f6d 2f6b  kajabi-cdn.com/k
+00000780: 616a 6162 692d 7374 6f72 6566 726f 6e74  ajabi-storefront
+00000790: 732d 7072 6f64 7563 7469 6f6e 2f66 696c  s-production/fil
+000007a0: 652d 7570 6c6f 6164 732f 7468 656d 6573  e-uploads/themes
+000007b0: 2f32 3135 3134 3030 3031 352f 7365 7474  /2151400015/sett
+000007c0: 696e 6773 5f69 6d61 6765 732f 3734 3733  ings_images/7473
+000007d0: 3637 652d 3164 3738 2d65 6561 642d 3261  67e-1d78-eead-2a
+000007e0: 322d 3765 3562 3333 3661 3737 355f 5363  2-7e5b336a775_Sc
+000007f0: 7265 656e 7368 6f74 5f32 3032 342d 3035  reenshot_2024-05
+00000800: 2d30 385f 6174 5f31 332e 3438 2e30 382e  -08_at_13.48.08.
+00000810: 6a70 6722 2077 6964 7468 3d22 3130 3025  jpg" width="100%
+00000820: 223e 0a20 2020 2020 203c 6120 6872 6566  ">.      <a href
+00000830: 3d22 6874 7470 733a 2f2f 7777 772e 796f  ="https://www.yo
+00000840: 7574 7562 652e 636f 6d2f 7761 7463 683f  utube.com/watch?
+00000850: 763d 4b2d 5663 7050 7763 4d38 6b22 2073  v=K-VcpPwcM8k" s
+00000860: 7479 6c65 3d22 6469 7370 6c61 793a 696e  tyle="display:in
+00000870: 6c69 6e65 2d62 6c6f 636b 3b70 6164 6469  line-block;paddi
+00000880: 6e67 3a31 3070 7820 3230 7078 3b62 6163  ng:10px 20px;bac
+00000890: 6b67 726f 756e 642d 636f 6c6f 723a 7265  kground-color:re
+000008a0: 643b 636f 6c6f 723a 7768 6974 653b 7465  d;color:white;te
+000008b0: 7874 2d64 6563 6f72 6174 696f 6e3a 6e6f  xt-decoration:no
+000008c0: 6e65 3b66 6f6e 742d 7369 7a65 3a31 3670  ne;font-size:16p
+000008d0: 783b 666f 6e74 2d77 6569 6768 743a 626f  x;font-weight:bo
+000008e0: 6c64 3b62 6f72 6465 722d 7261 6469 7573  ld;border-radius
+000008f0: 3a35 7078 3b74 7261 6e73 6974 696f 6e3a  :5px;transition:
+00000900: 6261 636b 6772 6f75 6e64 2d63 6f6c 6f72  background-color
+00000910: 2030 2e33 733b 2220 7461 7267 6574 3d22   0.3s;" target="
+00000920: 5f62 6c61 6e6b 223e 5761 7463 6820 5669  _blank">Watch Vi
+00000930: 6465 6f3c 2f61 3e0a 0a0a 2020 3c2f 703e  deo</a>...  </p>
+00000940: 0a0a 2020 3c62 723e 0a0a 2020 3c62 723e  ..  <br>..  <br>
+00000950: 0a0a 5b21 5b50 7950 4920 7665 7273 696f  ..[![PyPI versio
+00000960: 6e5d 2868 7474 7073 3a2f 2f62 6164 6765  n](https://badge
+00000970: 2e66 7572 792e 696f 2f70 792f 6173 6f6e  .fury.io/py/ason
+00000980: 652e 7376 6729 5d28 6874 7470 733a 2f2f  e.svg)](https://
+00000990: 6261 6467 652e 6675 7279 2e69 6f2f 7079  badge.fury.io/py
+000009a0: 2f61 736f 6e65 290a 5b21 5b70 7974 686f  /asone).[![pytho
+000009b0: 6e2d 7665 7273 696f 6e5d 2868 7474 7073  n-version](https
+000009c0: 3a2f 2f69 6d67 2e73 6869 656c 6473 2e69  ://img.shields.i
+000009d0: 6f2f 7079 7069 2f70 7976 6572 7369 6f6e  o/pypi/pyversion
+000009e0: 732f 7375 7065 7276 6973 696f 6e29 5d28  s/supervision)](
+000009f0: 6874 7470 733a 2f2f 6261 6467 652e 6675  https://badge.fu
+00000a00: 7279 2e69 6f2f 7079 2f61 736f 6e65 290a  ry.io/py/asone).
+00000a10: 5b21 5b63 6f6c 6162 5d28 6874 7470 733a  [![colab](https:
+00000a20: 2f2f 636f 6c61 622e 7265 7365 6172 6368  //colab.research
+00000a30: 2e67 6f6f 676c 652e 636f 6d2f 6173 7365  .google.com/asse
+00000a40: 7473 2f63 6f6c 6162 2d62 6164 6765 2e73  ts/colab-badge.s
+00000a50: 7667 295d 2868 7474 7073 3a2f 2f64 7269  vg)](https://dri
+00000a60: 7665 2e67 6f6f 676c 652e 636f 6d2f 6669  ve.google.com/fi
+00000a70: 6c65 2f64 2f31 7879 3550 3957 4749 3139  le/d/1xy5P9WGI19
+00000a80: 2d50 7a52 4833 6365 4f6d 6f43 6770 3633  -PzRH3ceOmoCgp63
+00000a90: 4b36 4a5f 4c73 2f76 6965 773f 7573 703d  K6J_Ls/view?usp=
+00000aa0: 7368 6172 696e 6729 0a5b 215b 7374 6172  sharing).[![star
+00000ab0: 7420 7769 7468 2077 6879 5d28 6874 7470  t with why](http
+00000ac0: 733a 2f2f 696d 672e 7368 6965 6c64 732e  s://img.shields.
+00000ad0: 696f 2f62 6164 6765 2f76 6572 7369 6f6e  io/badge/version
+00000ae0: 2d32 2e30 2e30 2d67 7265 656e 295d 2868  -2.0.0-green)](h
+00000af0: 7474 7073 3a2f 2f67 6974 6875 622e 636f  ttps://github.co
+00000b00: 6d2f 6175 676d 656e 7465 6473 7461 7274  m/augmentedstart
+00000b10: 7570 732f 4153 2d4f 6e65 290a 5b21 5b47  ups/AS-One).[![G
+00000b20: 504c 7633 204c 6963 656e 7365 5d28 6874  PLv3 License](ht
+00000b30: 7470 733a 2f2f 696d 672e 7368 6965 6c64  tps://img.shield
+00000b40: 732e 696f 2f62 6164 6765 2f4c 6963 656e  s.io/badge/Licen
+00000b50: 7365 2d47 504c 2532 3076 332d 7965 6c6c  se-GPL%20v3-yell
+00000b60: 6f77 2e73 7667 295d 2868 7474 7073 3a2f  ow.svg)](https:/
+00000b70: 2f6f 7065 6e73 6f75 7263 652e 6f72 672f  /opensource.org/
+00000b80: 6c69 6365 6e73 6573 2f29 0a0a 3c2f 6469  licenses/)..</di
+00000b90: 763e 0a0a 2323 20f0 9f91 8b20 4865 6c6c  v>..## .... Hell
+00000ba0: 6f0a 0a3d 3d55 5044 4154 453a 2041 534f  o..==UPDATE: ASO
+00000bb0: 6e65 2076 3220 6973 206e 6f77 206f 7574  ne v2 is now out
+00000bc0: 2120 5765 2776 6520 7570 6461 7465 6420  ! We've updated 
+00000bd0: 7769 7468 2059 4f4c 4f56 3920 616e 6420  with YOLOV9 and 
+00000be0: 5341 4d3d 3d0a 0a41 532d 4f6e 6520 6973  SAM==..AS-One is
+00000bf0: 2061 2070 7974 686f 6e20 7772 6170 7065   a python wrappe
+00000c00: 7220 666f 7220 6d75 6c74 6970 6c65 2064  r for multiple d
+00000c10: 6574 6563 7469 6f6e 2061 6e64 2074 7261  etection and tra
+00000c20: 636b 696e 6720 616c 676f 7269 7468 6d73  cking algorithms
+00000c30: 2061 6c6c 2061 7420 6f6e 6520 706c 6163   all at one plac
+00000c40: 652e 2044 6966 6665 7265 6e74 2074 7261  e. Different tra
+00000c50: 636b 6572 7320 7375 6368 2061 7320 6042  ckers such as `B
+00000c60: 7974 6554 7261 636b 602c 2060 4465 6570  yteTrack`, `Deep
+00000c70: 534f 5254 6020 6f72 2060 4e6f 7246 6169  SORT` or `NorFai
+00000c80: 7260 2063 616e 2062 6520 696e 7465 6772  r` can be integr
+00000c90: 6174 6564 2077 6974 6820 6469 6666 6572  ated with differ
+00000ca0: 656e 7420 7665 7273 696f 6e73 206f 6620  ent versions of 
+00000cb0: 6059 4f4c 4f60 2077 6974 6820 6d69 6e69  `YOLO` with mini
+00000cc0: 6d75 6d20 6c69 6e65 7320 6f66 2063 6f64  mum lines of cod
+00000cd0: 652e 0a54 6869 7320 7079 7468 6f6e 2077  e..This python w
+00000ce0: 7261 7070 6572 2070 726f 7669 6465 7320  rapper provides 
+00000cf0: 594f 4c4f 206d 6f64 656c 7320 696e 2060  YOLO models in `
+00000d00: 4f4e 4e58 602c 2060 5079 546f 7263 6860  ONNX`, `PyTorch`
+00000d10: 2026 2060 436f 7265 4d4c 6020 666c 6176   & `CoreML` flav
+00000d20: 6f72 732e 2057 6520 706c 616e 2074 6f20  ors. We plan to 
+00000d30: 6f66 6665 7220 7375 7070 6f72 7420 666f  offer support fo
+00000d40: 7220 6675 7475 7265 2076 6572 7369 6f6e  r future version
+00000d50: 7320 6f66 2059 4f4c 4f20 7768 656e 2074  s of YOLO when t
+00000d60: 6865 7920 6765 7420 7265 6c65 6173 6564  hey get released
+00000d70: 2e0a 0a54 6869 7320 6973 204f 6e65 204c  ...This is One L
+00000d80: 6962 7261 7279 2066 6f72 206d 6f73 7420  ibrary for most 
+00000d90: 6f66 2079 6f75 7220 636f 6d70 7574 6572  of your computer
+00000da0: 2076 6973 696f 6e20 6e65 6564 732e 0a0a   vision needs...
+00000db0: 4966 2079 6f75 2077 6f75 6c64 206c 696b  If you would lik
+00000dc0: 6520 746f 2064 6976 6520 6465 6570 6572  e to dive deeper
+00000dd0: 2069 6e74 6f20 594f 4c4f 204f 626a 6563   into YOLO Objec
+00000de0: 7420 4465 7465 6374 696f 6e20 616e 6420  t Detection and 
+00000df0: 5472 6163 6b69 6e67 2c20 7468 656e 2063  Tracking, then c
+00000e00: 6865 636b 206f 7574 206f 7572 205b 636f  heck out our [co
+00000e10: 7572 7365 735d 2868 7474 7073 3a2f 2f77  urses](https://w
+00000e20: 7777 2e61 7567 6d65 6e74 6564 7374 6172  ww.augmentedstar
+00000e30: 7475 7073 2e63 6f6d 2f73 746f 7265 2920  tups.com/store) 
+00000e40: 616e 6420 5b70 726f 6a65 6374 735d 2868  and [projects](h
+00000e50: 7474 7073 3a2f 2f73 746f 7265 2e61 7567  ttps://store.aug
+00000e60: 6d65 6e74 6564 7374 6172 7475 7073 2e63  mentedstartups.c
+00000e70: 6f6d 290a 0a5b 3c69 6d67 2073 7263 3d22  om)..[<img src="
+00000e80: 6874 7470 733a 2f2f 7333 2e61 6d61 7a6f  https://s3.amazo
+00000e90: 6e61 7773 2e63 6f6d 2f6b 616a 6162 692d  naws.com/kajabi-
+00000ea0: 7374 6f72 6566 726f 6e74 732d 7072 6f64  storefronts-prod
+00000eb0: 7563 7469 6f6e 2f62 6c6f 6773 2f32 3236  uction/blogs/226
+00000ec0: 3036 2f69 6d61 6765 732f 3046 4478 3833  06/images/0FDx83
+00000ed0: 5658 5359 4f59 304e 414f 326b 4d63 5f41  VXSYOY0NAO2kMc_A
+00000ee0: 534f 6e65 5f57 696e 646f 7773 5f50 6c61  SOne_Windows_Pla
+00000ef0: 792e 6a70 6722 2077 6964 7468 3d22 3530  y.jpg" width="50
+00000f00: 2522 3e5d 2868 7474 7073 3a2f 2f77 7777  %">](https://www
+00000f10: 2e79 6f75 7475 6265 2e63 6f6d 2f77 6174  .youtube.com/wat
+00000f20: 6368 3f76 3d4b 2d56 6370 5077 634d 386b  ch?v=K-VcpPwcM8k
+00000f30: 290a 0a57 6174 6368 2074 6865 2073 7465  )..Watch the ste
+00000f40: 702d 6279 2d73 7465 7020 7475 746f 7269  p-by-step tutori
+00000f50: 616c 20f0 9fa4 9d0a 0a0a 0a23 2320 f09f  al ........## ..
+00000f60: 92bb 2049 6e73 7461 6c6c 0a3c 6465 7461  .. Install.<deta
+00000f70: 696c 733e 3c73 756d 6d61 7279 3e20 f09f  ils><summary> ..
+00000f80: 94a5 2050 7265 7265 7175 6973 6974 6573  .. Prerequisites
+00000f90: 3c2f 7375 6d6d 6172 793e 0a0a 2d20 4d61  </summary>..- Ma
+00000fa0: 6b65 2073 7572 6520 746f 2069 6e73 7461  ke sure to insta
+00000fb0: 6c6c 2060 4750 5560 2064 7269 7665 7273  ll `GPU` drivers
+00000fc0: 2069 6e20 796f 7572 2073 7973 7465 6d20   in your system 
+00000fd0: 6966 2079 6f75 2077 616e 7420 746f 2075  if you want to u
+00000fe0: 7365 2060 4750 5560 202e 2046 6f6c 6c6f  se `GPU` . Follo
+00000ff0: 7720 5b64 7269 7665 7220 696e 7374 616c  w [driver instal
+00001000: 6c61 7469 6f6e 5d28 6173 6f6e 652f 6c69  lation](asone/li
+00001010: 6e75 782f 496e 7374 7275 6374 696f 6e73  nux/Instructions
+00001020: 2f44 7269 7665 722d 496e 7374 616c 6c61  /Driver-Installa
+00001030: 7469 6f6e 732e 6d64 2920 666f 7220 6675  tions.md) for fu
+00001040: 7274 6865 7220 696e 7374 7275 6374 696f  rther instructio
+00001050: 6e73 2e0a 2d20 4d61 6b65 2073 7572 6520  ns..- Make sure 
+00001060: 796f 7520 6861 7665 205b 4d53 2042 7569  you have [MS Bui
+00001070: 6c64 2074 6f6f 6c73 5d28 6874 7470 733a  ld tools](https:
+00001080: 2f2f 616b 612e 6d73 2f76 732f 3137 2f72  //aka.ms/vs/17/r
+00001090: 656c 6561 7365 2f76 735f 4275 696c 6454  elease/vs_BuildT
+000010a0: 6f6f 6c73 2e65 7865 2920 696e 7374 616c  ools.exe) instal
+000010b0: 6c65 6420 696e 2073 7973 7465 6d20 6966  led in system if
+000010c0: 2075 7369 6e67 2077 696e 646f 7773 2e0a   using windows..
+000010d0: 2d20 5b44 6f77 6e6c 6f61 6420 6769 7420  - [Download git 
+000010e0: 666f 7220 7769 6e64 6f77 735d 2868 7474  for windows](htt
+000010f0: 7073 3a2f 2f67 6974 2d73 636d 2e63 6f6d  ps://git-scm.com
+00001100: 2f64 6f77 6e6c 6f61 642f 7769 6e29 2069  /download/win) i
+00001110: 6620 6e6f 7420 696e 7374 616c 6c65 642e  f not installed.
+00001120: 0a3c 2f64 6574 6169 6c73 3e0a 0a60 6060  .</details>..```
+00001130: 6261 7368 0a70 6970 2069 6e73 7461 6c6c  bash.pip install
+00001140: 2061 736f 6e65 0a60 6060 0a0a 3c64 6574   asone.```..<det
+00001150: 6169 6c73 3e0a 3c73 756d 6d61 7279 3e20  ails>.<summary> 
+00001160: f09f 9189 2049 6e73 7461 6c6c 2066 726f  .... Install fro
+00001170: 6d20 536f 7572 6365 3c2f 7375 6d6d 6172  m Source</summar
+00001180: 793e 0a0a 2323 2320 f09f 92be 2043 6c6f  y>..### .... Clo
+00001190: 6e65 2074 6865 2052 6570 6f73 6974 6f72  ne the Repositor
+000011a0: 790a 0a4e 6176 6967 6174 6520 746f 2061  y..Navigate to a
+000011b0: 6e20 656d 7074 7920 666f 6c64 6572 206f  n empty folder o
+000011c0: 6620 796f 7572 2063 686f 6963 652e 0a0a  f your choice...
+000011d0: 6067 6974 2063 6c6f 6e65 2068 7474 7073  `git clone https
+000011e0: 3a2f 2f67 6974 6875 622e 636f 6d2f 6175  ://github.com/au
+000011f0: 676d 656e 7465 6473 7461 7274 7570 732f  gmentedstartups/
+00001200: 4153 2d4f 6e65 2e67 6974 600a 0a43 6861  AS-One.git`..Cha
+00001210: 6e67 6520 4469 7265 6374 6f72 7920 746f  nge Directory to
+00001220: 2041 532d 4f6e 650a 0a60 6364 2041 532d   AS-One..`cd AS-
+00001230: 4f6e 6560 0a0a 3c64 6574 6169 6c73 206f  One`..<details o
+00001240: 7065 6e3e 0a3c 7375 6d6d 6172 793e 20f0  pen>.<summary> .
+00001250: 9f91 8920 466f 7220 4c69 6e75 783c 2f73  ... For Linux</s
+00001260: 756d 6d61 7279 3e0a 0a0a 6060 6073 6865  ummary>...```she
+00001270: 6c6c 0a70 7974 686f 6e33 202d 6d20 7665  ll.python3 -m ve
+00001280: 6e76 202e 656e 760a 736f 7572 6365 202e  nv .env.source .
+00001290: 656e 762f 6269 6e2f 6163 7469 7661 7465  env/bin/activate
+000012a0: 0a0a 7069 7020 696e 7374 616c 6c20 2d72  ..pip install -r
+000012b0: 2072 6571 7569 7265 6d65 6e74 732e 7478   requirements.tx
+000012c0: 740a 0a23 2066 6f72 2043 5055 0a70 6970  t..# for CPU.pip
+000012d0: 2069 6e73 7461 6c6c 2074 6f72 6368 2074   install torch t
+000012e0: 6f72 6368 7669 7369 6f6e 0a23 2066 6f72  orchvision.# for
+000012f0: 2047 5055 0a70 6970 2069 6e73 7461 6c6c   GPU.pip install
+00001300: 2074 6f72 6368 2074 6f72 6368 7669 7369   torch torchvisi
+00001310: 6f6e 202d 2d65 7874 7261 2d69 6e64 6578  on --extra-index
+00001320: 2d75 726c 2068 7474 7073 3a2f 2f64 6f77  -url https://dow
+00001330: 6e6c 6f61 642e 7079 746f 7263 682e 6f72  nload.pytorch.or
+00001340: 672f 7768 6c2f 6375 3131 330a 6060 600a  g/whl/cu113.```.
+00001350: 0a0a 3c2f 6465 7461 696c 733e 0a0a 3c64  ..</details>..<d
+00001360: 6574 6169 6c73 3e0a 3c73 756d 6d61 7279  etails>.<summary
+00001370: 3e20 f09f 9189 2046 6f72 2057 696e 646f  > .... For Windo
+00001380: 7773 2031 302f 3131 3c2f 7375 6d6d 6172  ws 10/11</summar
+00001390: 793e 0a0a 6060 6073 6865 6c6c 0a70 7974  y>..```shell.pyt
+000013a0: 686f 6e20 2d6d 2076 656e 7620 2e65 6e76  hon -m venv .env
+000013b0: 0a2e 656e 765c 5363 7269 7074 735c 6163  ..env\Scripts\ac
+000013c0: 7469 7661 7465 0a70 6970 2069 6e73 7461  tivate.pip insta
+000013d0: 6c6c 206e 756d 7079 2043 7974 686f 6e0a  ll numpy Cython.
+000013e0: 7069 7020 696e 7374 616c 6c20 6c61 700a  pip install lap.
+000013f0: 7069 7020 696e 7374 616c 6c20 2d65 2067  pip install -e g
+00001400: 6974 2b68 7474 7073 3a2f 2f67 6974 6875  it+https://githu
+00001410: 622e 636f 6d2f 7361 6d73 6f6e 2d77 616e  b.com/samson-wan
+00001420: 672f 6379 7468 6f6e 5f62 626f 782e 6769  g/cython_bbox.gi
+00001430: 7423 6567 673d 6379 7468 6f6e 2d62 626f  t#egg=cython-bbo
+00001440: 780a 0a70 6970 2069 6e73 7461 6c6c 2061  x..pip install a
+00001450: 736f 6e65 206f 6e6e 7872 756e 7469 6d65  sone onnxruntime
+00001460: 2d67 7075 3d3d 312e 3132 2e31 0a70 6970  -gpu==1.12.1.pip
+00001470: 2069 6e73 7461 6c6c 2074 7970 696e 675f   install typing_
+00001480: 6578 7465 6e73 696f 6e73 3d3d 342e 372e  extensions==4.7.
+00001490: 310a 7069 7020 696e 7374 616c 6c20 7375  1.pip install su
+000014a0: 7065 722d 6772 6164 6965 6e74 733d 3d33  per-gradients==3
+000014b0: 2e31 2e33 0a23 2066 6f72 2043 5055 0a70  .1.3.# for CPU.p
+000014c0: 6970 2069 6e73 7461 6c6c 2074 6f72 6368  ip install torch
+000014d0: 2074 6f72 6368 7669 7369 6f6e 0a0a 2320   torchvision..# 
+000014e0: 666f 7220 4750 550a 7069 7020 696e 7374  for GPU.pip inst
+000014f0: 616c 6c20 746f 7263 6820 746f 7263 6876  all torch torchv
+00001500: 6973 696f 6e20 2d2d 6578 7472 612d 696e  ision --extra-in
+00001510: 6465 782d 7572 6c20 6874 7470 733a 2f2f  dex-url https://
+00001520: 646f 776e 6c6f 6164 2e70 7974 6f72 6368  download.pytorch
+00001530: 2e6f 7267 2f77 686c 2f63 7531 3133 0a6f  .org/whl/cu113.o
+00001540: 720a 7069 7020 696e 7374 616c 6c20 746f  r.pip install to
+00001550: 7263 683d 3d31 2e31 302e 312b 6375 3131  rch==1.10.1+cu11
+00001560: 3320 746f 7263 6876 6973 696f 6e3d 3d30  3 torchvision==0
+00001570: 2e31 312e 322b 6375 3131 3320 746f 7263  .11.2+cu113 torc
+00001580: 6861 7564 696f 3d3d 3d30 2e31 302e 312b  haudio===0.10.1+
+00001590: 6375 3131 3320 2d66 2068 7474 7073 3a2f  cu113 -f https:/
+000015a0: 2f64 6f77 6e6c 6f61 642e 7079 746f 7263  /download.pytorc
+000015b0: 682e 6f72 672f 7768 6c2f 6375 3131 332f  h.org/whl/cu113/
+000015c0: 746f 7263 685f 7374 6162 6c65 2e68 746d  torch_stable.htm
+000015d0: 6c0a 6060 600a 0a3c 2f64 6574 6169 6c73  l.```..</details
+000015e0: 3e0a 3c64 6574 6169 6c73 3e0a 3c73 756d  >.<details>.<sum
+000015f0: 6d61 7279 3e20 f09f 9189 2046 6f72 204d  mary> .... For M
+00001600: 6163 4f53 3c2f 7375 6d6d 6172 793e 0a0a  acOS</summary>..
+00001610: 6060 6073 6865 6c6c 0a70 7974 686f 6e33  ```shell.python3
+00001620: 202d 6d20 7665 6e76 202e 656e 760a 736f   -m venv .env.so
+00001630: 7572 6365 202e 656e 762f 6269 6e2f 6163  urce .env/bin/ac
+00001640: 7469 7661 7465 0a0a 0a70 6970 2069 6e73  tivate...pip ins
+00001650: 7461 6c6c 202d 7220 7265 7175 6972 656d  tall -r requirem
+00001660: 656e 7473 2e74 7874 0a0a 2320 666f 7220  ents.txt..# for 
+00001670: 4350 550a 7069 7020 696e 7374 616c 6c20  CPU.pip install 
+00001680: 746f 7263 6820 746f 7263 6876 6973 696f  torch torchvisio
+00001690: 6e0a 6060 600a 0a3c 2f64 6574 6169 6c73  n.```..</details
+000016a0: 3e0a 3c2f 6465 7461 696c 733e 0a0a 2323  >.</details>..##
+000016b0: 2020 5175 6963 6b20 5374 6172 7420 f09f    Quick Start ..
+000016c0: 8f83 e280 8de2 9982 efb8 8f0a 0a55 7365  .............Use
+000016d0: 2074 7261 636b 6572 206f 6e20 7361 6d70   tracker on samp
+000016e0: 6c65 2076 6964 656f 2e0a 0a60 6060 7079  le video...```py
+000016f0: 7468 6f6e 0a69 6d70 6f72 7420 6173 6f6e  thon.import ason
+00001700: 650a 6672 6f6d 2061 736f 6e65 2069 6d70  e.from asone imp
+00001710: 6f72 7420 4153 4f6e 650a 0a6d 6f64 656c  ort ASOne..model
+00001720: 203d 2041 534f 6e65 2874 7261 636b 6572   = ASOne(tracker
+00001730: 3d61 736f 6e65 2e42 5954 4554 5241 434b  =asone.BYTETRACK
+00001740: 2c20 6465 7465 6374 6f72 3d61 736f 6e65  , detector=asone
+00001750: 2e59 4f4c 4f56 395f 432c 2075 7365 5f63  .YOLOV9_C, use_c
+00001760: 7564 613d 5472 7565 290a 7472 6163 6b73  uda=True).tracks
+00001770: 203d 206d 6f64 656c 2e76 6964 656f 5f74   = model.video_t
+00001780: 7261 636b 6572 2827 6461 7461 2f73 616d  racker('data/sam
+00001790: 706c 655f 7669 6465 6f73 2f74 6573 742e  ple_videos/test.
+000017a0: 6d70 3427 2c20 6669 6c74 6572 5f63 6c61  mp4', filter_cla
+000017b0: 7373 6573 3d5b 2763 6172 275d 290a 0a66  sses=['car'])..f
+000017c0: 6f72 206d 6f64 656c 5f6f 7574 7075 7420  or model_output 
+000017d0: 696e 2074 7261 636b 733a 0a20 2020 2061  in tracks:.    a
+000017e0: 6e6e 6f74 6174 696f 6e73 203d 2041 534f  nnotations = ASO
+000017f0: 6e65 2e64 7261 7728 6d6f 6465 6c5f 6f75  ne.draw(model_ou
+00001800: 7470 7574 2c20 6469 7370 6c61 793d 4661  tput, display=Fa
+00001810: 6c73 6529 0a60 6060 0a0a 0a23 2323 2052  lse).```...### R
+00001820: 756e 2069 6e20 6047 6f6f 676c 6520 436f  un in `Google Co
+00001830: 6c61 6260 20f0 9f92 bb0a 0a0a 3c61 2068  lab` .......<a h
+00001840: 7265 663d 2268 7474 7073 3a2f 2f64 7269  ref="https://dri
+00001850: 7665 2e67 6f6f 676c 652e 636f 6d2f 6669  ve.google.com/fi
+00001860: 6c65 2f64 2f31 7879 3550 3957 4749 3139  le/d/1xy5P9WGI19
+00001870: 2d50 7a52 4833 6365 4f6d 6f43 6770 3633  -PzRH3ceOmoCgp63
+00001880: 4b36 4a5f 4c73 2f76 6965 773f 7573 703d  K6J_Ls/view?usp=
+00001890: 7368 6172 696e 6722 3e3c 696d 6720 7372  sharing"><img sr
+000018a0: 633d 2268 7474 7073 3a2f 2f63 6f6c 6162  c="https://colab
+000018b0: 2e72 6573 6561 7263 682e 676f 6f67 6c65  .research.google
+000018c0: 2e63 6f6d 2f61 7373 6574 732f 636f 6c61  .com/assets/cola
+000018d0: 622d 6261 6467 652e 7376 6722 2061 6c74  b-badge.svg" alt
+000018e0: 3d22 4f70 656e 2049 6e20 436f 6c61 6222  ="Open In Colab"
+000018f0: 3e3c 2f61 3e0a 0a23 2320 2053 616d 706c  ></a>..##  Sampl
+00001900: 6520 436f 6465 2053 6e69 7070 6574 7320  e Code Snippets 
+00001910: f09f 9383 0a0a 3c64 6574 6169 6c73 3e0a  ......<details>.
+00001920: 3c73 756d 6d61 7279 3e36 2e31 20f0 9f91  <summary>6.1 ...
+00001930: 8920 4f62 6a65 6374 2044 6574 6563 7469  . Object Detecti
+00001940: 6f6e 3c2f 7375 6d6d 6172 793e 0a0a 6060  on</summary>..``
+00001950: 6070 7974 686f 6e0a 696d 706f 7274 2061  `python.import a
+00001960: 736f 6e65 0a66 726f 6d20 6173 6f6e 6520  sone.from asone 
+00001970: 696d 706f 7274 2041 534f 6e65 0a0a 6d6f  import ASOne..mo
+00001980: 6465 6c20 3d20 4153 4f6e 6528 6465 7465  del = ASOne(dete
+00001990: 6374 6f72 3d61 736f 6e65 2e59 4f4c 4f56  ctor=asone.YOLOV
+000019a0: 395f 432c 2075 7365 5f63 7564 613d 5472  9_C, use_cuda=Tr
+000019b0: 7565 2920 2320 5365 7420 7573 655f 6375  ue) # Set use_cu
+000019c0: 6461 2074 6f20 4661 6c73 6520 666f 7220  da to False for 
+000019d0: 6370 750a 7669 6420 3d20 6d6f 6465 6c2e  cpu.vid = model.
+000019e0: 7265 6164 5f76 6964 656f 2827 6461 7461  read_video('data
+000019f0: 2f73 616d 706c 655f 7669 6465 6f73 2f74  /sample_videos/t
+00001a00: 6573 742e 6d70 3427 290a 0a66 6f72 2069  est.mp4')..for i
+00001a10: 6d67 2069 6e20 7669 643a 0a20 2020 2064  mg in vid:.    d
+00001a20: 6574 6563 7469 6f6e 203d 206d 6f64 656c  etection = model
+00001a30: 2e64 6574 6563 7465 7228 696d 6729 0a20  .detecter(img). 
+00001a40: 2020 2061 6e6e 6f74 6174 696f 6e73 203d     annotations =
+00001a50: 2041 534f 6e65 2e64 7261 7728 6465 7465   ASOne.draw(dete
+00001a60: 6374 696f 6e2c 2069 6d67 3d69 6d67 2c20  ction, img=img, 
+00001a70: 6469 7370 6c61 793d 5472 7565 290a 6060  display=True).``
+00001a80: 600a 0a52 756e 2074 6865 2060 6173 6f6e  `..Run the `ason
+00001a90: 652f 6465 6d6f 5f64 6574 6563 746f 722e  e/demo_detector.
+00001aa0: 7079 6020 746f 2074 6573 7420 6465 7465  py` to test dete
+00001ab0: 6374 6f72 2e0a 0a60 6060 7368 656c 6c0a  ctor...```shell.
+00001ac0: 2320 7275 6e20 6f6e 2067 7075 0a70 7974  # run on gpu.pyt
+00001ad0: 686f 6e20 2d6d 2061 736f 6e65 2e64 656d  hon -m asone.dem
+00001ae0: 6f5f 6465 7465 6374 6f72 2064 6174 612f  o_detector data/
+00001af0: 7361 6d70 6c65 5f76 6964 656f 732f 7465  sample_videos/te
+00001b00: 7374 2e6d 7034 0a0a 2320 7275 6e20 6f6e  st.mp4..# run on
+00001b10: 2063 7075 0a70 7974 686f 6e20 2d6d 2061   cpu.python -m a
+00001b20: 736f 6e65 2e64 656d 6f5f 6465 7465 6374  sone.demo_detect
+00001b30: 6f72 2064 6174 612f 7361 6d70 6c65 5f76  or data/sample_v
+00001b40: 6964 656f 732f 7465 7374 2e6d 7034 202d  ideos/test.mp4 -
+00001b50: 2d63 7075 0a60 6060 0a0a 0a3c 6465 7461  -cpu.```...<deta
+00001b60: 696c 733e 0a3c 7375 6d6d 6172 793e 362e  ils>.<summary>6.
+00001b70: 312e 3120 f09f 9189 2055 7365 2043 7573  1.1 .... Use Cus
+00001b80: 746f 6d20 5472 6169 6e65 6420 5765 6967  tom Trained Weig
+00001b90: 6874 7320 666f 7220 4465 7465 6374 6f72  hts for Detector
+00001ba0: 3c2f 7375 6d6d 6172 793e 0a3c 212d 2d20  </summary>.<!-- 
+00001bb0: 2323 2320 362e 312e 3220 5573 6520 4375  ### 6.1.2 Use Cu
+00001bc0: 7374 6f6d 2054 7261 696e 6564 2057 6569  stom Trained Wei
+00001bd0: 6768 7473 202d 2d3e 0a0a 5573 6520 796f  ghts -->..Use yo
+00001be0: 7572 2063 7573 746f 6d20 7765 6967 6874  ur custom weight
+00001bf0: 7320 6f66 2061 2064 6574 6563 746f 7220  s of a detector 
+00001c00: 6d6f 6465 6c20 7472 6169 6e65 6420 6f6e  model trained on
+00001c10: 2063 7573 746f 6d20 6461 7461 2062 7920   custom data by 
+00001c20: 7369 6d70 6c79 2070 726f 7669 6469 6e67  simply providing
+00001c30: 2070 6174 6820 6f66 2074 6865 2077 6569   path of the wei
+00001c40: 6768 7473 2066 696c 652e 0a0a 6060 6070  ghts file...```p
+00001c50: 7974 686f 6e0a 696d 706f 7274 2061 736f  ython.import aso
+00001c60: 6e65 0a66 726f 6d20 6173 6f6e 6520 696d  ne.from asone im
+00001c70: 706f 7274 2041 534f 6e65 0a0a 6d6f 6465  port ASOne..mode
+00001c80: 6c20 3d20 4153 4f6e 6528 6465 7465 6374  l = ASOne(detect
+00001c90: 6f72 3d61 736f 6e65 2e59 4f4c 4f56 395f  or=asone.YOLOV9_
+00001ca0: 432c 2077 6569 6768 7473 3d27 6461 7461  C, weights='data
+00001cb0: 2f63 7573 746f 6d5f 7765 6967 6874 732f  /custom_weights/
+00001cc0: 796f 6c6f 7637 5f63 7573 746f 6d2e 7074  yolov7_custom.pt
+00001cd0: 272c 2075 7365 5f63 7564 613d 5472 7565  ', use_cuda=True
+00001ce0: 2920 2320 5365 7420 7573 655f 6375 6461  ) # Set use_cuda
+00001cf0: 2074 6f20 4661 6c73 6520 666f 7220 6370   to False for cp
+00001d00: 750a 7669 6420 3d20 6d6f 6465 6c2e 7265  u.vid = model.re
+00001d10: 6164 5f76 6964 656f 2827 6461 7461 2f73  ad_video('data/s
+00001d20: 616d 706c 655f 7669 6465 6f73 2f6c 6963  ample_videos/lic
+00001d30: 656e 7365 5f76 6964 656f 2e6d 7034 2729  ense_video.mp4')
+00001d40: 0a0a 666f 7220 696d 6720 696e 2076 6964  ..for img in vid
+00001d50: 3a0a 2020 2020 6465 7465 6374 696f 6e20  :.    detection 
+00001d60: 3d20 6d6f 6465 6c2e 6465 7465 6374 6572  = model.detecter
+00001d70: 2869 6d67 290a 2020 2020 616e 6e6f 7461  (img).    annota
+00001d80: 7469 6f6e 7320 3d20 4153 4f6e 652e 6472  tions = ASOne.dr
+00001d90: 6177 2864 6574 6563 7469 6f6e 2c20 696d  aw(detection, im
+00001da0: 673d 696d 672c 2064 6973 706c 6179 3d54  g=img, display=T
+00001db0: 7275 652c 2063 6c61 7373 5f6e 616d 6573  rue, class_names
+00001dc0: 3d5b 276c 6963 656e 7365 5f70 6c61 7465  =['license_plate
+00001dd0: 275d 290a 6060 600a 0a3c 2f64 6574 6169  ']).```..</detai
+00001de0: 6c73 3e0a 0a3c 6465 7461 696c 733e 0a3c  ls>..<details>.<
+00001df0: 7375 6d6d 6172 793e 362e 312e 3220 f09f  summary>6.1.2 ..
+00001e00: 9189 2043 6861 6e67 696e 6720 4465 7465  .. Changing Dete
+00001e10: 6374 6f72 204d 6f64 656c 7320 3c2f 7375  ctor Models </su
+00001e20: 6d6d 6172 793e 0a0a 4368 616e 6765 2064  mmary>..Change d
+00001e30: 6574 6563 746f 7220 6279 2073 696d 706c  etector by simpl
+00001e40: 7920 6368 616e 6769 6e67 2064 6574 6563  y changing detec
+00001e50: 746f 7220 666c 6167 2e20 5468 6520 666c  tor flag. The fl
+00001e60: 6167 7320 6172 6520 7072 6f76 6964 6564  ags are provided
+00001e70: 2069 6e20 5b62 656e 6368 6d61 726b 5d28   in [benchmark](
+00001e80: 6173 6f6e 652f 6c69 6e75 782f 496e 7374  asone/linux/Inst
+00001e90: 7275 6374 696f 6e73 2f42 656e 6368 6d61  ructions/Benchma
+00001ea0: 726b 696e 672e 6d64 2920 7461 626c 6573  rking.md) tables
+00001eb0: 2e0a 0a2d 204f 7572 206c 6962 7261 7279  ...- Our library
+00001ec0: 206e 6f77 2073 7570 706f 7274 7320 594f   now supports YO
+00001ed0: 4c4f 7635 2c20 594f 4c4f 7637 2c20 616e  LOv5, YOLOv7, an
+00001ee0: 6420 594f 4c4f 7638 206f 6e20 6d61 634f  d YOLOv8 on macO
+00001ef0: 532e 0a0a 6060 6070 7974 686f 6e0a 2320  S...```python.# 
+00001f00: 4368 616e 6765 2064 6574 6563 746f 720a  Change detector.
+00001f10: 6d6f 6465 6c20 3d20 4153 4f6e 6528 6465  model = ASOne(de
+00001f20: 7465 6374 6f72 3d61 736f 6e65 2e59 4f4c  tector=asone.YOL
+00001f30: 4f58 5f53 5f50 5954 4f52 4348 2c20 7573  OX_S_PYTORCH, us
+00001f40: 655f 6375 6461 3d54 7275 6529 0a0a 2320  e_cuda=True)..# 
+00001f50: 466f 7220 6d61 634f 730a 2320 594f 4c4f  For macOs.# YOLO
+00001f60: 350a 6d6f 6465 6c20 3d20 4153 4f6e 6528  5.model = ASOne(
+00001f70: 6465 7465 6374 6f72 3d61 736f 6e65 2e59  detector=asone.Y
+00001f80: 4f4c 4f56 3558 5f4d 4c4d 4f44 454c 290a  OLOV5X_MLMODEL).
+00001f90: 2320 594f 4c4f 370a 6d6f 6465 6c20 3d20  # YOLO7.model = 
+00001fa0: 4153 4f6e 6528 6465 7465 6374 6f72 3d61  ASOne(detector=a
+00001fb0: 736f 6e65 2e59 4f4c 4f56 375f 4d4c 4d4f  sone.YOLOV7_MLMO
+00001fc0: 4445 4c29 0a23 2059 4f4c 4f38 0a6d 6f64  DEL).# YOLO8.mod
+00001fd0: 656c 203d 2041 534f 6e65 2864 6574 6563  el = ASOne(detec
+00001fe0: 746f 723d 6173 6f6e 652e 594f 4c4f 5638  tor=asone.YOLOV8
+00001ff0: 4c5f 4d4c 4d4f 4445 4c29 0a60 6060 0a0a  L_MLMODEL).```..
+00002000: 3c2f 6465 7461 696c 733e 0a0a 3c2f 6465  </details>..</de
+00002010: 7461 696c 733e 0a0a 3c64 6574 6169 6c73  tails>..<details
+00002020: 3e0a 3c73 756d 6d61 7279 3e36 2e32 20f0  >.<summary>6.2 .
+00002030: 9f91 8920 4f62 6a65 6374 2054 7261 636b  ... Object Track
+00002040: 696e 6720 3c2f 7375 6d6d 6172 793e 0a0a  ing </summary>..
+00002050: 5573 6520 7472 6163 6b65 7220 6f6e 2073  Use tracker on s
+00002060: 616d 706c 6520 7669 6465 6f2e 0a0a 6060  ample video...``
+00002070: 6070 7974 686f 6e0a 696d 706f 7274 2061  `python.import a
+00002080: 736f 6e65 0a66 726f 6d20 6173 6f6e 6520  sone.from asone 
+00002090: 696d 706f 7274 2041 534f 6e65 0a0a 2320  import ASOne..# 
+000020a0: 496e 7374 616e 7469 6174 6520 4173 6f6e  Instantiate Ason
+000020b0: 6520 6f62 6a65 6374 0a6d 6f64 656c 203d  e object.model =
+000020c0: 2041 534f 6e65 2874 7261 636b 6572 3d61   ASOne(tracker=a
+000020d0: 736f 6e65 2e42 5954 4554 5241 434b 2c20  sone.BYTETRACK, 
+000020e0: 6465 7465 6374 6f72 3d61 736f 6e65 2e59  detector=asone.Y
+000020f0: 4f4c 4f56 395f 432c 2075 7365 5f63 7564  OLOV9_C, use_cud
+00002100: 613d 5472 7565 2920 2373 6574 2075 7365  a=True) #set use
+00002110: 5f63 7564 613d 4661 6c73 6520 746f 2075  _cuda=False to u
+00002120: 7365 2063 7075 0a74 7261 636b 7320 3d20  se cpu.tracks = 
+00002130: 6d6f 6465 6c2e 7669 6465 6f5f 7472 6163  model.video_trac
+00002140: 6b65 7228 2764 6174 612f 7361 6d70 6c65  ker('data/sample
+00002150: 5f76 6964 656f 732f 7465 7374 2e6d 7034  _videos/test.mp4
+00002160: 272c 2066 696c 7465 725f 636c 6173 7365  ', filter_classe
+00002170: 733d 5b27 6361 7227 5d29 0a0a 2320 4c6f  s=['car'])..# Lo
+00002180: 6f70 206f 7665 7220 7472 6163 6b20 746f  op over track to
+00002190: 2072 6574 7269 6576 6520 6f75 7470 7574   retrieve output
+000021a0: 7320 6f66 2065 6163 6820 6672 616d 650a  s of each frame.
+000021b0: 666f 7220 6d6f 6465 6c5f 6f75 7470 7574  for model_output
+000021c0: 2069 6e20 7472 6163 6b73 3a0a 2020 2020   in tracks:.    
+000021d0: 616e 6e6f 7461 7469 6f6e 7320 3d20 4153  annotations = AS
+000021e0: 4f6e 652e 6472 6177 286d 6f64 656c 5f6f  One.draw(model_o
+000021f0: 7574 7075 742c 2064 6973 706c 6179 3d54  utput, display=T
+00002200: 7275 6529 0a20 2020 2023 2044 6f20 616e  rue).    # Do an
+00002210: 7974 6869 6e67 2077 6974 6820 6262 6f78  ything with bbox
+00002220: 6573 2068 6572 650a 6060 600a 0a5b 4e6f  es here.```..[No
+00002230: 7465 5d20 5573 6520 6361 6e20 7573 6520  te] Use can use 
+00002240: 6375 7374 6f6d 2077 6569 6768 7473 2066  custom weights f
+00002250: 6f72 2061 2064 6574 6563 746f 7220 6d6f  or a detector mo
+00002260: 6465 6c20 6279 2073 696d 706c 7920 7072  del by simply pr
+00002270: 6f76 6964 696e 6720 7061 7468 206f 6620  oviding path of 
+00002280: 7468 6520 7765 6967 6874 7320 6669 6c65  the weights file
+00002290: 2e20 696e 2060 4153 4f6e 6560 2063 6c61  . in `ASOne` cla
+000022a0: 7373 2e0a 0a3c 6465 7461 696c 733e 0a3c  ss...<details>.<
+000022b0: 7375 6d6d 6172 793e 362e 322e 3120 f09f  summary>6.2.1 ..
+000022c0: 9189 2043 6861 6e67 696e 6720 4465 7465  .. Changing Dete
+000022d0: 6374 6f72 2061 6e64 2054 7261 636b 696e  ctor and Trackin
+000022e0: 6720 4d6f 6465 6c73 3c2f 7375 6d6d 6172  g Models</summar
+000022f0: 793e 0a0a 3c21 2d2d 2023 2323 2043 6861  y>..<!-- ### Cha
+00002300: 6e67 696e 6720 4465 7465 6374 6f72 2061  nging Detector a
+00002310: 6e64 2054 7261 636b 696e 6720 4d6f 6465  nd Tracking Mode
+00002320: 6c73 202d 2d3e 0a0a 4368 616e 6765 2054  ls -->..Change T
+00002330: 7261 636b 6572 2062 7920 7369 6d70 6c79  racker by simply
+00002340: 2063 6861 6e67 696e 6720 7468 6520 7472   changing the tr
+00002350: 6163 6b65 7220 666c 6167 2e0a 0a54 6865  acker flag...The
+00002360: 2066 6c61 6773 2061 7265 2070 726f 7669   flags are provi
+00002370: 6465 6420 696e 205b 6265 6e63 686d 6172  ded in [benchmar
+00002380: 6b5d 2861 736f 6e65 2f6c 696e 7578 2f49  k](asone/linux/I
+00002390: 6e73 7472 7563 7469 6f6e 732f 4265 6e63  nstructions/Benc
+000023a0: 686d 6172 6b69 6e67 2e6d 6429 2074 6162  hmarking.md) tab
+000023b0: 6c65 732e 0a0a 6060 6070 7974 686f 6e0a  les...```python.
+000023c0: 6d6f 6465 6c20 3d20 4153 4f6e 6528 7472  model = ASOne(tr
+000023d0: 6163 6b65 723d 6173 6f6e 652e 4259 5445  acker=asone.BYTE
+000023e0: 5452 4143 4b2c 2064 6574 6563 746f 723d  TRACK, detector=
+000023f0: 6173 6f6e 652e 594f 4c4f 5639 5f43 2c20  asone.YOLOV9_C, 
+00002400: 7573 655f 6375 6461 3d54 7275 6529 0a23  use_cuda=True).#
+00002410: 2043 6861 6e67 6520 7472 6163 6b65 720a   Change tracker.
+00002420: 6d6f 6465 6c20 3d20 4153 4f6e 6528 7472  model = ASOne(tr
+00002430: 6163 6b65 723d 6173 6f6e 652e 4445 4550  acker=asone.DEEP
+00002440: 534f 5254 2c20 6465 7465 6374 6f72 3d61  SORT, detector=a
+00002450: 736f 6e65 2e59 4f4c 4f56 395f 432c 2075  sone.YOLOV9_C, u
+00002460: 7365 5f63 7564 613d 5472 7565 290a 6060  se_cuda=True).``
+00002470: 600a 0a60 6060 7079 7468 6f6e 0a23 2043  `..```python.# C
+00002480: 6861 6e67 6520 4465 7465 6374 6f72 0a6d  hange Detector.m
+00002490: 6f64 656c 203d 2041 534f 6e65 2874 7261  odel = ASOne(tra
+000024a0: 636b 6572 3d61 736f 6e65 2e44 4545 5053  cker=asone.DEEPS
+000024b0: 4f52 542c 2064 6574 6563 746f 723d 6173  ORT, detector=as
+000024c0: 6f6e 652e 594f 4c4f 585f 535f 5059 544f  one.YOLOX_S_PYTO
+000024d0: 5243 482c 2075 7365 5f63 7564 613d 5472  RCH, use_cuda=Tr
+000024e0: 7565 290a 6060 600a 0a3c 2f64 6574 6169  ue).```..</detai
+000024f0: 6c73 3e0a 0a52 756e 2074 6865 2060 6173  ls>..Run the `as
+00002500: 6f6e 652f 6465 6d6f 5f74 7261 636b 6572  one/demo_tracker
+00002510: 2e70 7960 2074 6f20 7465 7374 2064 6574  .py` to test det
+00002520: 6563 746f 722e 0a0a 6060 6073 6865 6c6c  ector...```shell
+00002530: 0a23 2072 756e 206f 6e20 6770 750a 7079  .# run on gpu.py
+00002540: 7468 6f6e 202d 6d20 6173 6f6e 652e 6465  thon -m asone.de
+00002550: 6d6f 5f74 7261 636b 6572 2064 6174 612f  mo_tracker data/
+00002560: 7361 6d70 6c65 5f76 6964 656f 732f 7465  sample_videos/te
+00002570: 7374 2e6d 7034 0a0a 2320 7275 6e20 6f6e  st.mp4..# run on
+00002580: 2063 7075 0a70 7974 686f 6e20 2d6d 2061   cpu.python -m a
+00002590: 736f 6e65 2e64 656d 6f5f 7472 6163 6b65  sone.demo_tracke
+000025a0: 7220 6461 7461 2f73 616d 706c 655f 7669  r data/sample_vi
+000025b0: 6465 6f73 2f74 6573 742e 6d70 3420 2d2d  deos/test.mp4 --
+000025c0: 6370 750a 6060 600a 0a3c 2f64 6574 6169  cpu.```..</detai
+000025d0: 6c73 3e0a 0a3c 6465 7461 696c 733e 0a3c  ls>..<details>.<
+000025e0: 7375 6d6d 6172 793e 362e 3320 f09f 9189  summary>6.3 ....
+000025f0: 2053 6567 6d65 6e74 6174 696f 6e3c 2f73   Segmentation</s
+00002600: 756d 6d61 7279 3e0a 0a0a 6060 6070 7974  ummary>...```pyt
+00002610: 686f 6e0a 696d 706f 7274 2061 736f 6e65  hon.import asone
+00002620: 0a66 726f 6d20 6173 6f6e 6520 696d 706f  .from asone impo
+00002630: 7274 2041 534f 6e65 0a0a 6d6f 6465 6c20  rt ASOne..model 
+00002640: 3d20 4153 4f6e 6528 6465 7465 6374 6f72  = ASOne(detector
+00002650: 3d61 736f 6e65 2e59 4f4c 4f56 395f 432c  =asone.YOLOV9_C,
+00002660: 2073 6567 6d65 6e74 6f72 3d61 736f 6e65   segmentor=asone
+00002670: 2e53 414d 2c20 7573 655f 6375 6461 3d54  .SAM, use_cuda=T
+00002680: 7275 6529 2023 7365 7420 7573 655f 6375  rue) #set use_cu
+00002690: 6461 3d46 616c 7365 2074 6f20 7573 6520  da=False to use 
+000026a0: 6370 750a 7472 6163 6b73 203d 206d 6f64  cpu.tracks = mod
+000026b0: 656c 2e76 6964 656f 5f64 6574 6563 7465  el.video_detecte
+000026c0: 7228 2764 6174 612f 7361 6d70 6c65 5f76  r('data/sample_v
+000026d0: 6964 656f 732f 7465 7374 2e6d 7034 272c  ideos/test.mp4',
+000026e0: 2066 696c 7465 725f 636c 6173 7365 733d   filter_classes=
+000026f0: 5b27 6361 7227 5d29 0a0a 666f 7220 6d6f  ['car'])..for mo
+00002700: 6465 6c5f 6f75 7470 7574 2069 6e20 7472  del_output in tr
+00002710: 6163 6b73 3a0a 2020 2020 616e 6e6f 7461  acks:.    annota
+00002720: 7469 6f6e 7320 3d20 4153 4f6e 652e 6472  tions = ASOne.dr
+00002730: 6177 5f6d 6173 6b73 286d 6f64 656c 5f6f  aw_masks(model_o
+00002740: 7574 7075 742c 2064 6973 706c 6179 3d54  utput, display=T
+00002750: 7275 6529 2023 2044 7261 7720 6d61 736b  rue) # Draw mask
+00002760: 730a 6060 600a 3c2f 6465 7461 696c 733e  s.```.</details>
+00002770: 0a0a 3c64 6574 6169 6c73 3e0a 3c73 756d  ..<details>.<sum
+00002780: 6d61 7279 3e36 2e34 20f0 9f91 8920 5465  mary>6.4 .... Te
+00002790: 7874 2044 6574 6563 7469 6f6e 3c2f 7375  xt Detection</su
+000027a0: 6d6d 6172 793e 0a0a 5361 6d70 6c65 2063  mmary>..Sample c
+000027b0: 6f64 6520 746f 2064 6574 6563 7420 7465  ode to detect te
+000027c0: 7874 206f 6e20 616e 2069 6d61 6765 0a0a  xt on an image..
+000027d0: 6060 6070 7974 686f 6e0a 2320 4465 7465  ```python.# Dete
+000027e0: 6374 2061 6e64 2072 6563 6f67 6e69 7a65  ct and recognize
+000027f0: 2074 6578 740a 696d 706f 7274 2061 736f   text.import aso
+00002800: 6e65 0a66 726f 6d20 6173 6f6e 6520 696d  ne.from asone im
+00002810: 706f 7274 2041 534f 6e65 2c20 7574 696c  port ASOne, util
+00002820: 730a 696d 706f 7274 2063 7632 0a0a 6d6f  s.import cv2..mo
+00002830: 6465 6c20 3d20 4153 4f6e 6528 6465 7465  del = ASOne(dete
+00002840: 6374 6f72 3d61 736f 6e65 2e43 5241 4654  ctor=asone.CRAFT
+00002850: 2c20 7265 636f 676e 697a 6572 3d61 736f  , recognizer=aso
+00002860: 6e65 2e45 4153 594f 4352 2c20 7573 655f  ne.EASYOCR, use_
+00002870: 6375 6461 3d54 7275 6529 2023 2053 6574  cuda=True) # Set
+00002880: 2075 7365 5f63 7564 6120 746f 2046 616c   use_cuda to Fal
+00002890: 7365 2066 6f72 2063 7075 0a69 6d67 203d  se for cpu.img =
+000028a0: 2063 7632 2e69 6d72 6561 6428 2764 6174   cv2.imread('dat
+000028b0: 612f 7361 6d70 6c65 5f69 6d67 732f 7361  a/sample_imgs/sa
+000028c0: 6d70 6c65 5f74 6578 742e 6a70 6567 2729  mple_text.jpeg')
+000028d0: 0a72 6573 756c 7473 203d 206d 6f64 656c  .results = model
+000028e0: 2e64 6574 6563 745f 7465 7874 2869 6d67  .detect_text(img
+000028f0: 290a 616e 6e6f 7461 7469 6f6e 7320 3d20  ).annotations = 
+00002900: 7574 696c 732e 6472 6177 5f74 6578 7428  utils.draw_text(
+00002910: 696d 672c 2072 6573 756c 7473 2c20 6469  img, results, di
+00002920: 7370 6c61 793d 5472 7565 290a 6060 600a  splay=True).```.
+00002930: 0a55 7365 2054 7261 636b 6572 206f 6e20  .Use Tracker on 
+00002940: 5465 7874 0a0a 6060 6070 7974 686f 6e0a  Text..```python.
+00002950: 696d 706f 7274 2061 736f 6e65 0a66 726f  import asone.fro
+00002960: 6d20 6173 6f6e 6520 696d 706f 7274 2041  m asone import A
+00002970: 534f 6e65 0a0a 2320 496e 7374 616e 7469  SOne..# Instanti
+00002980: 6174 6520 4173 6f6e 6520 6f62 6a65 6374  ate Asone object
+00002990: 0a6d 6f64 656c 203d 2041 534f 6e65 2874  .model = ASOne(t
+000029a0: 7261 636b 6572 3d61 736f 6e65 2e44 4545  racker=asone.DEE
+000029b0: 5053 4f52 542c 2064 6574 6563 746f 723d  PSORT, detector=
+000029c0: 6173 6f6e 652e 4352 4146 542c 2072 6563  asone.CRAFT, rec
+000029d0: 6f67 6e69 7a65 723d 6173 6f6e 652e 4541  ognizer=asone.EA
+000029e0: 5359 4f43 522c 2075 7365 5f63 7564 613d  SYOCR, use_cuda=
+000029f0: 5472 7565 2920 2373 6574 2075 7365 5f63  True) #set use_c
+00002a00: 7564 613d 4661 6c73 6520 746f 2075 7365  uda=False to use
+00002a10: 2063 7075 0a74 7261 636b 7320 3d20 6d6f   cpu.tracks = mo
+00002a20: 6465 6c2e 7669 6465 6f5f 7472 6163 6b65  del.video_tracke
+00002a30: 7228 2764 6174 612f 7361 6d70 6c65 5f76  r('data/sample_v
+00002a40: 6964 656f 732f 4754 415f 352d 556e 6971  ideos/GTA_5-Uniq
+00002a50: 7565 5f4c 6963 656e 7365 5f50 6c61 7465  ue_License_Plate
+00002a60: 2e6d 7034 2729 0a0a 2320 4c6f 6f70 206f  .mp4')..# Loop o
+00002a70: 7665 7220 7472 6163 6b20 746f 2072 6574  ver track to ret
+00002a80: 7269 6576 6520 6f75 7470 7574 7320 6f66  rieve outputs of
+00002a90: 2065 6163 6820 6672 616d 650a 666f 7220   each frame.for 
+00002aa0: 6d6f 6465 6c5f 6f75 7470 7574 2069 6e20  model_output in 
+00002ab0: 7472 6163 6b73 3a0a 2020 2020 616e 6e6f  tracks:.    anno
+00002ac0: 7461 7469 6f6e 7320 3d20 4153 4f6e 652e  tations = ASOne.
+00002ad0: 6472 6177 286d 6f64 656c 5f6f 7574 7075  draw(model_outpu
+00002ae0: 742c 2064 6973 706c 6179 3d54 7275 6529  t, display=True)
+00002af0: 0a0a 2020 2020 2320 446f 2061 6e79 7468  ..    # Do anyth
+00002b00: 696e 6720 7769 7468 2062 626f 7865 7320  ing with bboxes 
+00002b10: 6865 7265 0a60 6060 0a0a 5275 6e20 7468  here.```..Run th
+00002b20: 6520 6061 736f 6e65 2f64 656d 6f5f 6f63  e `asone/demo_oc
+00002b30: 722e 7079 6020 746f 2074 6573 7420 6f63  r.py` to test oc
+00002b40: 722e 0a0a 6060 6073 6865 6c6c 0a23 2072  r...```shell.# r
+00002b50: 756e 206f 6e20 6770 750a 2070 7974 686f  un on gpu. pytho
+00002b60: 6e20 2d6d 2061 736f 6e65 2e64 656d 6f5f  n -m asone.demo_
+00002b70: 6f63 7220 6461 7461 2f73 616d 706c 655f  ocr data/sample_
+00002b80: 7669 6465 6f73 2f47 5441 5f35 2d55 6e69  videos/GTA_5-Uni
+00002b90: 7175 655f 4c69 6365 6e73 655f 506c 6174  que_License_Plat
+00002ba0: 652e 6d70 340a 0a23 2072 756e 206f 6e20  e.mp4..# run on 
+00002bb0: 6370 750a 2070 7974 686f 6e20 2d6d 2061  cpu. python -m a
+00002bc0: 736f 6e65 2e64 656d 6f5f 6f63 7220 6461  sone.demo_ocr da
+00002bd0: 7461 2f73 616d 706c 655f 7669 6465 6f73  ta/sample_videos
+00002be0: 2f47 5441 5f35 2d55 6e69 7175 655f 4c69  /GTA_5-Unique_Li
+00002bf0: 6365 6e73 655f 506c 6174 652e 6d70 3420  cense_Plate.mp4 
+00002c00: 2d2d 6370 750a 6060 600a 0a3c 2f64 6574  --cpu.```..</det
+00002c10: 6169 6c73 3e0a 0a3c 6465 7461 696c 733e  ails>..<details>
+00002c20: 0a3c 7375 6d6d 6172 793e 362e 3520 f09f  .<summary>6.5 ..
+00002c30: 9189 2050 6f73 6520 4573 7469 6d61 7469  .. Pose Estimati
+00002c40: 6f6e 3c2f 7375 6d6d 6172 793e 0a0a 0a53  on</summary>...S
+00002c50: 616d 706c 6520 636f 6465 2074 6f20 6573  ample code to es
+00002c60: 7469 6d61 7465 2070 6f73 6520 6f6e 2061  timate pose on a
+00002c70: 6e20 696d 6167 650a 0a60 6060 7079 7468  n image..```pyth
+00002c80: 6f6e 0a23 2050 6f73 6520 4573 7469 6d61  on.# Pose Estima
+00002c90: 7469 6f6e 0a69 6d70 6f72 7420 6173 6f6e  tion.import ason
+00002ca0: 650a 6672 6f6d 2061 736f 6e65 2069 6d70  e.from asone imp
+00002cb0: 6f72 7420 506f 7365 4573 7469 6d61 746f  ort PoseEstimato
+00002cc0: 722c 2075 7469 6c73 0a69 6d70 6f72 7420  r, utils.import 
+00002cd0: 6376 320a 0a6d 6f64 656c 203d 2050 6f73  cv2..model = Pos
+00002ce0: 6545 7374 696d 6174 6f72 2865 7374 696d  eEstimator(estim
+00002cf0: 6174 6f72 5f66 6c61 673d 6173 6f6e 652e  ator_flag=asone.
+00002d00: 594f 4c4f 5638 4d5f 504f 5345 2c20 7573  YOLOV8M_POSE, us
+00002d10: 655f 6375 6461 3d54 7275 6529 2023 7365  e_cuda=True) #se
+00002d20: 7420 7573 655f 6375 6461 3d46 616c 7365  t use_cuda=False
+00002d30: 2074 6f20 7573 6520 6370 750a 696d 6720   to use cpu.img 
+00002d40: 3d20 6376 322e 696d 7265 6164 2827 6461  = cv2.imread('da
+00002d50: 7461 2f73 616d 706c 655f 696d 6773 2f74  ta/sample_imgs/t
+00002d60: 6573 7432 2e6a 7067 2729 0a6b 7074 7320  est2.jpg').kpts 
+00002d70: 3d20 6d6f 6465 6c2e 6573 7469 6d61 7465  = model.estimate
+00002d80: 5f69 6d61 6765 2869 6d67 290a 616e 6e6f  _image(img).anno
+00002d90: 7461 7469 6f6e 7320 3d20 7574 696c 732e  tations = utils.
+00002da0: 6472 6177 5f6b 7074 7328 6b70 7473 2c20  draw_kpts(kpts, 
+00002db0: 696d 6167 653d 696d 672c 2064 6973 706c  image=img, displ
+00002dc0: 6179 3d54 7275 6529 0a60 6060 0a0a 2d20  ay=True).```..- 
+00002dd0: 4e6f 7720 796f 7520 6361 6e20 7573 6520  Now you can use 
+00002de0: 596f 6c6f 7638 2061 6e64 2059 6f6c 6f76  Yolov8 and Yolov
+00002df0: 372d 7736 2066 6f72 2070 6f73 6520 6573  7-w6 for pose es
+00002e00: 7469 6d61 7469 6f6e 2e20 5468 6520 666c  timation. The fl
+00002e10: 6167 7320 6172 6520 7072 6f76 6964 6564  ags are provided
+00002e20: 2069 6e20 5b62 656e 6368 6d61 726b 5d28   in [benchmark](
+00002e30: 6173 6f6e 652f 6c69 6e75 782f 496e 7374  asone/linux/Inst
+00002e40: 7275 6374 696f 6e73 2f42 656e 6368 6d61  ructions/Benchma
+00002e50: 726b 696e 672e 6d64 2920 7461 626c 6573  rking.md) tables
+00002e60: 2e0a 0a60 6060 7079 7468 6f6e 0a23 2050  ...```python.# P
+00002e70: 6f73 6520 4573 7469 6d61 7469 6f6e 206f  ose Estimation o
+00002e80: 6e20 7669 6465 6f0a 696d 706f 7274 2061  n video.import a
+00002e90: 736f 6e65 0a66 726f 6d20 6173 6f6e 6520  sone.from asone 
+00002ea0: 696d 706f 7274 2050 6f73 6545 7374 696d  import PoseEstim
+00002eb0: 6174 6f72 2c20 7574 696c 730a 0a6d 6f64  ator, utils..mod
+00002ec0: 656c 203d 2050 6f73 6545 7374 696d 6174  el = PoseEstimat
+00002ed0: 6f72 2865 7374 696d 6174 6f72 5f66 6c61  or(estimator_fla
+00002ee0: 673d 6173 6f6e 652e 594f 4c4f 5637 5f57  g=asone.YOLOV7_W
+00002ef0: 365f 504f 5345 2c20 7573 655f 6375 6461  6_POSE, use_cuda
+00002f00: 3d54 7275 6529 2023 7365 7420 7573 655f  =True) #set use_
+00002f10: 6375 6461 3d46 616c 7365 2074 6f20 7573  cuda=False to us
+00002f20: 6520 6370 750a 6573 7469 6d61 746f 7220  e cpu.estimator 
+00002f30: 3d20 6d6f 6465 6c2e 7669 6465 6f5f 6573  = model.video_es
+00002f40: 7469 6d61 746f 7228 2764 6174 612f 7361  timator('data/sa
+00002f50: 6d70 6c65 5f76 6964 656f 732f 666f 6f74  mple_videos/foot
+00002f60: 6261 6c6c 312e 6d70 3427 290a 666f 7220  ball1.mp4').for 
+00002f70: 6d6f 6465 6c5f 6f75 7470 7574 2069 6e20  model_output in 
+00002f80: 6573 7469 6d61 746f 723a 0a20 2020 2061  estimator:.    a
+00002f90: 6e6e 6f74 6174 696f 6e73 203d 2075 7469  nnotations = uti
+00002fa0: 6c73 2e64 7261 775f 6b70 7473 286d 6f64  ls.draw_kpts(mod
+00002fb0: 656c 5f6f 7574 7075 7429 0a20 2020 2023  el_output).    #
+00002fc0: 2044 6f20 616e 7974 6869 6e67 2077 6974   Do anything wit
+00002fd0: 6820 6b70 7473 2068 6572 650a 6060 600a  h kpts here.```.
+00002fe0: 0a52 756e 2074 6865 2060 6173 6f6e 652f  .Run the `asone/
+00002ff0: 6465 6d6f 5f70 6f73 655f 6573 7469 6d61  demo_pose_estima
+00003000: 746f 722e 7079 6020 746f 2074 6573 7420  tor.py` to test 
+00003010: 506f 7365 2065 7374 696d 6174 696f 6e2e  Pose estimation.
+00003020: 0a0a 6060 6073 6865 6c6c 0a23 2072 756e  ..```shell.# run
+00003030: 206f 6e20 6770 750a 2070 7974 686f 6e20   on gpu. python 
+00003040: 2d6d 2061 736f 6e65 2e64 656d 6f5f 706f  -m asone.demo_po
+00003050: 7365 5f65 7374 696d 6174 6f72 2064 6174  se_estimator dat
+00003060: 612f 7361 6d70 6c65 5f76 6964 656f 732f  a/sample_videos/
+00003070: 666f 6f74 6261 6c6c 312e 6d70 340a 0a23  football1.mp4..#
+00003080: 2072 756e 206f 6e20 6370 750a 2070 7974   run on cpu. pyt
+00003090: 686f 6e20 2d6d 2061 736f 6e65 2e64 656d  hon -m asone.dem
+000030a0: 6f5f 706f 7365 5f65 7374 696d 6174 6f72  o_pose_estimator
+000030b0: 2064 6174 612f 7361 6d70 6c65 5f76 6964   data/sample_vid
+000030c0: 656f 732f 666f 6f74 6261 6c6c 312e 6d70  eos/football1.mp
+000030d0: 3420 2d2d 6370 750a 6060 600a 0a3c 2f64  4 --cpu.```..</d
+000030e0: 6574 6169 6c73 3e0a 0a54 6f20 7365 7475  etails>..To setu
+000030f0: 7020 4153 4f6e 6520 7573 696e 6720 446f  p ASOne using Do
+00003100: 636b 6572 2066 6f6c 6c6f 7720 696e 7374  cker follow inst
+00003110: 7275 6374 696f 6e73 2067 6976 656e 2069  ructions given i
+00003120: 6e20 5b64 6f63 6b65 7220 7365 7475 705d  n [docker setup]
+00003130: 2861 736f 6e65 2f6c 696e 7578 2f49 6e73  (asone/linux/Ins
+00003140: 7472 7563 7469 6f6e 732f 446f 636b 6572  tructions/Docker
+00003150: 2d53 6574 7570 2e6d 6429 f09f 90b3 0a0a  -Setup.md)......
+00003160: 2323 2320 546f 446f 20f0 9f93 9d0a 0a2d  ### ToDo ......-
+00003170: 205b 785d 2046 6972 7374 2052 656c 6561   [x] First Relea
+00003180: 7365 0a2d 205b 785d 2049 6d70 6f72 7420  se.- [x] Import 
+00003190: 7472 6169 6e65 6420 6d6f 6465 6c73 0a2d  trained models.-
+000031a0: 205b 785d 2053 696d 706c 6966 7920 636f   [x] Simplify co
+000031b0: 6465 2065 7665 6e20 6675 7274 6865 720a  de even further.
+000031c0: 2d20 5b78 5d20 5570 6461 7465 6420 666f  - [x] Updated fo
+000031d0: 7220 594f 4c4f 7638 0a2d 205b 785d 204f  r YOLOv8.- [x] O
+000031e0: 4352 2061 6e64 2043 6f75 6e74 696e 670a  CR and Counting.
+000031f0: 2d20 5b78 5d20 4f43 534f 5254 2c20 5374  - [x] OCSORT, St
+00003200: 726f 6e67 534f 5254 2c20 4d6f 5450 790a  rongSORT, MoTPy.
+00003210: 2d20 5b78 5d20 4d31 2f32 2041 7070 6c65  - [x] M1/2 Apple
+00003220: 2053 696c 6963 6f6e 2043 6f6d 7061 7469   Silicon Compati
+00003230: 6269 6c69 7479 0a2d 205b 785d 2050 6f73  bility.- [x] Pos
+00003240: 6520 4573 7469 6d61 7469 6f6e 2059 4f4c  e Estimation YOL
+00003250: 4f76 372f 7638 0a2d 205b 785d 2059 4f4c  Ov7/v8.- [x] YOL
+00003260: 4f2d 4e41 530a 2d20 5b78 5d20 5570 6461  O-NAS.- [x] Upda
+00003270: 7465 6420 666f 7220 594f 4c4f 7638 2e31  ted for YOLOv8.1
+00003280: 0a2d 205b 785d 2059 4f4c 4f56 390a 2d20  .- [x] YOLOV9.- 
+00003290: 5b78 5d20 5341 4d20 496e 7465 6772 6174  [x] SAM Integrat
+000032a0: 696f 6e0a 0a0a 7c20 4f66 6665 7265 6420  ion...| Offered 
+000032b0: 4279 20f0 9f92 bc20 3a20 2020 2020 2020  By .... :       
+000032c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000032f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003340: 2020 2020 2020 2020 2020 207c 204d 6169             | Mai
+00003350: 6e74 6169 6e65 6420 4279 20f0 9f91 a8e2  ntained By .....
+00003360: 808d f09f 92bb 203a 2020 2020 2020 2020  ...... :        
+00003370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000033e0: 2020 2020 2020 2020 2020 2020 7c0a 7c20              |.| 
+000033f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003400: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003410: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003420: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003430: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003440: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003450: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003460: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003470: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003480: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 207c 202d  ------------ | -
+00003490: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000034a0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000034b0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000034c0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000034d0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000034e0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+000034f0: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003500: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003510: 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d 2d2d  ----------------
+00003520: 207c 0a7c 205b 215b 4175 676d 656e 7465   |.| [![Augmente
+00003530: 6453 7461 7275 7073 5d28 6874 7470 733a  dStarups](https:
+00003540: 2f2f 7573 6572 2d69 6d61 6765 732e 6769  //user-images.gi
+00003550: 7468 7562 7573 6572 636f 6e74 656e 742e  thubusercontent.
+00003560: 636f 6d2f 3130 3730 3335 3435 342f 3139  com/107035454/19
+00003570: 3531 3135 3236 332d 6433 3237 3165 6633  5115263-d3271ef3
+00003580: 2d39 3733 622d 3430 6134 2d38 3363 382d  -973b-40a4-83c8-
+00003590: 3061 6465 3837 3237 6464 3430 2e70 6e67  0ade8727dd40.png
+000035a0: 295d 2868 7474 7073 3a2f 2f61 7567 6d65  )](https://augme
+000035b0: 6e74 6564 7374 6172 7475 7073 2e63 6f6d  ntedstartups.com
+000035c0: 2920 7c20 5b21 5b41 7863 656c 6572 6174  ) | [![Axcelerat
+000035d0: 6541 495d 2868 7474 7073 3a2f 2f75 7365  eAI](https://use
+000035e0: 722d 696d 6167 6573 2e67 6974 6875 6275  r-images.githubu
+000035f0: 7365 7263 6f6e 7465 6e74 2e63 6f6d 2f31  sercontent.com/1
+00003600: 3037 3033 3534 3534 2f31 3935 3131 3438  07035454/1951148
+00003610: 3730 2d36 3931 6338 6135 322d 6663 6630  70-691c8a52-fcf0
+00003620: 2d34 3632 652d 3965 3032 2d61 3732 3066  -462e-9e02-a720f
+00003630: 6338 3362 3933 662e 706e 6729 5d28 6874  c83b93f.png)](ht
+00003640: 7470 733a 2f2f 6178 6365 6c65 7261 7465  tps://axcelerate
+00003650: 2e61 692f 2920 7c0a 0a0a                 .ai/) |...
```

## Comparing `asone-0.3.3.dist-info/RECORD` & `asone-2.0.0.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,170 +1,250 @@
-asone/__init__.py,sha256=8Gnz7vdGKMgSRVFMmbwKWY_3alFhqyJ-om7F1fq8Z3E,2850
-asone/asone.py,sha256=w33igfr9JjHR-uMlJ6ttVroHbh_Y36G_yR2p0pvmQ8c,10674
-asone/demo_detector.py,sha256=_QtQhnOEnLaKaoCkZaHFQQcqLuZtiZpVFNdFnBjcj0o,2634
+asone/__init__.py,sha256=5QN3hi8bG7ovvZbYoB8VJN2KBYQajBgg93RVaDn1lYM,3080
+asone/asone.py,sha256=xm6nXLwyMm95D-EAhO4aqmrAOf3b6a3BZ12tOm17EAE,17811
+asone/demo_detector.py,sha256=oasBqRyFJRTC1A4mv1zFEQTOszP_BaJXUiw6IrGbBW0,2639
 asone/demo_ocr.py,sha256=W-pRUC_z52Wb-9_C8f12N25npc3jIy-l0sttn_ylE3M,2149
 asone/demo_pose_estimator.py,sha256=ryQUAcu7LZsVUcJImtEFAMK9zAB0iwMeShljPUNfNd8,2451
+asone/demo_segmentor.py,sha256=ZlaWetoVHGpEPdZCz9Z1gbwyjObArQN92Zl3Q7Kl6bw,2875
 asone/demo_tracker.py,sha256=pWdFogJL3W2yR_UmN4997fGUYe0xiYkfHRHhzx_G3vA,1722
-asone/pose_estimator.py,sha256=v7bKzunE57ppM7B7cRjAaWZ-VI5XxzLvkUa0-kwPa-w,2942
-asone/detectors/__init__.py,sha256=k8C_M140PId6CXC9Pkupjj4hrISCwNyz_7xVyW9DAig,573
-asone/detectors/detector.py,sha256=TytcwUosYhEekYtWYdPe7735d_qqc3__mj_48PznqHg,5450
+asone/pose_estimator.py,sha256=6wqX5ptvjkQjXJL1qxhPXBeA_DOHbsJB9wQ2lDtkSKQ,5527
+asone/detectors/__init__.py,sha256=bRIWEX0oUIbZ32e_WOz4oDfOX_rKd4MRIi-FBbbslTc,652
+asone/detectors/detector.py,sha256=a_ANLkXUVQQ64eeNWg6rrV2kxB_86u8wb2JK2GvtLfE,5272
 asone/detectors/easyocr_detector/__init__.py,sha256=s6CVaMCy-Y4-k7gxZ6jCg28mGp_YxrvweOICgMwbLzc,66
 asone/detectors/easyocr_detector/text_detector.py,sha256=l_Ao5QIO39v2FoXKROrt0wezaToPE9IWGj-HwihfCOk,2094
 asone/detectors/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/utils/cfg_path.py,sha256=meeJjd_Ici6Khmf7YjuTErq4mrJAE1qDqhtXPDFiSn0,533
 asone/detectors/utils/coreml_utils.py,sha256=G4qkahiEnLxHPT_nxI0SAZ7Qy34r3zf036ZSNhsF_Gc,1545
 asone/detectors/utils/exp_name.py,sha256=znQ0oMgfyFSEWI6YOgjekVsGdWOeOI-Uom9BLdL9YNY,1478
-asone/detectors/utils/weights_path.py,sha256=kkET2tvvEtlKCBtP7vJiF1i5_ZGWh13-mFu73aLs-7s,9122
+asone/detectors/utils/weights_path.py,sha256=BiBNClOjG7pqHjXPUEwFSUAJGu9LrOWEEs7B-5eleHY,9796
 asone/detectors/yolonas/__init__.py,sha256=KZhNS-C5my65fEwx8kgnnRU0p6UN8svdT04tc2EuyPU,66
-asone/detectors/yolonas/yolonas.py,sha256=PQzosYKeLuoitNTxNuRt2KZIjhPl02oiNT52R9nh86Q,3957
+asone/detectors/yolonas/yolonas.py,sha256=9Dh6uKF-eq48td436bs__Hzqp9rVNEnK1vKilSahBuE,4038
 asone/detectors/yolor/__init__.py,sha256=rK6ZEZXSC091X3i_towa6w7-DC0ABVOMF3tsUZdqftA,69
-asone/detectors/yolor/yolor_detector.py,sha256=GPfszy9rdsv1F_8kdUScrQdrGcSRzLT6y41lHKiQ_3M,5315
+asone/detectors/yolor/yolor_detector.py,sha256=gQrqTR8MMxsdRQsUVX0mWT66h4L60Sk_moiwSICsXt4,5417
 asone/detectors/yolor/cfg/yolor_csp.cfg,sha256=03194cNE7d-d3freWbD6Jfn1qIl6clliprVW8nHYj8E,14241
 asone/detectors/yolor/cfg/yolor_csp_x.cfg,sha256=jokGophucWBWc7YB5mnBffkUWmojxu-a4Z2aKa54FO8,16338
 asone/detectors/yolor/cfg/yolor_p6.cfg,sha256=4sEvW_-v-cZU9Azpx-oG9eU1RstD4Ni1Q2ZuElCo-6o,18330
 asone/detectors/yolor/models/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 asone/detectors/yolor/models/common.py,sha256=e23HDO0VBXkT__m8Smgq-iY1XCPj7eR16bfDIBvPJjc,38971
 asone/detectors/yolor/models/export.py,sha256=r_e6dF6-5XhrUGZ_YjO2e-tG-e6emErq-ZrmKbI-fEw,2733
 asone/detectors/yolor/models/models.py,sha256=MM7hzFL4Qb40orOqvKG8PYkczYU-NRyJ6CNyeoJp1fo,36694
 asone/detectors/yolor/utils/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 asone/detectors/yolor/utils/activations.py,sha256=mtDs_tL3QwgXUl8M1HnjrUvoS6HTvADvXBHBM1lhGlM,2200
-asone/detectors/yolor/utils/autoanchor.py,sha256=twwl2-CC5YFabKb0_FR8O6cmGuoDJ366-5COUcuygSM,6707
+asone/detectors/yolor/utils/autoanchor.py,sha256=6lt5SkoR0m4Ld0HY4MDvKChQNreCnEFO1w8ran-UO78,6729
 asone/detectors/yolor/utils/datasets.py,sha256=PkjecRmyjak7TxenXCtqt4i7v2hS8fMeO21oaPR7jVk,54966
 asone/detectors/yolor/utils/export.py,sha256=_h6L6YF6QT_cd3if8BC_tbySGvBhhoKEZ3DfPML_ulQ,3310
 asone/detectors/yolor/utils/general.py,sha256=UsRyyBG349uFxQcKXfl9vwx9P9C7gs9e6l9o-vu4SyQ,18709
 asone/detectors/yolor/utils/google_utils.py,sha256=zm_jwK3jEIz33wUW5Ra-M-fSW12Tdo7QpDXQxn0DZjE,4964
 asone/detectors/yolor/utils/layers.py,sha256=2ncCTFxdqM3sDx3E8UUCJKdmzVfvBVyU3YfwXeiRb34,18495
 asone/detectors/yolor/utils/loss.py,sha256=sw3zUfj4lsER3qEllr0oz1P1UcfFYhjcWaQ0fhUUzss,7443
 asone/detectors/yolor/utils/metrics.py,sha256=vmxuZ9LKAHOVZ7L1AFG_xtJC_AYqo8Em2SlPZulAtC8,5137
 asone/detectors/yolor/utils/parse_config.py,sha256=VFeWMavkPpT6ddQW6HIGsdEDMkxWg7gOXlQEM-K0m3o,2995
 asone/detectors/yolor/utils/plots.py,sha256=19Z3Xk4Z28BnPruyoPpeyhKwasZfB4GQNxsIlrUAUdo,15468
 asone/detectors/yolor/utils/torch_utils.py,sha256=jNQVAq95mtTR4G2bRvAx4hczttGddxKtsY465e3IceI,9396
 asone/detectors/yolor/utils/yolor_utils.py,sha256=ABOlxvZM1JNYBiyI61aglpmfx6e8oQYN4pCG0Op8iOU,9267
 asone/detectors/yolov5/__init__.py,sha256=mVVYSOviSotOMReWcSP7Vq3iZWShB34altKnreF_nK0,72
-asone/detectors/yolov5/yolov5_detector.py,sha256=mdx_HJx0Jp08n9ATw6VD1hcaRzknDQg5k1A9VhLGSo4,6417
+asone/detectors/yolov5/yolov5_detector.py,sha256=7ZgAnR32SSVUw7zzhMK13Gv4H3i5PZTKyMC3pfYwd3U,6498
 asone/detectors/yolov5/yolov5/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/detectors/yolov5/yolov5/models/__init__.py,sha256=TkKpSkpmF4gQOK8yHwCN7-VqQqrNAEFyQHfoe88Labg,64
-asone/detectors/yolov5/yolov5/models/common.py,sha256=_r1B3ylrtS5hcY3ifzUXpRRpxl5bpE6ZeVTLb4nUiQ0,36615
+asone/detectors/yolov5/yolov5/export.py,sha256=oUeyoKtPNoDLms0ZPG4LgSnsi1yitRL8_SJXV-rwVto,42563
+asone/detectors/yolov5/yolov5/models/__init__.py,sha256=ddbiNmRvLVuZXXrDmipKS8nJdYq4l2tNEXlDDNIQMXk,70
+asone/detectors/yolov5/yolov5/models/common.py,sha256=zqzFw5_XxTp4N6WnX2WSNmJD13dmxYeUDP3dBTjbfVo,36653
 asone/detectors/yolov5/yolov5/models/experimental.py,sha256=tcQWn9XstiyE22Brmm950pJfgqcq1poO0nnf_-r9oOQ,2340
-asone/detectors/yolov5/yolov5/models/general.py,sha256=31jeYQ-flUCfGY5m9hS_7flMppHIgteOQoxYTFhHlao,42725
+asone/detectors/yolov5/yolov5/models/general.py,sha256=s_PxIgkC34tgOsRARFL2dPS40oRVM35vc9He0vleoYw,42733
+asone/detectors/yolov5/yolov5/models/tf.py,sha256=DZzfoARHYU_31sBZlPwdvdOGHcYUTYl9xhbL4QYuzEM,32135
 asone/detectors/yolov5/yolov5/models/yolo.py,sha256=g7bU0exAXBU2O76Ov82VfhfeIqHQBN9jknVBviv8qzE,15923
 asone/detectors/yolov5/yolov5/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asone/detectors/yolov5/yolov5/utils/activations.py,sha256=gv9yE4qccNujhYfZ53-XL9EfCrenlojtmEFxvOs6MrE,4608
+asone/detectors/yolov5/yolov5/utils/augmentations.py,sha256=OnR3o4nQ2X-r2GfM-luzmIoWu2YzQJzCUWU4EUzvNco,18703
+asone/detectors/yolov5/yolov5/utils/dataloaders.py,sha256=_qh8Ug97P4geksngVo8vkUsv5avT3bXCW83MfYafo4E,60093
+asone/detectors/yolov5/yolov5/utils/downloads.py.py,sha256=Hx9ZohY7rMEHtzo40p98lJgq4QTGI4yKB4RLc-wqkhk,5307
+asone/detectors/yolov5/yolov5/utils/general.py,sha256=NuwhUzJp-KVMeTOl8DAW3j7m9SBgpIM0lMJjnh-OhaE,50965
+asone/detectors/yolov5/yolov5/utils/metrics.py,sha256=VG6JG2xVmD6PfbIWVi46FLlWkVxudf4d_jo0bflEgdY,15500
 asone/detectors/yolov5/yolov5/utils/torch_utils.py,sha256=ripAzFGlzBgVAHq3yABdAwKPLR5dFllIha_8UEAIccc,15973
 asone/detectors/yolov5/yolov5/utils/yolov5_utils.py,sha256=2PiMch361g8JRZkdjQiY3jF2v0ReCeTbLj3UiaXpbMY,8854
 asone/detectors/yolov6/__init__.py,sha256=oSeXuhTzdjjfPm2qaswO_7zpfKnGxr2lvva0BfTe68M,72
-asone/detectors/yolov6/yolov6_detector.py,sha256=9GlyNcNJIBWIswDxBOTqP90nisKotk1igsI_BjY4hKY,5640
+asone/detectors/yolov6/yolov6_detector.py,sha256=djrooUtUokssRGAePYlbieemg9Blptn9vBqiYnzhiUk,5723
 asone/detectors/yolov6/yolov6/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov6/yolov6/assigners/__init__.py,sha256=X3xqE8mFqmAj_kjiyCne4PNYCbOrL9KUrK6_lYM3rFA,85
 asone/detectors/yolov6/yolov6/assigners/anchor_generator.py,sha256=iDVbI8hXCW78iVXrihYaRI2F4H9DzlfoSziwfEDWUHI,2372
 asone/detectors/yolov6/yolov6/assigners/assigner_utils.py,sha256=FX2f4nyocuX3VUetaBo64K-kImrDExUiSAfAGByeWZ0,3682
-asone/detectors/yolov6/yolov6/assigners/atss_assigner.py,sha256=BcmJrCeOzuqSjZSdMAzVLeuqlHIhiJxomROo4u0I4-s,7099
+asone/detectors/yolov6/yolov6/assigners/atss_assigner.py,sha256=UU90-rT_yFtTjZVJNErzrpck7uMZsVspeJ4eyz2PGlA,7145
 asone/detectors/yolov6/yolov6/assigners/iou2d_calculator.py,sha256=RAnX8NlITg8UmY0DNFno8T_5J_LMO8-1Rkm61cnq2rk,9211
-asone/detectors/yolov6/yolov6/assigners/tal_assigner.py,sha256=vFOVn1e-McCPo9R30Pd5SOnmmd6_-5cAPIOw_j8B5hw,6143
+asone/detectors/yolov6/yolov6/assigners/tal_assigner.py,sha256=VLGtHLS_D2GeJx5ETnkZpk9UFqe5wP5Nd8qfeRUp9-Q,6166
 asone/detectors/yolov6/yolov6/layers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/detectors/yolov6/yolov6/layers/common.py,sha256=VBf87pSljZlKdv7GNkvJ0KQnphjzDJLsQ4rxZUwaNfc,18272
+asone/detectors/yolov6/yolov6/layers/common.py,sha256=8cy4YRketcVdyPfDS85GOQM2blVoXK_bVVLz90EFUrg,18295
 asone/detectors/yolov6/yolov6/layers/dbb_transforms.py,sha256=4vDsbE568ozHUPvQm-s4DFxKz4DkP1FHJkNpd1NfjvY,1913
 asone/detectors/yolov6/yolov6/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/detectors/yolov6/yolov6/models/efficientrep.py,sha256=ZtxyMr9u7aFfdcSCNPO1DchylXd_As1iG-S1zzD0fO0,5842
-asone/detectors/yolov6/yolov6/models/effidehead.py,sha256=BJlyRC-HiTpNICI7SvnsnbkdcqXcu0w3O6ghGSknTbU,8278
+asone/detectors/yolov6/yolov6/models/efficientrep.py,sha256=ettm7BF8iaeew0pyoarCFQWE3-i4CaFQ3bHIH6vZSiM,5865
+asone/detectors/yolov6/yolov6/models/effidehead.py,sha256=DiaMjldG-QbNiN9uLDXzWTVC3EkzimKMw581HcCQU0c,8347
 asone/detectors/yolov6/yolov6/models/end2end.py,sha256=Agay9U7TupZnBLr_aYO8qW8WGSPv_IwNX75jhbZKatg,10838
-asone/detectors/yolov6/yolov6/models/loss.py,sha256=-soKHOvhFkSvRmAw2ep6pkpcrbxUIRlMMXcT44eRgic,8760
-asone/detectors/yolov6/yolov6/models/loss_distill.py,sha256=hU0re1r9H9Oct1PdTCDkcKz-fSKG498pCT4kLC7yZ88,13474
-asone/detectors/yolov6/yolov6/models/reppan.py,sha256=SvIYSA_R_-xhd1FA2g0iMbYKqY0pJYRF1vLR3M8nwHc,7217
-asone/detectors/yolov6/yolov6/models/yolo.py,sha256=3yx72C8DlFWwIAOpVXD4Wl5Xe6_kNfIoKA_rooMvLnA,3951
+asone/detectors/yolov6/yolov6/models/loss.py,sha256=5rbGew1wbXben1i3auEaLIoAtTVqT8l7dU4znghIkWs,8875
+asone/detectors/yolov6/yolov6/models/loss_distill.py,sha256=vlpnhzBbVevREOevMf8Ps33Jq5elEsDyiCXuYW0855s,13589
+asone/detectors/yolov6/yolov6/models/reppan.py,sha256=pjSzQRcDBnpu2UQ20Zw6C6JCzWe0rEAHN34mfFFBHa0,7240
+asone/detectors/yolov6/yolov6/models/yolo.py,sha256=osIG35fWsB_ZSQyx4k8PP3XK066C-cofuCLRJDbhw2A,4066
 asone/detectors/yolov6/yolov6/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asone/detectors/yolov6/yolov6/utils/checkpoint.py,sha256=JKosPXUKTIwHB3jXvsVa1unu-7C-7m5F2vPG6A9ryG4,2306
 asone/detectors/yolov6/yolov6/utils/events.py,sha256=CrXv7iKTeK9TPlfdeOsB1S1ZxGxLPy8KScBuB9R-gFw,1880
+asone/detectors/yolov6/yolov6/utils/figure_iou.py,sha256=m4BgLEqK5twut6IrSwr7TGvezGUZkITTF0uhTs-vDYE,5739
 asone/detectors/yolov6/yolov6/utils/general.py,sha256=3chdS9R10j2upvSybru0fhTgqO3jVP4Dk6uOdtRGXUM,2674
-asone/detectors/yolov6/yolov6/utils/torch_utils.py,sha256=uL9fUXbCmW1FNkELYHyOWIfuv8aTZP_u0zIvzJGqYx4,3373
+asone/detectors/yolov6/yolov6/utils/torch_utils.py,sha256=TSzC4ywQ0slZz6YejDlpGKjDOal-9A_I0YYcJUTYSIs,3419
 asone/detectors/yolov6/yolov6/utils/yolov6_utils.py,sha256=QArZQ3UEctSjBNR82Koau6kjDsXuGSMmy3kUIWrqDvk,9628
 asone/detectors/yolov7/__init__.py,sha256=Aykqp9f9UfvAQdGoKhoJv0Q_yb8DbxYEJ7TjUvzEE34,72
-asone/detectors/yolov7/yolov7_detector.py,sha256=b4xz-pr48iw932Wzl4awJF5u-w2vBV_AVXFJhOrcf0E,6904
+asone/detectors/yolov7/yolov7_detector.py,sha256=Dh_WonBz1alKRUDaGZwIgGJX2tWpza3xHWD-0f951YA,6917
 asone/detectors/yolov7/yolov7/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/detectors/yolov7/yolov7/models/__init__.py,sha256=TkKpSkpmF4gQOK8yHwCN7-VqQqrNAEFyQHfoe88Labg,64
+asone/detectors/yolov7/yolov7/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov7/yolov7/models/common.py,sha256=my6xnnGfHEE6sWlFnt1E_eGUsF5JvXKZu1vx8eC41PU,84188
-asone/detectors/yolov7/yolov7/models/experimental.py,sha256=7wh9oPcJtjP9RfFE5b-2uYohD85-dalCrGYkNRzTYYU,1603
+asone/detectors/yolov7/yolov7/models/experimental.py,sha256=ddnWzKvVG-0ulzNGi1kxdtpuKQEGKQBe0xV_KuRAl4Q,1639
 asone/detectors/yolov7/yolov7/models/yolo.py,sha256=zgs6pklpKOEaWMARPatJ5asTjXSuNinRUgG9sidRKRM,41743
 asone/detectors/yolov7/yolov7/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/detectors/yolov7/yolov7/utils/torch_utils.py,sha256=7r4uhQSYmEChWUrNENskL0_ujH-DbEoFQEgoL32eqWw,15467
 asone/detectors/yolov7/yolov7/utils/yolov7_utils.py,sha256=nI3J_QQJ-r1EoQQ4pxDBCJQROh0if2YUZywam2hS7Xo,8212
 asone/detectors/yolov8/__init__.py,sha256=m1DxmLUVuMjSuiiP7p6VdQnm_3Mggf-eRuHfux0nWGs,72
-asone/detectors/yolov8/yolov8_detector.py,sha256=EzulARy8olMhRVGivkyZ67dKJjXAsw6BTMFd4TOe7MI,5911
+asone/detectors/yolov8/yolov8_detector.py,sha256=LnENu350_AI_G-lRNqbDdEFUcuMLlfVUxRxNJb3sKQw,6014
 asone/detectors/yolov8/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-asone/detectors/yolov8/utils/yolov8_utils.py,sha256=zIwOOi5Rdf8JJMBmDn7vWL12sr9VP-ZJN21ve1FeHqo,2043
+asone/detectors/yolov8/utils/yolov8_utils.py,sha256=JY8GDyDOuKE55K0_-A5M3vUDoy1H3q31ATZzxxo2aMA,2033
+asone/detectors/yolov9/__init__.py,sha256=-YcmKN7GUXV12f9o2jl_nhQO_NrtyVoNGMZlm6Q6Rec,72
+asone/detectors/yolov9/export.py,sha256=hfVARe7kXXAY0CzL8Zrflq4qIRQ-YSCDTcQot-Cg12c,32555
+asone/detectors/yolov9/yolov9_detector.py,sha256=j8tu8mRtyVbvIyIr70WsL7fTgnz3NtFUZQDnaBdcOCg,6981
+asone/detectors/yolov9/yolov9/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asone/detectors/yolov9/yolov9/models/__init__.py,sha256=4zALCCxfSyzOKNmB_Y-R1A0iUhPpCOrKbkJ1srJWyxo,7
+asone/detectors/yolov9/yolov9/models/common.py,sha256=_S-EFacQAAlsn1nIHx3Z3tf-8BytI7zRoQfSv6vtX-c,54084
+asone/detectors/yolov9/yolov9/models/experimental.py,sha256=BYozwjwwzoBXLDTvyMjT7HylnTTOYWtaufYuphCqeSo,11697
+asone/detectors/yolov9/yolov9/models/tf.py,sha256=F_Vp7RuQOsncNim1BhwcjZHaNnit_6t57eKBpCfHVQU,26813
+asone/detectors/yolov9/yolov9/models/yolo.py,sha256=dZWfT6AwErmlqRNPELLH_dcuglW0Ws_b4KIL9-zqLhk,38730
+asone/detectors/yolov9/yolov9/utils/__init__.py,sha256=23CMilhWQ-5-SnUjGwqxLKYPtN4y40uXmiMOrTKRNsw,2203
+asone/detectors/yolov9/yolov9/utils/activations.py,sha256=ubcp7mZTmOom53iXfrixEKaHUm68sgFDZErsakelIAY,3373
+asone/detectors/yolov9/yolov9/utils/augmentations.py,sha256=1gYbB0h39doaOiR0Os2Ud4Yh--LIoaUrmGYUcGCOInE,17123
+asone/detectors/yolov9/yolov9/utils/autoanchor.py,sha256=Onkrtu_FubyfLHP-LMEz1_6dOBdhTeSJPedaKiIrv44,7438
+asone/detectors/yolov9/yolov9/utils/autobatch.py,sha256=pBoC_6N9BED0EMAjbeaL_RLV_6uHbwjEo56dye-ZmaY,2977
+asone/detectors/yolov9/yolov9/utils/callbacks.py,sha256=MtizBKHAp1pYt_ftrLEsbfI7CGAzdjWfxuM4umV89Wk,2591
+asone/detectors/yolov9/yolov9/utils/coco_utils.py,sha256=mtGPaf9ycCtaukuhN0uGOeED3UlWICX4CSeShP69A9w,3256
+asone/detectors/yolov9/yolov9/utils/dataloaders.py,sha256=roJeiK0I121yVUnvMEw20KiSVvaSDnDNd8CGjAc1RGo,55706
+asone/detectors/yolov9/yolov9/utils/downloads.py,sha256=h3wsx2i2VYL9Iff3RmoBSygYJ5pa06btGPsobwKr52Y,4641
+asone/detectors/yolov9/yolov9/utils/general.py,sha256=GamiQvJDcsXRRjEu-xTPnQ89gvVspCudlRTFw5Kh8Vc,47085
+asone/detectors/yolov9/yolov9/utils/lion.py,sha256=0gJjzwGVkzuh67umqSVbLgpCFz4QDi-oEUfgUPcIowc,2518
+asone/detectors/yolov9/yolov9/utils/loss.py,sha256=7MlmX4ZD8d2YLVKdqC6lIngEaFBC93yrehQKYtHsNGg,16136
+asone/detectors/yolov9/yolov9/utils/loss_tal.py,sha256=egePOccaCdx7OsB_17-qPGfb8blBxeQOWuYf2pmArwo,9838
+asone/detectors/yolov9/yolov9/utils/loss_tal_dual.py,sha256=0Rqjc87l7SxkxSkSljvfTWuZj5WCXZnA-goAKE05BFo,18187
+asone/detectors/yolov9/yolov9/utils/loss_tal_triple.py,sha256=WVjbzg2Qo09Y1nY8mpBNL1QAIzkareT6lpA95vz8Ha4,13742
+asone/detectors/yolov9/yolov9/utils/metrics.py,sha256=La6PRLYmm2J91ukRYFi4aLoKJ9GlWc_G5Fk7vEQA1Ts,15943
+asone/detectors/yolov9/yolov9/utils/plots.py,sha256=zhE1poJNlzEdCFHlvn5_ecM-7km8fbASkutkO3sZQsk,25358
+asone/detectors/yolov9/yolov9/utils/torch_utils.py,sha256=gNmvoWBi0CUKiX0pugOEme8yY3xCR1rQkiwufho0b2s,23464
+asone/detectors/yolov9/yolov9/utils/triton.py,sha256=rLMZ1wN02UDH0gzyeutcr3KZ_vxV0SFY-4ib3vjHR3M,3528
+asone/detectors/yolov9/yolov9/utils/yolov9_utils.py,sha256=joDvi8o0mpCiN7UlcM4QlOf7sm_JymnAw4EQTyUoSx8,8777
+asone/detectors/yolov9/yolov9/utils/segment/__init__.py,sha256=BIYCj6TRzGWCEbYG5ZNaTHQ4am6c9QVbgS80hLG0blc,6
+asone/detectors/yolov9/yolov9/utils/segment/augmentations.py,sha256=WjCg0oi0lduzxHJRC35ecugFfGpzx2YjsxXjEGow1FQ,3672
+asone/detectors/yolov9/yolov9/utils/segment/dataloaders.py,sha256=SSHzXeqVG2elzCCAc3avW1nnpM03YdXPp8XxqPmNKlM,13855
+asone/detectors/yolov9/yolov9/utils/segment/general.py,sha256=-cwPcaE6c-fhso-SdVAXN7ivZnYtNIrPkbRDxTdb818,4934
+asone/detectors/yolov9/yolov9/utils/segment/loss.py,sha256=0kkB18iZwAKOABIE5i-JCies078FL9P_TDpbeIFgvCc,8620
+asone/detectors/yolov9/yolov9/utils/segment/loss_tal.py,sha256=VuB2RFvRmnynA--RnUqDSYQhyPzw_dkN7lUdr7f9IIw,12024
+asone/detectors/yolov9/yolov9/utils/segment/loss_tal_dual.py,sha256=2UzEdyAUvD2F64DxnHY_NpSd8bMWu2jRUBhbbhiTlCM,34900
+asone/detectors/yolov9/yolov9/utils/segment/metrics.py,sha256=wMKCVhvnJW9k8taaZknirnJ3-QiaIB4Dyljm4H2DIjE,5377
+asone/detectors/yolov9/yolov9/utils/segment/plots.py,sha256=KcLJUiMfSdl04ZuLkhjD73naCZx5C6V__ROSDwQiWQY,6390
+asone/detectors/yolov9/yolov9/utils/segment/tal/__init__.py,sha256=BIYCj6TRzGWCEbYG5ZNaTHQ4am6c9QVbgS80hLG0blc,6
+asone/detectors/yolov9/yolov9/utils/segment/tal/anchor_generator.py,sha256=KaHlNf_sKGEIWNgoKKe79sXW6q6zQikOf4i9KeR7ZAA,1557
+asone/detectors/yolov9/yolov9/utils/segment/tal/assigner.py,sha256=nSLJnFqDGe_OsZnDlCupd8w2DSc6Mr2a_YTgBqtK9W4,8316
+asone/detectors/yolov9/yolov9/utils/tal/__init__.py,sha256=BIYCj6TRzGWCEbYG5ZNaTHQ4am6c9QVbgS80hLG0blc,6
+asone/detectors/yolov9/yolov9/utils/tal/anchor_generator.py,sha256=zTbTzWZMmSQpb_vrEyyCf9msDUD-XNMiWWgpG3MCoM0,1587
+asone/detectors/yolov9/yolov9/utils/tal/assigner.py,sha256=e_ZbWbPRBe8wzkvOmRXwwpSiC_KS6UEIk9feQp2hchM,8231
 asone/detectors/yolox/__init__.py,sha256=7WgNUuH6D8WFO3-Tq6UBCms5mHbxp-bj-TudcocFdIY,69
-asone/detectors/yolox/yolox_detector.py,sha256=-v9Y_In4rUrSYPHz-FyPvTJ0pFgUsrxGmTi3Ok68VII,6573
+asone/detectors/yolox/yolox_detector.py,sha256=F6Je02vubNWJZqqoZsEaQBgeu4TglPutEp4umvH0vbo,6666
 asone/detectors/yolox/yolox_utils.py,sha256=Hnw0iRKDe_rG7ahEjthnmaEm9VAiLtQ06OoR4bqJscA,4277
 asone/detectors/yolox/exps/__init__.py,sha256=G_SRYxMk69Pprvwez5astCZqMghyh56hcN18Fzc2xDA,95
 asone/detectors/yolox/exps/yolov3.py,sha256=g-N5d6-5jWbGQYLARmuK2EbnQUbaFgjxOJjDIgoRF_A,1042
 asone/detectors/yolox/exps/yolox_l.py,sha256=WRMg9fU_5auZ3vUELR7_N7l1gcLkAOpQ8vZSn--3OdU,377
 asone/detectors/yolox/exps/yolox_m.py,sha256=wy3vIOIqZsWt-xXxnowKRbMxkXzjsox1sorAsj3txQ4,379
 asone/detectors/yolox/exps/yolox_nano.py,sha256=9AAioUkMK-SasRm5MUZ61OWmDREsezh_CUiIj0XvT5I,1561
 asone/detectors/yolox/exps/yolox_s.py,sha256=yM2653P9JuLqkV5AqhoCyRuhpWGLSSZdXzSlH7Ll_UE,379
 asone/detectors/yolox/exps/yolox_tiny.py,sha256=9iXkA2AhF3p7DfOO9_-SAAt6hgeAopaKbUYu6qVBO5o,562
 asone/detectors/yolox/exps/yolox_x.py,sha256=vQDRrQXDlR0C7fy356nTvVp2iAVyzoEMK9YuOkBmdVw,379
 asone/detectors/yolox/yolox/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asone/detectors/yolox/yolox/core/__init__.py,sha256=S1aI2luYeKi6b94LW1zytfo5NACpCuV2-4D3YhR5G8U,152
+asone/detectors/yolox/yolox/core/launch.py,sha256=mL27fvLgQHDBjCogoxgJXgWCe8w337bVHDG8AD4Pn_Q,4387
+asone/detectors/yolox/yolox/core/trainer.py,sha256=FIygjQ5py3mbEfElCT4bP9FQ0SHgyCtsL3STGWSsaaY,13707
+asone/detectors/yolox/yolox/data/__init__.py,sha256=OX3JmeCUYgqevMTIdVRSITiupEmpjDvItVY4Q1MLT0c,354
+asone/detectors/yolox/yolox/data/data_augment.py,sha256=-ZsLFWja_eCs2Z8KHiejNkSIU0mDTVWp3GMv5pHuNS0,7360
+asone/detectors/yolox/yolox/data/data_prefetcher.py,sha256=N_MEABfi2s5DByqhTqNFep03TIJaQ8wCwJ9voO5XaUI,1649
+asone/detectors/yolox/yolox/data/dataloading.py,sha256=FsbRWejeqGkJyNNlTGAQobrTyj9ag-hQj_S0UAKJOus,3671
+asone/detectors/yolox/yolox/data/samplers.py,sha256=W1I9s1BEkYHGO7Ubb0z9HxDgjFDvNjUB_IbzpS4DPHQ,2854
+asone/detectors/yolox/yolox/data/datasets/__init__.py,sha256=gk4UJlL8aa4KYNnp8uwlp81lV-dEM8sb1tWjzQ9Mwy8,325
+asone/detectors/yolox/yolox/data/datasets/coco.py,sha256=d2PMNGUi3MKPokZ9YQAYv3fwxRumONBXT0H_9sx_axc,6363
+asone/detectors/yolox/yolox/data/datasets/coco_classes.py,sha256=s4GTxIGnPx9nTO2rnlUbFbObGnqu0-CeFlBTYsxUrVE,1296
+asone/detectors/yolox/yolox/data/datasets/datasets_wrapper.py,sha256=fDeq0l1oAzptYSuoAmpSyLOIjJrclR9JYxcjftiyicE,10878
+asone/detectors/yolox/yolox/data/datasets/mosaicdetection.py,sha256=kfIFs2mmrmQv6gqTgVFTWSCaluQWTahtCXfh0tjjOu0,9573
+asone/detectors/yolox/yolox/data/datasets/voc.py,sha256=5sTIK10-bxQVp_4TSzgjNfz6KtWL7xjbH-KACouaSMY,11946
+asone/detectors/yolox/yolox/data/datasets/voc_classes.py,sha256=xhG2JYVKLNA38fU7lsw9PvAcfqfygTAp3cYyggGeWXI,442
+asone/detectors/yolox/yolox/evaluators/__init__.py,sha256=U0tRC0fSNoM7caQghtqrpW05JJuzpjTRUUCVrMN0R6Q,178
+asone/detectors/yolox/yolox/evaluators/coco_evaluator.py,sha256=8EYXspykTC_duHeaeinukcQC6SNxNK8W5L63N9QcYQI,11467
+asone/detectors/yolox/yolox/evaluators/voc_eval.py,sha256=DJnb4X4WCacXln_6hz63azxUXIwc7MHo40fIKQW0g2M,5631
+asone/detectors/yolox/yolox/evaluators/voc_evaluator.py,sha256=Gs9MgMe_96Py7mIyGhqbtvn1J0POCOBYG4FlHS95jpU,6564
 asone/detectors/yolox/yolox/exp/__init__.py,sha256=HKl5mLYfZ0qyGE8Y2fL94PmOLDBzHuT1XGa5Arnr4Sw,181
 asone/detectors/yolox/yolox/exp/base_exp.py,sha256=oo0GAPlQyAyhsU-I5JCQGOjsa2wQebqGMb3mBGkPwzw,2017
 asone/detectors/yolox/yolox/exp/build.py,sha256=DWm-ti1Yh3cGDfx-efe0cESx7TipsgkKp6Uzt4UZ08w,1334
-asone/detectors/yolox/yolox/exp/yolox_base.py,sha256=uRmzUwzWMGR88LkH8zgKq_WxTvnNqeaXacS-ALzsxkM,11986
+asone/detectors/yolox/yolox/exp/yolox_base.py,sha256=d0DEYQtvOusr4z11pbPhavl4hIBHqz4mLr1YyvtyyK0,12149
 asone/detectors/yolox/yolox/exp/default/__init__.py,sha256=iL7Bt5n3PoEAkAqa_GuZd8jzBHF_cvNzrWgmQl_r6bI,995
 asone/detectors/yolox/yolox/models/__init__.py,sha256=jiRCv0xJPbcb1uhy84QVKk-0x2riUstDAFOA9Yx6hnI,308
-asone/detectors/yolox/yolox/models/build.py,sha256=tU1tJmynzlaHj3ZAfUgIZGqwGWKZoBV-_TIrb5jYqBQ,4266
-asone/detectors/yolox/yolox/models/darknet.py,sha256=NoydtFFm6GNpHPdGCzFNBHko-Q6HRMSSpnO27_m4CfM,6019
+asone/detectors/yolox/yolox/models/build.py,sha256=THiHL84yRaT1rAha7Hd5gd0Fp-Z7TKaSaoBS2l0RIL8,4288
+asone/detectors/yolox/yolox/models/darknet.py,sha256=-oEPhkzZoHUjc6w6JvxYlsXMKTq7LXAHv_YAnwbF3jA,6053
 asone/detectors/yolox/yolox/models/losses.py,sha256=f6aF-0ZTuradWIDD90nt64pMq_5x-t8KzFFRwuqnVwI,1677
 asone/detectors/yolox/yolox/models/network_blocks.py,sha256=9JAkCmdHmfG1SKxMpXHH8-WdTnXv7o6-seJObk4Q0qQ,6092
-asone/detectors/yolox/yolox/models/yolo_fpn.py,sha256=qShIiNNd1pxXecdpfw2XuCki7RHmMqdBvcIM4bgz1Ls,2476
-asone/detectors/yolox/yolox/models/yolo_head.py,sha256=PVlIm7tjPY-477ZM4mNyfWHaHYHIswm0FfowsNvDLv8,23361
-asone/detectors/yolox/yolox/models/yolo_pafpn.py,sha256=hXGvVX9sqs2mHlSBO-S-LXPEoIieH4duxVhgV-su694,3530
-asone/detectors/yolox/yolox/models/yolox.py,sha256=O4jzsZ4nIyq1RCtNLFOyDT8eQPbwk4cdZ0LmlDaPbaA,1364
+asone/detectors/yolox/yolox/models/yolo_fpn.py,sha256=baYdXkfI9LDFCOatUoTDtLIAv7ab_mdDVnUZ5iDh2Hg,2544
+asone/detectors/yolox/yolox/models/yolo_head.py,sha256=KImZ8oEKh3XAXbReKw7nxfMgNuVFkq8reENwBer9oFE,23429
+asone/detectors/yolox/yolox/models/yolo_pafpn.py,sha256=i9OApjAlg4FebrxIUbhoZ1g8sVii2VJHMRX22AG3VUE,3598
+asone/detectors/yolox/yolox/models/yolox.py,sha256=ZFQY60qxPSp_iEBEvKQrqcazDVej3dDrfpzVvJnoCKs,1432
 asone/detectors/yolox/yolox/utils/__init__.py,sha256=GsFKQX_AEgW5aCuE2mFdqMvmrSUuiXkKNTC4RidUKE0,475
-asone/detectors/yolox/yolox/utils/allreduce_norm.py,sha256=z1k0-u_itGxTHpSO1dvMOSMDBSLVERUPgaJi2SUn2-Q,2835
+asone/detectors/yolox/yolox/utils/allreduce_norm.py,sha256=qM9m_yZOe2Ltbu1CJb8qUBw1TLsskT5gSClt5QdmzC0,2868
 asone/detectors/yolox/yolox/utils/boxes.py,sha256=GFtrltHYaTSEdwOfaq1xSTCkoQMxffHBF6_OhWbxojc,4521
 asone/detectors/yolox/yolox/utils/checkpoint.py,sha256=RdsExxMOI0U3sR3RqH0-QTIEZvYWGhyU0ma-3vlODHw,1312
 asone/detectors/yolox/yolox/utils/compat.py,sha256=qPDeyeBWbPCgmiEbwIzke8er1t110jnuhdjAxf4-B84,310
 asone/detectors/yolox/yolox/utils/demo_utils.py,sha256=FDtrxmaTI_AUSvVkjpZpbEDcNyPX2uHQo3Z7GOTF1Ds,3829
 asone/detectors/yolox/yolox/utils/dist.py,sha256=AqUHh8TuD2loOSd2Mm_GlCHj61wmKlrtuRlWBtd8FQU,8062
 asone/detectors/yolox/yolox/utils/ema.py,sha256=FDIU-3eYZsuwC1eNIHi1yHCiPJ9FtUV4xcbqxHEM9io,2073
 asone/detectors/yolox/yolox/utils/logger.py,sha256=U9sb_QGDpPhEqVseff6XKj9zR9zzu7I2z5nCFbs6hrw,12664
 asone/detectors/yolox/yolox/utils/lr_scheduler.py,sha256=TQaqH6FUTAocRFXsP77SYXiYaLkQKz7FvFf8COnE5KY,6551
 asone/detectors/yolox/yolox/utils/metric.py,sha256=LXRhsN4cZGhfIFjLNSYI4myxkWPnNcVGVMIWLQvu_5A,3256
-asone/detectors/yolox/yolox/utils/model_utils.py,sha256=RYXdNuZdCqjFTz-tBo-tCzrJEYqeWhAdRzJUOIyOYas,5614
-asone/detectors/yolox/yolox/utils/setup_env.py,sha256=CdBa4qyatCIyzsvjvwGG7LiXkqFk6Vyg_LH8edf0gpY,2675
+asone/detectors/yolox/yolox/utils/model_utils.py,sha256=41BeYc-Vb3CtufuZz8ijbaeC2vD2EkWuSezlu2KOnIg,5636
+asone/detectors/yolox/yolox/utils/setup_env.py,sha256=a_bFZonigwCUtDsqQqcCr_-_O_Uf1KRsBJE5sUm9ADE,2708
 asone/detectors/yolox/yolox/utils/visualize.py,sha256=RvOyoU2Dge0CLivJC1k1gAcPFBlbcxCi6SrFNuiXaA4,3599
 asone/pose_estimators/__init__.py,sha256=WmuqTxEeODCG2wZt_iQxEQo504WeUNRh9osUsibivhc,146
 asone/pose_estimators/yolov7_pose/__init__.py,sha256=RZjVURBPfRk1mxVqfEevY1tobi1uIcOEA9g0wsZDadM,73
 asone/pose_estimators/yolov7_pose/main.py,sha256=hZETW1zmPD9fYFQdK__Av8w-CH9ABLqcPLm9D65BnxY,1001
-asone/pose_estimators/yolov7_pose/yolov7.py,sha256=1zPHBdV9r2NmFOBkjITSXcZKxg4rkXSXp6Ap0e6fWQU,2538
+asone/pose_estimators/yolov7_pose/yolov7.py,sha256=cUxZFyx-r6INXENO7bkvfrw1ujWOH2VR-6N0C961wjM,2703
 asone/pose_estimators/yolov7_pose/models/__init__.py,sha256=BIYCj6TRzGWCEbYG5ZNaTHQ4am6c9QVbgS80hLG0blc,6
 asone/pose_estimators/yolov7_pose/models/common.py,sha256=lloxRUfpWjCV-hTIJ_Y-u-gkbHjSgxieME8rodK9JDQ,86543
-asone/pose_estimators/yolov7_pose/models/experimental.py,sha256=kwrhVL_nfV_ypJg7uLJ8x8xQ-pJUpHqywh_FSQY9jTQ,10697
-asone/pose_estimators/yolov7_pose/models/yolo.py,sha256=RCNmI0ZqnPcLQtzS4Ouuuh30SlrzZ3_xn9Qw0ewsEjU,36966
+asone/pose_estimators/yolov7_pose/models/experimental.py,sha256=vJm1Zck6PJrY3OKtfq-vvKe3HroHyrGs7csLBpRQzyA,10737
+asone/pose_estimators/yolov7_pose/models/yolo.py,sha256=1MoZG0C0vY7vEYV-RRbwtrxUOZ2tONqvz4-4BfDydpo,37172
 asone/pose_estimators/yolov7_pose/utils/__init__.py,sha256=BIYCj6TRzGWCEbYG5ZNaTHQ4am6c9QVbgS80hLG0blc,6
 asone/pose_estimators/yolov7_pose/utils/activations.py,sha256=na7PWP8OM-cPNFzRR9g79V5kA4JibtgGs-v_iADjgZE,2320
 asone/pose_estimators/yolov7_pose/utils/add_nms.py,sha256=eYIBaAG91u78-omD6lp79dvR_qDRg_Ah6ZrfsPD8ACc,5795
-asone/pose_estimators/yolov7_pose/utils/autoanchor.py,sha256=0EYFblHLjWtLRJhgjW0V8aQ1b4M8H1TEDxm_ewW1yWg,7307
-asone/pose_estimators/yolov7_pose/utils/datasets.py,sha256=_OGM_vmy_SmVT1mBdeQ2C7vTxa7FseUyuptfcQ4n7ww,57539
-asone/pose_estimators/yolov7_pose/utils/general.py,sha256=4q9zkI9XcBHDN_gpQbk7DjIA6HjebFxKB7DvurOcPUw,37568
+asone/pose_estimators/yolov7_pose/utils/autoanchor.py,sha256=fieh-aOHbrOyeudek86Dz_j8qJEILW0KAi1c0kWM-hw,7375
+asone/pose_estimators/yolov7_pose/utils/datasets.py,sha256=-zT1klat7PBN0sDxeNJSLms96W5kw2kLBMs7xoT95os,57617
+asone/pose_estimators/yolov7_pose/utils/general.py,sha256=0o9xkFKlrhxXsnUGc_34RVPE-_DG7gafjJvbSAqym-I,37685
 asone/pose_estimators/yolov7_pose/utils/google_utils.py,sha256=LLudErDiY9rWUcQ4-xofDPNcxUCd_y3MF4xi2109pTo,4875
-asone/pose_estimators/yolov7_pose/utils/loss.py,sha256=WLNH4WrH7v2WIPNr1S8BcQONv6eL-1ELPiuiMzP7EYA,76641
-asone/pose_estimators/yolov7_pose/utils/metrics.py,sha256=OP7TiaKtpwD8Dr1yF1kIrDXDMjQuLkasva7m15yd58s,9192
-asone/pose_estimators/yolov7_pose/utils/plots.py,sha256=X_ZB38g_Y-NSjxqTfdqr4lhebYpi0ypmYahHo7FvUvE,23225
+asone/pose_estimators/yolov7_pose/utils/loss.py,sha256=R2Xd1aGaEwdAqJry75Vj7BOpBiR4rz-3bZyX95Y9xis,76709
+asone/pose_estimators/yolov7_pose/utils/metrics.py,sha256=p2OEuM5RYDXBWHBBbIKeDpf6BcJWM9Rt6r0ptiTCg5c,9230
+asone/pose_estimators/yolov7_pose/utils/plots.py,sha256=Q67nlLtXHVgYxQ8co0wRNOgjzzTJ6A4FjBg9ALUVR7M,23303
 asone/pose_estimators/yolov7_pose/utils/torch_utils.py,sha256=ljnIdmvAYIoRelsU17MZW_YqlOOdvEbWURQ1jfTF2aA,15840
 asone/pose_estimators/yolov7_pose/utils/yolov7_pose_utils.py,sha256=3fyjUEYqKmk3hzl0Y4bdcucJ7q2LCNYsarDFmhD2o7E,640
 asone/pose_estimators/yolov7_pose/utils/wandb_logging/__init__.py,sha256=BIYCj6TRzGWCEbYG5ZNaTHQ4am6c9QVbgS80hLG0blc,6
 asone/pose_estimators/yolov7_pose/utils/wandb_logging/log_dataset.py,sha256=eYEewzZgk9JhtbFKdZewidwNRsZJwJzsuVzejH8XIK4,839
-asone/pose_estimators/yolov7_pose/utils/wandb_logging/wandb_utils.py,sha256=3aA1xf2LmF4n3HBRmp2rWWt-ZxSX7rX8QO22hVU61mw,16571
+asone/pose_estimators/yolov7_pose/utils/wandb_logging/wandb_utils.py,sha256=zJ-dVpoA8SNLZpkogE4ft-W5TzbmkVQjfIsMyXT6M5o,16573
 asone/pose_estimators/yolov8_pose/__init__.py,sha256=LevsfmGYmcKNkJZXEb7ADgKh5Q5ZftyJjaWkOZsrAtw,73
 asone/pose_estimators/yolov8_pose/plots.py,sha256=M4bmDkpiAJpBd4YRZrdZxdOrnBc_slaYIAXdkyEjTrM,22441
 asone/pose_estimators/yolov8_pose/yolov8.py,sha256=S3lGg3oGzN8-SKlGTbAObnhxc7jSuwMB747MJHwhHdA,374
 asone/recognizers/__init__.py,sha256=nSJykZSpyOaIhmAJa2zHzD5xge7Wpr0ai7_oe3j0gCQ,182
 asone/recognizers/recognizer.py,sha256=HNLdohgno698w1D-TIp_eSLKV7uu3ltzHea4lfCKb90,933
 asone/recognizers/easyocr_recognizer/__init__.py,sha256=9EmmhNjR4M2YetUFG4XibRUF_heBynSrcos_LzDgAtQ,81
 asone/recognizers/easyocr_recognizer/easyocr_recognizer.py,sha256=8doZktZo4J2t8-TsiFIjCqOcK0BpyxCbX9UektFPj4s,1721
 asone/recognizers/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/recognizers/utils/recognizer_name.py,sha256=L_o9qS77PevQ8JTvOJTc2df0WYDXHDhn2tsgRaql3S8,196
+asone/segmentors/__init__.py,sha256=qlbWtqKmmUqbhpnPbaW4MX0HoyalJkk7bH1xp9nX5lE,74
+asone/segmentors/segmentor.py,sha256=23aOySmftXmewU9kvN8PcB-fEPpERTghaPqrg4UZicM,856
+asone/segmentors/segment_anything/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asone/segmentors/segment_anything/sam.py,sha256=nhMUJ9sfgCISf4MEB3_BmoZwYtAhK5Y7ss0lu3mRd0o,1872
+asone/segmentors/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+asone/segmentors/utils/weights_path.py,sha256=hvhF9_7sVb5nf7P3VRRqm6YLDfU0TPyoOD5BRwofENk,256
 asone/trackers/__init__.py,sha256=KThEUR5sY7Ra7Zi-74OSFNrz0aXe_czHbI2TK34mqXI,458
 asone/trackers/tracker.py,sha256=fFy22t2-X2EXhNb4-yeu8UoHwENDUjOg3OZgnFtU38M,1157
 asone/trackers/byte_track/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/trackers/byte_track/bytetracker.py,sha256=dYytRf4ZUYSfjbO073rwUQpZ_gpHxHh526nFjTCB1CA,2252
 asone/trackers/byte_track/tracker/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 asone/trackers/byte_track/tracker/basetrack.py,sha256=6DsGdsXkZ1fAqx4lPzksbCNGkNTa38_MyYawfXvCGq4,950
 asone/trackers/byte_track/tracker/byte_tracker.py,sha256=ZMi71j1QXm12eqgWKIa7xOvV-xo95_9k8A8_P-or8x8,11950
@@ -225,19 +305,21 @@
 asone/trackers/strong_sort/tracker/utils/log.py,sha256=ruYuKeq0CM8Vz17AH7YnnnCscMH2nCHOgqZkYCAhu5M,463
 asone/trackers/strong_sort/tracker/utils/parser.py,sha256=N_Rsu_XjVL07YhmHaHXX8uSKNJ3Ahqy-EUH07ugxmUk,1078
 asone/trackers/strong_sort/tracker/utils/tools.py,sha256=AqR1I_jgJmFMcubeKEGX-fc96AKa-x4EnIM6QA4aSY8,734
 asone/utils/__init__.py,sha256=ijJMciLhSXbW7EHWEzYT4oD0Ybzxs8BH8HboNBVZy9Q,581
 asone/utils/classes.py,sha256=ajXF6VM_0K1_9hmgb02zb1_wWM_OV4G-9Z8vtHQSoVY,1066
 asone/utils/colors.py,sha256=wfraLg9ULR0wLTz4UbAh2fkhXrvmRrODDEbbXNqHHIY,697
 asone/utils/counting.py,sha256=PThbapxvLFn6ftbEbV9kxHvWmBuXLglR33-athJa8EQ,558
-asone/utils/default_cfg.py,sha256=UzCAEVMGSLbeqYgmr3y5-F3rgXCVqdB8Hm7nPsOlMhU,358
-asone/utils/download.py,sha256=vz4xD9pW6PzToYeVGMD3_GT77IEaVn1R0wiiHSTcZQ4,5728
-asone/utils/draw.py,sha256=z_7MMSEQy14uOv-d-_mOhEKd3ZLTVm3_uqby-VlgOxU,11844
+asone/utils/default_cfg.py,sha256=J2TAJgO0pg4AghDEEbS5gGyGv5XruDvnLOK9ov94DCA,359
+asone/utils/download.py,sha256=Qy3jQ3PjKkmmHtnSSV7ZJspjb8guAqR8PWoKdGvBizI,6374
+asone/utils/draw.py,sha256=3zqyVELuJUFl2IDvvqWvb7uo7HC4wZ8Pqi7JIg9QCp8,12218
 asone/utils/ponits_conversion.py,sha256=rlPuPNplz2WzsIQScS4xRvwxkDKr18WI2kr9HI3W-iY,864
 asone/utils/pose_estimators_weights.py,sha256=d66imkevci3qQYD9u-XScWrJ2LnM_bNVuIGZzBePFcQ,1017
 asone/utils/temp_loader.py,sha256=K8NRezJkFkB_XQbcgkl1-h1pTWRV528ntqMwXuABaCs,796
-asone-0.3.3.dist-info/LICENCE,sha256=ixuiBLtpoK3iv89l7ylKkg9rs2GzF9ukPH7ynZYzK5s,35148
-asone-0.3.3.dist-info/METADATA,sha256=xONknUFiX-7cV4OQOhipP3jqgeRZjHiBlqH1Sx-5Hvk,14376
-asone-0.3.3.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-asone-0.3.3.dist-info/dependency_links.txt,sha256=Yt-SL99DmwySbgxGwJLEZqCU9bLw-mgok8v_E4vqBlE,72
-asone-0.3.3.dist-info/top_level.txt,sha256=n-xJvkjLnGLv_U9fB26iIIWEXbTcOkw2hvrAPeWaPUE,6
-asone-0.3.3.dist-info/RECORD,,
+asone/utils/utils.py,sha256=yupY4VMa88G4IBA5s6u0eRp3m_AXGJlbcUofQXB4LmE,552
+asone/utils/video_reader.py,sha256=HsgDy9lSWEBcbbKfdQMXtYS12GffRtu0ohtY8WghLFc,1096
+asone-2.0.0.dist-info/LICENCE,sha256=ixuiBLtpoK3iv89l7ylKkg9rs2GzF9ukPH7ynZYzK5s,35148
+asone-2.0.0.dist-info/METADATA,sha256=dJRdWmWDlFQM7AqSxo3amY2Gi13KfL7FOwFmgcmbvlk,13914
+asone-2.0.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+asone-2.0.0.dist-info/dependency_links.txt,sha256=Yt-SL99DmwySbgxGwJLEZqCU9bLw-mgok8v_E4vqBlE,72
+asone-2.0.0.dist-info/top_level.txt,sha256=n-xJvkjLnGLv_U9fB26iIIWEXbTcOkw2hvrAPeWaPUE,6
+asone-2.0.0.dist-info/RECORD,,
```

