# Comparing `tmp/ms1searchpy-2.7.3-py3-none-any.whl.zip` & `tmp/ms1searchpy-2.8.2-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,19 +1,20 @@
-Zip file size: 8553054 bytes, number of entries: 17
+Zip file size: 8559135 bytes, number of entries: 18
 -rw-r--r--  2.0 unx        0 b- defN 23-Mar-16 13:01 ms1searchpy/__init__.py
--rw-r--r--  2.0 unx     4185 b- defN 23-Mar-16 13:01 ms1searchpy/combine.py
+-rw-r--r--  2.0 unx     4236 b- defN 24-Apr-24 10:36 ms1searchpy/combine.py
 -rw-r--r--  2.0 unx     2746 b- defN 23-Mar-16 13:01 ms1searchpy/combine_proteins.py
--rw-r--r--  2.0 unx    24852 b- defN 24-Mar-29 12:18 ms1searchpy/directms1quant.py
--rw-r--r--  2.0 unx     6005 b- defN 24-Mar-20 15:41 ms1searchpy/group_specific.py
+-rw-r--r--  2.0 unx    24852 b- defN 24-Apr-24 14:12 ms1searchpy/directms1quant.py
+-rw-r--r--  2.0 unx    16412 b- defN 24-Apr-26 10:40 ms1searchpy/directms1quantmulti.py
+-rw-r--r--  2.0 unx     7218 b- defN 24-May-14 13:38 ms1searchpy/group_specific.py
 -rw-r--r--  2.0 unx    84395 b- defN 24-Mar-29 14:28 ms1searchpy/main.py
 -rw-r--r--  2.0 unx     7413 b- defN 23-Mar-16 13:01 ms1searchpy/ms1todiffacto.py
 -rw-r--r--  2.0 unx     5074 b- defN 24-Mar-14 15:01 ms1searchpy/search.py
 -rw-r--r--  2.0 unx    14862 b- defN 24-Jan-26 14:14 ms1searchpy/utils.py
 -rw-r--r--  2.0 unx    15305 b- defN 24-Mar-14 15:25 ms1searchpy/utils_figures.py
 -rw-r--r--  2.0 unx  9177032 b- defN 24-Jan-15 09:44 ms1searchpy/models/CSD_model_LCMSMS.hdf5
--rwxr-xr-x  2.0 unx      551 b- defN 24-Mar-29 14:54 ms1searchpy-2.7.3.dist-info/LICENSE
--rw-r--r--  2.0 unx     5771 b- defN 24-Mar-29 14:54 ms1searchpy-2.7.3.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Mar-29 14:54 ms1searchpy-2.7.3.dist-info/WHEEL
--rw-r--r--  2.0 unx      434 b- defN 24-Mar-29 14:54 ms1searchpy-2.7.3.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       12 b- defN 24-Mar-29 14:54 ms1searchpy-2.7.3.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1426 b- defN 24-Mar-29 14:54 ms1searchpy-2.7.3.dist-info/RECORD
-17 files, 9350155 bytes uncompressed, 8550714 bytes compressed:  8.6%
+-rwxr-xr-x  2.0 unx      551 b- defN 24-May-14 13:44 ms1searchpy-2.8.2.dist-info/LICENSE
+-rw-r--r--  2.0 unx     8712 b- defN 24-May-14 13:44 ms1searchpy-2.8.2.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-14 13:44 ms1searchpy-2.8.2.dist-info/WHEEL
+-rw-r--r--  2.0 unx      492 b- defN 24-May-14 13:44 ms1searchpy-2.8.2.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       12 b- defN 24-May-14 13:44 ms1searchpy-2.8.2.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1518 b- defN 24-May-14 13:44 ms1searchpy-2.8.2.dist-info/RECORD
+18 files, 9370922 bytes uncompressed, 8556651 bytes compressed:  8.7%
```

## zipnote {}

```diff
@@ -6,14 +6,17 @@
 
 Filename: ms1searchpy/combine_proteins.py
 Comment: 
 
 Filename: ms1searchpy/directms1quant.py
 Comment: 
 
+Filename: ms1searchpy/directms1quantmulti.py
+Comment: 
+
 Filename: ms1searchpy/group_specific.py
 Comment: 
 
 Filename: ms1searchpy/main.py
 Comment: 
 
 Filename: ms1searchpy/ms1todiffacto.py
@@ -27,26 +30,26 @@
 
 Filename: ms1searchpy/utils_figures.py
 Comment: 
 
 Filename: ms1searchpy/models/CSD_model_LCMSMS.hdf5
 Comment: 
 
-Filename: ms1searchpy-2.7.3.dist-info/LICENSE
+Filename: ms1searchpy-2.8.2.dist-info/LICENSE
 Comment: 
 
-Filename: ms1searchpy-2.7.3.dist-info/METADATA
+Filename: ms1searchpy-2.8.2.dist-info/METADATA
 Comment: 
 
-Filename: ms1searchpy-2.7.3.dist-info/WHEEL
+Filename: ms1searchpy-2.8.2.dist-info/WHEEL
 Comment: 
 
-Filename: ms1searchpy-2.7.3.dist-info/entry_points.txt
+Filename: ms1searchpy-2.8.2.dist-info/entry_points.txt
 Comment: 
 
-Filename: ms1searchpy-2.7.3.dist-info/top_level.txt
+Filename: ms1searchpy-2.8.2.dist-info/top_level.txt
 Comment: 
 
-Filename: ms1searchpy-2.7.3.dist-info/RECORD
+Filename: ms1searchpy-2.8.2.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## ms1searchpy/combine.py

```diff
@@ -24,21 +24,23 @@
     parser.add_argument('-fdr', help='protein fdr filter in %%', default=1.0, type=float)
     parser.add_argument('-prefix', help='decoy prefix', default='DECOY_')
     parser.add_argument('-nproc', help='number of processes', default=1, type=int)
     parser.add_argument('-pp', help='protein priority table for keeping protein groups when merge results by scoring', default='')
     args = vars(parser.parse_args())
     logging.basicConfig(format='%(levelname)9s: %(asctime)s %(message)s',
             datefmt='[%H:%M:%S]', level=logging.INFO)
+    process_files(args)
 
 
+def process_files(args):
     d_tmp = dict()
 
     df1 = None
     for idx, filen in enumerate(args['file']):
-        print('Reading file %s' % (filen, ))
+        logger.info('Reading file %s' % (filen, ))
         df3 = pd.read_csv(filen, sep='\t', usecols=['ids', 'qpreds', 'preds', 'decoy', 'seqs', 'proteins', 'peptide', 'iorig'])
         df3['ids'] = df3['ids'].apply(lambda x: '%d:%s' % (idx, str(x)))
         df3['fidx'] = idx
 
         df3 = df3[df3['qpreds'] <= 10]
 
 
@@ -107,13 +109,13 @@
     rt_diff = resdict['qpreds']
 
     if args['pp']:
         df4 = pd.read_table(args['pp'])
         prots_spc_basic2 = df4.set_index('dbname')['score'].to_dict()
     else:
         prots_spc_basic2 = False
-    
+
     final_iteration(resdict, mass_diff, rt_diff, pept_prot, protsN, base_out_name, prefix, isdecoy, isdecoy_key, escore, fdr, args['nproc'], prots_spc_basic2=prots_spc_basic2)
 
 
 if __name__ == '__main__':
     run()
```

## ms1searchpy/group_specific.py

```diff
@@ -1,13 +1,16 @@
 from .main import final_iteration, filter_results
 from .utils import prot_gen
 import pandas as pd
 from collections import defaultdict, Counter
 import argparse
 import logging
+import ete3
+from ete3 import NCBITaxa
+ncbi = NCBITaxa()
 
 logger = logging.getLogger(__name__)
 
 def run():
     parser = argparse.ArgumentParser(
         description='Combine DirectMS1 search results',
         epilog='''
@@ -17,49 +20,80 @@
     $ ms1combine.py file1_PFMs_ML.tsv ... filen_PFMs_ML.tsv
     -------------
     ''',
         formatter_class=argparse.ArgumentDefaultsHelpFormatter)
 
     parser.add_argument('file', nargs='+', help='input tsv PFMs_ML files for union')
     parser.add_argument('-d', '-db', help='path to protein fasta file', required=True)
-    parser.add_argument('-out', help='prefix output file names', default='groups_statistics.tsv')
+    parser.add_argument('-out', help='prefix output file names', default='group_specific_statistics_by_')
     parser.add_argument('-prots_full', help='path to any of *_proteins_full.tsv file. By default this file will be searched in the folder with PFMs_ML files', default='')
     parser.add_argument('-fdr', help='protein fdr filter in %%', default=1.0, type=float)
     parser.add_argument('-prefix', help='decoy prefix', default='DECOY_')
     parser.add_argument('-nproc', help='number of processes', default=1, type=int)
-    parser.add_argument('-groups', help='1(Default): To use taxonomy in protein name. 2: Use OX= from fasta file', default=1, type=int)
+    parser.add_argument('-groups', help="dbname: To use taxonomy in protein name. OX: Use OX= from fasta file. Or can be 'species', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom', 'domain'", default='dbname')
     parser.add_argument('-pp', help='protein priority table for keeping protein groups when merge results by scoring', default='')
     args = vars(parser.parse_args())
     logging.basicConfig(format='%(levelname)9s: %(asctime)s %(message)s',
             datefmt='[%H:%M:%S]', level=logging.INFO)
 
+    group_to_use = args['groups']
+    allowed_groups = [
+        'dbname', 'OX', 'species', 'genus', 'family', 'order', 'class', 'phylum', 'kingdom', 'domain'
+    ]
+    if group_to_use not in allowed_groups:
+        logging.critical('group is not correct! Must be: %s', ','.join(allowed_groups))
+        return -1
+
     dbname_map = dict()
-    cnt = Counter()
+    ox_map = dict()
     for dbinfo, dbseq in prot_gen(args):
         dbname = dbinfo.split(' ')[0]
 
-        if args['groups'] == 2:
+        if group_to_use != 'dbname':
             try:
                 ox = dbinfo.split('OX=')[-1].split(' ')[0]
             except:
                 ox = 'Unknown'
-        elif args['groups'] == 1:
+        else:
             try:
                 ox = dbinfo.split(' ')[0].split('|')[-1].split('_')[-1]
             except:
                 ox = 'Unknown'
-
-        else:
-            logger.error('groups must be 1 or 2')
-            break
         dbname_map[dbname] = ox
-        cnt[ox] += 1
+
+    cnt = Counter(dbname_map.values())
+
+    if group_to_use not in ['dbname', 'OX']:
+        for ox in cnt.keys():
+
+            line = ncbi.get_lineage(ox)
+            ranks = ncbi.get_rank(line)
+            if group_to_use not in ranks.values():
+                logger.warning('%s does not have %s', str(ox), group_to_use)
+                group_custom = 'OX:' + ox
+                # print('{} does not have {}'.format(i, group_to_use))
+                # continue
+
+            else:
+                ranks_rev = {k[1]:k[0] for k in ranks.items()}
+                # print(ranks_rev)
+                group_custom = ranks_rev[group_to_use]
+
+            ox_map[ox] = group_custom
+
+
+        for dbname in list(dbname_map.keys()):
+            dbname_map[dbname] = ox_map[dbname_map[dbname]]
+
+        cnt = Counter(dbname_map.values())
 
     print(cnt.most_common())
 
+    # return -1
+
     d_tmp = dict()
 
     df1 = None
     for idx, filen in enumerate(args['file']):
         logging.info('Reading file %s' % (filen, ))
         df3 = pd.read_csv(filen, sep='\t', usecols=['ids', 'qpreds', 'preds', 'decoy', 'seqs', 'proteins', 'peptide', 'iorig'])
         df3['ids'] = df3['ids'].apply(lambda x: '%d:%s' % (idx, str(x)))
@@ -113,15 +147,15 @@
     isdecoy = lambda x: x[0].startswith(prefix)
     isdecoy_key = lambda x: x.startswith(prefix)
     escore = lambda x: -x[1]
     fdr = float(args['fdr']) / 100
 
     # all_proteins = []
 
-    base_out_name = args['out']
+    base_out_name = args['out'] + group_to_use + '.tsv'
 
     out_dict = dict()
 
     for group_name in cnt:
 
         logging.info(group_name)
```

## Comparing `ms1searchpy-2.7.3.dist-info/LICENSE` & `ms1searchpy-2.8.2.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `ms1searchpy-2.7.3.dist-info/METADATA` & `ms1searchpy-2.8.2.dist-info/METADATA`

 * *Files 25% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: ms1searchpy
-Version: 2.7.3
+Version: 2.8.2
 Summary: A proteomics search engine for LC-MS1 spectra.
 Author: Mark Ivanov
 Author-email: pyteomics@googlegroups.com
 License: License :: OSI Approved :: Apache Software License
 Classifier: Intended Audience :: Science/Research
 Classifier: Programming Language :: Python :: 3
 Classifier: Topic :: Education
@@ -18,14 +18,16 @@
 Requires-Dist: scipy
 Requires-Dist: numpy
 Requires-Dist: scikit-learn
 Requires-Dist: lightgbm
 Requires-Dist: pandas
 Requires-Dist: biosaur2
 Requires-Dist: matplotlib
+Requires-Dist: seaborn
+Requires-Dist: ete3
 
 # ms1searchpy - a DirectMS1 proteomics search engine for LC-MS1 spectra
 
 `ms1searchpy` consumes LC-MS data (**mzML**) or peptide features (**tsv**) and performs protein identification and quantitation.
 
 ## Basic usage
 
@@ -127,13 +129,48 @@
 
     directms1quant -S1 sample1_r{1,2,3}.features_proteins_full.tsv -S2 sample2_r{1,2,3}.features_proteins_full.tsv
 
 It produces a filtered table of significantly changed proteins with p-values and fold changes,
 as well as the full protein table and a separate file simply listing all
 IDs of significantly modified proteins (e.g. for easy copy-paste into a StringDB search window).
 
+
+### Multi-condition protein profiling using directms1quantmulti
+
+You can make a quantitation for complex projects using script directms1quantmulti. The example below is shown for our project of time-series profiling of glioblastoma cell line under interferon treatment.
+
+Script takes a table with details for all project files. An example of a sample file table is available here in the examples folder. It should contain the following columns:
+
+File Name - filename of raw file. For example, “QEHFX_JB_000379”.
+
+group - sample group of file. In our example, there are K (Control group), IFN30 (treatment with 30 units/ml of interferon) and IFN1000 groups. The first group mentioned in the table will be used as control for pairwise directms1quant runs.  
+
+condition - sample subgroup of file. In our example, there are multiple time points after treatment, such as 0h, 30min, 1h, 2h, etc. By default, only the same conditions will be used for pairwise comparisons. For example, IFN30 0h vs K 0h; IFN1000 0h vs K 0h, etc.
+
+vs - column for specific condition comparison. For example, in our case, we did not have control samples at the 30 min time point. Thus, we would like to proceed directms1quant runs for IFN30 30 min vs K 0h; and IFN1000 30 min vs K 0h comparisons. Thus, for the 30 min IFN30 and IFN1000 files we put “0h” in the “vs” column. See example table for details.
+
+replicate - column for replicate number of specific condition and sample group.
+
+BatchMS - column for mass-spectrometry Batch. This parameter is used for extra normalization within a batch.
+
+
+The script consists of four different stages and you can rerun the script without rerunning previous stages (“-start_stage” option).
+
+Stage 1 is a set of pairwise DirectMS1Quant runs for different interferon treatment conditions versus control samples.
+
+Stage 2 is preparation of peptide LFQ table for all files using the results obtained in the previous step.
+
+Stage 3 is preparation of the protein LFQ table. Only the peptides labeled by DirectMS1Quant as significantly different between samples in at least X pairwise comparisons are used for protein quantitation. The X parameter is controlled by “min_signif_for_pept” option.
+
+Stage 4 is preparation of LFQ profiling figures for proteins specified in the file under “proteins_for_figure” option. The file should be a tsv table with column “dbname” containing protein database names in the swiss-prot format. Any default directms1quant output table with differentially expressed proteins can be used here.
+
+
+Example of script usage::
+
+    directms1quantmulti -db ~/fasta_folder/sprot_human_shuffled.fasta -pdir ~/folder_with_ms1searchpy_results/ -samples ~/samples.csv -min_signif_for_pept 2 -out DQmulti_2024 -pep_min_non_missing_samples 0.75 -start_stage 1 -proteins_for_figure ~/custom_list_of_proteins.tsv -figdir ~/output_figure_folder/
+
 ## Links
 
 - GitHub repo & issue tracker: https://github.com/markmipt/ms1searchpy
 - Mailing list: markmipt@gmail.com
 
 - DeepLC repo: https://github.com/compomics/DeepLC
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## Comparing `ms1searchpy-2.7.3.dist-info/RECORD` & `ms1searchpy-2.8.2.dist-info/RECORD`

 * *Files 20% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 ms1searchpy/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-ms1searchpy/combine.py,sha256=AOnPa_7Meqst5H6qM6faa4GbSIYzURmiH9cOUerKOq0,4185
+ms1searchpy/combine.py,sha256=7S61Ftnv4NJUmfnV6vjVp2uHwslkDcQQJVPzWYVm1nk,4236
 ms1searchpy/combine_proteins.py,sha256=LFJuwkb8UBy-1T-kAT3H4zxkqQ6VTso6SOLP7s8o0Ow,2746
 ms1searchpy/directms1quant.py,sha256=OuInuVdPCIsRbvRSCM1mnNqh0jQwvQhhcd6Bo0AbnnM,24852
-ms1searchpy/group_specific.py,sha256=DYpIYjTRc6mHWDnH7IOiSUYWmtYeRja13nrNkp71xe4,6005
+ms1searchpy/directms1quantmulti.py,sha256=bWlUOQX7S1nWsV-Zl10s9L_IRllX6tpJJvQGXgINo40,16412
+ms1searchpy/group_specific.py,sha256=AqEN5xkrsEdXeVFdqHUkQa0tmip14zQQrK4pu0tFZi4,7218
 ms1searchpy/main.py,sha256=eISGaa6d5-HBZoNkbK_YjnhMGZOQopRqWPgh4sJIoDo,84395
 ms1searchpy/ms1todiffacto.py,sha256=xGxcIe8-C_vSLx5Qz5qwSKa4oULJ-8cgq4DtCTXKe3s,7413
 ms1searchpy/search.py,sha256=LzcFU_j7pilzoHo-4b_D0gkMXGwruWt4G5vluWPa-Qk,5074
 ms1searchpy/utils.py,sha256=D59l42xbMYMyL6GEuKOCOPsdexaMmo-1j3cKSNPN9lE,14862
 ms1searchpy/utils_figures.py,sha256=KfBAVLoq7U57HV-hct8CpiOL4BCHADAWIBFbH-jWB_M,15305
 ms1searchpy/models/CSD_model_LCMSMS.hdf5,sha256=7nAu3-YWKjsuQNCpgoRpTjInA-dPe7kZE1pTGKg-3OQ,9177032
-ms1searchpy-2.7.3.dist-info/LICENSE,sha256=WanbJHdVmtsm-QgIuB0GDMrtkwBHY6WmTzwvX6ZZtgs,551
-ms1searchpy-2.7.3.dist-info/METADATA,sha256=7FFWae2w1xLIv8rJw8MViT6iu5L5aeSoFesC0JbeJmo,5771
-ms1searchpy-2.7.3.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-ms1searchpy-2.7.3.dist-info/entry_points.txt,sha256=YuzL1ECp7DWSpRCYpZ4861Qc2D7h7e5g7z2at76TWKg,434
-ms1searchpy-2.7.3.dist-info/top_level.txt,sha256=pyjbWV_odwavqf6q4mSj2P0L0zLqKEDftX53QvxeJlc,12
-ms1searchpy-2.7.3.dist-info/RECORD,,
+ms1searchpy-2.8.2.dist-info/LICENSE,sha256=WanbJHdVmtsm-QgIuB0GDMrtkwBHY6WmTzwvX6ZZtgs,551
+ms1searchpy-2.8.2.dist-info/METADATA,sha256=_1nBd7q4ZeyO56ocZAWJNWtapiH1VG41pVCvKCyo9DI,8712
+ms1searchpy-2.8.2.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+ms1searchpy-2.8.2.dist-info/entry_points.txt,sha256=ACLj6QbnpM9wI-CQA2YFf_ZmWEFqN9GZpbuxO6ZEeHE,492
+ms1searchpy-2.8.2.dist-info/top_level.txt,sha256=pyjbWV_odwavqf6q4mSj2P0L0zLqKEDftX53QvxeJlc,12
+ms1searchpy-2.8.2.dist-info/RECORD,,
```

