# Comparing `tmp/shexer-2.5.1.tar.gz` & `tmp/shexer-2.5.2.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "shexer-2.5.1.tar", last modified: Thu May  9 16:14:03 2024, max compression
+gzip compressed data, was "shexer-2.5.2.tar", last modified: Tue May 14 17:27:53 2024, max compression
```

## Comparing `shexer-2.5.1.tar` & `shexer-2.5.2.tar`

### file list

```diff
@@ -1,253 +1,262 @@
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.667791 shexer-2.5.1/
--rw-r--r--   0 runner    (1001) docker     (127)    11357 2024-05-09 16:13:55.000000 shexer-2.5.1/LICENSE
--rw-r--r--   0 runner    (1001) docker     (127)    28705 2024-05-09 16:14:03.667791 shexer-2.5.1/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)    27704 2024-05-09 16:13:55.000000 shexer-2.5.1/README.md
--rw-r--r--   0 runner    (1001) docker     (127)       79 2024-05-09 16:14:03.667791 shexer-2.5.1/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (127)     1356 2024-05-09 16:13:55.000000 shexer-2.5.1/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.643790 shexer-2.5.1/shexer/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      775 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/consts.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.643790 shexer-2.5.1/shexer/core/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.643790 shexer-2.5.1/shexer/core/instances/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      692 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/abstract_instance_tracker.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.643790 shexer-2.5.1/shexer/core/instances/annotators/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      378 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/annotator_func.py
--rw-r--r--   0 runner    (1001) docker     (127)     1774 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/annotator_tracking_instances.py
--rw-r--r--   0 runner    (1001) docker     (127)     3821 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/base_annotator.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      643 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/all_classes_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)      739 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/base_strategy_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)      784 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/compound_strategy_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)     2614 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/instance_cap_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)       82 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/instances_cap_exception.py
--rw-r--r--   0 runner    (1001) docker     (127)     1755 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/shape_qualifiers_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)      793 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/target_classes_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)     4446 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/instance_tracker.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/instances/mappings/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/mappings/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1054 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/mappings/shape_map_instance_tracker.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/instances/mix/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/mix/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2591 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/mix/mixed_instance_tracker.py
--rw-r--r--   0 runner    (1001) docker     (127)       20 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/instances/pconsts.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/profiling/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    12655 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/class_profiler.py
--rw-r--r--   0 runner    (1001) docker     (127)      172 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/consts.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/profiling/strategy/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/strategy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     7242 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/strategy/abstract_feature_direction_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     2522 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/strategy/direct_features_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     9630 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/profiling/strategy/include_reverse_features_strategy.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/shexing/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     6063 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/class_shexer.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/shexing/strategy/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    16801 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/abstract_shexing_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     5593 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/direct_and_inverse_shexing_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     2757 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/direct_shexing_strategy.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/core/shexing/strategy/minimal_iri_strategy/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/minimal_iri_strategy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      115 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/minimal_iri_strategy/abstract_min_iri_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     1770 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/minimal_iri_strategy/annotate_min_iri_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)      395 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/core/shexing/strategy/minimal_iri_strategy/ignore_min_iri_strategy.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/io/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      101 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/file.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.647791 shexer-2.5.1/shexer/io/graph/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/graph/yielder/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1564 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/base_triples_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)    16607 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/big_ttl_triples_yielder.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/graph/yielder/filter/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/filter/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      843 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/filter/filter_namespaces_triple_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     1110 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/multi_big_ttl_files_triple_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     1112 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/multi_nt_triples_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     1725 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/multi_rdflib_triple_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     1146 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/multi_tsv_nt_triples_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     1443 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/multi_zip_triples_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     2606 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/multifile_base_triples_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     5572 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/nt_triples_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     6814 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/rdflib_triple_yielder.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/graph/yielder/remote/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/remote/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3751 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/remote/sgraph_from_selectors_triple_yielder.py
--rw-r--r--   0 runner    (1001) docker     (127)     4624 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/graph/yielder/tsv_nt_triples_yielder.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/json/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/json/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      198 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/json/json_loader.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/line_reader/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/line_reader/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      275 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/line_reader/file_line_reader.py
--rw-r--r--   0 runner    (1001) docker     (127)      277 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/line_reader/gz_line_reader.py
--rw-r--r--   0 runner    (1001) docker     (127)      250 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/line_reader/raw_string_line_reader.py
--rw-r--r--   0 runner    (1001) docker     (127)      292 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/line_reader/xz_line_reader.py
--rw-r--r--   0 runner    (1001) docker     (127)      343 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/line_reader/zip_file_line_reader.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/profile/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/profile/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/profile/formater/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/profile/formater/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      395 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/profile/formater/abstract_profile_serializer.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shacl/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shacl/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shacl/formater/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shacl/formater/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    16369 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shacl/formater/shacl_serializer.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shape_map/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shape_map/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shape_map/label/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shape_map/label/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1371 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shape_map/label/shape_map_label_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shape_map/node_selector/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shape_map/node_selector/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     6617 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shape_map/node_selector/node_selector_parser.py
--rw-r--r--   0 runner    (1001) docker     (127)     4836 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shape_map/shape_map_parser.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shex/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/__init__.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shex/formater/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      236 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/consts.py
--rw-r--r--   0 runner    (1001) docker     (127)    10240 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/shex_serializer.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.651790 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     5954 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/base_statement_serializer.py
--rw-r--r--   0 runner    (1001) docker     (127)     2248 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/fixed_prop_choice_statement_serializer.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.655790 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      369 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/abs_freq_serializer.py
--rw-r--r--   0 runner    (1001) docker     (127)      166 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/base_frequency_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)      871 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/mixed_frequency_strategy.py
--rw-r--r--   0 runner    (1001) docker     (127)     1247 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/ratio_freq_serializer.py
--rw-r--r--   0 runner    (1001) docker     (127)     1468 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/inverse_statement_serializer.py
--rw-r--r--   0 runner    (1001) docker     (127)     3150 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/shex/formater/statement_serializers/st_serializers_factory.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.655790 shexer-2.5.1/shexer/io/sparql/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/sparql/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     4434 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/sparql/query.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.655790 shexer-2.5.1/shexer/io/uml/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/uml/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     6109 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/uml/uml_serializer.py
--rw-r--r--   0 runner    (1001) docker     (127)      457 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/io/wikidata.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.655790 shexer-2.5.1/shexer/model/
--rw-r--r--   0 runner    (1001) docker     (127)      527 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/IRI.py
--rw-r--r--   0 runner    (1001) docker     (127)      264 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/Literal.py
--rw-r--r--   0 runner    (1001) docker     (127)      784 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/Macro.py
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      480 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/bnode.py
--rw-r--r--   0 runner    (1001) docker     (127)       97 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/const_elem_types.py
--rw-r--r--   0 runner    (1001) docker     (127)     1097 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/fixed_prop_choice_statement.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.655790 shexer-2.5.1/shexer/model/graph/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/graph/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     6049 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/graph/abstract_sgraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     7492 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/graph/endpoint_sgraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     6074 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/graph/rdflib_sgraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     4032 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/hierarchy_tree.py
--rw-r--r--   0 runner    (1001) docker     (127)     2450 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/node_selector.py
--rw-r--r--   0 runner    (1001) docker     (127)      407 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/property.py
--rw-r--r--   0 runner    (1001) docker     (127)     3274 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/shape.py
--rw-r--r--   0 runner    (1001) docker     (127)      824 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/shape_map.py
--rw-r--r--   0 runner    (1001) docker     (127)     2627 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/model/statement.py
--rw-r--r--   0 runner    (1001) docker     (127)    26237 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/shaper.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.655790 shexer-2.5.1/shexer/utils/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      762 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/compression.py
--rw-r--r--   0 runner    (1001) docker     (127)       92 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/dict.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.659790 shexer-2.5.1/shexer/utils/factories/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     4326 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/class_profiler_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)     2272 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/class_shexer_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)      706 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/h_tree.py
--rw-r--r--   0 runner    (1001) docker     (127)    12134 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/instance_tracker_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)      423 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/iri_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)      280 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/remote_graph_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)     1957 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/shape_map_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)      604 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/shape_map_parser_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)     2515 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/shape_serializer_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)    20793 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/factories/triple_yielders_factory.py
--rw-r--r--   0 runner    (1001) docker     (127)      120 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/file.py
--rw-r--r--   0 runner    (1001) docker     (127)      383 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/log.py
--rw-r--r--   0 runner    (1001) docker     (127)      741 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/namespaces.py
--rw-r--r--   0 runner    (1001) docker     (127)      940 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/obj_references.py
--rw-r--r--   0 runner    (1001) docker     (127)     1965 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/shapes.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.659790 shexer-2.5.1/shexer/utils/structures/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/structures/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     3400 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/structures/dicts.py
--rw-r--r--   0 runner    (1001) docker     (127)     1371 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/target_elements.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.659790 shexer-2.5.1/shexer/utils/translators/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/translators/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2831 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/translators/list_of_classes_to_shape_map.py
--rw-r--r--   0 runner    (1001) docker     (127)     2950 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/triple_yielders.py
--rw-r--r--   0 runner    (1001) docker     (127)     5589 2024-05-09 16:13:55.000000 shexer-2.5.1/shexer/utils/uri.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.663791 shexer-2.5.1/shexer.egg-info/
--rw-r--r--   0 runner    (1001) docker     (127)    28705 2024-05-09 16:14:03.000000 shexer-2.5.1/shexer.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (127)     8284 2024-05-09 16:14:03.000000 shexer-2.5.1/shexer.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (127)        1 2024-05-09 16:14:03.000000 shexer-2.5.1/shexer.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (127)       56 2024-05-09 16:14:03.000000 shexer-2.5.1/shexer.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (127)       15 2024-05-09 16:14:03.000000 shexer-2.5.1/shexer.egg-info/top_level.txt
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.663791 shexer-2.5.1/test/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/test/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     1861 2024-05-09 16:13:55.000000 shexer-2.5.1/test/const.py
--rw-r--r--   0 runner    (1001) docker     (127)     9741 2024-05-09 16:13:55.000000 shexer-2.5.1/test/t_utils.py
--rw-r--r--   0 runner    (1001) docker     (127)     1450 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_all_classes_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)     1491 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_allow_opt_cardinality.py
--rw-r--r--   0 runner    (1001) docker     (127)     3477 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_allow_redundant_or.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.663791 shexer-2.5.1/test/test_bugs/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_bugs/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)      773 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_bugs/test_no_sharp_in_auto_shape_names.py
--rw-r--r--   0 runner    (1001) docker     (127)     1163 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_bugs/test_no_sharp_nor_slash_due_to_prefixing.py
--rw-r--r--   0 runner    (1001) docker     (127)    14823 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_compression_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)     2127 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_decimals.py
--rw-r--r--   0 runner    (1001) docker     (127)     5475 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_depth_for_building_subgraph.py
--rw-r--r--   0 runner    (1001) docker     (127)     3446 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_detect_minimal_iri.py
--rw-r--r--   0 runner    (1001) docker     (127)     1358 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_disable_comments.py
--rw-r--r--   0 runner    (1001) docker     (127)     2863 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_disable_endpoint_cache.py
--rw-r--r--   0 runner    (1001) docker     (127)     1456 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_disable_exact_cardinality.py
--rw-r--r--   0 runner    (1001) docker     (127)     2510 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_disable_or_statements.py
--rw-r--r--   0 runner    (1001) docker     (127)     3721 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_discard_and_compliant.py
--rw-r--r--   0 runner    (1001) docker     (127)     5103 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_examples_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)     2047 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_file_target_classes.py
--rw-r--r--   0 runner    (1001) docker     (127)     1644 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_graph_file_input.py
--rw-r--r--   0 runner    (1001) docker     (127)     3394 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_graph_list_of_file_inputs.py
--rw-r--r--   0 runner    (1001) docker     (127)     1916 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_infer_numeric_types_for_untyped_literals.py
--rw-r--r--   0 runner    (1001) docker     (127)     8509 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_input_format.py
--rw-r--r--   0 runner    (1001) docker     (127)     4539 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_instances_cap.py
--rw-r--r--   0 runner    (1001) docker     (127)     3308 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_instances_file_input.py
--rw-r--r--   0 runner    (1001) docker     (127)     3779 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_instances_report.py
--rw-r--r--   0 runner    (1001) docker     (127)     3485 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_instantiation_property.py
--rw-r--r--   0 runner    (1001) docker     (127)     1919 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_inverse_paths.py
--rw-r--r--   0 runner    (1001) docker     (127)     3528 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_keep_less_specific.py
--rw-r--r--   0 runner    (1001) docker     (127)     3986 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_list_of_url_input.py
--rw-r--r--   0 runner    (1001) docker     (127)     4051 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_namespaces_dict.py
--rw-r--r--   0 runner    (1001) docker     (127)     2042 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_namespaces_to_ignore.py
--rw-r--r--   0 runner    (1001) docker     (127)     4904 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_raw_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     4212 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_raw_shape_map.py
--rw-r--r--   0 runner    (1001) docker     (127)     1670 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_rdflib_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     2875 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_remove_empty_sahpes.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.663791 shexer-2.5.1/test/test_shacl/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shacl/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)     2181 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shacl/test_annotation.py
--rw-r--r--   0 runner    (1001) docker     (127)     2192 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shacl/test_class_selection.py
--rw-r--r--   0 runner    (1001) docker     (127)     3219 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shacl/test_detect_minimal_iri.py
--rw-r--r--   0 runner    (1001) docker     (127)      850 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shacl/test_https.py
--rw-r--r--   0 runner    (1001) docker     (127)     1499 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shacl/test_literal_types.py
--rw-r--r--   0 runner    (1001) docker     (127)     4225 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shape_map_file.py
--rw-r--r--   0 runner    (1001) docker     (127)     5969 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shape_map_format.py
--rw-r--r--   0 runner    (1001) docker     (127)     2262 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shape_qualifiers_mode.py
--rw-r--r--   0 runner    (1001) docker     (127)     2827 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_shapes_namespaces.py
--rw-r--r--   0 runner    (1001) docker     (127)     2401 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_sort.py
--rw-r--r--   0 runner    (1001) docker     (127)     2012 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_target_classes.py
--rw-r--r--   0 runner    (1001) docker     (127)     3061 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_threshold.py
--rw-r--r--   0 runner    (1001) docker     (127)     2595 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_uml_gen.py
--rw-r--r--   0 runner    (1001) docker     (127)     2526 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_url_endpoint.py
--rw-r--r--   0 runner    (1001) docker     (127)     1830 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_url_graph.py
--rw-r--r--   0 runner    (1001) docker     (127)     1893 2024-05-09 16:13:55.000000 shexer-2.5.1/test/test_wikidata_annotation.py
-drwxr-xr-x   0 runner    (1001) docker     (127)        0 2024-05-09 16:14:03.663791 shexer-2.5.1/ws/
--rw-r--r--   0 runner    (1001) docker     (127)        0 2024-05-09 16:13:55.000000 shexer-2.5.1/ws/__init__.py
--rw-r--r--   0 runner    (1001) docker     (127)    19366 2024-05-09 16:13:55.000000 shexer-2.5.1/ws/shexer_rest.py
--rw-r--r--   0 runner    (1001) docker     (127)       28 2024-05-09 16:13:55.000000 shexer-2.5.1/ws/wsgi.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:53.130661 shexer-2.5.2/
+-rw-rw-rw-   0        0        0    11558 2023-06-27 16:13:11.000000 shexer-2.5.2/LICENSE
+-rw-rw-rw-   0        0        0    28819 2024-05-14 17:27:53.131657 shexer-2.5.2/PKG-INFO
+-rw-rw-rw-   0        0        0    27944 2024-05-09 16:06:46.000000 shexer-2.5.2/README.md
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.295549 shexer-2.5.2/local_code/
+-rw-rw-rw-   0        0        0      188 2024-05-09 15:38:32.000000 shexer-2.5.2/local_code/TEST_XZ_READING.py
+-rw-rw-rw-   0        0        0        0 2023-07-20 16:50:30.000000 shexer-2.5.2/local_code/__init__.py
+-rw-rw-rw-   0        0        0     1278 2023-11-10 20:18:22.000000 shexer-2.5.2/local_code/beyza_test.py
+-rw-rw-rw-   0        0        0     1411 2023-11-30 17:16:03.000000 shexer-2.5.2/local_code/img_example.py
+-rw-rw-rw-   0        0        0     2756 2023-09-04 15:19:36.000000 shexer-2.5.2/local_code/split_non_split_thats_the_question.py
+-rw-rw-rw-   0        0        0     9733 2023-11-08 19:45:06.000000 shexer-2.5.2/local_code/tictactoe.py
+-rw-rw-rw-   0        0        0       88 2023-11-13 10:50:47.000000 shexer-2.5.2/local_code/whatever.py
+-rw-rw-rw-   0        0        0     1428 2023-10-02 17:19:16.000000 shexer-2.5.2/local_code/yasunori_Test.py
+-rw-rw-rw-   0        0        0       86 2024-05-14 17:27:53.138644 shexer-2.5.2/setup.cfg
+-rw-rw-rw-   0        0        0     1419 2024-05-14 17:26:53.000000 shexer-2.5.2/setup.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.318467 shexer-2.5.2/shexer/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/__init__.py
+-rw-rw-rw-   0        0        0      818 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/consts.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.359359 shexer-2.5.2/shexer/core/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.390277 shexer-2.5.2/shexer/core/instances/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/__init__.py
+-rw-rw-rw-   0        0        0      713 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/abstract_instance_tracker.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.422189 shexer-2.5.2/shexer/core/instances/annotators/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/__init__.py
+-rw-rw-rw-   0        0        0      383 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/annotator_func.py
+-rw-rw-rw-   0        0        0     1817 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/annotator_tracking_instances.py
+-rw-rw-rw-   0        0        0     3895 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/base_annotator.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.495065 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/__init__.py
+-rw-rw-rw-   0        0        0      665 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/all_classes_mode.py
+-rw-rw-rw-   0        0        0      760 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/base_strategy_mode.py
+-rw-rw-rw-   0        0        0      807 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/compound_strategy_mode.py
+-rw-rw-rw-   0        0        0     2675 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/instance_cap_mode.py
+-rw-rw-rw-   0        0        0       86 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/instances_cap_exception.py
+-rw-rw-rw-   0        0        0     1793 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/shape_qualifiers_mode.py
+-rw-rw-rw-   0        0        0      815 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/target_classes_mode.py
+-rw-rw-rw-   0        0        0     4553 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/instance_tracker.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.507996 shexer-2.5.2/shexer/core/instances/mappings/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/mappings/__init__.py
+-rw-rw-rw-   0        0        0     1081 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/mappings/shape_map_instance_tracker.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.521962 shexer-2.5.2/shexer/core/instances/mix/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/mix/__init__.py
+-rw-rw-rw-   0        0        0     2652 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/mix/mixed_instance_tracker.py
+-rw-rw-rw-   0        0        0       22 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/instances/pconsts.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.543939 shexer-2.5.2/shexer/core/profiling/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/profiling/__init__.py
+-rw-rw-rw-   0        0        0    12914 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/core/profiling/class_profiler.py
+-rw-rw-rw-   0        0        0      182 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/profiling/consts.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.581802 shexer-2.5.2/shexer/core/profiling/strategy/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/profiling/strategy/__init__.py
+-rw-rw-rw-   0        0        0     7395 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/core/profiling/strategy/abstract_feature_direction_strategy.py
+-rw-rw-rw-   0        0        0     2591 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/core/profiling/strategy/direct_features_strategy.py
+-rw-rw-rw-   0        0        0     9807 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/core/profiling/strategy/include_reverse_features_strategy.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.593767 shexer-2.5.2/shexer/core/shexing/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/__init__.py
+-rw-rw-rw-   0        0        0     6186 2023-10-20 16:00:26.000000 shexer-2.5.2/shexer/core/shexing/class_shexer.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.627676 shexer-2.5.2/shexer/core/shexing/strategy/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/strategy/__init__.py
+-rw-rw-rw-   0        0        0    17142 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/core/shexing/strategy/abstract_shexing_strategy.py
+-rw-rw-rw-   0        0        0     5685 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/strategy/direct_and_inverse_shexing_strategy.py
+-rw-rw-rw-   0        0        0     2804 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/strategy/direct_shexing_strategy.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.660606 shexer-2.5.2/shexer/core/shexing/strategy/minimal_iri_strategy/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/strategy/minimal_iri_strategy/__init__.py
+-rw-rw-rw-   0        0        0      118 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/strategy/minimal_iri_strategy/abstract_min_iri_strategy.py
+-rw-rw-rw-   0        0        0     1805 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/core/shexing/strategy/minimal_iri_strategy/annotate_min_iri_strategy.py
+-rw-rw-rw-   0        0        0      412 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/core/shexing/strategy/minimal_iri_strategy/ignore_min_iri_strategy.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.678574 shexer-2.5.2/shexer/io/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/__init__.py
+-rw-rw-rw-   0        0        0      103 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/file.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.681551 shexer-2.5.2/shexer/io/graph/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.802209 shexer-2.5.2/shexer/io/graph/yielder/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/__init__.py
+-rw-rw-rw-   0        0        0     1598 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/io/graph/yielder/base_triples_yielder.py
+-rw-rw-rw-   0        0        0    17014 2024-05-02 15:57:04.000000 shexer-2.5.2/shexer/io/graph/yielder/big_ttl_triples_yielder.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.812183 shexer-2.5.2/shexer/io/graph/yielder/filter/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/filter/__init__.py
+-rw-rw-rw-   0        0        0      862 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/filter/filter_namespaces_triple_yielder.py
+-rw-rw-rw-   0        0        0     1131 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/multi_big_ttl_files_triple_yielder.py
+-rw-rw-rw-   0        0        0     1132 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/multi_nt_triples_yielder.py
+-rw-rw-rw-   0        0        0     1757 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/multi_rdflib_triple_yielder.py
+-rw-rw-rw-   0        0        0     1166 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/multi_tsv_nt_triples_yielder.py
+-rw-rw-rw-   0        0        0     1483 2024-04-03 12:10:04.000000 shexer-2.5.2/shexer/io/graph/yielder/multi_zip_triples_yielder.py
+-rw-rw-rw-   0        0        0     2670 2024-04-03 12:10:04.000000 shexer-2.5.2/shexer/io/graph/yielder/multifile_base_triples_yielder.py
+-rw-rw-rw-   0        0        0     5686 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/nt_triples_yielder.py
+-rw-rw-rw-   0        0        0     6985 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/io/graph/yielder/rdflib_triple_yielder.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.825189 shexer-2.5.2/shexer/io/graph/yielder/remote/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/remote/__init__.py
+-rw-rw-rw-   0        0        0     3826 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/remote/sgraph_from_selectors_triple_yielder.py
+-rw-rw-rw-   0        0        0     4724 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/graph/yielder/tsv_nt_triples_yielder.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.836121 shexer-2.5.2/shexer/io/json/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/json/__init__.py
+-rw-rw-rw-   0        0        0      207 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/json/json_loader.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.878040 shexer-2.5.2/shexer/io/line_reader/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/line_reader/__init__.py
+-rw-rw-rw-   0        0        0      285 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/line_reader/file_line_reader.py
+-rw-rw-rw-   0        0        0      288 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/io/line_reader/gz_line_reader.py
+-rw-rw-rw-   0        0        0      260 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/line_reader/raw_string_line_reader.py
+-rw-rw-rw-   0        0        0      303 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/io/line_reader/xz_line_reader.py
+-rw-rw-rw-   0        0        0      353 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/line_reader/zip_file_line_reader.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.880011 shexer-2.5.2/shexer/io/profile/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/profile/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.890014 shexer-2.5.2/shexer/io/profile/formater/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/profile/formater/__init__.py
+-rw-rw-rw-   0        0        0      409 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/profile/formater/abstract_profile_serializer.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.892013 shexer-2.5.2/shexer/io/shacl/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shacl/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.905933 shexer-2.5.2/shexer/io/shacl/formater/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shacl/formater/__init__.py
+-rw-rw-rw-   0        0        0    16736 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/io/shacl/formater/shacl_serializer.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.918931 shexer-2.5.2/shexer/io/shape_map/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shape_map/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.931864 shexer-2.5.2/shexer/io/shape_map/label/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shape_map/label/__init__.py
+-rw-rw-rw-   0        0        0     1410 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shape_map/label/shape_map_label_parser.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.943830 shexer-2.5.2/shexer/io/shape_map/node_selector/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shape_map/node_selector/__init__.py
+-rw-rw-rw-   0        0        0     6755 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shape_map/node_selector/node_selector_parser.py
+-rw-rw-rw-   0        0        0     4966 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shape_map/shape_map_parser.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.945826 shexer-2.5.2/shexer/io/shex/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/__init__.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.966810 shexer-2.5.2/shexer/io/shex/formater/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/__init__.py
+-rw-rw-rw-   0        0        0      244 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/consts.py
+-rw-rw-rw-   0        0        0    10461 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/io/shex/formater/shex_serializer.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.018632 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/__init__.py
+-rw-rw-rw-   0        0        0     6083 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/base_statement_serializer.py
+-rw-rw-rw-   0        0        0     2287 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/fixed_prop_choice_statement_serializer.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.060557 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/__init__.py
+-rw-rw-rw-   0        0        0      383 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/abs_freq_serializer.py
+-rw-rw-rw-   0        0        0      171 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/base_frequency_strategy.py
+-rw-rw-rw-   0        0        0      887 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/mixed_frequency_strategy.py
+-rw-rw-rw-   0        0        0     1278 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/ratio_freq_serializer.py
+-rw-rw-rw-   0        0        0     1500 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/inverse_statement_serializer.py
+-rw-rw-rw-   0        0        0     3207 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/io/shex/formater/statement_serializers/st_serializers_factory.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.073485 shexer-2.5.2/shexer/io/sparql/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/sparql/__init__.py
+-rw-rw-rw-   0        0        0     4538 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/sparql/query.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.087447 shexer-2.5.2/shexer/io/uml/
+-rw-rw-rw-   0        0        0        0 2024-04-05 16:49:28.000000 shexer-2.5.2/shexer/io/uml/__init__.py
+-rw-rw-rw-   0        0        0     6256 2024-04-05 16:49:28.000000 shexer-2.5.2/shexer/io/uml/uml_serializer.py
+-rw-rw-rw-   0        0        0      469 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/io/wikidata.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.201178 shexer-2.5.2/shexer/model/
+-rw-rw-rw-   0        0        0      552 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/IRI.py
+-rw-rw-rw-   0        0        0      280 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/Literal.py
+-rw-rw-rw-   0        0        0      810 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/Macro.py
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/__init__.py
+-rw-rw-rw-   0        0        0      502 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/bnode.py
+-rw-rw-rw-   0        0        0      100 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/const_elem_types.py
+-rw-rw-rw-   0        0        0     1119 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/fixed_prop_choice_statement.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.235093 shexer-2.5.2/shexer/model/graph/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/graph/__init__.py
+-rw-rw-rw-   0        0        0     6186 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/graph/abstract_sgraph.py
+-rw-rw-rw-   0        0        0     7633 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/graph/endpoint_sgraph.py
+-rw-rw-rw-   0        0        0     6201 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/graph/rdflib_sgraph.py
+-rw-rw-rw-   0        0        0     4173 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/hierarchy_tree.py
+-rw-rw-rw-   0        0        0     2527 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/node_selector.py
+-rw-rw-rw-   0        0        0      427 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/property.py
+-rw-rw-rw-   0        0        0     3380 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/model/shape.py
+-rw-rw-rw-   0        0        0      858 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/shape_map.py
+-rw-rw-rw-   0        0        0     2716 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/model/statement.py
+-rw-rw-rw-   0        0        0    26715 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/shaper.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.332844 shexer-2.5.2/shexer/utils/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/__init__.py
+-rw-rw-rw-   0        0        0      788 2024-05-09 16:06:46.000000 shexer-2.5.2/shexer/utils/compression.py
+-rw-rw-rw-   0        0        0       94 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/dict.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.433525 shexer-2.5.2/shexer/utils/factories/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/__init__.py
+-rw-rw-rw-   0        0        0     4399 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/utils/factories/class_profiler_factory.py
+-rw-rw-rw-   0        0        0     2322 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/class_shexer_factory.py
+-rw-rw-rw-   0        0        0      728 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/h_tree.py
+-rw-rw-rw-   0        0        0    12338 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/instance_tracker_factory.py
+-rw-rw-rw-   0        0        0      437 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/iri_factory.py
+-rw-rw-rw-   0        0        0      286 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/remote_graph_factory.py
+-rw-rw-rw-   0        0        0     1985 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/shape_map_factory.py
+-rw-rw-rw-   0        0        0      616 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/factories/shape_map_parser_factory.py
+-rw-rw-rw-   0        0        0     2556 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/utils/factories/shape_serializer_factory.py
+-rw-rw-rw-   0        0        0    21108 2024-04-03 12:10:04.000000 shexer-2.5.2/shexer/utils/factories/triple_yielders_factory.py
+-rw-rw-rw-   0        0        0      123 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/file.py
+-rw-rw-rw-   0        0        0      397 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/log.py
+-rw-rw-rw-   0        0        0      761 2024-04-05 16:49:28.000000 shexer-2.5.2/shexer/utils/namespaces.py
+-rw-rw-rw-   0        0        0      967 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/obj_references.py
+-rw-rw-rw-   0        0        0     2008 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/shapes.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.444531 shexer-2.5.2/shexer/utils/structures/
+-rw-rw-rw-   0        0        0        0 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/utils/structures/__init__.py
+-rw-rw-rw-   0        0        0     3487 2024-05-08 19:42:50.000000 shexer-2.5.2/shexer/utils/structures/dicts.py
+-rw-rw-rw-   0        0        0     1397 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/target_elements.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:52.456461 shexer-2.5.2/shexer/utils/translators/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/translators/__init__.py
+-rw-rw-rw-   0        0        0     2881 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/translators/list_of_classes_to_shape_map.py
+-rw-rw-rw-   0        0        0     3026 2023-06-27 16:13:11.000000 shexer-2.5.2/shexer/utils/triple_yielders.py
+-rw-rw-rw-   0        0        0     5749 2024-04-05 16:49:28.000000 shexer-2.5.2/shexer/utils/uri.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:51.357363 shexer-2.5.2/shexer.egg-info/
+-rw-rw-rw-   0        0        0    28819 2024-05-14 17:27:50.000000 shexer-2.5.2/shexer.egg-info/PKG-INFO
+-rw-rw-rw-   0        0        0     8512 2024-05-14 17:27:51.000000 shexer-2.5.2/shexer.egg-info/SOURCES.txt
+-rw-rw-rw-   0        0        0        1 2024-05-14 17:27:50.000000 shexer-2.5.2/shexer.egg-info/dependency_links.txt
+-rw-rw-rw-   0        0        0       66 2024-05-14 17:27:50.000000 shexer-2.5.2/shexer.egg-info/requires.txt
+-rw-rw-rw-   0        0        0       26 2024-05-14 17:27:50.000000 shexer-2.5.2/shexer.egg-info/top_level.txt
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:53.014967 shexer-2.5.2/test/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/test/__init__.py
+-rw-rw-rw-   0        0        0     1903 2024-05-02 16:13:25.000000 shexer-2.5.2/test/const.py
+-rw-rw-rw-   0        0        0    10059 2024-05-08 19:42:50.000000 shexer-2.5.2/test/t_utils.py
+-rw-rw-rw-   0        0        0     1488 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_all_classes_mode.py
+-rw-rw-rw-   0        0        0     1525 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_allow_opt_cardinality.py
+-rw-rw-rw-   0        0        0     3541 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_allow_redundant_or.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:53.041973 shexer-2.5.2/test/test_bugs/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_bugs/__init__.py
+-rw-rw-rw-   0        0        0      796 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_bugs/test_no_sharp_in_auto_shape_names.py
+-rw-rw-rw-   0        0        0     1192 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_bugs/test_no_sharp_nor_slash_due_to_prefixing.py
+-rw-rw-rw-   0        0        0    15187 2024-05-09 16:06:46.000000 shexer-2.5.2/test/test_compression_mode.py
+-rw-rw-rw-   0        0        0     2171 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_decimals.py
+-rw-rw-rw-   0        0        0     5564 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_depth_for_building_subgraph.py
+-rw-rw-rw-   0        0        0     3526 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_detect_minimal_iri.py
+-rw-rw-rw-   0        0        0     1388 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_disable_comments.py
+-rw-rw-rw-   0        0        0     2922 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_disable_endpoint_cache.py
+-rw-rw-rw-   0        0        0     1491 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_disable_exact_cardinality.py
+-rw-rw-rw-   0        0        0     2557 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_disable_or_statements.py
+-rw-rw-rw-   0        0        0     3786 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_discard_and_compliant.py
+-rw-rw-rw-   0        0        0     5213 2024-05-09 09:33:55.000000 shexer-2.5.2/test/test_examples_mode.py
+-rw-rw-rw-   0        0        0     2090 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_file_target_classes.py
+-rw-rw-rw-   0        0        0     1677 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_graph_file_input.py
+-rw-rw-rw-   0        0        0     3456 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_graph_list_of_file_inputs.py
+-rw-rw-rw-   0        0        0     1951 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_infer_numeric_types_for_untyped_literals.py
+-rw-rw-rw-   0        0        0     8663 2024-05-02 15:57:04.000000 shexer-2.5.2/test/test_input_format.py
+-rw-rw-rw-   0        0        0     4648 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_instances_cap.py
+-rw-rw-rw-   0        0        0     3367 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_instances_file_input.py
+-rw-rw-rw-   0        0        0     3852 2024-05-08 19:22:53.000000 shexer-2.5.2/test/test_instances_report.py
+-rw-rw-rw-   0        0        0     3548 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_instantiation_property.py
+-rw-rw-rw-   0        0        0     1964 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_inverse_paths.py
+-rw-rw-rw-   0        0        0     3594 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_keep_less_specific.py
+-rw-rw-rw-   0        0        0     4051 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_list_of_url_input.py
+-rw-rw-rw-   0        0        0     4127 2024-05-02 16:13:25.000000 shexer-2.5.2/test/test_namespaces_dict.py
+-rw-rw-rw-   0        0        0     2082 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_namespaces_to_ignore.py
+-rw-rw-rw-   0        0        0     5000 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_raw_graph.py
+-rw-rw-rw-   0        0        0     4300 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_raw_shape_map.py
+-rw-rw-rw-   0        0        0     1711 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_rdflib_graph.py
+-rw-rw-rw-   0        0        0     2932 2023-10-20 16:00:26.000000 shexer-2.5.2/test/test_remove_empty_sahpes.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:53.105769 shexer-2.5.2/test/test_shacl/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shacl/__init__.py
+-rw-rw-rw-   0        0        0     2225 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shacl/test_annotation.py
+-rw-rw-rw-   0        0        0     2242 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shacl/test_class_selection.py
+-rw-rw-rw-   0        0        0     3291 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shacl/test_detect_minimal_iri.py
+-rw-rw-rw-   0        0        0      875 2023-11-10 20:24:47.000000 shexer-2.5.2/test/test_shacl/test_https.py
+-rw-rw-rw-   0        0        0     1534 2023-11-10 20:24:47.000000 shexer-2.5.2/test/test_shacl/test_literal_types.py
+-rw-rw-rw-   0        0        0     4313 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shape_map_file.py
+-rw-rw-rw-   0        0        0     6086 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shape_map_format.py
+-rw-rw-rw-   0        0        0     2307 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shape_qualifiers_mode.py
+-rw-rw-rw-   0        0        0     2889 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_shapes_namespaces.py
+-rw-rw-rw-   0        0        0     2452 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_sort.py
+-rw-rw-rw-   0        0        0     2058 2023-10-20 15:05:20.000000 shexer-2.5.2/test/test_target_classes.py
+-rw-rw-rw-   0        0        0     3120 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_threshold.py
+-rw-rw-rw-   0        0        0     2661 2024-05-02 16:13:25.000000 shexer-2.5.2/test/test_uml_gen.py
+-rw-rw-rw-   0        0        0     2578 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_url_endpoint.py
+-rw-rw-rw-   0        0        0     1867 2023-06-27 16:13:11.000000 shexer-2.5.2/test/test_url_graph.py
+-rw-rw-rw-   0        0        0     1931 2024-04-05 16:49:28.000000 shexer-2.5.2/test/test_wikidata_annotation.py
+drwxrwxrwx   0        0        0        0 2024-05-14 17:27:53.128662 shexer-2.5.2/ws/
+-rw-rw-rw-   0        0        0        0 2023-06-27 16:13:11.000000 shexer-2.5.2/ws/__init__.py
+-rw-rw-rw-   0        0        0    19884 2023-06-27 16:13:11.000000 shexer-2.5.2/ws/shexer_rest.py
+-rw-rw-rw-   0        0        0       28 2023-06-27 16:13:11.000000 shexer-2.5.2/ws/wsgi.py
```

### Comparing `shexer-2.5.1/LICENSE` & `shexer-2.5.2/LICENSE`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,201 +1,201 @@
-                                 Apache License
-                           Version 2.0, January 2004
-                        http://www.apache.org/licenses/
-
-   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-      "License" shall mean the terms and conditions for use, reproduction,
-      and distribution as defined by Sections 1 through 9 of this document.
-
-      "Licensor" shall mean the copyright owner or entity authorized by
-      the copyright owner that is granting the License.
-
-      "Legal Entity" shall mean the union of the acting entity and all
-      other entities that control, are controlled by, or are under common
-      control with that entity. For the purposes of this definition,
-      "control" means (i) the power, direct or indirect, to cause the
-      direction or management of such entity, whether by contract or
-      otherwise, or (ii) ownership of fifty percent (50%) or more of the
-      outstanding shares, or (iii) beneficial ownership of such entity.
-
-      "You" (or "Your") shall mean an individual or Legal Entity
-      exercising permissions granted by this License.
-
-      "Source" form shall mean the preferred form for making modifications,
-      including but not limited to software source code, documentation
-      source, and configuration files.
-
-      "Object" form shall mean any form resulting from mechanical
-      transformation or translation of a Source form, including but
-      not limited to compiled object code, generated documentation,
-      and conversions to other media types.
-
-      "Work" shall mean the work of authorship, whether in Source or
-      Object form, made available under the License, as indicated by a
-      copyright notice that is included in or attached to the work
-      (an example is provided in the Appendix below).
-
-      "Derivative Works" shall mean any work, whether in Source or Object
-      form, that is based on (or derived from) the Work and for which the
-      editorial revisions, annotations, elaborations, or other modifications
-      represent, as a whole, an original work of authorship. For the purposes
-      of this License, Derivative Works shall not include works that remain
-      separable from, or merely link (or bind by name) to the interfaces of,
-      the Work and Derivative Works thereof.
-
-      "Contribution" shall mean any work of authorship, including
-      the original version of the Work and any modifications or additions
-      to that Work or Derivative Works thereof, that is intentionally
-      submitted to Licensor for inclusion in the Work by the copyright owner
-      or by an individual or Legal Entity authorized to submit on behalf of
-      the copyright owner. For the purposes of this definition, "submitted"
-      means any form of electronic, verbal, or written communication sent
-      to the Licensor or its representatives, including but not limited to
-      communication on electronic mailing lists, source code control systems,
-      and issue tracking systems that are managed by, or on behalf of, the
-      Licensor for the purpose of discussing and improving the Work, but
-      excluding communication that is conspicuously marked or otherwise
-      designated in writing by the copyright owner as "Not a Contribution."
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity
-      on behalf of whom a Contribution has been received by Licensor and
-      subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      copyright license to reproduce, prepare Derivative Works of,
-      publicly display, publicly perform, sublicense, and distribute the
-      Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of
-      this License, each Contributor hereby grants to You a perpetual,
-      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
-      (except as stated in this section) patent license to make, have made,
-      use, offer to sell, sell, import, and otherwise transfer the Work,
-      where such license applies only to those patent claims licensable
-      by such Contributor that are necessarily infringed by their
-      Contribution(s) alone or by combination of their Contribution(s)
-      with the Work to which such Contribution(s) was submitted. If You
-      institute patent litigation against any entity (including a
-      cross-claim or counterclaim in a lawsuit) alleging that the Work
-      or a Contribution incorporated within the Work constitutes direct
-      or contributory patent infringement, then any patent licenses
-      granted to You under this License for that Work shall terminate
-      as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the
-      Work or Derivative Works thereof in any medium, with or without
-      modifications, and in Source or Object form, provided that You
-      meet the following conditions:
-
-      (a) You must give any other recipients of the Work or
-          Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices
-          stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works
-          that You distribute, all copyright, patent, trademark, and
-          attribution notices from the Source form of the Work,
-          excluding those notices that do not pertain to any part of
-          the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its
-          distribution, then any Derivative Works that You distribute must
-          include a readable copy of the attribution notices contained
-          within such NOTICE file, excluding those notices that do not
-          pertain to any part of the Derivative Works, in at least one
-          of the following places: within a NOTICE text file distributed
-          as part of the Derivative Works; within the Source form or
-          documentation, if provided along with the Derivative Works; or,
-          within a display generated by the Derivative Works, if and
-          wherever such third-party notices normally appear. The contents
-          of the NOTICE file are for informational purposes only and
-          do not modify the License. You may add Your own attribution
-          notices within Derivative Works that You distribute, alongside
-          or as an addendum to the NOTICE text from the Work, provided
-          that such additional attribution notices cannot be construed
-          as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and
-      may provide additional or different license terms and conditions
-      for use, reproduction, or distribution of Your modifications, or
-      for any such Derivative Works as a whole, provided Your use,
-      reproduction, and distribution of the Work otherwise complies with
-      the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise,
-      any Contribution intentionally submitted for inclusion in the Work
-      by You to the Licensor shall be under the terms and conditions of
-      this License, without any additional terms or conditions.
-      Notwithstanding the above, nothing herein shall supersede or modify
-      the terms of any separate license agreement you may have executed
-      with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade
-      names, trademarks, service marks, or product names of the Licensor,
-      except as required for reasonable and customary use in describing the
-      origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or
-      agreed to in writing, Licensor provides the Work (and each
-      Contributor provides its Contributions) on an "AS IS" BASIS,
-      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
-      implied, including, without limitation, any warranties or conditions
-      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
-      PARTICULAR PURPOSE. You are solely responsible for determining the
-      appropriateness of using or redistributing the Work and assume any
-      risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory,
-      whether in tort (including negligence), contract, or otherwise,
-      unless required by applicable law (such as deliberate and grossly
-      negligent acts) or agreed to in writing, shall any Contributor be
-      liable to You for damages, including any direct, indirect, special,
-      incidental, or consequential damages of any character arising as a
-      result of this License or out of the use or inability to use the
-      Work (including but not limited to damages for loss of goodwill,
-      work stoppage, computer failure or malfunction, or any and all
-      other commercial damages or losses), even if such Contributor
-      has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing
-      the Work or Derivative Works thereof, You may choose to offer,
-      and charge a fee for, acceptance of support, warranty, indemnity,
-      or other liability obligations and/or rights consistent with this
-      License. However, in accepting such obligations, You may act only
-      on Your own behalf and on Your sole responsibility, not on behalf
-      of any other Contributor, and only if You agree to indemnify,
-      defend, and hold each Contributor harmless for any liability
-      incurred by, or claims asserted against, such Contributor by reason
-      of your accepting any such warranty or additional liability.
-
-   END OF TERMS AND CONDITIONS
-
-   APPENDIX: How to apply the Apache License to your work.
-
-      To apply the Apache License to your work, attach the following
-      boilerplate notice, with the fields enclosed by brackets "[]"
-      replaced with your own identifying information. (Don't include
-      the brackets!)  The text should be enclosed in the appropriate
-      comment syntax for the file format. We also recommend that a
-      file or class name and description of purpose be included on the
-      same "printed page" as the copyright notice for easier
-      identification within third-party archives.
-
-   Copyright [yyyy] [name of copyright owner]
-
-   Licensed under the Apache License, Version 2.0 (the "License");
-   you may not use this file except in compliance with the License.
-   You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
+                                 Apache License
+                           Version 2.0, January 2004
+                        http://www.apache.org/licenses/
+
+   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+      "License" shall mean the terms and conditions for use, reproduction,
+      and distribution as defined by Sections 1 through 9 of this document.
+
+      "Licensor" shall mean the copyright owner or entity authorized by
+      the copyright owner that is granting the License.
+
+      "Legal Entity" shall mean the union of the acting entity and all
+      other entities that control, are controlled by, or are under common
+      control with that entity. For the purposes of this definition,
+      "control" means (i) the power, direct or indirect, to cause the
+      direction or management of such entity, whether by contract or
+      otherwise, or (ii) ownership of fifty percent (50%) or more of the
+      outstanding shares, or (iii) beneficial ownership of such entity.
+
+      "You" (or "Your") shall mean an individual or Legal Entity
+      exercising permissions granted by this License.
+
+      "Source" form shall mean the preferred form for making modifications,
+      including but not limited to software source code, documentation
+      source, and configuration files.
+
+      "Object" form shall mean any form resulting from mechanical
+      transformation or translation of a Source form, including but
+      not limited to compiled object code, generated documentation,
+      and conversions to other media types.
+
+      "Work" shall mean the work of authorship, whether in Source or
+      Object form, made available under the License, as indicated by a
+      copyright notice that is included in or attached to the work
+      (an example is provided in the Appendix below).
+
+      "Derivative Works" shall mean any work, whether in Source or Object
+      form, that is based on (or derived from) the Work and for which the
+      editorial revisions, annotations, elaborations, or other modifications
+      represent, as a whole, an original work of authorship. For the purposes
+      of this License, Derivative Works shall not include works that remain
+      separable from, or merely link (or bind by name) to the interfaces of,
+      the Work and Derivative Works thereof.
+
+      "Contribution" shall mean any work of authorship, including
+      the original version of the Work and any modifications or additions
+      to that Work or Derivative Works thereof, that is intentionally
+      submitted to Licensor for inclusion in the Work by the copyright owner
+      or by an individual or Legal Entity authorized to submit on behalf of
+      the copyright owner. For the purposes of this definition, "submitted"
+      means any form of electronic, verbal, or written communication sent
+      to the Licensor or its representatives, including but not limited to
+      communication on electronic mailing lists, source code control systems,
+      and issue tracking systems that are managed by, or on behalf of, the
+      Licensor for the purpose of discussing and improving the Work, but
+      excluding communication that is conspicuously marked or otherwise
+      designated in writing by the copyright owner as "Not a Contribution."
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity
+      on behalf of whom a Contribution has been received by Licensor and
+      subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      copyright license to reproduce, prepare Derivative Works of,
+      publicly display, publicly perform, sublicense, and distribute the
+      Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of
+      this License, each Contributor hereby grants to You a perpetual,
+      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
+      (except as stated in this section) patent license to make, have made,
+      use, offer to sell, sell, import, and otherwise transfer the Work,
+      where such license applies only to those patent claims licensable
+      by such Contributor that are necessarily infringed by their
+      Contribution(s) alone or by combination of their Contribution(s)
+      with the Work to which such Contribution(s) was submitted. If You
+      institute patent litigation against any entity (including a
+      cross-claim or counterclaim in a lawsuit) alleging that the Work
+      or a Contribution incorporated within the Work constitutes direct
+      or contributory patent infringement, then any patent licenses
+      granted to You under this License for that Work shall terminate
+      as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the
+      Work or Derivative Works thereof in any medium, with or without
+      modifications, and in Source or Object form, provided that You
+      meet the following conditions:
+
+      (a) You must give any other recipients of the Work or
+          Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices
+          stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works
+          that You distribute, all copyright, patent, trademark, and
+          attribution notices from the Source form of the Work,
+          excluding those notices that do not pertain to any part of
+          the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its
+          distribution, then any Derivative Works that You distribute must
+          include a readable copy of the attribution notices contained
+          within such NOTICE file, excluding those notices that do not
+          pertain to any part of the Derivative Works, in at least one
+          of the following places: within a NOTICE text file distributed
+          as part of the Derivative Works; within the Source form or
+          documentation, if provided along with the Derivative Works; or,
+          within a display generated by the Derivative Works, if and
+          wherever such third-party notices normally appear. The contents
+          of the NOTICE file are for informational purposes only and
+          do not modify the License. You may add Your own attribution
+          notices within Derivative Works that You distribute, alongside
+          or as an addendum to the NOTICE text from the Work, provided
+          that such additional attribution notices cannot be construed
+          as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and
+      may provide additional or different license terms and conditions
+      for use, reproduction, or distribution of Your modifications, or
+      for any such Derivative Works as a whole, provided Your use,
+      reproduction, and distribution of the Work otherwise complies with
+      the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise,
+      any Contribution intentionally submitted for inclusion in the Work
+      by You to the Licensor shall be under the terms and conditions of
+      this License, without any additional terms or conditions.
+      Notwithstanding the above, nothing herein shall supersede or modify
+      the terms of any separate license agreement you may have executed
+      with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade
+      names, trademarks, service marks, or product names of the Licensor,
+      except as required for reasonable and customary use in describing the
+      origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or
+      agreed to in writing, Licensor provides the Work (and each
+      Contributor provides its Contributions) on an "AS IS" BASIS,
+      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+      implied, including, without limitation, any warranties or conditions
+      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
+      PARTICULAR PURPOSE. You are solely responsible for determining the
+      appropriateness of using or redistributing the Work and assume any
+      risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory,
+      whether in tort (including negligence), contract, or otherwise,
+      unless required by applicable law (such as deliberate and grossly
+      negligent acts) or agreed to in writing, shall any Contributor be
+      liable to You for damages, including any direct, indirect, special,
+      incidental, or consequential damages of any character arising as a
+      result of this License or out of the use or inability to use the
+      Work (including but not limited to damages for loss of goodwill,
+      work stoppage, computer failure or malfunction, or any and all
+      other commercial damages or losses), even if such Contributor
+      has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing
+      the Work or Derivative Works thereof, You may choose to offer,
+      and charge a fee for, acceptance of support, warranty, indemnity,
+      or other liability obligations and/or rights consistent with this
+      License. However, in accepting such obligations, You may act only
+      on Your own behalf and on Your sole responsibility, not on behalf
+      of any other Contributor, and only if You agree to indemnify,
+      defend, and hold each Contributor harmless for any liability
+      incurred by, or claims asserted against, such Contributor by reason
+      of your accepting any such warranty or additional liability.
+
+   END OF TERMS AND CONDITIONS
+
+   APPENDIX: How to apply the Apache License to your work.
+
+      To apply the Apache License to your work, attach the following
+      boilerplate notice, with the fields enclosed by brackets "[]"
+      replaced with your own identifying information. (Don't include
+      the brackets!)  The text should be enclosed in the appropriate
+      comment syntax for the file format. We also recommend that a
+      file or class name and description of purpose be included on the
+      same "printed page" as the copyright notice for easier
+      identification within third-party archives.
+
+   Copyright [yyyy] [name of copyright owner]
+
+   Licensed under the Apache License, Version 2.0 (the "License");
+   you may not use this file except in compliance with the License.
+   You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
```

### Comparing `shexer-2.5.1/PKG-INFO` & `shexer-2.5.2/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,266 +1,260 @@
-Metadata-Version: 2.1
-Name: shexer
-Version: 2.5.1
-Summary: Automatic schema extraction for RDF graphs
-Home-page: https://github.com/DaniFdezAlvarez/shexer
-Download-URL: https://github.com/DaniFdezAlvarez/shexer/archive/2.5.1.tar.gz
-Author: Daniel Fernandez-Alvarez
-Author-email: danifdezalvarez@gmail.com
-Keywords: testing,shexer,shexerp3,rdf,shex,shacl,schema
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Intended Audience :: Science/Research
-Classifier: Intended Audience :: Information Technology
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Description-Content-Type: text/markdown
-License-File: LICENSE
-Requires-Dist: Flask
-Requires-Dist: Flask-Cors
-Requires-Dist: rdflib
-Requires-Dist: SPARQLWrapper
-Requires-Dist: wlighter
-Requires-Dist: plantuml
-
-# sheXer
-
-This library can be used to perform automatic extraction of shape expressions (ShEx) or Shapes Constraint Language (SHACL) for a target RDF grpah. Please, feel free to add an issue to this repository if you find any bug in sheXer or if you have a feature request.
-
-
-Language:
-
-[![Pyversions](https://img.shields.io/pypi/pyversions/shexer.svg)](https://pypi.python.org/pypi/shexer)
-
-## Citation
-
-Use this work in case you want to cite this software: [Automatic extraction of shapes using sheXer](https://doi.org/10.1016/j.knosys.2021.107975).
-
-If you want to read the paper but cannot access the full-content using the previous link, there is a [preprint available in Researchgate](https://www.researchgate.net/publication/357146819_Automatic_extraction_of_shapes_using_sheXer).
-
-
-However, please, be aware that this software capabilities' have evolved and improved since the publication of the mentioned paper.
-
-## Installation
-
-sheXer can be installed using pip:
-
-    $ pip install shexer
-	
-Iy you want to install sheXer by source, all its external dependencies are listed in the file requirements.txt. You can install them all as well using pip:
-
-    $ pip install -r requirements.txt
-
-sheXer includes a package to deploy a wer service exposing sheXer with a REST API. In case you are not interested in deploying this web service, you don't need to install any dependency related to Flask.
-
-
-## Features
-
-* **Process huge sources**. sheXer does not need to load the whole content of the graph in main memory at any time, so big graphs can be processed in average hardware. Currently this is available just for some input formats: n-triples (choose const.NT as for input_format), and turtle (choose const.TURTLE_ITER).
-
-* **Several ways to provide input data**, consisting of a target graph and some target shapes. Tha graph can be provided via raw string content, local/remote file(s), or tracking on the fly some triples from a SPARQL endpoint. There are defined interfaces in case you want to implement some other way to provide input information. 
-
-* **Several ways to select your target shapes**. You may want to generate shapes for each class in the graph or maybe just for some of them. You may want to generate a shape for some custom node agrupations. Or maybe you are extracting some shapes from a big grpah and you just want to explore the neighborhood of some seed nodes.  For custom node aggrupations sheXer supports ShEx's shape maps syntax, and it provides configuration params to target different classes or graph depths. 
-
-* **Valid ShEx and SHACL**. The produced shapes are compilant with the current specification of ShEx2 and SHACL.
-
-* **UML**. Ypu can also generate UML-like views of the extracted schemas.
-
-* **Threshold of tolerance**. The constraints inferred for each shape may not be compatible with every node associated to the shapes. With this threshold you can indicate the minimun percentage of nodes that should conform with a constraint c. If c does not reach the indicated ratio, its associated information will not appear in the final shape.
-
-* **Informative comments** (just for ShEx, by now). Each constraint inferred is associated to one or more comments. Those comments include different types of information, such as the ratio of nodes that actually conform with a given constraint. You can keep this informative comments or exclude them from the results.
-
-* **Sorted constraints** (just for ShEx, by now). For a given constraint, sheXer keeps the ratio of nodes that conform with it. This is used as a score of trustworthiness. The constraints in a shape are sorted w.r.t. this score.
-
-* **Literals recognition**. All kinds of typed literals are recognized and treated separately when inferring the constraints. In case a literal is not explicitly associated with a type in the original KG, xsd:string is used by default. By default, when sheXer finds an untyped literal it tries to infer its type when it is a number. Support to some other untyped literals, such as geolocated points, may be included in future releases.
-
-* **Shapes interlinkage**: sheXer is able to detect links between shapes when there is a link between two nodes and those nodes are used to extract some shape. When it detects triples linking a node that does not belong to any other shape, then it uses the macro IRI instead.
-
-* **Special treatment of rdf:type** (or the specified instantiation property). When the predicate of a triple is rdf:type, sheXer creates a constraint whose object is a value set containing a single element. This is the actual object of the original triple.
-
-* **Cardinality management**. Some of the triples of a given instance may fit in an infinite number of constraint triples with the same predicate and object but different cardinality. For example, if a given instance has a single label specified by rdfs:label, that makes it fit with infinite triple constraints with the schema {rdfs:label xsd:string C}, where C can be any cardinality that includes the posibility of a single occurrence: {1}, + , {1,2}, {1,3}, {1,4},... Currently, sheXer admints exact cardinalities ({2}, {3}..), kleene closure (\*), positive closure (+), and optional cardinality (?).
-
-* **Inverse paths**. sheXer can extract constraints related to incomming links. Shapes are usually described using contraints realted to outgoing links, i.d., triples in which the node is the subject. However, sheXer can extract also constraints where the node is the object.
-
-* **Configurable priority of cardinalities**. sheXer can be configured to prioritize the less specific cardinality or the most specific one if its trustworthiness score is high enough.
-
-* **Example serialization**. sheXer is able to produce outputs that include examples of instances among the input data matching each shape and/or examples of node constraints matching each constraint of each shape. Currently, this feature works only with ShEx outputs.
-
-* **All compliant mode**: You can produce shapes that conform with every instance using to extract them. This is done by using cadinalities \* or ? for every constraint extracted that does not conform with EVERY instance. You may prefer to avoid these cardinalities and keep constraints that may not conform with every instance, but include the most frequent features of the instances. Both settings are available in sheXer.
-
-* **Management of empty shapes**. You may get some shapes with no constraints, either because there where no isntances to explore or because the extracted features were not as common as requested with the threshold of tolerance. You can configure sheXer to automatically erase those shapes and every mention to them from the results. 
-
-* **Adaptation to Wikidata model**. sheXer includes configuration params to handle Wikidata's data model regarding qualifiers, so you can automatically extract the schema of qualifier nodes too. You can also produce content where each Wikidata ID is associated with  its label in comments, as sheXer is integrated with [wLighter](https://github.com/DaniFdezAlvarez/wLighter).
-
-
-## Experimental results
-
-In the folder [experiments](https://github.com/DaniFdezAlvarez/shexer/tree/develop/experiments), you can see some results of applying this tool over different graphs with different configurations.
-
-## Example code
-
-The following code takes the graph in _raw\_graph_ and extracts shapes for instances of the classes <http://example.org/Person> and <http://example.org/Gender>. The input file format in n-triples and the results are serialized in ShExC to the file shaper_example.shex.
-
-```python
-from shexer.shaper import Shaper
-from shexer.consts import NT, SHEXC, SHACL_TURTLE
-
-target_classes = [
-    "http://example.org/Person",
-    "http://example.org/Gender"
-]
-
-namespaces_dict = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
-                   "http://example.org/": "ex",
-                   "http://weso.es/shapes/": "",
-                   "http://www.w3.org/2001/XMLSchema#": "xsd"
-                   }
-
-raw_graph = """
-<http://example.org/sarah> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
-<http://example.org/sarah> <http://example.org/age> "30"^^<http://www.w3.org/2001/XMLSchema#int> .
-<http://example.org/sarah> <http://example.org/name> "Sarah" .
-<http://example.org/sarah> <http://example.org/gender> <http://example.org/Female> .
-<http://example.org/sarah> <http://example.org/occupation> <http://example.org/Doctor> .
-<http://example.org/sarah> <http://example.org/brother> <http://example.org/Jim> .
-
-<http://example.org/jim> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
-<http://example.org/jim> <http://example.org/age> "28"^^<http://www.w3.org/2001/XMLSchema#int> .
-<http://example.org/jim> <http://example.org/name> "Jimbo".
-<http://example.org/jim> <http://example.org/surname> "Mendes".
-<http://example.org/jim> <http://example.org/gender> <http://example.org/Male> .
-
-<http://example.org/Male> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Male> <http://www.w3.org/2000/01/rdf-schema#label> "Male" .
-<http://example.org/Female> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Female> <http://www.w3.org/2000/01/rdf-schema#label> "Female" .
-<http://example.org/Other> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Other> <http://www.w3.org/2000/01/rdf-schema#label> "Other gender" .
-"""
-
-
-
-input_nt_file = "target_graph.nt"
-
-shaper = Shaper(target_classes=target_classes,
-                raw_graph=raw_graph,
-                input_format=NT,
-                namespaces_dict=namespaces_dict,  # Default: no prefixes
-                instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type")  # Default rdf:type
-
-output_file = "shaper_example.shex"
-
-shaper.shex_graph(output_file=output_file,
-                  acceptance_threshold=0.1)
-
-print("Done!")
-
-```
-
-By default, sheXer generates ShExC. If you want to produce SHACL, indicate it as a param in the shex_graph method as follows:
-
-```python
-# Use the same imports and param definition of the previous example code
-
-output_file = "shaper_example.ttl"
-
-shaper.shex_graph(output_file=output_file,
-                  acceptance_threshold=0.1,
-                  output_format=SHACL_TURTLE)
-
-print("Done!")
-
-```
-
-You can also find some examples of how to process Wikidata with sheXer in [this Jupyter notebook](https://github.com/DaniFdezAlvarez/shexer/blob/master/doc/shexer_wikidata_tutorial.ipynb).
-
-
-## The Class Shaper
-
-Most of the features provided by this software are reachable using the class Shaper. As it is shown in the previous example code, one must get an instance of Shaper with some params and execute a method to perform the schema extraction.
-
-### init
-The __init__ method of Shaper includes many params, being optional most of them. Don't panic due to the high number of params. You just need to focus on three main questions:
-
-* How are you going to provide the graph to the library? Via a raw string, a local file, a downloadable content, an SPARQL endpoint...
-* Which shapes do you want to extract? A group of target classes, every class in the graph, or custom node groupings specified with shape maps (in a string, in a file...)?
-* Do you want to configure some special feature to tune the extraction process? Priority to less specific constraints, all-compliant mode, disbale comments...
-
-You'll find a param in the __init__ of Shaper to provide the information in the way you want. Use it using a keyword when creating your instance of Shaper (as in the example code of this document) and just forget about the rest. Shaper has a default value for them all.
-
-The following list describes each param of the __init__ of Shaper:
-
-#### Params to define target shapes:
-You must indicate al least one way to identify target instances and the shapes that should be generated. Some of this params are compatible, some others are not. For example, sheXer do not allow to indicate target classes and to activate all-classes mode, as it is contradictory. However, you can provide a shape map to make custom node aggrupations and use all_classes mode too, so you obtain shapes for those groupings and for each class.
-
-* target_classes (default None): a list containing URIs (string) of the classes whose shape must be extracted. 
-* file_target_classes (default None): a path to a file containing the URIs of the classes whose shape must be extracted. 
-* all_classes_mode (default False): when it is set to True, you do not net to provide a list of target classes. sheXer will produce a shape for each class with at least one instance. 
-* shape_map_raw (default None): use it to provide custom groupings of nodes using a shape map as a raw string.
-* shape_map_file (default None): use it to provide a path to a local file containing custom groupings of nodes using a shape map.
-
-#### Params to provide the input
-You must provide at least an input: a file, a string, an endpoint, a remote graph... you may also want to tune some other aspects, such as the format of the input or namespace-prefix pairs to be used.
-
-
-* instances_file_input (default None): in case you have a separate file in which instantiation relations can be found, provide its path here. If you dont provide any value, the shaper will look for instances in the graph used as input.
-* graph_file_input (default None): a path to the file in which the target graph can be found.
-* graph_list_of_files_input (default None): in case your graph is separated in several files (all of them with the same format), provide a list of string paths to those files here.
-* raw_graph (default None): a simple raw string containing the target graph.
-* url_graph_input (default None): use it to provide a URL of some downloadable RDF content available online to be used as target graph.
-* list_of_url_input (default None): use it to provide several URLs of downloadable RDF content available online to be used as target graph.
-* url_endpoint (default None): it expects the URL of an SPARQL endpoint. Use it if you want to get some relevant triples form that endpoint instead of providing a whole RDF graph. In this case, the triples will be those ones whose subject is one of the nodes used to build the shapes (instances of a target class, result of a node selector in a shape map).
-* instances_cap (default -1): when this param is set to a positive value, sheXer will only use a maximun of instance_cap instances to get extract each shape. This may cause some lost of information, but if the sample of instances used is representative enough, your results won't be that different but you'll save main memory and execution time. 
-* depth_for_building_subgraph (default 1): use this param just in case you are working against a SPARQL endpoint. This integer indicates the max distance from any seed node to consider in order to track a subgraph from the endpoint. Please, remind that a high depth can cause a massive number of queries and have a high performance cost. 
-* track_classes_for_entities_at_last_depth_level (default True): use this param just in case you are working against a SPARQL endpoint. If it set to True, it makes a step further to the distance to the seed nodes indicated in the param depth. However, it will just look for triples related to typing, not the whole neighborhood of the nodes in the last level of depth.
-* limit_remote_instances *DEPRECATED* (default -1). Use this param if you are working against an endpoint using the param target_classes. If it is set to a positive number, sheXer will just get limit_remote_instances instances for each class from the endpoint (by adding LIMIT at the end of the sparql query). This is useful when working with big sources with tons on instances, causing too many or too heavy SPARQL queries to retrieve  all the content. NOTE: This parameter only affects computation consuming SPARQL endpoints. On the other hand, the parameter instances_cap works for any case, including SPARQL endpoints. Due to retrocompatibility reasons, limit_remote_instances still works, but it will be removed in future sheXer releases.
-* disable_endpoint_cache (default False). By default, if sheXer is told to consume triples from an endpoint, it will make some SPARQL queries and store the results in a local graph. If this parameter is set to True, sheXer won't save that content locally. This will help to reduce main memory usage, but will decrease the performance, as sheXer will need to make more SPARQL queries to the endpoint.
-* namespaces_dict (default None): dictionary in which the keys are namespaces and the values are their expected prefixes in the outputs. 
-* input_format (default "NT"): the format of the graph which is going to be computed. The default value is const.NT. IMPORTANT: currently, sheXer does not guess input format, so ensure you specify the format here in case you are not providing n-triples content. In case you provide a combined input (several files, several URLs...) they all should have the same format. If you work against an endpoit, then this param do not have any effect.
-* compression_mode (default None). Only when you are working with local files, if they are compressed, you do not need to uncompress to parse them. Currently supported formats are ZIP, GZ, and XZ. Set compression_format to "zip", "gz", or "xz" to work with such files. Each gz or xz file will be assumed to contain a single graph file. Each zip file will be assumed to be a directory containing one or more graph files. In case the zip contains several files, they will be all parsed and merged (they should have the same format, indicated with input_format). In every case, sheXer won't write any uncompressed content to your disk.
-
-#### Params to tune the shexing process
-
-All this parameters have a default value so you do not need to use any of them. But you can modify the schema extraction in many different ways.
-
-* instantiation_property (default rdf:type): full URI (no prefixes) of the property linking instances and classes (ex: P31 in Wikidata's ontology)
-* namespaces_to_ignore (default None): list of namespaces of properties used in the target graph which are going to be ignored. For example, if you set namespaces_to_ignore to \[http://example.org/\], every triple whose predicate belongs to that namespace will not be computed. It just excludes properties whose name is a direct child of the namespace. For example, triples with <http:/example.org/foo> will be ignored, but triples with <http://example.org/anotherLevel/foo> will be computed.
-* infer_numeric_types_for_untyped_literals (default False): when it is set to True, if the parser finds a triple whose object in a number untyped (something like 56 instead of "56"^^xsd:int), it will accept it and consider it an int if it has decimals or a float if it does not. If it is set to False, triples like that will raise a parsing error.
-* discard_useles_constraints_with_positive_closure (default True): if it is set to True, when two constraints have been extracted with identical property and object, and one of them has '+' cardinality while the other one has a specific number of occurrences (example: {1}, {2}...), if they both have the same rate of compliance among the instances, the constraint with the '+' cardinality is discarded.
-* all_instances_are_compliant_mode (default True): when set to True, every inferred constraint which is not valid for all the instances of the class associated to the shape, then the cardinality of that constraint is changed to '\*' or '?'. With this, every instance conforms to the shape associated with its class. When it is set to False, no cardinality is changed, so there may be instances that do not conform to the inferred shape.
-* keep_less_specific (default True): when it is set to True, for a group of constraints with the same property and object but different cardinality, the one with less specific cardinality ('+') will be preserved, and the rest of constraints used to provide info in comments. When it is set to False, the preserved constraint will be the one with an integer as cardinality and the highest rate of conformance with the instances of the class.
-* disable_or_statements (default True): when set to False, sheXer tries to infer constraints with the operator oneOf (|) in case there are constraints with the same property but different object. By default, sheXer groups those constraint in a isngle one having the less general object possible. For instance, when the objects are different shapes, it merges the constraints a single one whose object is IRI.
-* allow_redundant_or (default False): when this is set to True, the example described for the disable_or_statements behaves differently. Let's say we have a set of candidate constraints whose property is the same but whose object differs: one have IRI, and two other have different shape labels (:A and :B). Whith allow_redundant_or=False, sheXer generates a single constraint with IRI and moves the information about the rest of discarded constraints with more specific objects to comments. However, with allow_redundant_or=True, the constraint generated will have a node constraint with a disjunction such as IRI OR @A OR @B. From the point of view of validation, as IRI subsumes :A and :B, this has no effect. However, some user whose extracted shapes are used to generate further products find this feature useful.   
-* allow_opt_cardinality (default True). When all-compliant mode is active, if there is a constraint which does not conform with every isntance but its maximun cardinality for any instance is {1}, it uses the optional cardinality (?). When set to False, it uses Kleene closure instead.
-* disable_opt_cardinality (dafault False). When set to True, it prevents any constraint to have a higher cardinality higher than one, even if every instance has that cardinality. For example, a constraint such as *ex:alias xsd:string {3}* will be changed to *ex:alias xsd:string +*.
-* shape_qualifiers_mode (default False). When it is set to True, it assumes a data model similar to Wikidata's one, where entity nodes are linked with qualifiers (BNodes) instead of the actual object meant by the triple. It is used to produce legible shapes for those special BNodes.
-* namespaces_for_qualifier_props (default None). Provide here a list of namespace in which the indirect properties used to link an entity with a qualifier node can be found. A reasonable configuration for Wikidata is namespaces_for_qualifier_props = \["http://www.wikidata.org/prop/"\] .
-* inverse_paths (default False). When it is set to True, sheXer will produce constraints with inverse_paths too. This is, constraints referring to triples in which the target node acst as object. Direct and inverse paths will be sorted in the final results w.r.t. their trutsworthiness score.
-* detect_minimal_iri (default False). When it is set to True, each shape will be associated with a regex pattern. That pattern expresses the initial part of the IRI that is common to every isntance used to extract a given shape. This pattern is only serialized when it is a "worthy" one (long enough, not just "http://", etc.).
-
-
-#### Params to tune some features of the output
-Again, all these params have a default value and you don't need to worry about them unless you want to tune the output.
-
-* remove_empty_shapes (default: True). When set to True, the result does not contain any empty shape nor any mention to it. If a shape A has a constraint pointing to a shape B and B is empty, then the constraint is modified and the macro IRI is used instead of B.
-* disable_comments (dafault: False). When set to True, the results do not contain comments.
-* shapes_namespace (default: http://weso.es/shapes/). This property allows you to change the namespace in which the shape labels are created in case you do not want to use the default one. The prefix of this namespace will be the empty prefix unless the empty prefix is already being used by other namespace. In that case, sheXer looks for other preferred prefixes, or will generate a random one if any of the default ones is available. 
-* wikidata_annotation (default: False). This param can be used when the output will contain Wikidata IDs. Using the library [wLighter](https://github.com/DaniFdezAlvarez/wLighter), the ourput is annotated with comments that associate a given every Wikidata ID with its English label. 
-* instances_report_mode (default, const.RATIO_INSTANCES). With this parameter, you can configure how is the information about instances complying to each expression shown. By default, sheXer shows a percetage of instances. If you set this parameter to const.ABSOLUTE_INSTANCES, then the comments will contain the exact number of complying instances instead of the ratio. sheXer will write a comment next to the shape label so you can also know how many isntances were used to extract a shape. If you set the parameter to const.MIXED_INSTANCES, the comments will contain both relative and absolute information.
-* decimals (default: -1). With this parameter you can configure the numnber of decimals to be used when writing ratios in comments. A negative numnber means that ratios will be written using its top precission. If you set this parameter to a natural number (including 0), then such number will be the number of decimals used. sheXer will round (not truncate) the original ratio to that precission.
-* examples_mode (default: None). You can set this parameter to one of the values included in the '#EXAMPLES' section of shexer.consts. If you choose SHAPE_EXAMPLES, sheXer will write the URI of an instance matching each shape extracted as a comment next to the shape label. If you choose CONSTRAINT_EXAMPLES, sheXer will write a comment including an example of node constraint matching each triple constraint of each shape (each value is used by an instance example with the triple constraint's property). If you choose ALL_EXAMPLES, sheXer will do both things. When the value of this parameter is None, sheXer will not serialize examples in comments.
-
-
-### Method __shex\_graph__
-
-The method __shex\_graph__  of shexer triggers all the inference process and gives back a result. It receives several parameters, being optional some of them:
-
-* string_output (default False): when it is set to True, the method returns a string representation of the inferred shapes. It must be set to True iff output_file is None.
-* output_file (default None): it specifies the path of the file in which the inferred shapes will be written. It must have a value different to None iff string_output is False.
-* output_format (default "ShExC"): format in which the inferred shapes will be serialized. The values currently supported are const.SHEXC and const.SHACLE_TURTLE.
-* aceptance_threshold (default 0): Given a certain inferred constraint __c__ for a shape __s__, the ammount of instances which conform to this constraint (ignoring constraints with '\*' cardinality) should be at least __aceptance\_threshold__. If this does not happen, then __c__ will not be included in __s__.
-* verbose (dafault False): when it is set to True, the extraction process will print log messages through the standard output.
-* to_uml_path (default None). This parameter expects to receive a disk path. If you provide a value here, sheXer will generate a UML diagram containing the extracted scheme and will save it in the path indicated as a PNG image. WARNING: you should be connected to Internet in  order to make this work.
-
-
+Metadata-Version: 2.1
+Name: shexer
+Version: 2.5.2
+Summary: Automatic schema extraction for RDF graphs
+Home-page: https://github.com/DaniFdezAlvarez/shexer
+Download-URL: https://github.com/DaniFdezAlvarez/shexer/archive/2.5.2.tar.gz
+Author: Daniel Fernandez-Alvarez
+Author-email: danifdezalvarez@gmail.com
+Keywords: testing,shexer,shexerp3,rdf,shex,shacl,schema
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Intended Audience :: Science/Research
+Classifier: Intended Audience :: Information Technology
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Description-Content-Type: text/markdown
+License-File: LICENSE
+
+# sheXer
+
+This library can be used to perform automatic extraction of shape expressions (ShEx) or Shapes Constraint Language (SHACL) for a target RDF grpah. Please, feel free to add an issue to this repository if you find any bug in sheXer or if you have a feature request.
+
+
+Language:
+
+[![Pyversions](https://img.shields.io/pypi/pyversions/shexer.svg)](https://pypi.python.org/pypi/shexer)
+
+## Citation
+
+Use this work in case you want to cite this software: [Automatic extraction of shapes using sheXer](https://doi.org/10.1016/j.knosys.2021.107975).
+
+If you want to read the paper but cannot access the full-content using the previous link, there is a [preprint available in Researchgate](https://www.researchgate.net/publication/357146819_Automatic_extraction_of_shapes_using_sheXer).
+
+
+However, please, be aware that this software capabilities' have evolved and improved since the publication of the mentioned paper.
+
+## Installation
+
+sheXer can be installed using pip:
+
+    $ pip install shexer
+	
+Iy you want to install sheXer by source, all its external dependencies are listed in the file requirements.txt. You can install them all as well using pip:
+
+    $ pip install -r requirements.txt
+
+sheXer includes a package to deploy a wer service exposing sheXer with a REST API. In case you are not interested in deploying this web service, you don't need to install any dependency related to Flask.
+
+
+## Features
+
+* **Process huge sources**. sheXer does not need to load the whole content of the graph in main memory at any time, so big graphs can be processed in average hardware. Currently this is available just for some input formats: n-triples (choose const.NT as for input_format), and turtle (choose const.TURTLE_ITER).
+
+* **Several ways to provide input data**, consisting of a target graph and some target shapes. Tha graph can be provided via raw string content, local/remote file(s), or tracking on the fly some triples from a SPARQL endpoint. There are defined interfaces in case you want to implement some other way to provide input information. 
+
+* **Several ways to select your target shapes**. You may want to generate shapes for each class in the graph or maybe just for some of them. You may want to generate a shape for some custom node agrupations. Or maybe you are extracting some shapes from a big grpah and you just want to explore the neighborhood of some seed nodes.  For custom node aggrupations sheXer supports ShEx's shape maps syntax, and it provides configuration params to target different classes or graph depths. 
+
+* **Valid ShEx and SHACL**. The produced shapes are compilant with the current specification of ShEx2 and SHACL.
+
+* **UML**. Ypu can also generate UML-like views of the extracted schemas.
+
+* **Threshold of tolerance**. The constraints inferred for each shape may not be compatible with every node associated to the shapes. With this threshold you can indicate the minimun percentage of nodes that should conform with a constraint c. If c does not reach the indicated ratio, its associated information will not appear in the final shape.
+
+* **Informative comments** (just for ShEx, by now). Each constraint inferred is associated to one or more comments. Those comments include different types of information, such as the ratio of nodes that actually conform with a given constraint. You can keep this informative comments or exclude them from the results.
+
+* **Sorted constraints** (just for ShEx, by now). For a given constraint, sheXer keeps the ratio of nodes that conform with it. This is used as a score of trustworthiness. The constraints in a shape are sorted w.r.t. this score.
+
+* **Literals recognition**. All kinds of typed literals are recognized and treated separately when inferring the constraints. In case a literal is not explicitly associated with a type in the original KG, xsd:string is used by default. By default, when sheXer finds an untyped literal it tries to infer its type when it is a number. Support to some other untyped literals, such as geolocated points, may be included in future releases.
+
+* **Shapes interlinkage**: sheXer is able to detect links between shapes when there is a link between two nodes and those nodes are used to extract some shape. When it detects triples linking a node that does not belong to any other shape, then it uses the macro IRI instead.
+
+* **Special treatment of rdf:type** (or the specified instantiation property). When the predicate of a triple is rdf:type, sheXer creates a constraint whose object is a value set containing a single element. This is the actual object of the original triple.
+
+* **Cardinality management**. Some of the triples of a given instance may fit in an infinite number of constraint triples with the same predicate and object but different cardinality. For example, if a given instance has a single label specified by rdfs:label, that makes it fit with infinite triple constraints with the schema {rdfs:label xsd:string C}, where C can be any cardinality that includes the posibility of a single occurrence: {1}, + , {1,2}, {1,3}, {1,4},... Currently, sheXer admints exact cardinalities ({2}, {3}..), kleene closure (\*), positive closure (+), and optional cardinality (?).
+
+* **Inverse paths**. sheXer can extract constraints related to incomming links. Shapes are usually described using contraints realted to outgoing links, i.d., triples in which the node is the subject. However, sheXer can extract also constraints where the node is the object.
+
+* **Configurable priority of cardinalities**. sheXer can be configured to prioritize the less specific cardinality or the most specific one if its trustworthiness score is high enough.
+
+* **Example serialization**. sheXer is able to produce outputs that include examples of instances among the input data matching each shape and/or examples of node constraints matching each constraint of each shape. Currently, this feature works only with ShEx outputs.
+
+* **All compliant mode**: You can produce shapes that conform with every instance using to extract them. This is done by using cadinalities \* or ? for every constraint extracted that does not conform with EVERY instance. You may prefer to avoid these cardinalities and keep constraints that may not conform with every instance, but include the most frequent features of the instances. Both settings are available in sheXer.
+
+* **Management of empty shapes**. You may get some shapes with no constraints, either because there where no isntances to explore or because the extracted features were not as common as requested with the threshold of tolerance. You can configure sheXer to automatically erase those shapes and every mention to them from the results. 
+
+* **Adaptation to Wikidata model**. sheXer includes configuration params to handle Wikidata's data model regarding qualifiers, so you can automatically extract the schema of qualifier nodes too. You can also produce content where each Wikidata ID is associated with  its label in comments, as sheXer is integrated with [wLighter](https://github.com/DaniFdezAlvarez/wLighter).
+
+
+## Experimental results
+
+In the folder [experiments](https://github.com/DaniFdezAlvarez/shexer/tree/develop/experiments), you can see some results of applying this tool over different graphs with different configurations.
+
+## Example code
+
+The following code takes the graph in _raw\_graph_ and extracts shapes for instances of the classes <http://example.org/Person> and <http://example.org/Gender>. The input file format in n-triples and the results are serialized in ShExC to the file shaper_example.shex.
+
+```python
+from shexer.shaper import Shaper
+from shexer.consts import NT, SHEXC, SHACL_TURTLE
+
+target_classes = [
+    "http://example.org/Person",
+    "http://example.org/Gender"
+]
+
+namespaces_dict = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
+                   "http://example.org/": "ex",
+                   "http://weso.es/shapes/": "",
+                   "http://www.w3.org/2001/XMLSchema#": "xsd"
+                   }
+
+raw_graph = """
+<http://example.org/sarah> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
+<http://example.org/sarah> <http://example.org/age> "30"^^<http://www.w3.org/2001/XMLSchema#int> .
+<http://example.org/sarah> <http://example.org/name> "Sarah" .
+<http://example.org/sarah> <http://example.org/gender> <http://example.org/Female> .
+<http://example.org/sarah> <http://example.org/occupation> <http://example.org/Doctor> .
+<http://example.org/sarah> <http://example.org/brother> <http://example.org/Jim> .
+
+<http://example.org/jim> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
+<http://example.org/jim> <http://example.org/age> "28"^^<http://www.w3.org/2001/XMLSchema#int> .
+<http://example.org/jim> <http://example.org/name> "Jimbo".
+<http://example.org/jim> <http://example.org/surname> "Mendes".
+<http://example.org/jim> <http://example.org/gender> <http://example.org/Male> .
+
+<http://example.org/Male> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Male> <http://www.w3.org/2000/01/rdf-schema#label> "Male" .
+<http://example.org/Female> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Female> <http://www.w3.org/2000/01/rdf-schema#label> "Female" .
+<http://example.org/Other> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Other> <http://www.w3.org/2000/01/rdf-schema#label> "Other gender" .
+"""
+
+
+
+input_nt_file = "target_graph.nt"
+
+shaper = Shaper(target_classes=target_classes,
+                raw_graph=raw_graph,
+                input_format=NT,
+                namespaces_dict=namespaces_dict,  # Default: no prefixes
+                instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type")  # Default rdf:type
+
+output_file = "shaper_example.shex"
+
+shaper.shex_graph(output_file=output_file,
+                  acceptance_threshold=0.1)
+
+print("Done!")
+
+```
+
+By default, sheXer generates ShExC. If you want to produce SHACL, indicate it as a param in the shex_graph method as follows:
+
+```python
+# Use the same imports and param definition of the previous example code
+
+output_file = "shaper_example.ttl"
+
+shaper.shex_graph(output_file=output_file,
+                  acceptance_threshold=0.1,
+                  output_format=SHACL_TURTLE)
+
+print("Done!")
+
+```
+
+You can also find some examples of how to process Wikidata with sheXer in [this Jupyter notebook](https://github.com/DaniFdezAlvarez/shexer/blob/master/doc/shexer_wikidata_tutorial.ipynb).
+
+
+## The Class Shaper
+
+Most of the features provided by this software are reachable using the class Shaper. As it is shown in the previous example code, one must get an instance of Shaper with some params and execute a method to perform the schema extraction.
+
+### init
+The __init__ method of Shaper includes many params, being optional most of them. Don't panic due to the high number of params. You just need to focus on three main questions:
+
+* How are you going to provide the graph to the library? Via a raw string, a local file, a downloadable content, an SPARQL endpoint...
+* Which shapes do you want to extract? A group of target classes, every class in the graph, or custom node groupings specified with shape maps (in a string, in a file...)?
+* Do you want to configure some special feature to tune the extraction process? Priority to less specific constraints, all-compliant mode, disbale comments...
+
+You'll find a param in the __init__ of Shaper to provide the information in the way you want. Use it using a keyword when creating your instance of Shaper (as in the example code of this document) and just forget about the rest. Shaper has a default value for them all.
+
+The following list describes each param of the __init__ of Shaper:
+
+#### Params to define target shapes:
+You must indicate al least one way to identify target instances and the shapes that should be generated. Some of this params are compatible, some others are not. For example, sheXer do not allow to indicate target classes and to activate all-classes mode, as it is contradictory. However, you can provide a shape map to make custom node aggrupations and use all_classes mode too, so you obtain shapes for those groupings and for each class.
+
+* target_classes (default None): a list containing URIs (string) of the classes whose shape must be extracted. 
+* file_target_classes (default None): a path to a file containing the URIs of the classes whose shape must be extracted. 
+* all_classes_mode (default False): when it is set to True, you do not net to provide a list of target classes. sheXer will produce a shape for each class with at least one instance. 
+* shape_map_raw (default None): use it to provide custom groupings of nodes using a shape map as a raw string.
+* shape_map_file (default None): use it to provide a path to a local file containing custom groupings of nodes using a shape map.
+
+#### Params to provide the input
+You must provide at least an input: a file, a string, an endpoint, a remote graph... you may also want to tune some other aspects, such as the format of the input or namespace-prefix pairs to be used.
+
+
+* instances_file_input (default None): in case you have a separate file in which instantiation relations can be found, provide its path here. If you dont provide any value, the shaper will look for instances in the graph used as input.
+* graph_file_input (default None): a path to the file in which the target graph can be found.
+* graph_list_of_files_input (default None): in case your graph is separated in several files (all of them with the same format), provide a list of string paths to those files here.
+* raw_graph (default None): a simple raw string containing the target graph.
+* url_graph_input (default None): use it to provide a URL of some downloadable RDF content available online to be used as target graph.
+* list_of_url_input (default None): use it to provide several URLs of downloadable RDF content available online to be used as target graph.
+* url_endpoint (default None): it expects the URL of an SPARQL endpoint. Use it if you want to get some relevant triples form that endpoint instead of providing a whole RDF graph. In this case, the triples will be those ones whose subject is one of the nodes used to build the shapes (instances of a target class, result of a node selector in a shape map).
+* instances_cap (default -1): when this param is set to a positive value, sheXer will only use a maximun of instance_cap instances to get extract each shape. This may cause some lost of information, but if the sample of instances used is representative enough, your results won't be that different but you'll save main memory and execution time. 
+* depth_for_building_subgraph (default 1): use this param just in case you are working against a SPARQL endpoint. This integer indicates the max distance from any seed node to consider in order to track a subgraph from the endpoint. Please, remind that a high depth can cause a massive number of queries and have a high performance cost. 
+* track_classes_for_entities_at_last_depth_level (default True): use this param just in case you are working against a SPARQL endpoint. If it set to True, it makes a step further to the distance to the seed nodes indicated in the param depth. However, it will just look for triples related to typing, not the whole neighborhood of the nodes in the last level of depth.
+* limit_remote_instances *DEPRECATED* (default -1). Use this param if you are working against an endpoint using the param target_classes. If it is set to a positive number, sheXer will just get limit_remote_instances instances for each class from the endpoint (by adding LIMIT at the end of the sparql query). This is useful when working with big sources with tons on instances, causing too many or too heavy SPARQL queries to retrieve  all the content. NOTE: This parameter only affects computation consuming SPARQL endpoints. On the other hand, the parameter instances_cap works for any case, including SPARQL endpoints. Due to retrocompatibility reasons, limit_remote_instances still works, but it will be removed in future sheXer releases.
+* disable_endpoint_cache (default False). By default, if sheXer is told to consume triples from an endpoint, it will make some SPARQL queries and store the results in a local graph. If this parameter is set to True, sheXer won't save that content locally. This will help to reduce main memory usage, but will decrease the performance, as sheXer will need to make more SPARQL queries to the endpoint.
+* namespaces_dict (default None): dictionary in which the keys are namespaces and the values are their expected prefixes in the outputs. 
+* input_format (default "NT"): the format of the graph which is going to be computed. The default value is const.NT. IMPORTANT: currently, sheXer does not guess input format, so ensure you specify the format here in case you are not providing n-triples content. In case you provide a combined input (several files, several URLs...) they all should have the same format. If you work against an endpoit, then this param do not have any effect.
+* compression_mode (default None). Only when you are working with local files, if they are compressed, you do not need to uncompress to parse them. Currently supported formats are ZIP, GZ, and XZ. Set compression_format to "zip", "gz", or "xz" to work with such files. Each gz or xz file will be assumed to contain a single graph file. Each zip file will be assumed to be a directory containing one or more graph files. In case the zip contains several files, they will be all parsed and merged (they should have the same format, indicated with input_format). In every case, sheXer won't write any uncompressed content to your disk.
+
+#### Params to tune the shexing process
+
+All this parameters have a default value so you do not need to use any of them. But you can modify the schema extraction in many different ways.
+
+* instantiation_property (default rdf:type): full URI (no prefixes) of the property linking instances and classes (ex: P31 in Wikidata's ontology)
+* namespaces_to_ignore (default None): list of namespaces of properties used in the target graph which are going to be ignored. For example, if you set namespaces_to_ignore to \[http://example.org/\], every triple whose predicate belongs to that namespace will not be computed. It just excludes properties whose name is a direct child of the namespace. For example, triples with <http:/example.org/foo> will be ignored, but triples with <http://example.org/anotherLevel/foo> will be computed.
+* infer_numeric_types_for_untyped_literals (default False): when it is set to True, if the parser finds a triple whose object in a number untyped (something like 56 instead of "56"^^xsd:int), it will accept it and consider it an int if it has decimals or a float if it does not. If it is set to False, triples like that will raise a parsing error.
+* discard_useles_constraints_with_positive_closure (default True): if it is set to True, when two constraints have been extracted with identical property and object, and one of them has '+' cardinality while the other one has a specific number of occurrences (example: {1}, {2}...), if they both have the same rate of compliance among the instances, the constraint with the '+' cardinality is discarded.
+* all_instances_are_compliant_mode (default True): when set to True, every inferred constraint which is not valid for all the instances of the class associated to the shape, then the cardinality of that constraint is changed to '\*' or '?'. With this, every instance conforms to the shape associated with its class. When it is set to False, no cardinality is changed, so there may be instances that do not conform to the inferred shape.
+* keep_less_specific (default True): when it is set to True, for a group of constraints with the same property and object but different cardinality, the one with less specific cardinality ('+') will be preserved, and the rest of constraints used to provide info in comments. When it is set to False, the preserved constraint will be the one with an integer as cardinality and the highest rate of conformance with the instances of the class.
+* disable_or_statements (default True): when set to False, sheXer tries to infer constraints with the operator oneOf (|) in case there are constraints with the same property but different object. By default, sheXer groups those constraint in a isngle one having the less general object possible. For instance, when the objects are different shapes, it merges the constraints a single one whose object is IRI.
+* allow_redundant_or (default False): when this is set to True, the example described for the disable_or_statements behaves differently. Let's say we have a set of candidate constraints whose property is the same but whose object differs: one have IRI, and two other have different shape labels (:A and :B). Whith allow_redundant_or=False, sheXer generates a single constraint with IRI and moves the information about the rest of discarded constraints with more specific objects to comments. However, with allow_redundant_or=True, the constraint generated will have a node constraint with a disjunction such as IRI OR @A OR @B. From the point of view of validation, as IRI subsumes :A and :B, this has no effect. However, some user whose extracted shapes are used to generate further products find this feature useful.   
+* allow_opt_cardinality (default True). When all-compliant mode is active, if there is a constraint which does not conform with every isntance but its maximun cardinality for any instance is {1}, it uses the optional cardinality (?). When set to False, it uses Kleene closure instead.
+* disable_opt_cardinality (dafault False). When set to True, it prevents any constraint to have a higher cardinality higher than one, even if every instance has that cardinality. For example, a constraint such as *ex:alias xsd:string {3}* will be changed to *ex:alias xsd:string +*.
+* shape_qualifiers_mode (default False). When it is set to True, it assumes a data model similar to Wikidata's one, where entity nodes are linked with qualifiers (BNodes) instead of the actual object meant by the triple. It is used to produce legible shapes for those special BNodes.
+* namespaces_for_qualifier_props (default None). Provide here a list of namespace in which the indirect properties used to link an entity with a qualifier node can be found. A reasonable configuration for Wikidata is namespaces_for_qualifier_props = \["http://www.wikidata.org/prop/"\] .
+* inverse_paths (default False). When it is set to True, sheXer will produce constraints with inverse_paths too. This is, constraints referring to triples in which the target node acst as object. Direct and inverse paths will be sorted in the final results w.r.t. their trutsworthiness score.
+* detect_minimal_iri (default False). When it is set to True, each shape will be associated with a regex pattern. That pattern expresses the initial part of the IRI that is common to every isntance used to extract a given shape. This pattern is only serialized when it is a "worthy" one (long enough, not just "http://", etc.).
+
+
+#### Params to tune some features of the output
+Again, all these params have a default value and you don't need to worry about them unless you want to tune the output.
+
+* remove_empty_shapes (default: True). When set to True, the result does not contain any empty shape nor any mention to it. If a shape A has a constraint pointing to a shape B and B is empty, then the constraint is modified and the macro IRI is used instead of B.
+* disable_comments (dafault: False). When set to True, the results do not contain comments.
+* shapes_namespace (default: http://weso.es/shapes/). This property allows you to change the namespace in which the shape labels are created in case you do not want to use the default one. The prefix of this namespace will be the empty prefix unless the empty prefix is already being used by other namespace. In that case, sheXer looks for other preferred prefixes, or will generate a random one if any of the default ones is available. 
+* wikidata_annotation (default: False). This param can be used when the output will contain Wikidata IDs. Using the library [wLighter](https://github.com/DaniFdezAlvarez/wLighter), the ourput is annotated with comments that associate a given every Wikidata ID with its English label. 
+* instances_report_mode (default, const.RATIO_INSTANCES). With this parameter, you can configure how is the information about instances complying to each expression shown. By default, sheXer shows a percetage of instances. If you set this parameter to const.ABSOLUTE_INSTANCES, then the comments will contain the exact number of complying instances instead of the ratio. sheXer will write a comment next to the shape label so you can also know how many isntances were used to extract a shape. If you set the parameter to const.MIXED_INSTANCES, the comments will contain both relative and absolute information.
+* decimals (default: -1). With this parameter you can configure the numnber of decimals to be used when writing ratios in comments. A negative numnber means that ratios will be written using its top precission. If you set this parameter to a natural number (including 0), then such number will be the number of decimals used. sheXer will round (not truncate) the original ratio to that precission.
+* examples_mode (default: None). You can set this parameter to one of the values included in the '#EXAMPLES' section of shexer.consts. If you choose SHAPE_EXAMPLES, sheXer will write the URI of an instance matching each shape extracted as a comment next to the shape label. If you choose CONSTRAINT_EXAMPLES, sheXer will write a comment including an example of node constraint matching each triple constraint of each shape (each value is used by an instance example with the triple constraint's property). If you choose ALL_EXAMPLES, sheXer will do both things. When the value of this parameter is None, sheXer will not serialize examples in comments.
+
+
+### Method __shex\_graph__
+
+The method __shex\_graph__  of shexer triggers all the inference process and gives back a result. It receives several parameters, being optional some of them:
+
+* string_output (default False): when it is set to True, the method returns a string representation of the inferred shapes. It must be set to True iff output_file is None.
+* output_file (default None): it specifies the path of the file in which the inferred shapes will be written. It must have a value different to None iff string_output is False.
+* output_format (default "ShExC"): format in which the inferred shapes will be serialized. The values currently supported are const.SHEXC and const.SHACLE_TURTLE.
+* aceptance_threshold (default 0): Given a certain inferred constraint __c__ for a shape __s__, the ammount of instances which conform to this constraint (ignoring constraints with '\*' cardinality) should be at least __aceptance\_threshold__. If this does not happen, then __c__ will not be included in __s__.
+* verbose (dafault False): when it is set to True, the extraction process will print log messages through the standard output.
+* to_uml_path (default None). This parameter expects to receive a disk path. If you provide a value here, sheXer will generate a UML diagram containing the extracted scheme and will save it in the path indicated as a PNG image. WARNING: you should be connected to Internet in  order to make this work.
+
+
```

### Comparing `shexer-2.5.1/README.md` & `shexer-2.5.2/README.md`

 * *Ordering differences only*

 * *Files 4% similar despite different names*

```diff
@@ -1,240 +1,240 @@
-# sheXer
-
-This library can be used to perform automatic extraction of shape expressions (ShEx) or Shapes Constraint Language (SHACL) for a target RDF grpah. Please, feel free to add an issue to this repository if you find any bug in sheXer or if you have a feature request.
-
-
-Language:
-
-[![Pyversions](https://img.shields.io/pypi/pyversions/shexer.svg)](https://pypi.python.org/pypi/shexer)
-
-## Citation
-
-Use this work in case you want to cite this software: [Automatic extraction of shapes using sheXer](https://doi.org/10.1016/j.knosys.2021.107975).
-
-If you want to read the paper but cannot access the full-content using the previous link, there is a [preprint available in Researchgate](https://www.researchgate.net/publication/357146819_Automatic_extraction_of_shapes_using_sheXer).
-
-
-However, please, be aware that this software capabilities' have evolved and improved since the publication of the mentioned paper.
-
-## Installation
-
-sheXer can be installed using pip:
-
-    $ pip install shexer
-	
-Iy you want to install sheXer by source, all its external dependencies are listed in the file requirements.txt. You can install them all as well using pip:
-
-    $ pip install -r requirements.txt
-
-sheXer includes a package to deploy a wer service exposing sheXer with a REST API. In case you are not interested in deploying this web service, you don't need to install any dependency related to Flask.
-
-
-## Features
-
-* **Process huge sources**. sheXer does not need to load the whole content of the graph in main memory at any time, so big graphs can be processed in average hardware. Currently this is available just for some input formats: n-triples (choose const.NT as for input_format), and turtle (choose const.TURTLE_ITER).
-
-* **Several ways to provide input data**, consisting of a target graph and some target shapes. Tha graph can be provided via raw string content, local/remote file(s), or tracking on the fly some triples from a SPARQL endpoint. There are defined interfaces in case you want to implement some other way to provide input information. 
-
-* **Several ways to select your target shapes**. You may want to generate shapes for each class in the graph or maybe just for some of them. You may want to generate a shape for some custom node agrupations. Or maybe you are extracting some shapes from a big grpah and you just want to explore the neighborhood of some seed nodes.  For custom node aggrupations sheXer supports ShEx's shape maps syntax, and it provides configuration params to target different classes or graph depths. 
-
-* **Valid ShEx and SHACL**. The produced shapes are compilant with the current specification of ShEx2 and SHACL.
-
-* **UML**. Ypu can also generate UML-like views of the extracted schemas.
-
-* **Threshold of tolerance**. The constraints inferred for each shape may not be compatible with every node associated to the shapes. With this threshold you can indicate the minimun percentage of nodes that should conform with a constraint c. If c does not reach the indicated ratio, its associated information will not appear in the final shape.
-
-* **Informative comments** (just for ShEx, by now). Each constraint inferred is associated to one or more comments. Those comments include different types of information, such as the ratio of nodes that actually conform with a given constraint. You can keep this informative comments or exclude them from the results.
-
-* **Sorted constraints** (just for ShEx, by now). For a given constraint, sheXer keeps the ratio of nodes that conform with it. This is used as a score of trustworthiness. The constraints in a shape are sorted w.r.t. this score.
-
-* **Literals recognition**. All kinds of typed literals are recognized and treated separately when inferring the constraints. In case a literal is not explicitly associated with a type in the original KG, xsd:string is used by default. By default, when sheXer finds an untyped literal it tries to infer its type when it is a number. Support to some other untyped literals, such as geolocated points, may be included in future releases.
-
-* **Shapes interlinkage**: sheXer is able to detect links between shapes when there is a link between two nodes and those nodes are used to extract some shape. When it detects triples linking a node that does not belong to any other shape, then it uses the macro IRI instead.
-
-* **Special treatment of rdf:type** (or the specified instantiation property). When the predicate of a triple is rdf:type, sheXer creates a constraint whose object is a value set containing a single element. This is the actual object of the original triple.
-
-* **Cardinality management**. Some of the triples of a given instance may fit in an infinite number of constraint triples with the same predicate and object but different cardinality. For example, if a given instance has a single label specified by rdfs:label, that makes it fit with infinite triple constraints with the schema {rdfs:label xsd:string C}, where C can be any cardinality that includes the posibility of a single occurrence: {1}, + , {1,2}, {1,3}, {1,4},... Currently, sheXer admints exact cardinalities ({2}, {3}..), kleene closure (\*), positive closure (+), and optional cardinality (?).
-
-* **Inverse paths**. sheXer can extract constraints related to incomming links. Shapes are usually described using contraints realted to outgoing links, i.d., triples in which the node is the subject. However, sheXer can extract also constraints where the node is the object.
-
-* **Configurable priority of cardinalities**. sheXer can be configured to prioritize the less specific cardinality or the most specific one if its trustworthiness score is high enough.
-
-* **Example serialization**. sheXer is able to produce outputs that include examples of instances among the input data matching each shape and/or examples of node constraints matching each constraint of each shape. Currently, this feature works only with ShEx outputs.
-
-* **All compliant mode**: You can produce shapes that conform with every instance using to extract them. This is done by using cadinalities \* or ? for every constraint extracted that does not conform with EVERY instance. You may prefer to avoid these cardinalities and keep constraints that may not conform with every instance, but include the most frequent features of the instances. Both settings are available in sheXer.
-
-* **Management of empty shapes**. You may get some shapes with no constraints, either because there where no isntances to explore or because the extracted features were not as common as requested with the threshold of tolerance. You can configure sheXer to automatically erase those shapes and every mention to them from the results. 
-
-* **Adaptation to Wikidata model**. sheXer includes configuration params to handle Wikidata's data model regarding qualifiers, so you can automatically extract the schema of qualifier nodes too. You can also produce content where each Wikidata ID is associated with  its label in comments, as sheXer is integrated with [wLighter](https://github.com/DaniFdezAlvarez/wLighter).
-
-
-## Experimental results
-
-In the folder [experiments](https://github.com/DaniFdezAlvarez/shexer/tree/develop/experiments), you can see some results of applying this tool over different graphs with different configurations.
-
-## Example code
-
-The following code takes the graph in _raw\_graph_ and extracts shapes for instances of the classes <http://example.org/Person> and <http://example.org/Gender>. The input file format in n-triples and the results are serialized in ShExC to the file shaper_example.shex.
-
-```python
-from shexer.shaper import Shaper
-from shexer.consts import NT, SHEXC, SHACL_TURTLE
-
-target_classes = [
-    "http://example.org/Person",
-    "http://example.org/Gender"
-]
-
-namespaces_dict = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
-                   "http://example.org/": "ex",
-                   "http://weso.es/shapes/": "",
-                   "http://www.w3.org/2001/XMLSchema#": "xsd"
-                   }
-
-raw_graph = """
-<http://example.org/sarah> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
-<http://example.org/sarah> <http://example.org/age> "30"^^<http://www.w3.org/2001/XMLSchema#int> .
-<http://example.org/sarah> <http://example.org/name> "Sarah" .
-<http://example.org/sarah> <http://example.org/gender> <http://example.org/Female> .
-<http://example.org/sarah> <http://example.org/occupation> <http://example.org/Doctor> .
-<http://example.org/sarah> <http://example.org/brother> <http://example.org/Jim> .
-
-<http://example.org/jim> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
-<http://example.org/jim> <http://example.org/age> "28"^^<http://www.w3.org/2001/XMLSchema#int> .
-<http://example.org/jim> <http://example.org/name> "Jimbo".
-<http://example.org/jim> <http://example.org/surname> "Mendes".
-<http://example.org/jim> <http://example.org/gender> <http://example.org/Male> .
-
-<http://example.org/Male> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Male> <http://www.w3.org/2000/01/rdf-schema#label> "Male" .
-<http://example.org/Female> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Female> <http://www.w3.org/2000/01/rdf-schema#label> "Female" .
-<http://example.org/Other> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Other> <http://www.w3.org/2000/01/rdf-schema#label> "Other gender" .
-"""
-
-
-
-input_nt_file = "target_graph.nt"
-
-shaper = Shaper(target_classes=target_classes,
-                raw_graph=raw_graph,
-                input_format=NT,
-                namespaces_dict=namespaces_dict,  # Default: no prefixes
-                instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type")  # Default rdf:type
-
-output_file = "shaper_example.shex"
-
-shaper.shex_graph(output_file=output_file,
-                  acceptance_threshold=0.1)
-
-print("Done!")
-
-```
-
-By default, sheXer generates ShExC. If you want to produce SHACL, indicate it as a param in the shex_graph method as follows:
-
-```python
-# Use the same imports and param definition of the previous example code
-
-output_file = "shaper_example.ttl"
-
-shaper.shex_graph(output_file=output_file,
-                  acceptance_threshold=0.1,
-                  output_format=SHACL_TURTLE)
-
-print("Done!")
-
-```
-
-You can also find some examples of how to process Wikidata with sheXer in [this Jupyter notebook](https://github.com/DaniFdezAlvarez/shexer/blob/master/doc/shexer_wikidata_tutorial.ipynb).
-
-
-## The Class Shaper
-
-Most of the features provided by this software are reachable using the class Shaper. As it is shown in the previous example code, one must get an instance of Shaper with some params and execute a method to perform the schema extraction.
-
-### init
-The __init__ method of Shaper includes many params, being optional most of them. Don't panic due to the high number of params. You just need to focus on three main questions:
-
-* How are you going to provide the graph to the library? Via a raw string, a local file, a downloadable content, an SPARQL endpoint...
-* Which shapes do you want to extract? A group of target classes, every class in the graph, or custom node groupings specified with shape maps (in a string, in a file...)?
-* Do you want to configure some special feature to tune the extraction process? Priority to less specific constraints, all-compliant mode, disbale comments...
-
-You'll find a param in the __init__ of Shaper to provide the information in the way you want. Use it using a keyword when creating your instance of Shaper (as in the example code of this document) and just forget about the rest. Shaper has a default value for them all.
-
-The following list describes each param of the __init__ of Shaper:
-
-#### Params to define target shapes:
-You must indicate al least one way to identify target instances and the shapes that should be generated. Some of this params are compatible, some others are not. For example, sheXer do not allow to indicate target classes and to activate all-classes mode, as it is contradictory. However, you can provide a shape map to make custom node aggrupations and use all_classes mode too, so you obtain shapes for those groupings and for each class.
-
-* target_classes (default None): a list containing URIs (string) of the classes whose shape must be extracted. 
-* file_target_classes (default None): a path to a file containing the URIs of the classes whose shape must be extracted. 
-* all_classes_mode (default False): when it is set to True, you do not net to provide a list of target classes. sheXer will produce a shape for each class with at least one instance. 
-* shape_map_raw (default None): use it to provide custom groupings of nodes using a shape map as a raw string.
-* shape_map_file (default None): use it to provide a path to a local file containing custom groupings of nodes using a shape map.
-
-#### Params to provide the input
-You must provide at least an input: a file, a string, an endpoint, a remote graph... you may also want to tune some other aspects, such as the format of the input or namespace-prefix pairs to be used.
-
-
-* instances_file_input (default None): in case you have a separate file in which instantiation relations can be found, provide its path here. If you dont provide any value, the shaper will look for instances in the graph used as input.
-* graph_file_input (default None): a path to the file in which the target graph can be found.
-* graph_list_of_files_input (default None): in case your graph is separated in several files (all of them with the same format), provide a list of string paths to those files here.
-* raw_graph (default None): a simple raw string containing the target graph.
-* url_graph_input (default None): use it to provide a URL of some downloadable RDF content available online to be used as target graph.
-* list_of_url_input (default None): use it to provide several URLs of downloadable RDF content available online to be used as target graph.
-* url_endpoint (default None): it expects the URL of an SPARQL endpoint. Use it if you want to get some relevant triples form that endpoint instead of providing a whole RDF graph. In this case, the triples will be those ones whose subject is one of the nodes used to build the shapes (instances of a target class, result of a node selector in a shape map).
-* instances_cap (default -1): when this param is set to a positive value, sheXer will only use a maximun of instance_cap instances to get extract each shape. This may cause some lost of information, but if the sample of instances used is representative enough, your results won't be that different but you'll save main memory and execution time. 
-* depth_for_building_subgraph (default 1): use this param just in case you are working against a SPARQL endpoint. This integer indicates the max distance from any seed node to consider in order to track a subgraph from the endpoint. Please, remind that a high depth can cause a massive number of queries and have a high performance cost. 
-* track_classes_for_entities_at_last_depth_level (default True): use this param just in case you are working against a SPARQL endpoint. If it set to True, it makes a step further to the distance to the seed nodes indicated in the param depth. However, it will just look for triples related to typing, not the whole neighborhood of the nodes in the last level of depth.
-* limit_remote_instances *DEPRECATED* (default -1). Use this param if you are working against an endpoint using the param target_classes. If it is set to a positive number, sheXer will just get limit_remote_instances instances for each class from the endpoint (by adding LIMIT at the end of the sparql query). This is useful when working with big sources with tons on instances, causing too many or too heavy SPARQL queries to retrieve  all the content. NOTE: This parameter only affects computation consuming SPARQL endpoints. On the other hand, the parameter instances_cap works for any case, including SPARQL endpoints. Due to retrocompatibility reasons, limit_remote_instances still works, but it will be removed in future sheXer releases.
-* disable_endpoint_cache (default False). By default, if sheXer is told to consume triples from an endpoint, it will make some SPARQL queries and store the results in a local graph. If this parameter is set to True, sheXer won't save that content locally. This will help to reduce main memory usage, but will decrease the performance, as sheXer will need to make more SPARQL queries to the endpoint.
-* namespaces_dict (default None): dictionary in which the keys are namespaces and the values are their expected prefixes in the outputs. 
-* input_format (default "NT"): the format of the graph which is going to be computed. The default value is const.NT. IMPORTANT: currently, sheXer does not guess input format, so ensure you specify the format here in case you are not providing n-triples content. In case you provide a combined input (several files, several URLs...) they all should have the same format. If you work against an endpoit, then this param do not have any effect.
-* compression_mode (default None). Only when you are working with local files, if they are compressed, you do not need to uncompress to parse them. Currently supported formats are ZIP, GZ, and XZ. Set compression_format to "zip", "gz", or "xz" to work with such files. Each gz or xz file will be assumed to contain a single graph file. Each zip file will be assumed to be a directory containing one or more graph files. In case the zip contains several files, they will be all parsed and merged (they should have the same format, indicated with input_format). In every case, sheXer won't write any uncompressed content to your disk.
-
-#### Params to tune the shexing process
-
-All this parameters have a default value so you do not need to use any of them. But you can modify the schema extraction in many different ways.
-
-* instantiation_property (default rdf:type): full URI (no prefixes) of the property linking instances and classes (ex: P31 in Wikidata's ontology)
-* namespaces_to_ignore (default None): list of namespaces of properties used in the target graph which are going to be ignored. For example, if you set namespaces_to_ignore to \[http://example.org/\], every triple whose predicate belongs to that namespace will not be computed. It just excludes properties whose name is a direct child of the namespace. For example, triples with <http:/example.org/foo> will be ignored, but triples with <http://example.org/anotherLevel/foo> will be computed.
-* infer_numeric_types_for_untyped_literals (default False): when it is set to True, if the parser finds a triple whose object in a number untyped (something like 56 instead of "56"^^xsd:int), it will accept it and consider it an int if it has decimals or a float if it does not. If it is set to False, triples like that will raise a parsing error.
-* discard_useles_constraints_with_positive_closure (default True): if it is set to True, when two constraints have been extracted with identical property and object, and one of them has '+' cardinality while the other one has a specific number of occurrences (example: {1}, {2}...), if they both have the same rate of compliance among the instances, the constraint with the '+' cardinality is discarded.
-* all_instances_are_compliant_mode (default True): when set to True, every inferred constraint which is not valid for all the instances of the class associated to the shape, then the cardinality of that constraint is changed to '\*' or '?'. With this, every instance conforms to the shape associated with its class. When it is set to False, no cardinality is changed, so there may be instances that do not conform to the inferred shape.
-* keep_less_specific (default True): when it is set to True, for a group of constraints with the same property and object but different cardinality, the one with less specific cardinality ('+') will be preserved, and the rest of constraints used to provide info in comments. When it is set to False, the preserved constraint will be the one with an integer as cardinality and the highest rate of conformance with the instances of the class.
-* disable_or_statements (default True): when set to False, sheXer tries to infer constraints with the operator oneOf (|) in case there are constraints with the same property but different object. By default, sheXer groups those constraint in a isngle one having the less general object possible. For instance, when the objects are different shapes, it merges the constraints a single one whose object is IRI.
-* allow_redundant_or (default False): when this is set to True, the example described for the disable_or_statements behaves differently. Let's say we have a set of candidate constraints whose property is the same but whose object differs: one have IRI, and two other have different shape labels (:A and :B). Whith allow_redundant_or=False, sheXer generates a single constraint with IRI and moves the information about the rest of discarded constraints with more specific objects to comments. However, with allow_redundant_or=True, the constraint generated will have a node constraint with a disjunction such as IRI OR @A OR @B. From the point of view of validation, as IRI subsumes :A and :B, this has no effect. However, some user whose extracted shapes are used to generate further products find this feature useful.   
-* allow_opt_cardinality (default True). When all-compliant mode is active, if there is a constraint which does not conform with every isntance but its maximun cardinality for any instance is {1}, it uses the optional cardinality (?). When set to False, it uses Kleene closure instead.
-* disable_opt_cardinality (dafault False). When set to True, it prevents any constraint to have a higher cardinality higher than one, even if every instance has that cardinality. For example, a constraint such as *ex:alias xsd:string {3}* will be changed to *ex:alias xsd:string +*.
-* shape_qualifiers_mode (default False). When it is set to True, it assumes a data model similar to Wikidata's one, where entity nodes are linked with qualifiers (BNodes) instead of the actual object meant by the triple. It is used to produce legible shapes for those special BNodes.
-* namespaces_for_qualifier_props (default None). Provide here a list of namespace in which the indirect properties used to link an entity with a qualifier node can be found. A reasonable configuration for Wikidata is namespaces_for_qualifier_props = \["http://www.wikidata.org/prop/"\] .
-* inverse_paths (default False). When it is set to True, sheXer will produce constraints with inverse_paths too. This is, constraints referring to triples in which the target node acst as object. Direct and inverse paths will be sorted in the final results w.r.t. their trutsworthiness score.
-* detect_minimal_iri (default False). When it is set to True, each shape will be associated with a regex pattern. That pattern expresses the initial part of the IRI that is common to every isntance used to extract a given shape. This pattern is only serialized when it is a "worthy" one (long enough, not just "http://", etc.).
-
-
-#### Params to tune some features of the output
-Again, all these params have a default value and you don't need to worry about them unless you want to tune the output.
-
-* remove_empty_shapes (default: True). When set to True, the result does not contain any empty shape nor any mention to it. If a shape A has a constraint pointing to a shape B and B is empty, then the constraint is modified and the macro IRI is used instead of B.
-* disable_comments (dafault: False). When set to True, the results do not contain comments.
-* shapes_namespace (default: http://weso.es/shapes/). This property allows you to change the namespace in which the shape labels are created in case you do not want to use the default one. The prefix of this namespace will be the empty prefix unless the empty prefix is already being used by other namespace. In that case, sheXer looks for other preferred prefixes, or will generate a random one if any of the default ones is available. 
-* wikidata_annotation (default: False). This param can be used when the output will contain Wikidata IDs. Using the library [wLighter](https://github.com/DaniFdezAlvarez/wLighter), the ourput is annotated with comments that associate a given every Wikidata ID with its English label. 
-* instances_report_mode (default, const.RATIO_INSTANCES). With this parameter, you can configure how is the information about instances complying to each expression shown. By default, sheXer shows a percetage of instances. If you set this parameter to const.ABSOLUTE_INSTANCES, then the comments will contain the exact number of complying instances instead of the ratio. sheXer will write a comment next to the shape label so you can also know how many isntances were used to extract a shape. If you set the parameter to const.MIXED_INSTANCES, the comments will contain both relative and absolute information.
-* decimals (default: -1). With this parameter you can configure the numnber of decimals to be used when writing ratios in comments. A negative numnber means that ratios will be written using its top precission. If you set this parameter to a natural number (including 0), then such number will be the number of decimals used. sheXer will round (not truncate) the original ratio to that precission.
-* examples_mode (default: None). You can set this parameter to one of the values included in the '#EXAMPLES' section of shexer.consts. If you choose SHAPE_EXAMPLES, sheXer will write the URI of an instance matching each shape extracted as a comment next to the shape label. If you choose CONSTRAINT_EXAMPLES, sheXer will write a comment including an example of node constraint matching each triple constraint of each shape (each value is used by an instance example with the triple constraint's property). If you choose ALL_EXAMPLES, sheXer will do both things. When the value of this parameter is None, sheXer will not serialize examples in comments.
-
-
-### Method __shex\_graph__
-
-The method __shex\_graph__  of shexer triggers all the inference process and gives back a result. It receives several parameters, being optional some of them:
-
-* string_output (default False): when it is set to True, the method returns a string representation of the inferred shapes. It must be set to True iff output_file is None.
-* output_file (default None): it specifies the path of the file in which the inferred shapes will be written. It must have a value different to None iff string_output is False.
-* output_format (default "ShExC"): format in which the inferred shapes will be serialized. The values currently supported are const.SHEXC and const.SHACLE_TURTLE.
-* aceptance_threshold (default 0): Given a certain inferred constraint __c__ for a shape __s__, the ammount of instances which conform to this constraint (ignoring constraints with '\*' cardinality) should be at least __aceptance\_threshold__. If this does not happen, then __c__ will not be included in __s__.
-* verbose (dafault False): when it is set to True, the extraction process will print log messages through the standard output.
-* to_uml_path (default None). This parameter expects to receive a disk path. If you provide a value here, sheXer will generate a UML diagram containing the extracted scheme and will save it in the path indicated as a PNG image. WARNING: you should be connected to Internet in  order to make this work.
-
-
+# sheXer
+
+This library can be used to perform automatic extraction of shape expressions (ShEx) or Shapes Constraint Language (SHACL) for a target RDF grpah. Please, feel free to add an issue to this repository if you find any bug in sheXer or if you have a feature request.
+
+
+Language:
+
+[![Pyversions](https://img.shields.io/pypi/pyversions/shexer.svg)](https://pypi.python.org/pypi/shexer)
+
+## Citation
+
+Use this work in case you want to cite this software: [Automatic extraction of shapes using sheXer](https://doi.org/10.1016/j.knosys.2021.107975).
+
+If you want to read the paper but cannot access the full-content using the previous link, there is a [preprint available in Researchgate](https://www.researchgate.net/publication/357146819_Automatic_extraction_of_shapes_using_sheXer).
+
+
+However, please, be aware that this software capabilities' have evolved and improved since the publication of the mentioned paper.
+
+## Installation
+
+sheXer can be installed using pip:
+
+    $ pip install shexer
+	
+Iy you want to install sheXer by source, all its external dependencies are listed in the file requirements.txt. You can install them all as well using pip:
+
+    $ pip install -r requirements.txt
+
+sheXer includes a package to deploy a wer service exposing sheXer with a REST API. In case you are not interested in deploying this web service, you don't need to install any dependency related to Flask.
+
+
+## Features
+
+* **Process huge sources**. sheXer does not need to load the whole content of the graph in main memory at any time, so big graphs can be processed in average hardware. Currently this is available just for some input formats: n-triples (choose const.NT as for input_format), and turtle (choose const.TURTLE_ITER).
+
+* **Several ways to provide input data**, consisting of a target graph and some target shapes. Tha graph can be provided via raw string content, local/remote file(s), or tracking on the fly some triples from a SPARQL endpoint. There are defined interfaces in case you want to implement some other way to provide input information. 
+
+* **Several ways to select your target shapes**. You may want to generate shapes for each class in the graph or maybe just for some of them. You may want to generate a shape for some custom node agrupations. Or maybe you are extracting some shapes from a big grpah and you just want to explore the neighborhood of some seed nodes.  For custom node aggrupations sheXer supports ShEx's shape maps syntax, and it provides configuration params to target different classes or graph depths. 
+
+* **Valid ShEx and SHACL**. The produced shapes are compilant with the current specification of ShEx2 and SHACL.
+
+* **UML**. Ypu can also generate UML-like views of the extracted schemas.
+
+* **Threshold of tolerance**. The constraints inferred for each shape may not be compatible with every node associated to the shapes. With this threshold you can indicate the minimun percentage of nodes that should conform with a constraint c. If c does not reach the indicated ratio, its associated information will not appear in the final shape.
+
+* **Informative comments** (just for ShEx, by now). Each constraint inferred is associated to one or more comments. Those comments include different types of information, such as the ratio of nodes that actually conform with a given constraint. You can keep this informative comments or exclude them from the results.
+
+* **Sorted constraints** (just for ShEx, by now). For a given constraint, sheXer keeps the ratio of nodes that conform with it. This is used as a score of trustworthiness. The constraints in a shape are sorted w.r.t. this score.
+
+* **Literals recognition**. All kinds of typed literals are recognized and treated separately when inferring the constraints. In case a literal is not explicitly associated with a type in the original KG, xsd:string is used by default. By default, when sheXer finds an untyped literal it tries to infer its type when it is a number. Support to some other untyped literals, such as geolocated points, may be included in future releases.
+
+* **Shapes interlinkage**: sheXer is able to detect links between shapes when there is a link between two nodes and those nodes are used to extract some shape. When it detects triples linking a node that does not belong to any other shape, then it uses the macro IRI instead.
+
+* **Special treatment of rdf:type** (or the specified instantiation property). When the predicate of a triple is rdf:type, sheXer creates a constraint whose object is a value set containing a single element. This is the actual object of the original triple.
+
+* **Cardinality management**. Some of the triples of a given instance may fit in an infinite number of constraint triples with the same predicate and object but different cardinality. For example, if a given instance has a single label specified by rdfs:label, that makes it fit with infinite triple constraints with the schema {rdfs:label xsd:string C}, where C can be any cardinality that includes the posibility of a single occurrence: {1}, + , {1,2}, {1,3}, {1,4},... Currently, sheXer admints exact cardinalities ({2}, {3}..), kleene closure (\*), positive closure (+), and optional cardinality (?).
+
+* **Inverse paths**. sheXer can extract constraints related to incomming links. Shapes are usually described using contraints realted to outgoing links, i.d., triples in which the node is the subject. However, sheXer can extract also constraints where the node is the object.
+
+* **Configurable priority of cardinalities**. sheXer can be configured to prioritize the less specific cardinality or the most specific one if its trustworthiness score is high enough.
+
+* **Example serialization**. sheXer is able to produce outputs that include examples of instances among the input data matching each shape and/or examples of node constraints matching each constraint of each shape. Currently, this feature works only with ShEx outputs.
+
+* **All compliant mode**: You can produce shapes that conform with every instance using to extract them. This is done by using cadinalities \* or ? for every constraint extracted that does not conform with EVERY instance. You may prefer to avoid these cardinalities and keep constraints that may not conform with every instance, but include the most frequent features of the instances. Both settings are available in sheXer.
+
+* **Management of empty shapes**. You may get some shapes with no constraints, either because there where no isntances to explore or because the extracted features were not as common as requested with the threshold of tolerance. You can configure sheXer to automatically erase those shapes and every mention to them from the results. 
+
+* **Adaptation to Wikidata model**. sheXer includes configuration params to handle Wikidata's data model regarding qualifiers, so you can automatically extract the schema of qualifier nodes too. You can also produce content where each Wikidata ID is associated with  its label in comments, as sheXer is integrated with [wLighter](https://github.com/DaniFdezAlvarez/wLighter).
+
+
+## Experimental results
+
+In the folder [experiments](https://github.com/DaniFdezAlvarez/shexer/tree/develop/experiments), you can see some results of applying this tool over different graphs with different configurations.
+
+## Example code
+
+The following code takes the graph in _raw\_graph_ and extracts shapes for instances of the classes <http://example.org/Person> and <http://example.org/Gender>. The input file format in n-triples and the results are serialized in ShExC to the file shaper_example.shex.
+
+```python
+from shexer.shaper import Shaper
+from shexer.consts import NT, SHEXC, SHACL_TURTLE
+
+target_classes = [
+    "http://example.org/Person",
+    "http://example.org/Gender"
+]
+
+namespaces_dict = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
+                   "http://example.org/": "ex",
+                   "http://weso.es/shapes/": "",
+                   "http://www.w3.org/2001/XMLSchema#": "xsd"
+                   }
+
+raw_graph = """
+<http://example.org/sarah> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
+<http://example.org/sarah> <http://example.org/age> "30"^^<http://www.w3.org/2001/XMLSchema#int> .
+<http://example.org/sarah> <http://example.org/name> "Sarah" .
+<http://example.org/sarah> <http://example.org/gender> <http://example.org/Female> .
+<http://example.org/sarah> <http://example.org/occupation> <http://example.org/Doctor> .
+<http://example.org/sarah> <http://example.org/brother> <http://example.org/Jim> .
+
+<http://example.org/jim> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
+<http://example.org/jim> <http://example.org/age> "28"^^<http://www.w3.org/2001/XMLSchema#int> .
+<http://example.org/jim> <http://example.org/name> "Jimbo".
+<http://example.org/jim> <http://example.org/surname> "Mendes".
+<http://example.org/jim> <http://example.org/gender> <http://example.org/Male> .
+
+<http://example.org/Male> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Male> <http://www.w3.org/2000/01/rdf-schema#label> "Male" .
+<http://example.org/Female> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Female> <http://www.w3.org/2000/01/rdf-schema#label> "Female" .
+<http://example.org/Other> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Other> <http://www.w3.org/2000/01/rdf-schema#label> "Other gender" .
+"""
+
+
+
+input_nt_file = "target_graph.nt"
+
+shaper = Shaper(target_classes=target_classes,
+                raw_graph=raw_graph,
+                input_format=NT,
+                namespaces_dict=namespaces_dict,  # Default: no prefixes
+                instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type")  # Default rdf:type
+
+output_file = "shaper_example.shex"
+
+shaper.shex_graph(output_file=output_file,
+                  acceptance_threshold=0.1)
+
+print("Done!")
+
+```
+
+By default, sheXer generates ShExC. If you want to produce SHACL, indicate it as a param in the shex_graph method as follows:
+
+```python
+# Use the same imports and param definition of the previous example code
+
+output_file = "shaper_example.ttl"
+
+shaper.shex_graph(output_file=output_file,
+                  acceptance_threshold=0.1,
+                  output_format=SHACL_TURTLE)
+
+print("Done!")
+
+```
+
+You can also find some examples of how to process Wikidata with sheXer in [this Jupyter notebook](https://github.com/DaniFdezAlvarez/shexer/blob/master/doc/shexer_wikidata_tutorial.ipynb).
+
+
+## The Class Shaper
+
+Most of the features provided by this software are reachable using the class Shaper. As it is shown in the previous example code, one must get an instance of Shaper with some params and execute a method to perform the schema extraction.
+
+### init
+The __init__ method of Shaper includes many params, being optional most of them. Don't panic due to the high number of params. You just need to focus on three main questions:
+
+* How are you going to provide the graph to the library? Via a raw string, a local file, a downloadable content, an SPARQL endpoint...
+* Which shapes do you want to extract? A group of target classes, every class in the graph, or custom node groupings specified with shape maps (in a string, in a file...)?
+* Do you want to configure some special feature to tune the extraction process? Priority to less specific constraints, all-compliant mode, disbale comments...
+
+You'll find a param in the __init__ of Shaper to provide the information in the way you want. Use it using a keyword when creating your instance of Shaper (as in the example code of this document) and just forget about the rest. Shaper has a default value for them all.
+
+The following list describes each param of the __init__ of Shaper:
+
+#### Params to define target shapes:
+You must indicate al least one way to identify target instances and the shapes that should be generated. Some of this params are compatible, some others are not. For example, sheXer do not allow to indicate target classes and to activate all-classes mode, as it is contradictory. However, you can provide a shape map to make custom node aggrupations and use all_classes mode too, so you obtain shapes for those groupings and for each class.
+
+* target_classes (default None): a list containing URIs (string) of the classes whose shape must be extracted. 
+* file_target_classes (default None): a path to a file containing the URIs of the classes whose shape must be extracted. 
+* all_classes_mode (default False): when it is set to True, you do not net to provide a list of target classes. sheXer will produce a shape for each class with at least one instance. 
+* shape_map_raw (default None): use it to provide custom groupings of nodes using a shape map as a raw string.
+* shape_map_file (default None): use it to provide a path to a local file containing custom groupings of nodes using a shape map.
+
+#### Params to provide the input
+You must provide at least an input: a file, a string, an endpoint, a remote graph... you may also want to tune some other aspects, such as the format of the input or namespace-prefix pairs to be used.
+
+
+* instances_file_input (default None): in case you have a separate file in which instantiation relations can be found, provide its path here. If you dont provide any value, the shaper will look for instances in the graph used as input.
+* graph_file_input (default None): a path to the file in which the target graph can be found.
+* graph_list_of_files_input (default None): in case your graph is separated in several files (all of them with the same format), provide a list of string paths to those files here.
+* raw_graph (default None): a simple raw string containing the target graph.
+* url_graph_input (default None): use it to provide a URL of some downloadable RDF content available online to be used as target graph.
+* list_of_url_input (default None): use it to provide several URLs of downloadable RDF content available online to be used as target graph.
+* url_endpoint (default None): it expects the URL of an SPARQL endpoint. Use it if you want to get some relevant triples form that endpoint instead of providing a whole RDF graph. In this case, the triples will be those ones whose subject is one of the nodes used to build the shapes (instances of a target class, result of a node selector in a shape map).
+* instances_cap (default -1): when this param is set to a positive value, sheXer will only use a maximun of instance_cap instances to get extract each shape. This may cause some lost of information, but if the sample of instances used is representative enough, your results won't be that different but you'll save main memory and execution time. 
+* depth_for_building_subgraph (default 1): use this param just in case you are working against a SPARQL endpoint. This integer indicates the max distance from any seed node to consider in order to track a subgraph from the endpoint. Please, remind that a high depth can cause a massive number of queries and have a high performance cost. 
+* track_classes_for_entities_at_last_depth_level (default True): use this param just in case you are working against a SPARQL endpoint. If it set to True, it makes a step further to the distance to the seed nodes indicated in the param depth. However, it will just look for triples related to typing, not the whole neighborhood of the nodes in the last level of depth.
+* limit_remote_instances *DEPRECATED* (default -1). Use this param if you are working against an endpoint using the param target_classes. If it is set to a positive number, sheXer will just get limit_remote_instances instances for each class from the endpoint (by adding LIMIT at the end of the sparql query). This is useful when working with big sources with tons on instances, causing too many or too heavy SPARQL queries to retrieve  all the content. NOTE: This parameter only affects computation consuming SPARQL endpoints. On the other hand, the parameter instances_cap works for any case, including SPARQL endpoints. Due to retrocompatibility reasons, limit_remote_instances still works, but it will be removed in future sheXer releases.
+* disable_endpoint_cache (default False). By default, if sheXer is told to consume triples from an endpoint, it will make some SPARQL queries and store the results in a local graph. If this parameter is set to True, sheXer won't save that content locally. This will help to reduce main memory usage, but will decrease the performance, as sheXer will need to make more SPARQL queries to the endpoint.
+* namespaces_dict (default None): dictionary in which the keys are namespaces and the values are their expected prefixes in the outputs. 
+* input_format (default "NT"): the format of the graph which is going to be computed. The default value is const.NT. IMPORTANT: currently, sheXer does not guess input format, so ensure you specify the format here in case you are not providing n-triples content. In case you provide a combined input (several files, several URLs...) they all should have the same format. If you work against an endpoit, then this param do not have any effect.
+* compression_mode (default None). Only when you are working with local files, if they are compressed, you do not need to uncompress to parse them. Currently supported formats are ZIP, GZ, and XZ. Set compression_format to "zip", "gz", or "xz" to work with such files. Each gz or xz file will be assumed to contain a single graph file. Each zip file will be assumed to be a directory containing one or more graph files. In case the zip contains several files, they will be all parsed and merged (they should have the same format, indicated with input_format). In every case, sheXer won't write any uncompressed content to your disk.
+
+#### Params to tune the shexing process
+
+All this parameters have a default value so you do not need to use any of them. But you can modify the schema extraction in many different ways.
+
+* instantiation_property (default rdf:type): full URI (no prefixes) of the property linking instances and classes (ex: P31 in Wikidata's ontology)
+* namespaces_to_ignore (default None): list of namespaces of properties used in the target graph which are going to be ignored. For example, if you set namespaces_to_ignore to \[http://example.org/\], every triple whose predicate belongs to that namespace will not be computed. It just excludes properties whose name is a direct child of the namespace. For example, triples with <http:/example.org/foo> will be ignored, but triples with <http://example.org/anotherLevel/foo> will be computed.
+* infer_numeric_types_for_untyped_literals (default False): when it is set to True, if the parser finds a triple whose object in a number untyped (something like 56 instead of "56"^^xsd:int), it will accept it and consider it an int if it has decimals or a float if it does not. If it is set to False, triples like that will raise a parsing error.
+* discard_useles_constraints_with_positive_closure (default True): if it is set to True, when two constraints have been extracted with identical property and object, and one of them has '+' cardinality while the other one has a specific number of occurrences (example: {1}, {2}...), if they both have the same rate of compliance among the instances, the constraint with the '+' cardinality is discarded.
+* all_instances_are_compliant_mode (default True): when set to True, every inferred constraint which is not valid for all the instances of the class associated to the shape, then the cardinality of that constraint is changed to '\*' or '?'. With this, every instance conforms to the shape associated with its class. When it is set to False, no cardinality is changed, so there may be instances that do not conform to the inferred shape.
+* keep_less_specific (default True): when it is set to True, for a group of constraints with the same property and object but different cardinality, the one with less specific cardinality ('+') will be preserved, and the rest of constraints used to provide info in comments. When it is set to False, the preserved constraint will be the one with an integer as cardinality and the highest rate of conformance with the instances of the class.
+* disable_or_statements (default True): when set to False, sheXer tries to infer constraints with the operator oneOf (|) in case there are constraints with the same property but different object. By default, sheXer groups those constraint in a isngle one having the less general object possible. For instance, when the objects are different shapes, it merges the constraints a single one whose object is IRI.
+* allow_redundant_or (default False): when this is set to True, the example described for the disable_or_statements behaves differently. Let's say we have a set of candidate constraints whose property is the same but whose object differs: one have IRI, and two other have different shape labels (:A and :B). Whith allow_redundant_or=False, sheXer generates a single constraint with IRI and moves the information about the rest of discarded constraints with more specific objects to comments. However, with allow_redundant_or=True, the constraint generated will have a node constraint with a disjunction such as IRI OR @A OR @B. From the point of view of validation, as IRI subsumes :A and :B, this has no effect. However, some user whose extracted shapes are used to generate further products find this feature useful.   
+* allow_opt_cardinality (default True). When all-compliant mode is active, if there is a constraint which does not conform with every isntance but its maximun cardinality for any instance is {1}, it uses the optional cardinality (?). When set to False, it uses Kleene closure instead.
+* disable_opt_cardinality (dafault False). When set to True, it prevents any constraint to have a higher cardinality higher than one, even if every instance has that cardinality. For example, a constraint such as *ex:alias xsd:string {3}* will be changed to *ex:alias xsd:string +*.
+* shape_qualifiers_mode (default False). When it is set to True, it assumes a data model similar to Wikidata's one, where entity nodes are linked with qualifiers (BNodes) instead of the actual object meant by the triple. It is used to produce legible shapes for those special BNodes.
+* namespaces_for_qualifier_props (default None). Provide here a list of namespace in which the indirect properties used to link an entity with a qualifier node can be found. A reasonable configuration for Wikidata is namespaces_for_qualifier_props = \["http://www.wikidata.org/prop/"\] .
+* inverse_paths (default False). When it is set to True, sheXer will produce constraints with inverse_paths too. This is, constraints referring to triples in which the target node acst as object. Direct and inverse paths will be sorted in the final results w.r.t. their trutsworthiness score.
+* detect_minimal_iri (default False). When it is set to True, each shape will be associated with a regex pattern. That pattern expresses the initial part of the IRI that is common to every isntance used to extract a given shape. This pattern is only serialized when it is a "worthy" one (long enough, not just "http://", etc.).
+
+
+#### Params to tune some features of the output
+Again, all these params have a default value and you don't need to worry about them unless you want to tune the output.
+
+* remove_empty_shapes (default: True). When set to True, the result does not contain any empty shape nor any mention to it. If a shape A has a constraint pointing to a shape B and B is empty, then the constraint is modified and the macro IRI is used instead of B.
+* disable_comments (dafault: False). When set to True, the results do not contain comments.
+* shapes_namespace (default: http://weso.es/shapes/). This property allows you to change the namespace in which the shape labels are created in case you do not want to use the default one. The prefix of this namespace will be the empty prefix unless the empty prefix is already being used by other namespace. In that case, sheXer looks for other preferred prefixes, or will generate a random one if any of the default ones is available. 
+* wikidata_annotation (default: False). This param can be used when the output will contain Wikidata IDs. Using the library [wLighter](https://github.com/DaniFdezAlvarez/wLighter), the ourput is annotated with comments that associate a given every Wikidata ID with its English label. 
+* instances_report_mode (default, const.RATIO_INSTANCES). With this parameter, you can configure how is the information about instances complying to each expression shown. By default, sheXer shows a percetage of instances. If you set this parameter to const.ABSOLUTE_INSTANCES, then the comments will contain the exact number of complying instances instead of the ratio. sheXer will write a comment next to the shape label so you can also know how many isntances were used to extract a shape. If you set the parameter to const.MIXED_INSTANCES, the comments will contain both relative and absolute information.
+* decimals (default: -1). With this parameter you can configure the numnber of decimals to be used when writing ratios in comments. A negative numnber means that ratios will be written using its top precission. If you set this parameter to a natural number (including 0), then such number will be the number of decimals used. sheXer will round (not truncate) the original ratio to that precission.
+* examples_mode (default: None). You can set this parameter to one of the values included in the '#EXAMPLES' section of shexer.consts. If you choose SHAPE_EXAMPLES, sheXer will write the URI of an instance matching each shape extracted as a comment next to the shape label. If you choose CONSTRAINT_EXAMPLES, sheXer will write a comment including an example of node constraint matching each triple constraint of each shape (each value is used by an instance example with the triple constraint's property). If you choose ALL_EXAMPLES, sheXer will do both things. When the value of this parameter is None, sheXer will not serialize examples in comments.
+
+
+### Method __shex\_graph__
+
+The method __shex\_graph__  of shexer triggers all the inference process and gives back a result. It receives several parameters, being optional some of them:
+
+* string_output (default False): when it is set to True, the method returns a string representation of the inferred shapes. It must be set to True iff output_file is None.
+* output_file (default None): it specifies the path of the file in which the inferred shapes will be written. It must have a value different to None iff string_output is False.
+* output_format (default "ShExC"): format in which the inferred shapes will be serialized. The values currently supported are const.SHEXC and const.SHACLE_TURTLE.
+* aceptance_threshold (default 0): Given a certain inferred constraint __c__ for a shape __s__, the ammount of instances which conform to this constraint (ignoring constraints with '\*' cardinality) should be at least __aceptance\_threshold__. If this does not happen, then __c__ will not be included in __s__.
+* verbose (dafault False): when it is set to True, the extraction process will print log messages through the standard output.
+* to_uml_path (default None). This parameter expects to receive a disk path. If you provide a value here, sheXer will generate a UML diagram containing the extracted scheme and will save it in the path indicated as a PNG image. WARNING: you should be connected to Internet in  order to make this work.
+
+
```

### Comparing `shexer-2.5.1/setup.py` & `shexer-2.5.2/setup.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,38 +1,39 @@
-from distutils.core import setup
-from setuptools import find_packages
-
-def read(file_path):
-	with open(file_path, "r") as in_stream:
-		return in_stream.read()
-
-setup(
-  name = 'shexer',
-  packages = find_packages(exclude=["*.local_code.*"]), # this must be the same as the name above
-  version = '2.5.1',
-  description = 'Automatic schema extraction for RDF graphs',
-  author = 'Daniel Fernandez-Alvarez',
-  author_email = 'danifdezalvarez@gmail.com',
-  url = 'https://github.com/DaniFdezAlvarez/shexer',
-  download_url = 'https://github.com/DaniFdezAlvarez/shexer/archive/2.5.1.tar.gz',
-  keywords = ['testing', 'shexer', 'shexerp3', "rdf", "shex", "shacl", "schema"],
-  long_description = read('README.md'),
-  long_description_content_type='text/markdown',
-  classifiers=[
-        "Programming Language :: Python :: 3.7",
-        "Programming Language :: Python :: 3.8",
-        "Programming Language :: Python :: 3.9",
-		"Programming Language :: Python :: 3.10",
-		"Programming Language :: Python :: 3.11",
-        "Intended Audience :: Science/Research",
-        "Intended Audience :: Information Technology",
-        "Topic :: Software Development :: Libraries :: Python Modules"
-    ],
-  install_requires=[            
-          'Flask',
-          'Flask-Cors',
-		  'rdflib',
-		  'SPARQLWrapper',
-          'wlighter',
-          'plantuml'
-      ],
-)
+from distutils.core import setup
+from setuptools import find_packages
+
+def read(file_path):
+	with open(file_path, "r") as in_stream:
+		return in_stream.read()
+
+setup(
+  name = 'shexer',
+  packages = find_packages(exclude=["*.local_code.*"]), # this must be the same as the name above
+  version = '2.5.2',
+  description = 'Automatic schema extraction for RDF graphs',
+  author = 'Daniel Fernandez-Alvarez',
+  author_email = 'danifdezalvarez@gmail.com',
+  url = 'https://github.com/DaniFdezAlvarez/shexer',
+  download_url = 'https://github.com/DaniFdezAlvarez/shexer/archive/2.5.2.tar.gz',
+  keywords = ['testing', 'shexer', 'shexerp3', "rdf", "shex", "shacl", "schema"],
+  long_description = read('README.md'),
+  long_description_content_type='text/markdown',
+  classifiers=[
+        "Programming Language :: Python :: 3.7",
+        "Programming Language :: Python :: 3.8",
+        "Programming Language :: Python :: 3.9",
+		"Programming Language :: Python :: 3.10",
+		"Programming Language :: Python :: 3.11",
+        "Intended Audience :: Science/Research",
+        "Intended Audience :: Information Technology",
+        "Topic :: Software Development :: Libraries :: Python Modules"
+    ],
+  install_requires=[            
+          'Flask',
+          'Flask-Cors',
+		  'rdflib',
+		  'SPARQLWrapper',
+          'wlighter',
+          'plantuml',
+          'python-xz'
+      ],
+)
```

### Comparing `shexer-2.5.1/shexer/core/instances/annotators/annotator_tracking_instances.py` & `shexer-2.5.2/shexer/core/instances/annotators/annotator_tracking_instances.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,43 +1,43 @@
-from shexer.core.instances.pconsts import _S, _P, _O
-from shexer.core.instances.annotators.base_annotator import BaseAnnotator
-
-class AnnotatorTrackingInstances(BaseAnnotator):
-
-    def __init__(self, instance_tracker):
-        super().__init__(instance_tracker)
-
-    def annotate_triple(self, a_triple):
-        if self._instance_tracker.is_subclass_property(a_triple[_P]):
-            self._annotate_subclass(a_triple)
-        else:
-            super().annotate_triple(a_triple)
-
-    def is_relevant_triple(self, a_triple):
-        if a_triple[_P] == self._subclass_property:
-            return True
-        else:
-            return super().annotate_triple(a_triple)
-
-    def annotation_post_parsing(self):
-        for a_key_class in self._instances_dict:
-            self._classes_considered_in_htree.add(a_key_class)
-        iri_node = self._htree.iri_node
-        for a_key_class in self._classes_considered_in_htree:
-            a_class_node = self._get_appropiate_iri_node_and_add_to_htree_if_needed(a_key_class)
-            if not a_class_node.has_parents():
-                a_class_node.add_parent(iri_node)
-
-    def _get_appropiate_iri_node_and_add_to_htree_if_needed(self, str_iri):
-        return self._htree.get_node_of_element(str_iri) if self._htree.contains_element(str_iri) \
-            else self._htree.create_node_IRI(str_iri)
-
-    def _annotate_subclass(self, a_triple):
-        str_s = str(a_triple[_S])
-        str_o = str(a_triple[_O])
-
-        subj_node = self._get_appropiate_iri_node_and_add_to_htree_if_needed(str_s)
-        obj_node = self._get_appropiate_iri_node_and_add_to_htree_if_needed(str_o)
-        subj_node.add_parent(obj_node)
-
-        self._classes_considered_in_htree.add(str_s)
-        self._classes_considered_in_htree.add(str_o)
+from shexer.core.instances.pconsts import _S, _P, _O
+from shexer.core.instances.annotators.base_annotator import BaseAnnotator
+
+class AnnotatorTrackingInstances(BaseAnnotator):
+
+    def __init__(self, instance_tracker):
+        super().__init__(instance_tracker)
+
+    def annotate_triple(self, a_triple):
+        if self._instance_tracker.is_subclass_property(a_triple[_P]):
+            self._annotate_subclass(a_triple)
+        else:
+            super().annotate_triple(a_triple)
+
+    def is_relevant_triple(self, a_triple):
+        if a_triple[_P] == self._subclass_property:
+            return True
+        else:
+            return super().annotate_triple(a_triple)
+
+    def annotation_post_parsing(self):
+        for a_key_class in self._instances_dict:
+            self._classes_considered_in_htree.add(a_key_class)
+        iri_node = self._htree.iri_node
+        for a_key_class in self._classes_considered_in_htree:
+            a_class_node = self._get_appropiate_iri_node_and_add_to_htree_if_needed(a_key_class)
+            if not a_class_node.has_parents():
+                a_class_node.add_parent(iri_node)
+
+    def _get_appropiate_iri_node_and_add_to_htree_if_needed(self, str_iri):
+        return self._htree.get_node_of_element(str_iri) if self._htree.contains_element(str_iri) \
+            else self._htree.create_node_IRI(str_iri)
+
+    def _annotate_subclass(self, a_triple):
+        str_s = str(a_triple[_S])
+        str_o = str(a_triple[_O])
+
+        subj_node = self._get_appropiate_iri_node_and_add_to_htree_if_needed(str_s)
+        obj_node = self._get_appropiate_iri_node_and_add_to_htree_if_needed(str_o)
+        subj_node.add_parent(obj_node)
+
+        self._classes_considered_in_htree.add(str_s)
+        self._classes_considered_in_htree.add(str_o)
```

### Comparing `shexer-2.5.1/shexer/core/instances/annotators/base_annotator.py` & `shexer-2.5.2/shexer/core/instances/annotators/base_annotator.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,74 +1,74 @@
-from shexer.core.instances.pconsts import _S, _P, _O
-from shexer.core.instances.annotators.strategy_mode.target_classes_mode import TargetClassesMode
-from shexer.core.instances.annotators.strategy_mode.all_classes_mode import AllClasesMode
-from shexer.core.instances.annotators.strategy_mode.shape_qualifiers_mode import ShapeQualifiersMode
-from shexer.core.instances.annotators.strategy_mode.compound_strategy_mode import CompoundStrategyMode
-from shexer.core.instances.annotators.strategy_mode.instance_cap_mode import InstanceCapMode
-
-
-class BaseAnnotator(object):
-
-    def __init__(self, instance_tracker):
-        self._instance_tracker = instance_tracker
-
-        # Some short-path to avoid verbosity and too deep references. We'll be gentle with private stuff ;)
-        self._all_classes_mode = self._instance_tracker._all_classes_mode
-        self._instantiation_property = self._instance_tracker._instantiation_property
-        self._subclass_property = self._instance_tracker._subclass_property
-        self._instances_dict = self._instance_tracker._instances_dict
-        self._classes_considered_in_htree = self._instance_tracker._classes_considered_in_htree
-        self._htree = self._instance_tracker._htree
-        self._shape_qualifiers_mode = self._instance_tracker._shape_qualifiers_mode
-        self._namespaces_for_qualifiers_props = self._instance_tracker._namespaces_for_qualifiers_props
-        self._target_classes = self._instance_tracker._target_classes
-        self._shapes_namespace = self._instance_tracker._shapes_namespace
-        self._instances_cap = self._instance_tracker._instances_cap
-
-        self._strategy_mode = self._get_proper_strategy()
-
-    def is_relevant_triple(self, a_triple):
-        return self._strategy_mode.is_relevant_triple(a_triple)
-
-    def annotate_triple(self, a_triple):
-        self._strategy_mode.annotate_triple(a_triple)
-
-    def add_instance_to_instances_dict(self, a_triple):
-        if a_triple[_S].iri not in self._instances_dict:
-            self._instances_dict[a_triple[_S].iri] = []
-
-    # def annotate_class(self, a_triple):
-    #     self._strategy_mode.annotate_class(a_triple)
-
-    def annotation_post_parsing(self):
-        self._strategy_mode.annotation_post_parsing()
-
-
-    def _get_proper_strategy(self):
-        result = None
-        strategies_list = []
-        target_classes_flag = False
-        if self._all_classes_mode:
-            strategies_list.append(AllClasesMode(annotator_ref=self))
-        if self._target_classes is not None and len(self._target_classes) > 0:
-            strategies_list.append(TargetClassesMode(annotator_ref=self))
-            target_classes_flag = True
-        if self._shape_qualifiers_mode:
-            strategies_list.append(
-                ShapeQualifiersMode(annotator_ref=self,
-                                    namespaces_for_qualifiers_props=self._namespaces_for_qualifiers_props,
-                                    shapes_namespace=self._shapes_namespace))
-
-        if len(strategies_list) == 0:
-            raise ValueError("Wrong combination of params when building the instance tracker. There are not target classes")
-        if len(strategies_list) == 1:
-            result = strategies_list[0]
-        else:
-            result = CompoundStrategyMode(annotator_ref=self,
-                                        list_of_strategies=strategies_list)
-        return result if self._instances_cap <= 0 else \
-            InstanceCapMode(annotator_ref=self,
-                            internal_strategy=result,
-                            instance_limit=self._instances_cap,
-                            n_target_classes=-1 if not target_classes_flag or len(strategies_list) > 1
-                                                   else len(self._target_classes)
-                            )
+from shexer.core.instances.pconsts import _S, _P, _O
+from shexer.core.instances.annotators.strategy_mode.target_classes_mode import TargetClassesMode
+from shexer.core.instances.annotators.strategy_mode.all_classes_mode import AllClasesMode
+from shexer.core.instances.annotators.strategy_mode.shape_qualifiers_mode import ShapeQualifiersMode
+from shexer.core.instances.annotators.strategy_mode.compound_strategy_mode import CompoundStrategyMode
+from shexer.core.instances.annotators.strategy_mode.instance_cap_mode import InstanceCapMode
+
+
+class BaseAnnotator(object):
+
+    def __init__(self, instance_tracker):
+        self._instance_tracker = instance_tracker
+
+        # Some short-path to avoid verbosity and too deep references. We'll be gentle with private stuff ;)
+        self._all_classes_mode = self._instance_tracker._all_classes_mode
+        self._instantiation_property = self._instance_tracker._instantiation_property
+        self._subclass_property = self._instance_tracker._subclass_property
+        self._instances_dict = self._instance_tracker._instances_dict
+        self._classes_considered_in_htree = self._instance_tracker._classes_considered_in_htree
+        self._htree = self._instance_tracker._htree
+        self._shape_qualifiers_mode = self._instance_tracker._shape_qualifiers_mode
+        self._namespaces_for_qualifiers_props = self._instance_tracker._namespaces_for_qualifiers_props
+        self._target_classes = self._instance_tracker._target_classes
+        self._shapes_namespace = self._instance_tracker._shapes_namespace
+        self._instances_cap = self._instance_tracker._instances_cap
+
+        self._strategy_mode = self._get_proper_strategy()
+
+    def is_relevant_triple(self, a_triple):
+        return self._strategy_mode.is_relevant_triple(a_triple)
+
+    def annotate_triple(self, a_triple):
+        self._strategy_mode.annotate_triple(a_triple)
+
+    def add_instance_to_instances_dict(self, a_triple):
+        if a_triple[_S].iri not in self._instances_dict:
+            self._instances_dict[a_triple[_S].iri] = []
+
+    # def annotate_class(self, a_triple):
+    #     self._strategy_mode.annotate_class(a_triple)
+
+    def annotation_post_parsing(self):
+        self._strategy_mode.annotation_post_parsing()
+
+
+    def _get_proper_strategy(self):
+        result = None
+        strategies_list = []
+        target_classes_flag = False
+        if self._all_classes_mode:
+            strategies_list.append(AllClasesMode(annotator_ref=self))
+        if self._target_classes is not None and len(self._target_classes) > 0:
+            strategies_list.append(TargetClassesMode(annotator_ref=self))
+            target_classes_flag = True
+        if self._shape_qualifiers_mode:
+            strategies_list.append(
+                ShapeQualifiersMode(annotator_ref=self,
+                                    namespaces_for_qualifiers_props=self._namespaces_for_qualifiers_props,
+                                    shapes_namespace=self._shapes_namespace))
+
+        if len(strategies_list) == 0:
+            raise ValueError("Wrong combination of params when building the instance tracker. There are not target classes")
+        if len(strategies_list) == 1:
+            result = strategies_list[0]
+        else:
+            result = CompoundStrategyMode(annotator_ref=self,
+                                        list_of_strategies=strategies_list)
+        return result if self._instances_cap <= 0 else \
+            InstanceCapMode(annotator_ref=self,
+                            internal_strategy=result,
+                            instance_limit=self._instances_cap,
+                            n_target_classes=-1 if not target_classes_flag or len(strategies_list) > 1
+                                                   else len(self._target_classes)
+                            )
```

### Comparing `shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/all_classes_mode.py` & `shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/target_classes_mode.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-from shexer.core.instances.annotators.strategy_mode.base_strategy_mode import BaseStrategyMode
-from shexer.core.instances.pconsts import _P
-
-class AllClasesMode(BaseStrategyMode):
-
-    def __init__(self, annotator_ref):
-        super().__init__(annotator_ref)
-
-
-
-    def is_relevant_triple(self, a_triple):
-        if a_triple[_P] != self._instantiation_property:
-            return False
-        return True
-
-
-    def annotate_triple(self, a_triple):
-        if self._instance_tracker.is_an_instantiation_prop(a_triple[_P]):
-            self._annotator_ref.add_instance_to_instances_dict(a_triple)
-            self.annotate_class(a_triple)
-
-
+
+from shexer.core.instances.annotators.strategy_mode.base_strategy_mode import BaseStrategyMode
+from shexer.core.instances.pconsts import _P, _O
+
+class TargetClassesMode(BaseStrategyMode):
+
+    def __init__(self, annotator_ref):
+        super().__init__(annotator_ref)
+        self._target_classes = self._annotator_ref._target_classes
+
+    def is_relevant_triple(self, a_triple):
+        if a_triple[_P] != self._instantiation_property:
+            return False
+        if a_triple[_O] not in self._target_classes:
+            return False
+        return True
+
+    def annotate_triple(self, a_triple):
+        if self._instance_tracker.is_an_instantiation_prop(a_triple[_P]):
+            self._annotator_ref.add_instance_to_instances_dict(a_triple)
+            self.annotate_class(a_triple)
+
```

### Comparing `shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/instance_cap_mode.py` & `shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/instance_cap_mode.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,62 +1,62 @@
-from shexer.core.instances.annotators.strategy_mode.base_strategy_mode import BaseStrategyMode
-from shexer.core.instances.pconsts import _S, _P, _O
-from shexer.core.instances.annotators.strategy_mode.instances_cap_exception import InstancesCapException
-
-class InstanceCapMode(BaseStrategyMode):
-
-    def __init__(self, annotator_ref, internal_strategy, instance_limit, n_target_classes = -1):
-        super().__init__(annotator_ref)
-        self._internal_strategy = internal_strategy
-        self._instance_limit = instance_limit
-        self._class_counts = {}
-        self._n_target_classes = n_target_classes
-        self._n_classes_completed = 0
-
-        self.annotate_class = self._annotate_class_with_stop_condition if n_target_classes > 0 \
-            else self._annotate_class_with_no_stop_condition
-
-
-    def is_relevant_triple(self, a_triple):
-        return self._check_class_counts(a_triple) and self._internal_strategy.is_relevant_triple(a_triple)
-
-    def _check_class_counts(self, a_triple):
-        """
-        It returns False when it receives an instantiation triple whose class has already reached the maz number of
-        instances allowed.
-
-        :param a_triple:
-        :return:
-        """
-        if a_triple[_P] != self._instantiation_property:
-            return True
-        if a_triple[_O].iri not in self._class_counts:
-            return True
-        if self._class_counts[a_triple[_O].iri] < self._instance_limit:
-            return True
-        return False
-
-
-    def annotate_triple(self, a_triple):
-        if self._instance_tracker.is_an_instantiation_prop(a_triple[_P]):
-            self._annotator_ref.add_instance_to_instances_dict(a_triple)
-            self.annotate_class(a_triple)
-
-    def annotate_class(self, a_triple):
-        raise NotImplementedError()
-
-
-    def _annotate_class_with_stop_condition(self, a_triple):
-        self._instances_dict[a_triple[_S].iri].append(a_triple[_O].iri)
-        if a_triple[_O].iri not in self._class_counts:
-            self._class_counts[a_triple[_O].iri] = 0
-        self._class_counts[a_triple[_O].iri] += 1
-        if self._class_counts[a_triple[_O].iri] == self._instance_limit:
-            self._n_classes_completed += 1
-        if self._n_classes_completed == self._n_target_classes:
-            raise InstancesCapException()
-
-    def _annotate_class_with_no_stop_condition(self, a_triple):
-        self._instances_dict[a_triple[_S].iri].append(a_triple[_O].iri)
-        if a_triple[_O].iri not in self._class_counts:
-            self._class_counts[a_triple[_O].iri] = 0
+from shexer.core.instances.annotators.strategy_mode.base_strategy_mode import BaseStrategyMode
+from shexer.core.instances.pconsts import _S, _P, _O
+from shexer.core.instances.annotators.strategy_mode.instances_cap_exception import InstancesCapException
+
+class InstanceCapMode(BaseStrategyMode):
+
+    def __init__(self, annotator_ref, internal_strategy, instance_limit, n_target_classes = -1):
+        super().__init__(annotator_ref)
+        self._internal_strategy = internal_strategy
+        self._instance_limit = instance_limit
+        self._class_counts = {}
+        self._n_target_classes = n_target_classes
+        self._n_classes_completed = 0
+
+        self.annotate_class = self._annotate_class_with_stop_condition if n_target_classes > 0 \
+            else self._annotate_class_with_no_stop_condition
+
+
+    def is_relevant_triple(self, a_triple):
+        return self._check_class_counts(a_triple) and self._internal_strategy.is_relevant_triple(a_triple)
+
+    def _check_class_counts(self, a_triple):
+        """
+        It returns False when it receives an instantiation triple whose class has already reached the maz number of
+        instances allowed.
+
+        :param a_triple:
+        :return:
+        """
+        if a_triple[_P] != self._instantiation_property:
+            return True
+        if a_triple[_O].iri not in self._class_counts:
+            return True
+        if self._class_counts[a_triple[_O].iri] < self._instance_limit:
+            return True
+        return False
+
+
+    def annotate_triple(self, a_triple):
+        if self._instance_tracker.is_an_instantiation_prop(a_triple[_P]):
+            self._annotator_ref.add_instance_to_instances_dict(a_triple)
+            self.annotate_class(a_triple)
+
+    def annotate_class(self, a_triple):
+        raise NotImplementedError()
+
+
+    def _annotate_class_with_stop_condition(self, a_triple):
+        self._instances_dict[a_triple[_S].iri].append(a_triple[_O].iri)
+        if a_triple[_O].iri not in self._class_counts:
+            self._class_counts[a_triple[_O].iri] = 0
+        self._class_counts[a_triple[_O].iri] += 1
+        if self._class_counts[a_triple[_O].iri] == self._instance_limit:
+            self._n_classes_completed += 1
+        if self._n_classes_completed == self._n_target_classes:
+            raise InstancesCapException()
+
+    def _annotate_class_with_no_stop_condition(self, a_triple):
+        self._instances_dict[a_triple[_S].iri].append(a_triple[_O].iri)
+        if a_triple[_O].iri not in self._class_counts:
+            self._class_counts[a_triple[_O].iri] = 0
         self._class_counts[a_triple[_O].iri] += 1
```

### Comparing `shexer-2.5.1/shexer/core/instances/annotators/strategy_mode/shape_qualifiers_mode.py` & `shexer-2.5.2/shexer/core/instances/annotators/strategy_mode/shape_qualifiers_mode.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,38 +1,38 @@
-from shexer.core.instances.annotators.strategy_mode.base_strategy_mode import BaseStrategyMode
-from shexer.utils.triple_yielders import check_if_property_belongs_to_namespace_list
-from shexer.utils.shapes import build_shape_name_for_qualifier_prop_uri
-from shexer.core.instances.pconsts import _P, _O
-
-class ShapeQualifiersMode(BaseStrategyMode):
-
-    def __init__(self, annotator_ref, namespaces_for_qualifiers_props, shapes_namespace):
-        super().__init__(annotator_ref)
-        self._namespaces_for_qualifiers_props = namespaces_for_qualifiers_props
-        self._dict_of_qualifier_properties = {}
-        self._shapes_namespace = shapes_namespace
-
-
-    def is_relevant_triple(self, a_triple):
-        if check_if_property_belongs_to_namespace_list(str_prop=a_triple[_P].iri,
-                                                       namespaces=self._namespaces_for_qualifiers_props):
-            return True
-        return False
-
-
-    def annotate_triple(self, a_triple):
-        self._annotate_qualifier_shape(a_triple[_P])
-        self._annotate_instance_of_a_qualifier(a_triple)
-
-
-    def _annotate_instance_of_a_qualifier(self, a_triple):
-        if a_triple[_O].iri not in self._instances_dict:
-            self._instances_dict[a_triple[_O].iri] = []
-        self._instances_dict[a_triple[_O].iri].append(self._dict_of_qualifier_properties[a_triple[_P].iri])
-
-
-    def _annotate_qualifier_shape(self, a_property):
-        str_prop = a_property.iri
-        if str_prop not in self._dict_of_qualifier_properties:
-            self._dict_of_qualifier_properties[str_prop] = \
-                build_shape_name_for_qualifier_prop_uri(prop_uri=str_prop,
-                                                        shapes_namespace=self._shapes_namespace)
+from shexer.core.instances.annotators.strategy_mode.base_strategy_mode import BaseStrategyMode
+from shexer.utils.triple_yielders import check_if_property_belongs_to_namespace_list
+from shexer.utils.shapes import build_shape_name_for_qualifier_prop_uri
+from shexer.core.instances.pconsts import _P, _O
+
+class ShapeQualifiersMode(BaseStrategyMode):
+
+    def __init__(self, annotator_ref, namespaces_for_qualifiers_props, shapes_namespace):
+        super().__init__(annotator_ref)
+        self._namespaces_for_qualifiers_props = namespaces_for_qualifiers_props
+        self._dict_of_qualifier_properties = {}
+        self._shapes_namespace = shapes_namespace
+
+
+    def is_relevant_triple(self, a_triple):
+        if check_if_property_belongs_to_namespace_list(str_prop=a_triple[_P].iri,
+                                                       namespaces=self._namespaces_for_qualifiers_props):
+            return True
+        return False
+
+
+    def annotate_triple(self, a_triple):
+        self._annotate_qualifier_shape(a_triple[_P])
+        self._annotate_instance_of_a_qualifier(a_triple)
+
+
+    def _annotate_instance_of_a_qualifier(self, a_triple):
+        if a_triple[_O].iri not in self._instances_dict:
+            self._instances_dict[a_triple[_O].iri] = []
+        self._instances_dict[a_triple[_O].iri].append(self._dict_of_qualifier_properties[a_triple[_P].iri])
+
+
+    def _annotate_qualifier_shape(self, a_property):
+        str_prop = a_property.iri
+        if str_prop not in self._dict_of_qualifier_properties:
+            self._dict_of_qualifier_properties[str_prop] = \
+                build_shape_name_for_qualifier_prop_uri(prop_uri=str_prop,
+                                                        shapes_namespace=self._shapes_namespace)
```

### Comparing `shexer-2.5.1/shexer/core/instances/mix/mixed_instance_tracker.py` & `shexer-2.5.2/shexer/core/instances/mix/mixed_instance_tracker.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,61 +1,61 @@
-from shexer.core.instances.abstract_instance_tracker import AbstractInstanceTracker
-from shexer.utils.log import log_msg
-
-class MixedInstanceTracker(AbstractInstanceTracker):
-
-    def __init__(self, list_of_instance_trackers):
-        self._reference_instance_tracker = list_of_instance_trackers[0]
-        self._secondary_instance_trackers = [] if len(list_of_instance_trackers) <= 1 else list_of_instance_trackers[1:]
-        self._disambiguator_counter = 0
-
-    def track_instances(self, verbose=True):
-        log_msg(verbose=verbose,
-                msg="Starting instance tracking process with a MixedInstance tracker. "
-                    "Several Instance Trackers may be launched...")
-        reference_instances_dict = self._reference_instance_tracker.track_instances(verbose=verbose)
-        for a_tracker in self._secondary_instance_trackers:
-            self._integrate_dicts(reference_dict=reference_instances_dict,
-                                  new_dict=a_tracker.track_instances(verbose=verbose),
-                                  new_tracker=a_tracker)
-        log_msg(verbose=verbose,
-                msg="Every instance tracker has finished and their results have been integrated."
-                    " {} instances have been located".format(len(reference_instances_dict)))
-        return reference_instances_dict
-
-    def _specific_disambiguator_prefix(self):
-        return "mixed_"
-
-    def _integrate_dicts(self, reference_dict, new_dict, new_tracker):
-        original_classes = self._find_all_classes_in_dict(reference_dict)
-        for an_instance, classes in new_dict.items():
-            if an_instance not in reference_dict:
-                reference_dict[an_instance] = []
-            for a_class in classes:
-                if a_class in original_classes:  # There is key_ambigüity, two trackers have
-                                                 # identhical names for different elements
-                    reference_dict[an_instance].append(self._get_label_for_ambiguous_class(a_class=a_class,
-                                                                                           tracker=new_tracker))
-                else:
-                    reference_dict[an_instance].append(a_class)
-
-
-    def _find_all_classes_in_dict(self, instances_dict):
-        result = set()
-        for classes in instances_dict.values():
-            for a_class in classes:
-                result.add(a_class)
-        return result
-
-
-
-    def _get_label_for_ambiguous_class(self, a_class, tracker):
-        return tracker.disambiguator_prefix + a_class
-
-
-
-
-
-
-
-
-
+from shexer.core.instances.abstract_instance_tracker import AbstractInstanceTracker
+from shexer.utils.log import log_msg
+
+class MixedInstanceTracker(AbstractInstanceTracker):
+
+    def __init__(self, list_of_instance_trackers):
+        self._reference_instance_tracker = list_of_instance_trackers[0]
+        self._secondary_instance_trackers = [] if len(list_of_instance_trackers) <= 1 else list_of_instance_trackers[1:]
+        self._disambiguator_counter = 0
+
+    def track_instances(self, verbose=True):
+        log_msg(verbose=verbose,
+                msg="Starting instance tracking process with a MixedInstance tracker. "
+                    "Several Instance Trackers may be launched...")
+        reference_instances_dict = self._reference_instance_tracker.track_instances(verbose=verbose)
+        for a_tracker in self._secondary_instance_trackers:
+            self._integrate_dicts(reference_dict=reference_instances_dict,
+                                  new_dict=a_tracker.track_instances(verbose=verbose),
+                                  new_tracker=a_tracker)
+        log_msg(verbose=verbose,
+                msg="Every instance tracker has finished and their results have been integrated."
+                    " {} instances have been located".format(len(reference_instances_dict)))
+        return reference_instances_dict
+
+    def _specific_disambiguator_prefix(self):
+        return "mixed_"
+
+    def _integrate_dicts(self, reference_dict, new_dict, new_tracker):
+        original_classes = self._find_all_classes_in_dict(reference_dict)
+        for an_instance, classes in new_dict.items():
+            if an_instance not in reference_dict:
+                reference_dict[an_instance] = []
+            for a_class in classes:
+                if a_class in original_classes:  # There is key_ambigüity, two trackers have
+                                                 # identhical names for different elements
+                    reference_dict[an_instance].append(self._get_label_for_ambiguous_class(a_class=a_class,
+                                                                                           tracker=new_tracker))
+                else:
+                    reference_dict[an_instance].append(a_class)
+
+
+    def _find_all_classes_in_dict(self, instances_dict):
+        result = set()
+        for classes in instances_dict.values():
+            for a_class in classes:
+                result.add(a_class)
+        return result
+
+
+
+    def _get_label_for_ambiguous_class(self, a_class, tracker):
+        return tracker.disambiguator_prefix + a_class
+
+
+
+
+
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer/core/profiling/class_profiler.py` & `shexer-2.5.2/shexer/core/profiling/class_profiler.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,259 +1,259 @@
-from shexer.utils.target_elements import determine_original_target_nodes_if_needed
-from shexer.model.property import Property
-from shexer.utils.uri import remove_corners
-from shexer.consts import SHAPES_DEFAULT_NAMESPACE, SHAPE_EXAMPLES, ALL_EXAMPLES
-from shexer.core.profiling.consts import POS_CLASSES
-from shexer.utils.log import log_msg
-from shexer.utils.uri import longest_common_prefix
-from shexer.core.profiling.strategy.direct_features_strategy import DirectFeaturesStrategy
-from shexer.core.profiling.strategy.include_reverse_features_strategy import IncludeReverseFeaturesStrategy
-from shexer.core.profiling.consts import RDF_TYPE_STR
-from shexer.utils.structures.dicts import ShapeExampleFeaturesDict
-
-_MINIMAL_IRI_INIT = "@"
-
-
-
-
-class ClassProfiler(object):
-
-    def __init__(self, triples_yielder, instances_dict, instantiation_property_str=RDF_TYPE_STR,
-                 remove_empty_shapes=True, original_target_classes=None, original_shape_map=None,
-                 shapes_namespace=SHAPES_DEFAULT_NAMESPACE, inverse_paths=False, detect_minimal_iri=False,
-                 examples_mode=None):
-        self._triples_yielder = triples_yielder
-        self._instances_dict = instances_dict  # TODO  refactor: change name once working again
-        # self._instances_shape_dict = {}
-        self._shapes_namespace = shapes_namespace
-        self._shape_names_dict = {}  # Will be filled during execution
-        self._relevant_triples = 0
-        self._instantiation_property_str = self._decide_instantiation_property(instantiation_property_str)
-        self._remove_empty_shapes = remove_empty_shapes
-        self._original_raw_target_classes = original_target_classes
-        self._classes_shape_dict = {}  # Will be filled later
-        self._class_counts = {}  # Will be filled later
-        self._detect_minimal_iri = detect_minimal_iri
-        self._examples_mode = examples_mode
-
-        self._original_target_nodes = determine_original_target_nodes_if_needed(remove_empty_shapes=remove_empty_shapes,
-                                                                                original_target_classes=original_target_classes,
-                                                                                original_shape_map=original_shape_map,
-                                                                                shapes_namespace=shapes_namespace)
-
-        if detect_minimal_iri or examples_mode is not None:
-            self._shape_feature_examples = ShapeExampleFeaturesDict(track_inverse_features=inverse_paths)
-            # This last one will be filled later if detect_minimal_iri is True
-        self._strategy = DirectFeaturesStrategy(class_profiler=self) if not inverse_paths \
-            else IncludeReverseFeaturesStrategy(class_profiler=self)
-
-
-
-    def profile_classes(self, verbose):
-        log_msg(verbose=verbose,
-                msg="Starting class profiler...")
-        self._init_class_counts_and_shape_dict()
-        log_msg(verbose=verbose,
-                msg="Instance counts completed. Annotating instance features...")
-        self._adapt_instances_dict()
-        self._build_shape_of_instances()
-        log_msg(verbose=verbose,
-                msg="Instance features annotated. Number of relevant triples computed: {}. "
-                    "Building shape profiles...".format(self._relevant_triples))
-
-        self._build_class_profile()
-        log_msg(verbose=verbose,
-                msg="Draft shape profiles built. Cleaning shape profiles...")
-        self._clean_class_profile()
-        log_msg(verbose=verbose,
-                msg="Shape profiles done. Working with {} shapes.".format(len(self._classes_shape_dict)))
-        if self._detect_minimal_iri or self._examples_mode in [SHAPE_EXAMPLES, ALL_EXAMPLES]:
-            log_msg(verbose=verbose,
-                    msg="Detecting example features for each shape...")
-            self._init_anotation_example_method()
-            self._detect_example_features()
-            log_msg(verbose=verbose,
-                    msg="Mimimal IRIs detected...")
-        return self._classes_shape_dict, self._class_counts, \
-            self._shape_feature_examples if (self._detect_minimal_iri or self._examples_mode is not None) else None
-
-    def get_target_classes_dict(self):
-        return self._instances_dict
-
-    def _detect_example_features(self):
-        self._init_class_features_dict()
-        self._annotate_example_features()
-
-
-    def _init_class_features_dict(self):
-        for a_class_key in self._class_counts:
-            self._shape_feature_examples.set_shape_min_iri(shape_id=a_class_key,
-                                                           min_iri=_MINIMAL_IRI_INIT)
-
-    def _init_anotation_example_method(self):
-        if self._detect_minimal_iri and self._examples_mode in [SHAPE_EXAMPLES, ALL_EXAMPLES]:
-            self._annotate_example_features = self._annotate_shape_examples_and_min_iris
-        elif self._detect_minimal_iri:
-            self._annotate_example_features = self._annotate_min_iris
-        else:  # not minimal IRIs, but if this was called, at this point, it means that we are looking for shape examples
-            self._annotate_example_features = self._annotate_shape_examples
-    def _annotate_example_features(self):
-        raise NotImplementedError()
-
-    def _annotate_min_iris(self):
-        for an_instance_iri in self._instances_dict:
-            for a_class_key in self._instances_dict[an_instance_iri][POS_CLASSES]:
-                self._update_shape_min_iri(target_shape=a_class_key,
-                                           instance_iri=an_instance_iri)
-    def _annotate_shape_examples(self):
-        for an_instance_iri in self._instances_dict:
-            for a_class_key in self._instances_dict[an_instance_iri][POS_CLASSES]:
-                if self._shape_feature_examples.shape_example(shape_id=a_class_key) is None:
-                    self._shape_feature_examples.set_shape_example(shape_id=a_class_key,
-                                                           example_iri=an_instance_iri)
-
-    def _annotate_shape_examples_and_min_iris(self):
-        for an_instance_iri in self._instances_dict:
-            for a_class_key in self._instances_dict[an_instance_iri][POS_CLASSES]:
-                self._update_shape_min_iri(target_shape=a_class_key,
-                                           instance_iri=an_instance_iri)
-                if self._shape_feature_examples.shape_example(shape_id=a_class_key) is None:
-                    self._shape_feature_examples.set_shape_example(shape_id=a_class_key,
-                                                           example_iri=an_instance_iri)
-
-
-    def _update_shape_min_iri(self, target_shape, instance_iri):
-        curr_iri = self._shape_feature_examples.shape_min_iri(shape_id=target_shape)
-        if curr_iri == _MINIMAL_IRI_INIT:
-            self._shape_feature_examples.set_shape_min_iri(shape_id=target_shape,
-                                                           min_iri=instance_iri)
-            return
-
-        self._shape_feature_examples.set_shape_min_iri(shape_id=target_shape,
-                                                       min_iri=longest_common_prefix(uri1=instance_iri,
-                                                                                     uri2=curr_iri))
-
-    @staticmethod
-    def _decide_instantiation_property(instantiation_property_str):
-        if instantiation_property_str == None:
-            return RDF_TYPE_STR
-        if type(instantiation_property_str) == Property:
-            return str(instantiation_property_str)
-        if type(instantiation_property_str) == str:
-            return remove_corners(a_uri=instantiation_property_str,
-                                  raise_error_if_no_corners=False)
-        raise ValueError("Unrecognized param type to define instantiation property")
-
-
-    def _init_class_counts_and_shape_dict(self):
-        """
-        IMPORTANT: this method should be called before adapting the instances_dict
-
-        :return:
-        """
-        self._init_original_targets()
-        self._init_annotated_targets()
-
-
-    def _init_annotated_targets(self):
-        self._strategy.init_annotated_targets()
-
-    def _init_original_targets(self):
-        self._strategy.init_original_targets()
-
-    def _build_class_profile(self):
-        for an_instance in self._instances_dict:
-            self._strategy.annotate_instance_features(an_instance)
-
-    def _clean_class_profile(self):
-        if not self._remove_empty_shapes:
-            return
-        shapes_to_remove = self._detect_shapes_to_remove()
-
-        while len(shapes_to_remove) != 0:
-            self._iteration_remove_empty_shapes(shapes_to_remove)
-            shapes_to_remove = self._detect_shapes_to_remove()
-
-    def _detect_shapes_to_remove(self):
-        shapes_to_remove = set()
-        for a_shape_key in self._classes_shape_dict:
-            if not self._is_original_target_shape(a_shape_key):
-                if not self._has_it_annotated_features(a_shape_key):
-                    shapes_to_remove.add(a_shape_key)
-        return shapes_to_remove
-
-    def _is_original_target_shape(self, shape_label):
-        return shape_label in self._original_target_nodes
-
-    def _has_it_annotated_features(self, shape_label):
-        return self._strategy.has_shape_annotated_features(shape_label)
-
-    def _iteration_remove_empty_shapes(self, target_shapes):
-        for a_shape_label_key in self._classes_shape_dict:
-            for a_prop_key in self._classes_shape_dict[a_shape_label_key]:
-                # print(self._classes_shape_dict[a_shape_label_key][a_prop_key])
-                for a_shape_to_remove in target_shapes:
-                    if a_shape_to_remove in self._classes_shape_dict[a_shape_label_key][a_prop_key]:
-                        del self._classes_shape_dict[a_shape_label_key][a_prop_key][a_shape_to_remove]
-        for a_shape_to_remove in target_shapes:
-            if a_shape_to_remove in self._classes_shape_dict:
-                del self._classes_shape_dict[a_shape_to_remove]
-
-    def _build_shape_of_instances(self):
-        for a_triple in self._yield_relevant_triples():
-            self._relevant_triples += 1
-            self._annotate_feature_of_target_instance(a_triple)
-
-    def _annotate_feature_of_target_instance(self, a_triple):
-        self._strategy.annotate_triple_features(a_triple)
-
-    def _adapt_instances_dict(self):
-        self._strategy.adapt_instances_dict()
-
-    def _adapt_entry_dict_if_needed(self, str_subj):
-        if type(self._instances_dict[str_subj]) == list:
-            self._instances_dict[str_subj] = (self._instances_dict[str_subj], {})
-
-    def _yield_relevant_triples(self):
-        for a_triple in self._triples_yielder.yield_triples():
-            if self._strategy.is_a_relevant_triple(a_triple):
-                yield a_triple
-
-    # def _set_anotation_instance_methods(self):
-    #     # MIN IRIS
-    #     if self._detect_minimal_iri:
-    #         self._update_shape_min_iri = self._update_shape_min_iri_active
-    #     else:
-    #         self._update_shape_min_iri = self._update_shape_min_iri_inactive
-    #
-    #     # EXAMPLE FEATURES
-    #     if self._examples_mode is None:
-    #         self._update_shape_examples = self._update_shape_examples_inactive
-    #     elif self._examples_mode == SHAPE_EXAMPLES:
-    #         self._update_shape_examples = self._update_shape_examples_only_shapes
-    #     elif self._examples_mode == CONSTRAINT_EXAMPLES:
-    #         self._update_shape_examples = self._update_shape_examples_only_constraints
-    #     elif self._examples_mode == ALL_EXAMPLES:
-    #         self._update_shape_examples = self._update_shape_examples_shapes_and_constraints
-    #     else:
-    #         raise ValueError("Unrecognized mode for getting shape examples. Choose one between the values offered in shexer.const, section # EXAMPLES")
-
-
-    #
-    # def _update_shape_examples_only_constraints(self, instance_id, shape_id):
-    #     self._strategy.look_for_example_features(instance_id=instance_id,
-    #                                              shape_id=shape_id)
-    #
-    # def _update_shape_examples_shapes_and_constraints(self, instance_id, shape_id):
-    #     self._update_shape_examples_only_shapes(instance_id, shape_id)
-    #     self._update_shape_examples_only_constraints(instance_id, shape_id)
-    #
-    # def _update_shape_examples(self, instance_id, shape_id):
-    #     raise NotImplementedError()
-    #
-    # def _update_shape_examples_inactive(self, instance_id, shape_id):
-    #     pass  # This is OK, do nothing
-    #
-
-
-
-
+from shexer.utils.target_elements import determine_original_target_nodes_if_needed
+from shexer.model.property import Property
+from shexer.utils.uri import remove_corners
+from shexer.consts import SHAPES_DEFAULT_NAMESPACE, SHAPE_EXAMPLES, ALL_EXAMPLES
+from shexer.core.profiling.consts import POS_CLASSES
+from shexer.utils.log import log_msg
+from shexer.utils.uri import longest_common_prefix
+from shexer.core.profiling.strategy.direct_features_strategy import DirectFeaturesStrategy
+from shexer.core.profiling.strategy.include_reverse_features_strategy import IncludeReverseFeaturesStrategy
+from shexer.core.profiling.consts import RDF_TYPE_STR
+from shexer.utils.structures.dicts import ShapeExampleFeaturesDict
+
+_MINIMAL_IRI_INIT = "@"
+
+
+
+
+class ClassProfiler(object):
+
+    def __init__(self, triples_yielder, instances_dict, instantiation_property_str=RDF_TYPE_STR,
+                 remove_empty_shapes=True, original_target_classes=None, original_shape_map=None,
+                 shapes_namespace=SHAPES_DEFAULT_NAMESPACE, inverse_paths=False, detect_minimal_iri=False,
+                 examples_mode=None):
+        self._triples_yielder = triples_yielder
+        self._instances_dict = instances_dict  # TODO  refactor: change name once working again
+        # self._instances_shape_dict = {}
+        self._shapes_namespace = shapes_namespace
+        self._shape_names_dict = {}  # Will be filled during execution
+        self._relevant_triples = 0
+        self._instantiation_property_str = self._decide_instantiation_property(instantiation_property_str)
+        self._remove_empty_shapes = remove_empty_shapes
+        self._original_raw_target_classes = original_target_classes
+        self._classes_shape_dict = {}  # Will be filled later
+        self._class_counts = {}  # Will be filled later
+        self._detect_minimal_iri = detect_minimal_iri
+        self._examples_mode = examples_mode
+
+        self._original_target_nodes = determine_original_target_nodes_if_needed(remove_empty_shapes=remove_empty_shapes,
+                                                                                original_target_classes=original_target_classes,
+                                                                                original_shape_map=original_shape_map,
+                                                                                shapes_namespace=shapes_namespace)
+
+        if detect_minimal_iri or examples_mode is not None:
+            self._shape_feature_examples = ShapeExampleFeaturesDict(track_inverse_features=inverse_paths)
+            # This last one will be filled later if detect_minimal_iri is True
+        self._strategy = DirectFeaturesStrategy(class_profiler=self) if not inverse_paths \
+            else IncludeReverseFeaturesStrategy(class_profiler=self)
+
+
+
+    def profile_classes(self, verbose):
+        log_msg(verbose=verbose,
+                msg="Starting class profiler...")
+        self._init_class_counts_and_shape_dict()
+        log_msg(verbose=verbose,
+                msg="Instance counts completed. Annotating instance features...")
+        self._adapt_instances_dict()
+        self._build_shape_of_instances()
+        log_msg(verbose=verbose,
+                msg="Instance features annotated. Number of relevant triples computed: {}. "
+                    "Building shape profiles...".format(self._relevant_triples))
+
+        self._build_class_profile()
+        log_msg(verbose=verbose,
+                msg="Draft shape profiles built. Cleaning shape profiles...")
+        self._clean_class_profile()
+        log_msg(verbose=verbose,
+                msg="Shape profiles done. Working with {} shapes.".format(len(self._classes_shape_dict)))
+        if self._detect_minimal_iri or self._examples_mode in [SHAPE_EXAMPLES, ALL_EXAMPLES]:
+            log_msg(verbose=verbose,
+                    msg="Detecting example features for each shape...")
+            self._init_anotation_example_method()
+            self._detect_example_features()
+            log_msg(verbose=verbose,
+                    msg="Mimimal IRIs detected...")
+        return self._classes_shape_dict, self._class_counts, \
+            self._shape_feature_examples if (self._detect_minimal_iri or self._examples_mode is not None) else None
+
+    def get_target_classes_dict(self):
+        return self._instances_dict
+
+    def _detect_example_features(self):
+        self._init_class_features_dict()
+        self._annotate_example_features()
+
+
+    def _init_class_features_dict(self):
+        for a_class_key in self._class_counts:
+            self._shape_feature_examples.set_shape_min_iri(shape_id=a_class_key,
+                                                           min_iri=_MINIMAL_IRI_INIT)
+
+    def _init_anotation_example_method(self):
+        if self._detect_minimal_iri and self._examples_mode in [SHAPE_EXAMPLES, ALL_EXAMPLES]:
+            self._annotate_example_features = self._annotate_shape_examples_and_min_iris
+        elif self._detect_minimal_iri:
+            self._annotate_example_features = self._annotate_min_iris
+        else:  # not minimal IRIs, but if this was called, at this point, it means that we are looking for shape examples
+            self._annotate_example_features = self._annotate_shape_examples
+    def _annotate_example_features(self):
+        raise NotImplementedError()
+
+    def _annotate_min_iris(self):
+        for an_instance_iri in self._instances_dict:
+            for a_class_key in self._instances_dict[an_instance_iri][POS_CLASSES]:
+                self._update_shape_min_iri(target_shape=a_class_key,
+                                           instance_iri=an_instance_iri)
+    def _annotate_shape_examples(self):
+        for an_instance_iri in self._instances_dict:
+            for a_class_key in self._instances_dict[an_instance_iri][POS_CLASSES]:
+                if self._shape_feature_examples.shape_example(shape_id=a_class_key) is None:
+                    self._shape_feature_examples.set_shape_example(shape_id=a_class_key,
+                                                           example_iri=an_instance_iri)
+
+    def _annotate_shape_examples_and_min_iris(self):
+        for an_instance_iri in self._instances_dict:
+            for a_class_key in self._instances_dict[an_instance_iri][POS_CLASSES]:
+                self._update_shape_min_iri(target_shape=a_class_key,
+                                           instance_iri=an_instance_iri)
+                if self._shape_feature_examples.shape_example(shape_id=a_class_key) is None:
+                    self._shape_feature_examples.set_shape_example(shape_id=a_class_key,
+                                                           example_iri=an_instance_iri)
+
+
+    def _update_shape_min_iri(self, target_shape, instance_iri):
+        curr_iri = self._shape_feature_examples.shape_min_iri(shape_id=target_shape)
+        if curr_iri == _MINIMAL_IRI_INIT:
+            self._shape_feature_examples.set_shape_min_iri(shape_id=target_shape,
+                                                           min_iri=instance_iri)
+            return
+
+        self._shape_feature_examples.set_shape_min_iri(shape_id=target_shape,
+                                                       min_iri=longest_common_prefix(uri1=instance_iri,
+                                                                                     uri2=curr_iri))
+
+    @staticmethod
+    def _decide_instantiation_property(instantiation_property_str):
+        if instantiation_property_str == None:
+            return RDF_TYPE_STR
+        if type(instantiation_property_str) == Property:
+            return str(instantiation_property_str)
+        if type(instantiation_property_str) == str:
+            return remove_corners(a_uri=instantiation_property_str,
+                                  raise_error_if_no_corners=False)
+        raise ValueError("Unrecognized param type to define instantiation property")
+
+
+    def _init_class_counts_and_shape_dict(self):
+        """
+        IMPORTANT: this method should be called before adapting the instances_dict
+
+        :return:
+        """
+        self._init_original_targets()
+        self._init_annotated_targets()
+
+
+    def _init_annotated_targets(self):
+        self._strategy.init_annotated_targets()
+
+    def _init_original_targets(self):
+        self._strategy.init_original_targets()
+
+    def _build_class_profile(self):
+        for an_instance in self._instances_dict:
+            self._strategy.annotate_instance_features(an_instance)
+
+    def _clean_class_profile(self):
+        if not self._remove_empty_shapes:
+            return
+        shapes_to_remove = self._detect_shapes_to_remove()
+
+        while len(shapes_to_remove) != 0:
+            self._iteration_remove_empty_shapes(shapes_to_remove)
+            shapes_to_remove = self._detect_shapes_to_remove()
+
+    def _detect_shapes_to_remove(self):
+        shapes_to_remove = set()
+        for a_shape_key in self._classes_shape_dict:
+            if not self._is_original_target_shape(a_shape_key):
+                if not self._has_it_annotated_features(a_shape_key):
+                    shapes_to_remove.add(a_shape_key)
+        return shapes_to_remove
+
+    def _is_original_target_shape(self, shape_label):
+        return shape_label in self._original_target_nodes
+
+    def _has_it_annotated_features(self, shape_label):
+        return self._strategy.has_shape_annotated_features(shape_label)
+
+    def _iteration_remove_empty_shapes(self, target_shapes):
+        for a_shape_label_key in self._classes_shape_dict:
+            for a_prop_key in self._classes_shape_dict[a_shape_label_key]:
+                # print(self._classes_shape_dict[a_shape_label_key][a_prop_key])
+                for a_shape_to_remove in target_shapes:
+                    if a_shape_to_remove in self._classes_shape_dict[a_shape_label_key][a_prop_key]:
+                        del self._classes_shape_dict[a_shape_label_key][a_prop_key][a_shape_to_remove]
+        for a_shape_to_remove in target_shapes:
+            if a_shape_to_remove in self._classes_shape_dict:
+                del self._classes_shape_dict[a_shape_to_remove]
+
+    def _build_shape_of_instances(self):
+        for a_triple in self._yield_relevant_triples():
+            self._relevant_triples += 1
+            self._annotate_feature_of_target_instance(a_triple)
+
+    def _annotate_feature_of_target_instance(self, a_triple):
+        self._strategy.annotate_triple_features(a_triple)
+
+    def _adapt_instances_dict(self):
+        self._strategy.adapt_instances_dict()
+
+    def _adapt_entry_dict_if_needed(self, str_subj):
+        if type(self._instances_dict[str_subj]) == list:
+            self._instances_dict[str_subj] = (self._instances_dict[str_subj], {})
+
+    def _yield_relevant_triples(self):
+        for a_triple in self._triples_yielder.yield_triples():
+            if self._strategy.is_a_relevant_triple(a_triple):
+                yield a_triple
+
+    # def _set_anotation_instance_methods(self):
+    #     # MIN IRIS
+    #     if self._detect_minimal_iri:
+    #         self._update_shape_min_iri = self._update_shape_min_iri_active
+    #     else:
+    #         self._update_shape_min_iri = self._update_shape_min_iri_inactive
+    #
+    #     # EXAMPLE FEATURES
+    #     if self._examples_mode is None:
+    #         self._update_shape_examples = self._update_shape_examples_inactive
+    #     elif self._examples_mode == SHAPE_EXAMPLES:
+    #         self._update_shape_examples = self._update_shape_examples_only_shapes
+    #     elif self._examples_mode == CONSTRAINT_EXAMPLES:
+    #         self._update_shape_examples = self._update_shape_examples_only_constraints
+    #     elif self._examples_mode == ALL_EXAMPLES:
+    #         self._update_shape_examples = self._update_shape_examples_shapes_and_constraints
+    #     else:
+    #         raise ValueError("Unrecognized mode for getting shape examples. Choose one between the values offered in shexer.const, section # EXAMPLES")
+
+
+    #
+    # def _update_shape_examples_only_constraints(self, instance_id, shape_id):
+    #     self._strategy.look_for_example_features(instance_id=instance_id,
+    #                                              shape_id=shape_id)
+    #
+    # def _update_shape_examples_shapes_and_constraints(self, instance_id, shape_id):
+    #     self._update_shape_examples_only_shapes(instance_id, shape_id)
+    #     self._update_shape_examples_only_constraints(instance_id, shape_id)
+    #
+    # def _update_shape_examples(self, instance_id, shape_id):
+    #     raise NotImplementedError()
+    #
+    # def _update_shape_examples_inactive(self, instance_id, shape_id):
+    #     pass  # This is OK, do nothing
+    #
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer/core/profiling/strategy/abstract_feature_direction_strategy.py` & `shexer-2.5.2/shexer/core/profiling/strategy/abstract_feature_direction_strategy.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,154 +1,154 @@
-from shexer.utils.shapes import build_shapes_name_for_class_uri
-from shexer.core.profiling.consts import POS_CLASSES, _S, _P, _O, POS_FEATURES_DIRECT, _ONE_TO_MANY, POS_FEATURES_INVERSE
-from shexer.model.IRI import IRI_ELEM_TYPE, IRI
-
-class AbstractFeatureDirectionStrategy(object):
-
-    def __init__(self, class_profiler):
-        self._class_profiler = class_profiler
-        self._i_dict = self._class_profiler._instances_dict
-        self._c_shapes_dict = self._class_profiler._classes_shape_dict
-        self._c_counts = self._class_profiler._class_counts
-        self._shape_names_dict = self._class_profiler._shape_names_dict
-        self._original_raw_target_classes = self._class_profiler._original_raw_target_classes
-        self._detect_minimal_iri = self._class_profiler._detect_minimal_iri
-        self._examples_mode = self._class_profiler._examples_mode
-        if self._detect_minimal_iri or self._examples_mode is not None:
-            self._shape_feature_examples = self._class_profiler._shape_feature_examples
-
-    def adapt_instances_dict(self):
-        raise NotImplementedError()
-
-    def is_a_relevant_triple(self, a_triple):
-        raise NotImplementedError()
-
-    def annotate_triple_features(self, a_triple):
-        raise NotImplementedError()
-
-    def annotate_instance_features(self, an_instance):
-        raise NotImplementedError()
-
-    def init_original_targets(self):
-        raise NotImplementedError()
-
-    def init_annotated_targets(self):
-        raise NotImplementedError()
-
-    def has_shape_annotated_features(self, shape_label):
-        raise NotImplementedError()
-    #
-    # def look_for_example_features(self, instance_id, shape_id):
-    #     raise NotImplementedError()
-
-    def _init_annotated_direct_features(self):
-        for an_instance, class_list in self._i_dict.items():
-            for a_class in class_list:
-                if a_class not in self._c_shapes_dict:
-                    self._c_shapes_dict[a_class] = {}
-                    self._c_counts[a_class] = 0
-                self._c_counts[a_class] += 1
-
-    def _annotate_direct_instance_features(self, an_instance):
-        direct_feautres_3tuple = self._infer_direct_3tuple_features(an_instance)
-
-        for a_class in self._i_dict[an_instance][POS_CLASSES]:
-            self._annotate_direct_instance_features_for_class(a_class, direct_feautres_3tuple)
-
-    def _infer_direct_3tuple_features(self, an_instance):
-        result = []
-        for a_prop in self._i_dict[an_instance][POS_FEATURES_DIRECT]:
-            for a_type in self._i_dict[an_instance][POS_FEATURES_DIRECT][a_prop]:
-                for a_valid_cardinality in self._infer_valid_cardinalities(a_prop,
-                                                                           self._i_dict[an_instance][POS_FEATURES_DIRECT][a_prop][a_type]):
-                    result.append( (a_prop, a_type, a_valid_cardinality) )
-        return result
-
-
-    def _infer_valid_cardinalities(self, a_property, a_cardinality):
-        """
-        Special teratment for self._instantiation_property_str. If thats the property, we are targetting specific URIs
-        instead of the type IRI.
-        Cardinality will be always "1"
-        :param a_property:
-        :param a_cardinality:
-        :return:
-        """
-        if a_property == self._class_profiler._instantiation_property_str:
-            yield 1
-        else:
-            yield a_cardinality
-            yield _ONE_TO_MANY
-
-    def _annotate_direct_instance_features_for_class(self, a_class, features_3tuple):
-        for a_feature_3tuple in features_3tuple:
-            self._introduce_needed_elements_in_shape_classes_dict(a_class, a_feature_3tuple)
-            # 3tuple: 0->str_prop, 1->str_type, 2->cardinality
-            self._c_shapes_dict[a_class][a_feature_3tuple[0]][a_feature_3tuple[1]][a_feature_3tuple[2]] += 1
-
-    def _introduce_needed_elements_in_shape_classes_dict(self, a_class, a_feature_3tuple):
-        str_prop = a_feature_3tuple[0]
-        str_type = a_feature_3tuple[1]
-        cardinality = a_feature_3tuple[2]
-        if str_prop not in self._c_shapes_dict[a_class]:
-            self._c_shapes_dict[a_class][str_prop] = {}
-        if str_type not in self._c_shapes_dict[a_class][str_prop]:
-            self._c_shapes_dict[a_class][str_prop][str_type] = {}
-        if cardinality not in self._c_shapes_dict[a_class][str_prop][str_type]:
-            self._c_shapes_dict[a_class][str_prop][str_type][cardinality] = 0
-
-    def _is_relevant_instance(self, an_instance):
-        return isinstance(an_instance, IRI) and an_instance.iri in self._i_dict
-
-    def _decide_type_elem(self, original_elem, str_prop):
-        """
-        Special traetment for self._instantiation_property_str property. We look for ValueSets instead of types when this property appears.
-
-        :param original_elem:
-        :param str_prop:
-        :return:
-        """
-        if str_prop != self._class_profiler._instantiation_property_str:
-            return original_elem.elem_type
-        return original_elem.iri
-
-    def _decide_shapes_elem(self, str_elem):
-        if str_elem not in self._i_dict:
-            return []
-        return [self._get_shape_name_for_a_class(a_class)
-                for a_class in self._i_dict[str_elem][POS_CLASSES]]
-
-    def _get_shape_name_for_a_class(self, a_class):
-        self._assign_shape_name_if_needed(a_class)
-        return self._shape_names_dict[a_class]
-
-    def _assign_shape_name_if_needed(self, a_class):
-        if a_class in self._shape_names_dict:
-            return
-        self._shape_names_dict[a_class] = \
-            build_shapes_name_for_class_uri(class_uri=a_class,
-                                            shapes_namespace=self._class_profiler._shapes_namespace)
-
-    def _annotate_target_subject(self, a_triple):
-        str_subj = a_triple[_S].iri
-        str_prop = a_triple[_P].iri
-        type_obj = self._decide_type_elem(a_triple[_O], str_prop)
-
-        obj_shapes = [] if type_obj != IRI_ELEM_TYPE else self._decide_shapes_elem(a_triple[_O].iri)
-
-        self._introduce_needed_elements_in_shape_instances_dict_for_subj(str_subj=str_subj,
-                                                                         str_prop=str_prop,
-                                                                         type_obj=type_obj,
-                                                                         obj_shapes=obj_shapes)
-        self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][type_obj] += 1
-        for a_shape in obj_shapes:
-            self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][a_shape] += 1
-
-
-    def _introduce_needed_elements_in_shape_instances_dict_for_subj(self, str_subj, str_prop, type_obj, obj_shapes):
-        if str_prop not in self._i_dict[str_subj][POS_FEATURES_DIRECT]:
-            self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop] = {}
-        if type_obj not in self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop]:
-            self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][type_obj] = 0
-        for a_shape in obj_shapes:
-            if a_shape not in self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop]:
+from shexer.utils.shapes import build_shapes_name_for_class_uri
+from shexer.core.profiling.consts import POS_CLASSES, _S, _P, _O, POS_FEATURES_DIRECT, _ONE_TO_MANY, POS_FEATURES_INVERSE
+from shexer.model.IRI import IRI_ELEM_TYPE, IRI
+
+class AbstractFeatureDirectionStrategy(object):
+
+    def __init__(self, class_profiler):
+        self._class_profiler = class_profiler
+        self._i_dict = self._class_profiler._instances_dict
+        self._c_shapes_dict = self._class_profiler._classes_shape_dict
+        self._c_counts = self._class_profiler._class_counts
+        self._shape_names_dict = self._class_profiler._shape_names_dict
+        self._original_raw_target_classes = self._class_profiler._original_raw_target_classes
+        self._detect_minimal_iri = self._class_profiler._detect_minimal_iri
+        self._examples_mode = self._class_profiler._examples_mode
+        if self._detect_minimal_iri or self._examples_mode is not None:
+            self._shape_feature_examples = self._class_profiler._shape_feature_examples
+
+    def adapt_instances_dict(self):
+        raise NotImplementedError()
+
+    def is_a_relevant_triple(self, a_triple):
+        raise NotImplementedError()
+
+    def annotate_triple_features(self, a_triple):
+        raise NotImplementedError()
+
+    def annotate_instance_features(self, an_instance):
+        raise NotImplementedError()
+
+    def init_original_targets(self):
+        raise NotImplementedError()
+
+    def init_annotated_targets(self):
+        raise NotImplementedError()
+
+    def has_shape_annotated_features(self, shape_label):
+        raise NotImplementedError()
+    #
+    # def look_for_example_features(self, instance_id, shape_id):
+    #     raise NotImplementedError()
+
+    def _init_annotated_direct_features(self):
+        for an_instance, class_list in self._i_dict.items():
+            for a_class in class_list:
+                if a_class not in self._c_shapes_dict:
+                    self._c_shapes_dict[a_class] = {}
+                    self._c_counts[a_class] = 0
+                self._c_counts[a_class] += 1
+
+    def _annotate_direct_instance_features(self, an_instance):
+        direct_feautres_3tuple = self._infer_direct_3tuple_features(an_instance)
+
+        for a_class in self._i_dict[an_instance][POS_CLASSES]:
+            self._annotate_direct_instance_features_for_class(a_class, direct_feautres_3tuple)
+
+    def _infer_direct_3tuple_features(self, an_instance):
+        result = []
+        for a_prop in self._i_dict[an_instance][POS_FEATURES_DIRECT]:
+            for a_type in self._i_dict[an_instance][POS_FEATURES_DIRECT][a_prop]:
+                for a_valid_cardinality in self._infer_valid_cardinalities(a_prop,
+                                                                           self._i_dict[an_instance][POS_FEATURES_DIRECT][a_prop][a_type]):
+                    result.append( (a_prop, a_type, a_valid_cardinality) )
+        return result
+
+
+    def _infer_valid_cardinalities(self, a_property, a_cardinality):
+        """
+        Special teratment for self._instantiation_property_str. If thats the property, we are targetting specific URIs
+        instead of the type IRI.
+        Cardinality will be always "1"
+        :param a_property:
+        :param a_cardinality:
+        :return:
+        """
+        if a_property == self._class_profiler._instantiation_property_str:
+            yield 1
+        else:
+            yield a_cardinality
+            yield _ONE_TO_MANY
+
+    def _annotate_direct_instance_features_for_class(self, a_class, features_3tuple):
+        for a_feature_3tuple in features_3tuple:
+            self._introduce_needed_elements_in_shape_classes_dict(a_class, a_feature_3tuple)
+            # 3tuple: 0->str_prop, 1->str_type, 2->cardinality
+            self._c_shapes_dict[a_class][a_feature_3tuple[0]][a_feature_3tuple[1]][a_feature_3tuple[2]] += 1
+
+    def _introduce_needed_elements_in_shape_classes_dict(self, a_class, a_feature_3tuple):
+        str_prop = a_feature_3tuple[0]
+        str_type = a_feature_3tuple[1]
+        cardinality = a_feature_3tuple[2]
+        if str_prop not in self._c_shapes_dict[a_class]:
+            self._c_shapes_dict[a_class][str_prop] = {}
+        if str_type not in self._c_shapes_dict[a_class][str_prop]:
+            self._c_shapes_dict[a_class][str_prop][str_type] = {}
+        if cardinality not in self._c_shapes_dict[a_class][str_prop][str_type]:
+            self._c_shapes_dict[a_class][str_prop][str_type][cardinality] = 0
+
+    def _is_relevant_instance(self, an_instance):
+        return isinstance(an_instance, IRI) and an_instance.iri in self._i_dict
+
+    def _decide_type_elem(self, original_elem, str_prop):
+        """
+        Special traetment for self._instantiation_property_str property. We look for ValueSets instead of types when this property appears.
+
+        :param original_elem:
+        :param str_prop:
+        :return:
+        """
+        if str_prop != self._class_profiler._instantiation_property_str:
+            return original_elem.elem_type
+        return original_elem.iri
+
+    def _decide_shapes_elem(self, str_elem):
+        if str_elem not in self._i_dict:
+            return []
+        return [self._get_shape_name_for_a_class(a_class)
+                for a_class in self._i_dict[str_elem][POS_CLASSES]]
+
+    def _get_shape_name_for_a_class(self, a_class):
+        self._assign_shape_name_if_needed(a_class)
+        return self._shape_names_dict[a_class]
+
+    def _assign_shape_name_if_needed(self, a_class):
+        if a_class in self._shape_names_dict:
+            return
+        self._shape_names_dict[a_class] = \
+            build_shapes_name_for_class_uri(class_uri=a_class,
+                                            shapes_namespace=self._class_profiler._shapes_namespace)
+
+    def _annotate_target_subject(self, a_triple):
+        str_subj = a_triple[_S].iri
+        str_prop = a_triple[_P].iri
+        type_obj = self._decide_type_elem(a_triple[_O], str_prop)
+
+        obj_shapes = [] if type_obj != IRI_ELEM_TYPE else self._decide_shapes_elem(a_triple[_O].iri)
+
+        self._introduce_needed_elements_in_shape_instances_dict_for_subj(str_subj=str_subj,
+                                                                         str_prop=str_prop,
+                                                                         type_obj=type_obj,
+                                                                         obj_shapes=obj_shapes)
+        self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][type_obj] += 1
+        for a_shape in obj_shapes:
+            self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][a_shape] += 1
+
+
+    def _introduce_needed_elements_in_shape_instances_dict_for_subj(self, str_subj, str_prop, type_obj, obj_shapes):
+        if str_prop not in self._i_dict[str_subj][POS_FEATURES_DIRECT]:
+            self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop] = {}
+        if type_obj not in self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop]:
+            self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][type_obj] = 0
+        for a_shape in obj_shapes:
+            if a_shape not in self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop]:
                 self._i_dict[str_subj][POS_FEATURES_DIRECT][str_prop][a_shape] = 0
```

### Comparing `shexer-2.5.1/shexer/core/profiling/strategy/direct_features_strategy.py` & `shexer-2.5.2/shexer/core/profiling/strategy/direct_features_strategy.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,69 +1,69 @@
-
-from shexer.core.profiling.strategy.abstract_feature_direction_strategy import AbstractFeatureDirectionStrategy
-from shexer.core.profiling.consts import _S, _P, _O, POS_CLASSES
-
-
-
-class DirectFeaturesStrategy(AbstractFeatureDirectionStrategy):
-
-    def __init__(self, class_profiler):
-        super().__init__(class_profiler)
-        self._set_annotation_methods()
-
-
-    def adapt_instances_dict(self):
-        for a_subj_key in self._i_dict:
-            self._i_dict[a_subj_key] = \
-                (self._i_dict[a_subj_key], {})
-
-    def is_a_relevant_triple(self, a_triple):
-        return self._is_relevant_instance(a_triple[_S])
-
-    def _annotate_triple_features(self, a_triple):
-        raise NotImplementedError()
-
-
-    def annotate_instance_features(self, an_instance):
-        self._annotate_direct_instance_features(an_instance)
-
-
-    def init_annotated_targets(self):
-        self._init_annotated_direct_features()
-
-    def init_original_targets(self):
-        if self._original_raw_target_classes:
-            for a_class in self._original_raw_target_classes:
-                self._c_shapes_dict[a_class] = {}
-                self._c_counts[a_class] = 0
-
-    def has_shape_annotated_features(self, shape_label):
-        if shape_label not in self._c_shapes_dict:
-            return False
-        return len(self._c_shapes_dict[shape_label]) > 0
-
-    def _set_annotation_methods(self):
-        if self._examples_mode is None:
-            self.annotate_triple_features = self._annotate_triple_features_no_examples
-        else:
-            self.annotate_triple_features = self._annotate_triple_features_with_examples
-
-
-    def _annotate_triple_features_with_examples(self, a_triple):
-        self._annotate_target_subject(a_triple)
-        self._annotate_example_no_inverse(a_triple=a_triple)
-
-    def _annotate_triple_features_no_examples(self, a_triple):
-        self._annotate_target_subject(a_triple)
-
-    def _annotate_example_no_inverse(self, a_triple):
-        for a_class_key in self._i_dict[str(a_triple[_S])][POS_CLASSES]:
-            if not self._shape_feature_examples.has_constraint_example(shape_id=a_class_key,
-                                                                       prop_id=str(a_triple[_P])):
-                self._shape_feature_examples.set_constraint_example(shape_id=a_class_key,
-                                                                    prop_id=str(a_triple[_P]),
-                                                                    example=str(a_triple[_O]))
-
-
-
-
-
+
+from shexer.core.profiling.strategy.abstract_feature_direction_strategy import AbstractFeatureDirectionStrategy
+from shexer.core.profiling.consts import _S, _P, _O, POS_CLASSES
+
+
+
+class DirectFeaturesStrategy(AbstractFeatureDirectionStrategy):
+
+    def __init__(self, class_profiler):
+        super().__init__(class_profiler)
+        self._set_annotation_methods()
+
+
+    def adapt_instances_dict(self):
+        for a_subj_key in self._i_dict:
+            self._i_dict[a_subj_key] = \
+                (self._i_dict[a_subj_key], {})
+
+    def is_a_relevant_triple(self, a_triple):
+        return self._is_relevant_instance(a_triple[_S])
+
+    def _annotate_triple_features(self, a_triple):
+        raise NotImplementedError()
+
+
+    def annotate_instance_features(self, an_instance):
+        self._annotate_direct_instance_features(an_instance)
+
+
+    def init_annotated_targets(self):
+        self._init_annotated_direct_features()
+
+    def init_original_targets(self):
+        if self._original_raw_target_classes:
+            for a_class in self._original_raw_target_classes:
+                self._c_shapes_dict[a_class] = {}
+                self._c_counts[a_class] = 0
+
+    def has_shape_annotated_features(self, shape_label):
+        if shape_label not in self._c_shapes_dict:
+            return False
+        return len(self._c_shapes_dict[shape_label]) > 0
+
+    def _set_annotation_methods(self):
+        if self._examples_mode is None:
+            self.annotate_triple_features = self._annotate_triple_features_no_examples
+        else:
+            self.annotate_triple_features = self._annotate_triple_features_with_examples
+
+
+    def _annotate_triple_features_with_examples(self, a_triple):
+        self._annotate_target_subject(a_triple)
+        self._annotate_example_no_inverse(a_triple=a_triple)
+
+    def _annotate_triple_features_no_examples(self, a_triple):
+        self._annotate_target_subject(a_triple)
+
+    def _annotate_example_no_inverse(self, a_triple):
+        for a_class_key in self._i_dict[str(a_triple[_S])][POS_CLASSES]:
+            if not self._shape_feature_examples.has_constraint_example(shape_id=a_class_key,
+                                                                       prop_id=str(a_triple[_P])):
+                self._shape_feature_examples.set_constraint_example(shape_id=a_class_key,
+                                                                    prop_id=str(a_triple[_P]),
+                                                                    example=str(a_triple[_O]))
+
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer/core/profiling/strategy/include_reverse_features_strategy.py` & `shexer-2.5.2/shexer/core/profiling/strategy/include_reverse_features_strategy.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,177 +1,177 @@
-from shexer.core.profiling.strategy.abstract_feature_direction_strategy import AbstractFeatureDirectionStrategy
-from shexer.core.profiling.consts import _S, _P, _O, POS_FEATURES_INVERSE, POS_CLASSES
-from shexer.model.IRI import IRI_ELEM_TYPE
-
-_C_MAP_POS_DIRECT = 0
-_C_MAP_POS_INVERSE = 1
-
-
-class IncludeReverseFeaturesStrategy(AbstractFeatureDirectionStrategy):
-
-
-
-    def __init__(self, class_profiler):
-        super().__init__(class_profiler)
-        self._set_annotation_methods()
-
-
-    def adapt_instances_dict(self):
-        for a_subj_key in self._i_dict:
-            self._i_dict[a_subj_key] = (self._i_dict[a_subj_key], {}, {})
-
-
-    def is_a_relevant_triple(self, a_triple):
-        target_elems = (a_triple[_S], a_triple[_O])
-        for elem in target_elems:
-            if self._is_relevant_instance(elem):
-                return True
-        return False
-
-
-    def annotate_triple_features(self, a_triple):
-        raise NotImplementedError()
-
-
-    def init_annotated_targets(self):
-        for an_instance, class_list in self._i_dict.items():
-            for a_class in class_list:
-                if a_class not in self._c_shapes_dict:
-                    self._c_shapes_dict[a_class] = ({}, {})
-                    self._c_counts[a_class] = 0
-                self._c_counts[a_class] += 1
-
-    def init_original_targets(self):
-        if self._original_raw_target_classes:
-            for a_class in self._original_raw_target_classes:
-                self._c_shapes_dict[a_class] = ({}, {})
-                self._c_counts[a_class] = 0
-
-    def annotate_instance_features(self, an_instance):
-        self._annotate_2d_direct_instance_features(an_instance)
-        self._annotate_2d_inverse_instance_features(an_instance)
-
-    def has_shape_annotated_features(self, shape_label):
-        if shape_label not in self._c_shapes_dict:
-            return False
-        return len(self._c_shapes_dict[shape_label][_C_MAP_POS_DIRECT]) > 0 or \
-               len(self._c_shapes_dict[shape_label][_C_MAP_POS_INVERSE]) > 0
-
-    def _annotate_2d_direct_instance_features(self, an_instance):
-        direct_feautres_3tuple = self._infer_direct_3tuple_features(an_instance)
-        for a_class in self._i_dict[an_instance][POS_CLASSES]:
-            self._annotate_2d_direct_instance_features_for_class(a_class, direct_feautres_3tuple)
-
-    def _annotate_2d_inverse_instance_features(self, an_instance):
-        inverse_feautres_3tuple = self._infer_inverse_3tuple_features(an_instance)
-        for a_class in self._i_dict[an_instance][POS_CLASSES]:
-            self._annotate_2d_inverse_instance_features_for_class(a_class, inverse_feautres_3tuple)
-
-    def _infer_inverse_3tuple_features(self, an_instance):
-        result = []
-        for a_prop in self._i_dict[an_instance][POS_FEATURES_INVERSE]:
-            for a_type in self._i_dict[an_instance][POS_FEATURES_INVERSE][a_prop]:
-                for a_valid_cardinality in self._infer_valid_cardinalities(a_prop,
-                                                                           self._i_dict[an_instance][POS_FEATURES_INVERSE][a_prop][a_type]):
-                    result.append( (a_prop, a_type, a_valid_cardinality) )
-        return result
-
-    def _annotate_2d_direct_instance_features_for_class(self, a_class, features_3tuple):
-        for a_feature_3tuple in features_3tuple:
-            self._introduce_needed_direct_elements_in_2d_shape_classes_dict(a_class, a_feature_3tuple)
-            # 3tuple: 0->str_prop, 1->str_type, 2->cardinality
-            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][a_feature_3tuple[0]][a_feature_3tuple[1]][a_feature_3tuple[2]] += 1
-
-    def _annotate_2d_inverse_instance_features_for_class(self, a_class, features_3tuple):
-        for a_feature_3tuple in features_3tuple:
-            self._introduce_needed_inverse_elements_in_2d_shape_classes_dict(a_class, a_feature_3tuple)
-            # 3tuple: 0->str_prop, 1->str_type, 2->cardinality
-            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][a_feature_3tuple[0]][a_feature_3tuple[1]][a_feature_3tuple[2]] += 1
-
-    def _introduce_needed_direct_elements_in_2d_shape_classes_dict(self, a_class, a_feature_3tuple):
-        str_prop = a_feature_3tuple[0]
-        str_type = a_feature_3tuple[1]
-        cardinality = a_feature_3tuple[2]
-        if str_prop not in self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT]:
-            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop] = {}
-        if str_type not in self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop]:
-            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop][str_type] = {}
-        if cardinality not in self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop][str_type]:
-            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop][str_type][cardinality] = 0
-
-    def _introduce_needed_inverse_elements_in_2d_shape_classes_dict(self, a_class, a_feature_3tuple):
-        str_prop = a_feature_3tuple[0]
-        str_type = a_feature_3tuple[1]
-        cardinality = a_feature_3tuple[2]
-        if str_prop not in self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE]:
-            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop] = {}
-        if str_type not in self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop]:
-            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop][str_type] = {}
-        if cardinality not in self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop][str_type]:
-            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop][str_type][cardinality] = 0
-
-
-    def _annotate_target_object(self, a_triple):  # TODO: refactor here, place this in superclass and parametrize positions
-        str_obj = a_triple[_O].iri
-        str_prop = a_triple[_P].iri
-        type_subj = self._decide_type_elem(a_triple[_S], str_prop)
-
-        subj_shapes = [] if type_subj != IRI_ELEM_TYPE else self._decide_shapes_elem(a_triple[_S].iri)
-
-        self._introduce_needed_elements_in_shape_instances_dict_for_obj(str_obj=str_obj,
-                                                                        str_prop=str_prop,
-                                                                        type_subj=type_subj,
-                                                                        subj_shapes=subj_shapes)
-        self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][type_subj] += 1
-        for a_shape in subj_shapes:
-            self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][a_shape] += 1
-
-    def _introduce_needed_elements_in_shape_instances_dict_for_obj(self, str_obj, str_prop, type_subj, subj_shapes):
-        if str_prop not in self._i_dict[str_obj][POS_FEATURES_INVERSE]:
-            self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop] = {}
-        if type_subj not in self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop]:
-            self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][type_subj] = 0
-        for a_shape in subj_shapes:
-            if a_shape not in self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop]:
-                self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][a_shape] = 0
-
-    def _set_annotation_methods(self):
-        if not self._examples_mode:
-            self.annotate_triple_features = self._annotate_triple_features_no_examples
-        else:
-            self.annotate_triple_features = self._annotate_triple_features_with_examples
-
-    def _annotate_triple_features_with_examples(self, a_triple):
-        if self._is_relevant_instance(a_triple[_S]):
-            self._annotate_target_subject(a_triple)
-            self._annotate_example_subject_inverse_paths(a_triple)
-        if self._is_relevant_instance(a_triple[_O]):
-            self._annotate_target_object(a_triple)
-            self._annotate_example_object_inverse_paths(a_triple)
-
-    def _annotate_triple_features_no_examples(self, a_triple):
-        if self._is_relevant_instance(a_triple[_S]):
-            self._annotate_target_subject(a_triple)
-        if self._is_relevant_instance(a_triple[_O]):
-            self._annotate_target_object(a_triple)
-
-    def _annotate_example_subject_inverse_paths(self, a_triple):
-        for a_class_key in self._i_dict[str(a_triple[_S])][POS_CLASSES]:
-            if not self._shape_feature_examples.has_constraint_example(shape_id=a_class_key,
-                                                                       prop_id=str(a_triple[_P]),
-                                                                       inverse=False):
-                self._shape_feature_examples.set_constraint_example(shape_id=a_class_key,
-                                                                    prop_id=str(a_triple[_P]),
-                                                                    example=str(a_triple[_O]),
-                                                                    inverse=False)
-
-    def _annotate_example_object_inverse_paths(self, a_triple):
-        for a_class_key in self._i_dict[str(a_triple[_O])][POS_CLASSES]:
-            if not self._shape_feature_examples.has_constraint_example(shape_id=a_class_key,
-                                                                       prop_id=str(a_triple[_P]),
-                                                                       inverse=True):
-                self._shape_feature_examples.set_constraint_example(shape_id=a_class_key,
-                                                                    prop_id=str(a_triple[_P]),
-                                                                    example=str(a_triple[_S]),
-                                                                    inverse=True)
-
-
+from shexer.core.profiling.strategy.abstract_feature_direction_strategy import AbstractFeatureDirectionStrategy
+from shexer.core.profiling.consts import _S, _P, _O, POS_FEATURES_INVERSE, POS_CLASSES
+from shexer.model.IRI import IRI_ELEM_TYPE
+
+_C_MAP_POS_DIRECT = 0
+_C_MAP_POS_INVERSE = 1
+
+
+class IncludeReverseFeaturesStrategy(AbstractFeatureDirectionStrategy):
+
+
+
+    def __init__(self, class_profiler):
+        super().__init__(class_profiler)
+        self._set_annotation_methods()
+
+
+    def adapt_instances_dict(self):
+        for a_subj_key in self._i_dict:
+            self._i_dict[a_subj_key] = (self._i_dict[a_subj_key], {}, {})
+
+
+    def is_a_relevant_triple(self, a_triple):
+        target_elems = (a_triple[_S], a_triple[_O])
+        for elem in target_elems:
+            if self._is_relevant_instance(elem):
+                return True
+        return False
+
+
+    def annotate_triple_features(self, a_triple):
+        raise NotImplementedError()
+
+
+    def init_annotated_targets(self):
+        for an_instance, class_list in self._i_dict.items():
+            for a_class in class_list:
+                if a_class not in self._c_shapes_dict:
+                    self._c_shapes_dict[a_class] = ({}, {})
+                    self._c_counts[a_class] = 0
+                self._c_counts[a_class] += 1
+
+    def init_original_targets(self):
+        if self._original_raw_target_classes:
+            for a_class in self._original_raw_target_classes:
+                self._c_shapes_dict[a_class] = ({}, {})
+                self._c_counts[a_class] = 0
+
+    def annotate_instance_features(self, an_instance):
+        self._annotate_2d_direct_instance_features(an_instance)
+        self._annotate_2d_inverse_instance_features(an_instance)
+
+    def has_shape_annotated_features(self, shape_label):
+        if shape_label not in self._c_shapes_dict:
+            return False
+        return len(self._c_shapes_dict[shape_label][_C_MAP_POS_DIRECT]) > 0 or \
+               len(self._c_shapes_dict[shape_label][_C_MAP_POS_INVERSE]) > 0
+
+    def _annotate_2d_direct_instance_features(self, an_instance):
+        direct_feautres_3tuple = self._infer_direct_3tuple_features(an_instance)
+        for a_class in self._i_dict[an_instance][POS_CLASSES]:
+            self._annotate_2d_direct_instance_features_for_class(a_class, direct_feautres_3tuple)
+
+    def _annotate_2d_inverse_instance_features(self, an_instance):
+        inverse_feautres_3tuple = self._infer_inverse_3tuple_features(an_instance)
+        for a_class in self._i_dict[an_instance][POS_CLASSES]:
+            self._annotate_2d_inverse_instance_features_for_class(a_class, inverse_feautres_3tuple)
+
+    def _infer_inverse_3tuple_features(self, an_instance):
+        result = []
+        for a_prop in self._i_dict[an_instance][POS_FEATURES_INVERSE]:
+            for a_type in self._i_dict[an_instance][POS_FEATURES_INVERSE][a_prop]:
+                for a_valid_cardinality in self._infer_valid_cardinalities(a_prop,
+                                                                           self._i_dict[an_instance][POS_FEATURES_INVERSE][a_prop][a_type]):
+                    result.append( (a_prop, a_type, a_valid_cardinality) )
+        return result
+
+    def _annotate_2d_direct_instance_features_for_class(self, a_class, features_3tuple):
+        for a_feature_3tuple in features_3tuple:
+            self._introduce_needed_direct_elements_in_2d_shape_classes_dict(a_class, a_feature_3tuple)
+            # 3tuple: 0->str_prop, 1->str_type, 2->cardinality
+            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][a_feature_3tuple[0]][a_feature_3tuple[1]][a_feature_3tuple[2]] += 1
+
+    def _annotate_2d_inverse_instance_features_for_class(self, a_class, features_3tuple):
+        for a_feature_3tuple in features_3tuple:
+            self._introduce_needed_inverse_elements_in_2d_shape_classes_dict(a_class, a_feature_3tuple)
+            # 3tuple: 0->str_prop, 1->str_type, 2->cardinality
+            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][a_feature_3tuple[0]][a_feature_3tuple[1]][a_feature_3tuple[2]] += 1
+
+    def _introduce_needed_direct_elements_in_2d_shape_classes_dict(self, a_class, a_feature_3tuple):
+        str_prop = a_feature_3tuple[0]
+        str_type = a_feature_3tuple[1]
+        cardinality = a_feature_3tuple[2]
+        if str_prop not in self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT]:
+            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop] = {}
+        if str_type not in self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop]:
+            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop][str_type] = {}
+        if cardinality not in self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop][str_type]:
+            self._c_shapes_dict[a_class][_C_MAP_POS_DIRECT][str_prop][str_type][cardinality] = 0
+
+    def _introduce_needed_inverse_elements_in_2d_shape_classes_dict(self, a_class, a_feature_3tuple):
+        str_prop = a_feature_3tuple[0]
+        str_type = a_feature_3tuple[1]
+        cardinality = a_feature_3tuple[2]
+        if str_prop not in self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE]:
+            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop] = {}
+        if str_type not in self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop]:
+            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop][str_type] = {}
+        if cardinality not in self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop][str_type]:
+            self._c_shapes_dict[a_class][_C_MAP_POS_INVERSE][str_prop][str_type][cardinality] = 0
+
+
+    def _annotate_target_object(self, a_triple):  # TODO: refactor here, place this in superclass and parametrize positions
+        str_obj = a_triple[_O].iri
+        str_prop = a_triple[_P].iri
+        type_subj = self._decide_type_elem(a_triple[_S], str_prop)
+
+        subj_shapes = [] if type_subj != IRI_ELEM_TYPE else self._decide_shapes_elem(a_triple[_S].iri)
+
+        self._introduce_needed_elements_in_shape_instances_dict_for_obj(str_obj=str_obj,
+                                                                        str_prop=str_prop,
+                                                                        type_subj=type_subj,
+                                                                        subj_shapes=subj_shapes)
+        self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][type_subj] += 1
+        for a_shape in subj_shapes:
+            self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][a_shape] += 1
+
+    def _introduce_needed_elements_in_shape_instances_dict_for_obj(self, str_obj, str_prop, type_subj, subj_shapes):
+        if str_prop not in self._i_dict[str_obj][POS_FEATURES_INVERSE]:
+            self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop] = {}
+        if type_subj not in self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop]:
+            self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][type_subj] = 0
+        for a_shape in subj_shapes:
+            if a_shape not in self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop]:
+                self._i_dict[str_obj][POS_FEATURES_INVERSE][str_prop][a_shape] = 0
+
+    def _set_annotation_methods(self):
+        if not self._examples_mode:
+            self.annotate_triple_features = self._annotate_triple_features_no_examples
+        else:
+            self.annotate_triple_features = self._annotate_triple_features_with_examples
+
+    def _annotate_triple_features_with_examples(self, a_triple):
+        if self._is_relevant_instance(a_triple[_S]):
+            self._annotate_target_subject(a_triple)
+            self._annotate_example_subject_inverse_paths(a_triple)
+        if self._is_relevant_instance(a_triple[_O]):
+            self._annotate_target_object(a_triple)
+            self._annotate_example_object_inverse_paths(a_triple)
+
+    def _annotate_triple_features_no_examples(self, a_triple):
+        if self._is_relevant_instance(a_triple[_S]):
+            self._annotate_target_subject(a_triple)
+        if self._is_relevant_instance(a_triple[_O]):
+            self._annotate_target_object(a_triple)
+
+    def _annotate_example_subject_inverse_paths(self, a_triple):
+        for a_class_key in self._i_dict[str(a_triple[_S])][POS_CLASSES]:
+            if not self._shape_feature_examples.has_constraint_example(shape_id=a_class_key,
+                                                                       prop_id=str(a_triple[_P]),
+                                                                       inverse=False):
+                self._shape_feature_examples.set_constraint_example(shape_id=a_class_key,
+                                                                    prop_id=str(a_triple[_P]),
+                                                                    example=str(a_triple[_O]),
+                                                                    inverse=False)
+
+    def _annotate_example_object_inverse_paths(self, a_triple):
+        for a_class_key in self._i_dict[str(a_triple[_O])][POS_CLASSES]:
+            if not self._shape_feature_examples.has_constraint_example(shape_id=a_class_key,
+                                                                       prop_id=str(a_triple[_P]),
+                                                                       inverse=True):
+                self._shape_feature_examples.set_constraint_example(shape_id=a_class_key,
+                                                                    prop_id=str(a_triple[_P]),
+                                                                    example=str(a_triple[_S]),
+                                                                    inverse=True)
+
+
```

### Comparing `shexer-2.5.1/shexer/core/shexing/class_shexer.py` & `shexer-2.5.2/shexer/core/shexing/class_shexer.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,123 +1,123 @@
-import json
-
-from shexer.consts import RDF_TYPE, SHAPES_DEFAULT_NAMESPACE
-from shexer.core.shexing.strategy.direct_shexing_strategy import DirectShexingStrategy
-from shexer.core.shexing.strategy.direct_and_inverse_shexing_strategy import DirectAndInverseShexingStrategy
-from shexer.utils.target_elements import determine_original_target_nodes_if_needed
-from shexer.utils.log import log_msg
-from shexer.consts import RATIO_INSTANCES
-
-
-class ClassShexer(object):
-
-    def __init__(self, class_counts_dict, class_profile_dict=None, class_profile_json_file=None,
-                 remove_empty_shapes=True, original_target_classes=None, original_shape_map=None,
-                 discard_useless_constraints_with_positive_closure=True, keep_less_specific=True,
-                 all_compliant_mode=True, instantiation_property=RDF_TYPE, disable_or_statements=True,
-                 disable_comments=False, namespaces_dict=None, tolerance_to_keep_similar_rules=0,
-                 allow_opt_cardinality=True, disable_exact_cardinality=False,
-                 shapes_namespace=SHAPES_DEFAULT_NAMESPACE, inverse_paths=False,
-                 decimals=-1, instances_report_mode=RATIO_INSTANCES, detect_minimal_iri=False,
-                 class_min_iris_dict=None, allow_redundant_or=False):
-        self._class_counts_dict = class_counts_dict
-        self._class_profile_dict = class_profile_dict if class_profile_dict is not None else self._load_class_profile_dict_from_file(
-            class_profile_json_file)
-        self._class_min_iris_dict = class_min_iris_dict
-
-        self._shapes_list = []
-        self._remove_empty_shapes = remove_empty_shapes
-        self._all_compliant_mode = all_compliant_mode
-        self._disable_or_statements = disable_or_statements
-        self._instantiation_property_str = str(instantiation_property)
-        self._disable_comments = disable_comments
-        self._discard_useless_positive_closures = discard_useless_constraints_with_positive_closure
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-        self._keep_less_specific = keep_less_specific
-        self._tolerance = tolerance_to_keep_similar_rules
-        self._allow_opt_cardinality = allow_opt_cardinality
-        self._disable_exact_cardinality = disable_exact_cardinality
-        self._shapes_namespace = shapes_namespace
-        self._decimals = decimals
-        self._instances_report_mode = instances_report_mode
-        self._detect_minimal_iri = detect_minimal_iri
-        self._allow_redundant_or = allow_redundant_or
-
-        self._original_target_nodes = determine_original_target_nodes_if_needed(remove_empty_shapes=remove_empty_shapes,
-                                                                                original_target_classes=original_target_classes,
-                                                                                original_shape_map=original_shape_map,
-                                                                                shapes_namespace=shapes_namespace)
-        self._strategy = DirectShexingStrategy(self) if not inverse_paths \
-            else DirectAndInverseShexingStrategy(self)
-
-    def shex_classes(self, acceptance_threshold=0,
-                     verbose=False):
-        log_msg(verbose=verbose,
-                msg="Starting shape extraction...")
-        self._build_shapes(acceptance_threshold)
-        log_msg(verbose=verbose,
-                msg="Shape drafts built. Sorting constraints...")
-        self._sort_shapes()
-        log_msg(verbose=verbose,
-                msg="Constraints sorted. Adjusting cardinalities...")
-        self._set_valid_constraints_of_shapes()
-        log_msg(verbose=verbose,
-                msg="Cardinalities adjusted. Cleaning empty shapes if needed...")
-        self._clean_empty_shapes()
-        log_msg(verbose=verbose,
-                msg="No more shapes to clean. {} definitive shapes".format(len(self._shapes_list)))
-        return self._shapes_list
-
-    def _set_valid_constraints_of_shapes(self):
-        for a_shape in self._shapes_list:
-            self._strategy.set_valid_shape_constraints(a_shape)
-
-    def _build_shapes(self, acceptance_threshold):
-        for a_shape in self._strategy.yield_base_shapes(acceptance_threshold=acceptance_threshold):
-            self._shapes_list.append(a_shape)
-
-    def _sort_shapes(self):
-        for a_shape in self._shapes_list:
-            a_shape.sort_statements(reverse=True,
-                                    callback=self._value_to_compare_statements)
-
-    def _clean_empty_shapes(self):
-        if not self._remove_empty_shapes:
-            return
-        shapes_to_remove = self._detect_shapes_to_remove()
-
-        while (len(shapes_to_remove) != 0):
-            self._iteration_remove_empty_shapes(shapes_to_remove)
-            shapes_to_remove = self._detect_shapes_to_remove()
-
-    def _detect_shapes_to_remove(self):
-        result = set()
-        for a_shape in self._shapes_list:
-            if a_shape.n_statements == 0:
-                result.add(a_shape.name)
-        return result
-
-    def _iteration_remove_empty_shapes(self, shape_names_to_remove):
-        self._remove_shapes_without_statements(shape_names_to_remove)
-        self._remove_statements_to_gone_shapes(shape_names_to_remove)
-
-
-    def _remove_statements_to_gone_shapes(self, shape_names_to_remove):
-        for a_shape in self._shapes_list:
-            self._strategy.remove_statements_to_gone_shapes(a_shape, shape_names_to_remove)
-
-    def _remove_shapes_without_statements(self, shape_names_to_remove):
-        new_shape_list = []
-        for a_shape in self._shapes_list:
-            if not a_shape.name in shape_names_to_remove:
-                new_shape_list.append(a_shape)
-        self._shapes_list = new_shape_list
-
-    def _value_to_compare_statements(self, a_statement):
-        return a_statement.probability
-
-    @staticmethod
-    def _load_class_profile_dict_from_file(source_file):
-        with open(source_file, "r") as in_stream:
-            return json.load(in_stream)
-
-
+import json
+
+from shexer.consts import RDF_TYPE, SHAPES_DEFAULT_NAMESPACE
+from shexer.core.shexing.strategy.direct_shexing_strategy import DirectShexingStrategy
+from shexer.core.shexing.strategy.direct_and_inverse_shexing_strategy import DirectAndInverseShexingStrategy
+from shexer.utils.target_elements import determine_original_target_nodes_if_needed
+from shexer.utils.log import log_msg
+from shexer.consts import RATIO_INSTANCES
+
+
+class ClassShexer(object):
+
+    def __init__(self, class_counts_dict, class_profile_dict=None, class_profile_json_file=None,
+                 remove_empty_shapes=True, original_target_classes=None, original_shape_map=None,
+                 discard_useless_constraints_with_positive_closure=True, keep_less_specific=True,
+                 all_compliant_mode=True, instantiation_property=RDF_TYPE, disable_or_statements=True,
+                 disable_comments=False, namespaces_dict=None, tolerance_to_keep_similar_rules=0,
+                 allow_opt_cardinality=True, disable_exact_cardinality=False,
+                 shapes_namespace=SHAPES_DEFAULT_NAMESPACE, inverse_paths=False,
+                 decimals=-1, instances_report_mode=RATIO_INSTANCES, detect_minimal_iri=False,
+                 class_min_iris_dict=None, allow_redundant_or=False):
+        self._class_counts_dict = class_counts_dict
+        self._class_profile_dict = class_profile_dict if class_profile_dict is not None else self._load_class_profile_dict_from_file(
+            class_profile_json_file)
+        self._class_min_iris_dict = class_min_iris_dict
+
+        self._shapes_list = []
+        self._remove_empty_shapes = remove_empty_shapes
+        self._all_compliant_mode = all_compliant_mode
+        self._disable_or_statements = disable_or_statements
+        self._instantiation_property_str = str(instantiation_property)
+        self._disable_comments = disable_comments
+        self._discard_useless_positive_closures = discard_useless_constraints_with_positive_closure
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+        self._keep_less_specific = keep_less_specific
+        self._tolerance = tolerance_to_keep_similar_rules
+        self._allow_opt_cardinality = allow_opt_cardinality
+        self._disable_exact_cardinality = disable_exact_cardinality
+        self._shapes_namespace = shapes_namespace
+        self._decimals = decimals
+        self._instances_report_mode = instances_report_mode
+        self._detect_minimal_iri = detect_minimal_iri
+        self._allow_redundant_or = allow_redundant_or
+
+        self._original_target_nodes = determine_original_target_nodes_if_needed(remove_empty_shapes=remove_empty_shapes,
+                                                                                original_target_classes=original_target_classes,
+                                                                                original_shape_map=original_shape_map,
+                                                                                shapes_namespace=shapes_namespace)
+        self._strategy = DirectShexingStrategy(self) if not inverse_paths \
+            else DirectAndInverseShexingStrategy(self)
+
+    def shex_classes(self, acceptance_threshold=0,
+                     verbose=False):
+        log_msg(verbose=verbose,
+                msg="Starting shape extraction...")
+        self._build_shapes(acceptance_threshold)
+        log_msg(verbose=verbose,
+                msg="Shape drafts built. Sorting constraints...")
+        self._sort_shapes()
+        log_msg(verbose=verbose,
+                msg="Constraints sorted. Adjusting cardinalities...")
+        self._set_valid_constraints_of_shapes()
+        log_msg(verbose=verbose,
+                msg="Cardinalities adjusted. Cleaning empty shapes if needed...")
+        self._clean_empty_shapes()
+        log_msg(verbose=verbose,
+                msg="No more shapes to clean. {} definitive shapes".format(len(self._shapes_list)))
+        return self._shapes_list
+
+    def _set_valid_constraints_of_shapes(self):
+        for a_shape in self._shapes_list:
+            self._strategy.set_valid_shape_constraints(a_shape)
+
+    def _build_shapes(self, acceptance_threshold):
+        for a_shape in self._strategy.yield_base_shapes(acceptance_threshold=acceptance_threshold):
+            self._shapes_list.append(a_shape)
+
+    def _sort_shapes(self):
+        for a_shape in self._shapes_list:
+            a_shape.sort_statements(reverse=True,
+                                    callback=self._value_to_compare_statements)
+
+    def _clean_empty_shapes(self):
+        if not self._remove_empty_shapes:
+            return
+        shapes_to_remove = self._detect_shapes_to_remove()
+
+        while (len(shapes_to_remove) != 0):
+            self._iteration_remove_empty_shapes(shapes_to_remove)
+            shapes_to_remove = self._detect_shapes_to_remove()
+
+    def _detect_shapes_to_remove(self):
+        result = set()
+        for a_shape in self._shapes_list:
+            if a_shape.n_statements == 0:
+                result.add(a_shape.name)
+        return result
+
+    def _iteration_remove_empty_shapes(self, shape_names_to_remove):
+        self._remove_shapes_without_statements(shape_names_to_remove)
+        self._remove_statements_to_gone_shapes(shape_names_to_remove)
+
+
+    def _remove_statements_to_gone_shapes(self, shape_names_to_remove):
+        for a_shape in self._shapes_list:
+            self._strategy.remove_statements_to_gone_shapes(a_shape, shape_names_to_remove)
+
+    def _remove_shapes_without_statements(self, shape_names_to_remove):
+        new_shape_list = []
+        for a_shape in self._shapes_list:
+            if not a_shape.name in shape_names_to_remove:
+                new_shape_list.append(a_shape)
+        self._shapes_list = new_shape_list
+
+    def _value_to_compare_statements(self, a_statement):
+        return a_statement.probability
+
+    @staticmethod
+    def _load_class_profile_dict_from_file(source_file):
+        with open(source_file, "r") as in_stream:
+            return json.load(in_stream)
+
+
```

### Comparing `shexer-2.5.1/shexer/core/shexing/strategy/abstract_shexing_strategy.py` & `shexer-2.5.2/shexer/core/shexing/strategy/abstract_shexing_strategy.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,341 +1,341 @@
-from shexer.model.statement import POSITIVE_CLOSURE, KLEENE_CLOSURE, OPT_CARDINALITY
-from shexer.model.IRI import IRI_ELEM_TYPE
-from shexer.model.fixed_prop_choice_statement import FixedPropChoiceStatement
-from shexer.io.shex.formater.statement_serializers.st_serializers_factory import StSerializerFactory
-from shexer.core.shexing.strategy.minimal_iri_strategy.annotate_min_iri_strategy import AnnotateMinIriStrategy
-from shexer.core.shexing.strategy.minimal_iri_strategy.ignore_min_iri_strategy import IgnoreMinIriStrategy
-
-
-_DIRECT_ST_SERIALIZER = 0
-_INVERSE_ST_SERIALIZER = 1
-
-
-class AbstractShexingStrategy(object):
-
-    def __init__(self, class_shexer):
-        self._class_shexer = class_shexer
-        self._namespaces_dict = class_shexer._namespaces_dict
-        self._allow_opt_cardinality = class_shexer._allow_opt_cardinality
-        self._disable_comments = self._class_shexer._disable_comments
-        self._instantiation_property_str = self._class_shexer._instantiation_property_str
-        self._keep_less_specific = self._class_shexer._keep_less_specific
-        self._discard_useless_positive_closures = self._class_shexer._discard_useless_positive_closures
-        self._tolerance = self._class_shexer._tolerance
-        self._disable_or_statements = self._class_shexer._disable_or_statements
-        self._all_compliant_mode = self._class_shexer._all_compliant_mode
-        self._disable_exact_cardinality = self._class_shexer._disable_exact_cardinality
-        self._allow_redundant_or = self._class_shexer._allow_redundant_or
-
-        self._strategy_min_iri = AnnotateMinIriStrategy(class_shexer._class_min_iris_dict) \
-            if class_shexer._detect_minimal_iri \
-            else IgnoreMinIriStrategy()
-
-        self._statement_serializer_factory = StSerializerFactory(freq_mode=class_shexer._instances_report_mode,
-                                                                 decimals=class_shexer._decimals,
-                                                                 instantiation_property_str=self._instantiation_property_str,
-                                                                 disable_comments=self._disable_comments)
-
-
-    def yield_base_shapes(self, acceptance_threshold):
-        for a_shape in self._yield_base_shapes_direction_aware(acceptance_threshold=acceptance_threshold):
-            self._strategy_min_iri.annotate_shape_iri(a_shape)
-            yield a_shape
-
-    def _yield_base_shapes_direction_aware(self, acceptance_threshold):
-        raise NotImplementedError()
-
-    def set_valid_shape_constraints(self, shape):
-        raise NotImplementedError()
-
-    def remove_statements_to_gone_shapes(self, shape, shape_names_to_remove):
-        raise NotImplementedError()
-
-    def _tune_list_of_valid_statements(self, valid_statements):
-        """
-        This method modifies the statements objects received --> no return needed
-        :param valid_statements:
-        :return:
-        """
-        if not len(valid_statements) == 0:
-            valid_statements.sort(reverse=True, key=lambda x: x.probability)  # Restoring order completely
-                                                                              # before changing cardinalities
-
-            if self._all_compliant_mode:
-                self._modify_cardinalities_of_statements_non_compliant_with_all_instances(valid_statements)
-
-            if self._disable_exact_cardinality:
-                self._generalize_exact_cardinalities(valid_statements)
-
-            if self._disable_comments:
-                self._remove_comments_from_statements(valid_statements)
-
-    def _select_valid_statements_of_shape(self, original_statements):
-        if len(original_statements) == 0:
-            return []
-
-        for a_statement in original_statements:  # TODO Refactor!!! This is not the place to set the serializer
-            self._set_serializer_object_for_statements(a_statement)
-
-        result = self._group_constraints_with_same_prop_and_obj(original_statements)
-        result = self._group_IRI_constraints(result)
-
-        return result
-
-    def _compute_frequency(self, number_of_instances, n_ocurrences_statement):
-        return float(n_ocurrences_statement) / number_of_instances
-
-    def _modify_cardinalities_of_statements_non_compliant_with_all_instances(self, statements):
-        for a_statement in statements:
-            if a_statement.probability != 1:
-                self._change_statement_cardinality_to_all_compliant(a_statement)
-
-    def _change_statement_cardinality_to_all_compliant(self, statement):
-        comment_for_current_sentence = self._turn_statement_into_comment(statement)
-        statement.add_comment(comment=comment_for_current_sentence,
-                              insert_first=True)
-        statement.cardinality = OPT_CARDINALITY if \
-            self._allow_opt_cardinality and statement.cardinality == 1 \
-            else KLEENE_CLOSURE
-        statement.probability = 1
-
-    def _turn_statement_into_comment(self, a_statement):
-        return a_statement.comment_representation(namespaces_dict=self._namespaces_dict)
-
-    def _generalize_exact_cardinalities(self, statements):
-        for a_statement in statements:
-            if type(a_statement.cardinality) == int and a_statement.cardinality > 1:
-                a_statement.cardinality = POSITIVE_CLOSURE
-
-    def _remove_comments_from_statements(self, valid_statements):
-        for a_statement in valid_statements:
-            a_statement.remove_comments()
-
-    def _set_serializer_object_for_statements(self, statement):
-        statement.serializer_object = self._statement_serializer_factory.get_base_serializer(
-            is_inverse=statement.is_inverse
-        )
-
-    def _group_constraints_with_same_prop_and_obj(self, candidate_statements):
-        result = []
-        already_visited = set()
-        for i in range(0, len(candidate_statements)):
-            a_statement = candidate_statements[i]
-            if a_statement not in already_visited:
-                already_visited.add(a_statement)
-                group_to_decide = [a_statement]
-                for j in range(i + 1, len(candidate_statements)):
-                    if self._statements_have_same_tokens(a_statement,
-                                                         candidate_statements[j]):
-                        group_to_decide.append(candidate_statements[j])
-                        already_visited.add(candidate_statements[j])
-                if len(group_to_decide) == 1:
-                    result.append(a_statement)
-                else:
-                    result.append(self._decide_best_statement_with_cardinalities_in_comments(group_to_decide))
-        return result
-
-    def _statements_have_same_tokens(self, st1, st2):
-        if st1.st_property == st2.st_property and st1.st_type == st2.st_type:
-            return True
-        return False
-
-    def _decide_best_statement_with_cardinalities_in_comments(self, list_of_candidate_statements):
-        if self._discard_useless_positive_closures:
-            if self._is_a_group_of_statements_with_useless_positive_closure(list_of_candidate_statements):
-                return self._statement_for_a_group_with_a_useless_positive_closure(list_of_candidate_statements)
-        list_of_candidate_statements.sort(reverse=True, key=lambda x: x.probability)
-        result = None
-        if self._keep_less_specific:
-            for a_statement in list_of_candidate_statements:
-                if a_statement.cardinality == POSITIVE_CLOSURE:
-                    result = a_statement
-                    break
-            if result is None:
-                result = list_of_candidate_statements[0]
-        else:
-            for a_statement in list_of_candidate_statements:
-                if a_statement.cardinality != POSITIVE_CLOSURE:
-                    result = a_statement
-                    break
-            if result is None:
-                result = list_of_candidate_statements[0]
-
-        for a_statement in list_of_candidate_statements:
-            if a_statement.cardinality != result.cardinality:
-                result.add_comment(self._turn_statement_into_comment(a_statement))
-        return result
-
-    def _is_a_group_of_statements_with_useless_positive_closure(self, list_of_candidate_sentences):
-        if len(list_of_candidate_sentences) != 2:
-            return False
-        if abs(list_of_candidate_sentences[0].probability - list_of_candidate_sentences[1].probability) > self._tolerance:
-            return False
-        one_if_there_is_a_single_positive_closure = -1
-        for a_statement in list_of_candidate_sentences:
-            if POSITIVE_CLOSURE == a_statement.cardinality:
-                one_if_there_is_a_single_positive_closure *= -1
-        if one_if_there_is_a_single_positive_closure == 1:
-            return True
-        return False
-
-    def _statement_for_a_group_with_a_useless_positive_closure(self, group_of_candidate_statements):
-        for a_statement in group_of_candidate_statements:
-            if a_statement.cardinality != POSITIVE_CLOSURE:
-                return a_statement
-        raise ValueError("The received group does not contain any statement with positive closure")
-
-    def _group_IRI_constraints(self, candidate_statements):
-        result = []
-        already_visited = set()
-        for i in range(0, len(candidate_statements)):
-            a_statement = candidate_statements[i]
-            if a_statement.st_property == self._instantiation_property_str:
-                result.append(a_statement)
-                already_visited.add(a_statement)
-            else:  # a_statement.st_property != self._instantiation_property_str:
-                if a_statement not in already_visited:
-                    already_visited.add(a_statement)
-                    group_to_decide = [a_statement]
-
-                    for j in range(i + 1, len(candidate_statements)):
-                        if self._statements_have_same_prop(a_statement,
-                                                           candidate_statements[j]):
-                            group_to_decide.append(candidate_statements[j])
-                            already_visited.add(candidate_statements[j])
-                    if len(group_to_decide) == 1:
-                        result.append(a_statement)
-                    else:  # At this point, group_to_decide may contain a list of constraints with the same property and
-                           # different node constraint
-                        if self._disable_or_statements:
-                            for a_sentence in self._manage_group_to_decide_without_or(group_to_decide):
-                                result.append(a_sentence)
-                        else:
-                            for a_sentence in self._manage_group_to_decide_with_or(group_to_decide):
-                                result.append(a_sentence)
-
-        return result
-
-    def _statements_have_same_prop(self, st1, st2):
-        if st1.st_property == st2.st_property:
-            return True
-        return False
-
-    def _manage_group_to_decide_without_or(self, group_to_decide):
-        """
-        At this point, the candidate sentences can sahere prop, but no obj.
-        This is, every sentence in group_to_decide has an unique obj.
-
-        if len(group_to_decide) > 2 --> IRI should be picked, everything else to comments.
-        if len(group_to_decide) == 2 --> IRI if it has higher trustworthiness, the specific obj otherwhise
-
-        :param group_to_decide:
-        :return:
-        """
-        result = []
-        to_compose = []
-        for a_statement in group_to_decide:
-            if self._is_an_IRI(a_statement.st_type):
-                to_compose.append(a_statement)
-            else:
-                result.append(a_statement)
-        to_compose.sort(reverse=True, key=lambda x: x.probability)
-        target_sentence = self._get_IRI_statement_in_group(to_compose)  # May be None
-        self._remove_IRI_statements_if_useles(group_of_statements=to_compose)
-        if len(to_compose) > 1:
-            for a_statement in to_compose:
-                if a_statement.st_type != IRI_ELEM_TYPE:
-                    target_sentence.add_comment(self._turn_statement_into_comment(a_statement))
-            result.append(target_sentence)
-        elif len(to_compose) == 1:
-            result.append(to_compose[0])
-        # else  # No sentences to join
-
-        return result
-
-    def _manage_group_to_decide_with_or(self, group_to_decide):
-        if not self._group_contains_IRI_statements(group_to_decide):
-            for a_statement in group_to_decide:
-                yield a_statement
-        else:
-            for a_new_statement in self._compose_statements_with_IRI_objects(group_to_decide):
-                yield a_new_statement
-
-    def _is_an_IRI(self, statement_type):
-        return statement_type == IRI_ELEM_TYPE or statement_type.startswith("@")  # TODO careful here. Refactor
-
-
-    def _remove_IRI_statements_if_useles(self, group_of_statements):
-        # I am assuming a group of statements sorted by probability as param
-        if len(group_of_statements) <= 1:
-            return False
-        index_of_IRI_statement = -1
-        for i in range(0, len(group_of_statements)):
-            if group_of_statements[i].st_type == IRI_ELEM_TYPE:
-                index_of_IRI_statement = i
-                break
-        if index_of_IRI_statement != -1:
-            if group_of_statements[1].probability == group_of_statements[index_of_IRI_statement].probability:
-                # the previous 'if' works, trust me, im an engineer
-                del group_of_statements[index_of_IRI_statement]
-                return True
-        return False
-
-    def _group_contains_IRI_statements(self, list_of_candidate_statements):
-        for a_statement in list_of_candidate_statements:
-            if a_statement.st_type == IRI_ELEM_TYPE:
-                return True
-        return False
-
-    def _compose_statements_with_IRI_objects(self, list_of_candidate_statements):
-        result = []
-        to_compose = []
-        for a_statement in list_of_candidate_statements:
-            if self._is_an_IRI(a_statement.st_type):
-                to_compose.append(a_statement)
-            else:
-                result.append(a_statement)
-        to_compose.sort(reverse=True, key=lambda x: x.probability)
-        # target_probability = self._get_probability_of_IRI_statement_in_group(to_compose)
-        iri_statement = self._get_IRI_statement_in_group(to_compose)
-        was_removed_IRI = self._remove_IRI_statements_if_useles(to_compose)
-        if not was_removed_IRI and not self._allow_redundant_or:  # The IRI macro is still there
-            return [a_sentence for a_sentence in self._manage_group_to_decide_without_or(to_compose)] + result
-        elif len(to_compose) > 1:  # There are some sentences to join in an OR and no IRI macro
-            composed_statement = FixedPropChoiceStatement(
-                st_property=to_compose[0].st_property,
-                st_types=[a_statement.st_type for a_statement in to_compose],
-                cardinality=POSITIVE_CLOSURE,
-                probability=iri_statement.probability,
-                n_occurences=iri_statement.n_occurences,
-                serializer_object=self._statement_serializer_factory.get_choice_serializer(
-                    is_inverse=to_compose[0].is_inverse
-                ),
-                is_inverse=to_compose[0].is_inverse
-            )
-            for a_statement in to_compose:
-                if a_statement.st_type != IRI_ELEM_TYPE:
-                    composed_statement.add_comment(self._turn_statement_into_comment(a_statement))
-            result.append(composed_statement)
-        elif len(to_compose) == 1:  # There is just one sentence in the group to join with OR
-            result.append(to_compose[0])
-        # else  # No sentences to join
-        return result
-
-    # def _get_probability_of_IRI_statement_in_group(self, group_of_statements):
-    #     for a_statement in group_of_statements:
-    #         if a_statement.st_type == IRI_ELEM_TYPE:
-    #             return a_statement.probability
-    #     raise ValueError("There is no IRI statement within the received group")
-
-    def _get_IRI_statement_in_group(self, group_of_statements):
-        for a_statement in group_of_statements:
-            if a_statement.st_type == IRI_ELEM_TYPE:
-                return a_statement
-        return None
-
-    def _statements_without_shapes_to_remove(self, original_statements, shape_names_to_remove):
-        new_statements = []
-        for a_statement in original_statements:
-            if not a_statement.st_type in shape_names_to_remove:
-                new_statements.append(a_statement)
-        return new_statements
+from shexer.model.statement import POSITIVE_CLOSURE, KLEENE_CLOSURE, OPT_CARDINALITY
+from shexer.model.IRI import IRI_ELEM_TYPE
+from shexer.model.fixed_prop_choice_statement import FixedPropChoiceStatement
+from shexer.io.shex.formater.statement_serializers.st_serializers_factory import StSerializerFactory
+from shexer.core.shexing.strategy.minimal_iri_strategy.annotate_min_iri_strategy import AnnotateMinIriStrategy
+from shexer.core.shexing.strategy.minimal_iri_strategy.ignore_min_iri_strategy import IgnoreMinIriStrategy
+
+
+_DIRECT_ST_SERIALIZER = 0
+_INVERSE_ST_SERIALIZER = 1
+
+
+class AbstractShexingStrategy(object):
+
+    def __init__(self, class_shexer):
+        self._class_shexer = class_shexer
+        self._namespaces_dict = class_shexer._namespaces_dict
+        self._allow_opt_cardinality = class_shexer._allow_opt_cardinality
+        self._disable_comments = self._class_shexer._disable_comments
+        self._instantiation_property_str = self._class_shexer._instantiation_property_str
+        self._keep_less_specific = self._class_shexer._keep_less_specific
+        self._discard_useless_positive_closures = self._class_shexer._discard_useless_positive_closures
+        self._tolerance = self._class_shexer._tolerance
+        self._disable_or_statements = self._class_shexer._disable_or_statements
+        self._all_compliant_mode = self._class_shexer._all_compliant_mode
+        self._disable_exact_cardinality = self._class_shexer._disable_exact_cardinality
+        self._allow_redundant_or = self._class_shexer._allow_redundant_or
+
+        self._strategy_min_iri = AnnotateMinIriStrategy(class_shexer._class_min_iris_dict) \
+            if class_shexer._detect_minimal_iri \
+            else IgnoreMinIriStrategy()
+
+        self._statement_serializer_factory = StSerializerFactory(freq_mode=class_shexer._instances_report_mode,
+                                                                 decimals=class_shexer._decimals,
+                                                                 instantiation_property_str=self._instantiation_property_str,
+                                                                 disable_comments=self._disable_comments)
+
+
+    def yield_base_shapes(self, acceptance_threshold):
+        for a_shape in self._yield_base_shapes_direction_aware(acceptance_threshold=acceptance_threshold):
+            self._strategy_min_iri.annotate_shape_iri(a_shape)
+            yield a_shape
+
+    def _yield_base_shapes_direction_aware(self, acceptance_threshold):
+        raise NotImplementedError()
+
+    def set_valid_shape_constraints(self, shape):
+        raise NotImplementedError()
+
+    def remove_statements_to_gone_shapes(self, shape, shape_names_to_remove):
+        raise NotImplementedError()
+
+    def _tune_list_of_valid_statements(self, valid_statements):
+        """
+        This method modifies the statements objects received --> no return needed
+        :param valid_statements:
+        :return:
+        """
+        if not len(valid_statements) == 0:
+            valid_statements.sort(reverse=True, key=lambda x: x.probability)  # Restoring order completely
+                                                                              # before changing cardinalities
+
+            if self._all_compliant_mode:
+                self._modify_cardinalities_of_statements_non_compliant_with_all_instances(valid_statements)
+
+            if self._disable_exact_cardinality:
+                self._generalize_exact_cardinalities(valid_statements)
+
+            if self._disable_comments:
+                self._remove_comments_from_statements(valid_statements)
+
+    def _select_valid_statements_of_shape(self, original_statements):
+        if len(original_statements) == 0:
+            return []
+
+        for a_statement in original_statements:  # TODO Refactor!!! This is not the place to set the serializer
+            self._set_serializer_object_for_statements(a_statement)
+
+        result = self._group_constraints_with_same_prop_and_obj(original_statements)
+        result = self._group_IRI_constraints(result)
+
+        return result
+
+    def _compute_frequency(self, number_of_instances, n_ocurrences_statement):
+        return float(n_ocurrences_statement) / number_of_instances
+
+    def _modify_cardinalities_of_statements_non_compliant_with_all_instances(self, statements):
+        for a_statement in statements:
+            if a_statement.probability != 1:
+                self._change_statement_cardinality_to_all_compliant(a_statement)
+
+    def _change_statement_cardinality_to_all_compliant(self, statement):
+        comment_for_current_sentence = self._turn_statement_into_comment(statement)
+        statement.add_comment(comment=comment_for_current_sentence,
+                              insert_first=True)
+        statement.cardinality = OPT_CARDINALITY if \
+            self._allow_opt_cardinality and statement.cardinality == 1 \
+            else KLEENE_CLOSURE
+        statement.probability = 1
+
+    def _turn_statement_into_comment(self, a_statement):
+        return a_statement.comment_representation(namespaces_dict=self._namespaces_dict)
+
+    def _generalize_exact_cardinalities(self, statements):
+        for a_statement in statements:
+            if type(a_statement.cardinality) == int and a_statement.cardinality > 1:
+                a_statement.cardinality = POSITIVE_CLOSURE
+
+    def _remove_comments_from_statements(self, valid_statements):
+        for a_statement in valid_statements:
+            a_statement.remove_comments()
+
+    def _set_serializer_object_for_statements(self, statement):
+        statement.serializer_object = self._statement_serializer_factory.get_base_serializer(
+            is_inverse=statement.is_inverse
+        )
+
+    def _group_constraints_with_same_prop_and_obj(self, candidate_statements):
+        result = []
+        already_visited = set()
+        for i in range(0, len(candidate_statements)):
+            a_statement = candidate_statements[i]
+            if a_statement not in already_visited:
+                already_visited.add(a_statement)
+                group_to_decide = [a_statement]
+                for j in range(i + 1, len(candidate_statements)):
+                    if self._statements_have_same_tokens(a_statement,
+                                                         candidate_statements[j]):
+                        group_to_decide.append(candidate_statements[j])
+                        already_visited.add(candidate_statements[j])
+                if len(group_to_decide) == 1:
+                    result.append(a_statement)
+                else:
+                    result.append(self._decide_best_statement_with_cardinalities_in_comments(group_to_decide))
+        return result
+
+    def _statements_have_same_tokens(self, st1, st2):
+        if st1.st_property == st2.st_property and st1.st_type == st2.st_type:
+            return True
+        return False
+
+    def _decide_best_statement_with_cardinalities_in_comments(self, list_of_candidate_statements):
+        if self._discard_useless_positive_closures:
+            if self._is_a_group_of_statements_with_useless_positive_closure(list_of_candidate_statements):
+                return self._statement_for_a_group_with_a_useless_positive_closure(list_of_candidate_statements)
+        list_of_candidate_statements.sort(reverse=True, key=lambda x: x.probability)
+        result = None
+        if self._keep_less_specific:
+            for a_statement in list_of_candidate_statements:
+                if a_statement.cardinality == POSITIVE_CLOSURE:
+                    result = a_statement
+                    break
+            if result is None:
+                result = list_of_candidate_statements[0]
+        else:
+            for a_statement in list_of_candidate_statements:
+                if a_statement.cardinality != POSITIVE_CLOSURE:
+                    result = a_statement
+                    break
+            if result is None:
+                result = list_of_candidate_statements[0]
+
+        for a_statement in list_of_candidate_statements:
+            if a_statement.cardinality != result.cardinality:
+                result.add_comment(self._turn_statement_into_comment(a_statement))
+        return result
+
+    def _is_a_group_of_statements_with_useless_positive_closure(self, list_of_candidate_sentences):
+        if len(list_of_candidate_sentences) != 2:
+            return False
+        if abs(list_of_candidate_sentences[0].probability - list_of_candidate_sentences[1].probability) > self._tolerance:
+            return False
+        one_if_there_is_a_single_positive_closure = -1
+        for a_statement in list_of_candidate_sentences:
+            if POSITIVE_CLOSURE == a_statement.cardinality:
+                one_if_there_is_a_single_positive_closure *= -1
+        if one_if_there_is_a_single_positive_closure == 1:
+            return True
+        return False
+
+    def _statement_for_a_group_with_a_useless_positive_closure(self, group_of_candidate_statements):
+        for a_statement in group_of_candidate_statements:
+            if a_statement.cardinality != POSITIVE_CLOSURE:
+                return a_statement
+        raise ValueError("The received group does not contain any statement with positive closure")
+
+    def _group_IRI_constraints(self, candidate_statements):
+        result = []
+        already_visited = set()
+        for i in range(0, len(candidate_statements)):
+            a_statement = candidate_statements[i]
+            if a_statement.st_property == self._instantiation_property_str:
+                result.append(a_statement)
+                already_visited.add(a_statement)
+            else:  # a_statement.st_property != self._instantiation_property_str:
+                if a_statement not in already_visited:
+                    already_visited.add(a_statement)
+                    group_to_decide = [a_statement]
+
+                    for j in range(i + 1, len(candidate_statements)):
+                        if self._statements_have_same_prop(a_statement,
+                                                           candidate_statements[j]):
+                            group_to_decide.append(candidate_statements[j])
+                            already_visited.add(candidate_statements[j])
+                    if len(group_to_decide) == 1:
+                        result.append(a_statement)
+                    else:  # At this point, group_to_decide may contain a list of constraints with the same property and
+                           # different node constraint
+                        if self._disable_or_statements:
+                            for a_sentence in self._manage_group_to_decide_without_or(group_to_decide):
+                                result.append(a_sentence)
+                        else:
+                            for a_sentence in self._manage_group_to_decide_with_or(group_to_decide):
+                                result.append(a_sentence)
+
+        return result
+
+    def _statements_have_same_prop(self, st1, st2):
+        if st1.st_property == st2.st_property:
+            return True
+        return False
+
+    def _manage_group_to_decide_without_or(self, group_to_decide):
+        """
+        At this point, the candidate sentences can sahere prop, but no obj.
+        This is, every sentence in group_to_decide has an unique obj.
+
+        if len(group_to_decide) > 2 --> IRI should be picked, everything else to comments.
+        if len(group_to_decide) == 2 --> IRI if it has higher trustworthiness, the specific obj otherwhise
+
+        :param group_to_decide:
+        :return:
+        """
+        result = []
+        to_compose = []
+        for a_statement in group_to_decide:
+            if self._is_an_IRI(a_statement.st_type):
+                to_compose.append(a_statement)
+            else:
+                result.append(a_statement)
+        to_compose.sort(reverse=True, key=lambda x: x.probability)
+        target_sentence = self._get_IRI_statement_in_group(to_compose)  # May be None
+        self._remove_IRI_statements_if_useles(group_of_statements=to_compose)
+        if len(to_compose) > 1:
+            for a_statement in to_compose:
+                if a_statement.st_type != IRI_ELEM_TYPE:
+                    target_sentence.add_comment(self._turn_statement_into_comment(a_statement))
+            result.append(target_sentence)
+        elif len(to_compose) == 1:
+            result.append(to_compose[0])
+        # else  # No sentences to join
+
+        return result
+
+    def _manage_group_to_decide_with_or(self, group_to_decide):
+        if not self._group_contains_IRI_statements(group_to_decide):
+            for a_statement in group_to_decide:
+                yield a_statement
+        else:
+            for a_new_statement in self._compose_statements_with_IRI_objects(group_to_decide):
+                yield a_new_statement
+
+    def _is_an_IRI(self, statement_type):
+        return statement_type == IRI_ELEM_TYPE or statement_type.startswith("@")  # TODO careful here. Refactor
+
+
+    def _remove_IRI_statements_if_useles(self, group_of_statements):
+        # I am assuming a group of statements sorted by probability as param
+        if len(group_of_statements) <= 1:
+            return False
+        index_of_IRI_statement = -1
+        for i in range(0, len(group_of_statements)):
+            if group_of_statements[i].st_type == IRI_ELEM_TYPE:
+                index_of_IRI_statement = i
+                break
+        if index_of_IRI_statement != -1:
+            if group_of_statements[1].probability == group_of_statements[index_of_IRI_statement].probability:
+                # the previous 'if' works, trust me, im an engineer
+                del group_of_statements[index_of_IRI_statement]
+                return True
+        return False
+
+    def _group_contains_IRI_statements(self, list_of_candidate_statements):
+        for a_statement in list_of_candidate_statements:
+            if a_statement.st_type == IRI_ELEM_TYPE:
+                return True
+        return False
+
+    def _compose_statements_with_IRI_objects(self, list_of_candidate_statements):
+        result = []
+        to_compose = []
+        for a_statement in list_of_candidate_statements:
+            if self._is_an_IRI(a_statement.st_type):
+                to_compose.append(a_statement)
+            else:
+                result.append(a_statement)
+        to_compose.sort(reverse=True, key=lambda x: x.probability)
+        # target_probability = self._get_probability_of_IRI_statement_in_group(to_compose)
+        iri_statement = self._get_IRI_statement_in_group(to_compose)
+        was_removed_IRI = self._remove_IRI_statements_if_useles(to_compose)
+        if not was_removed_IRI and not self._allow_redundant_or:  # The IRI macro is still there
+            return [a_sentence for a_sentence in self._manage_group_to_decide_without_or(to_compose)] + result
+        elif len(to_compose) > 1:  # There are some sentences to join in an OR and no IRI macro
+            composed_statement = FixedPropChoiceStatement(
+                st_property=to_compose[0].st_property,
+                st_types=[a_statement.st_type for a_statement in to_compose],
+                cardinality=POSITIVE_CLOSURE,
+                probability=iri_statement.probability,
+                n_occurences=iri_statement.n_occurences,
+                serializer_object=self._statement_serializer_factory.get_choice_serializer(
+                    is_inverse=to_compose[0].is_inverse
+                ),
+                is_inverse=to_compose[0].is_inverse
+            )
+            for a_statement in to_compose:
+                if a_statement.st_type != IRI_ELEM_TYPE:
+                    composed_statement.add_comment(self._turn_statement_into_comment(a_statement))
+            result.append(composed_statement)
+        elif len(to_compose) == 1:  # There is just one sentence in the group to join with OR
+            result.append(to_compose[0])
+        # else  # No sentences to join
+        return result
+
+    # def _get_probability_of_IRI_statement_in_group(self, group_of_statements):
+    #     for a_statement in group_of_statements:
+    #         if a_statement.st_type == IRI_ELEM_TYPE:
+    #             return a_statement.probability
+    #     raise ValueError("There is no IRI statement within the received group")
+
+    def _get_IRI_statement_in_group(self, group_of_statements):
+        for a_statement in group_of_statements:
+            if a_statement.st_type == IRI_ELEM_TYPE:
+                return a_statement
+        return None
+
+    def _statements_without_shapes_to_remove(self, original_statements, shape_names_to_remove):
+        new_statements = []
+        for a_statement in original_statements:
+            if not a_statement.st_type in shape_names_to_remove:
+                new_statements.append(a_statement)
+        return new_statements
```

### Comparing `shexer-2.5.1/shexer/core/shexing/strategy/direct_and_inverse_shexing_strategy.py` & `shexer-2.5.2/shexer/core/shexing/strategy/direct_and_inverse_shexing_strategy.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,92 +1,92 @@
-from shexer.core.shexing.strategy.abstract_shexing_strategy import AbstractShexingStrategy
-from shexer.utils.shapes import build_shapes_name_for_class_uri
-from shexer.model.statement import Statement
-from shexer.model.shape import Shape
-
-_POS_FEATURES_DIRECT = 0
-_POS_FEATURES_INVERSE = 1
-
-
-class DirectAndInverseShexingStrategy(AbstractShexingStrategy):
-
-    def __init__(self, class_shexer):
-        super().__init__(class_shexer)
-        self._class_profile_dict = self._class_shexer._class_profile_dict
-        self._shapes_namespace = self._class_shexer._shapes_namespace
-        self._class_counts_dict = self._class_shexer._class_counts_dict
-
-    def remove_statements_to_gone_shapes(self, shape, shape_names_to_remove):
-        shape.direct_statements = self._statements_without_shapes_to_remove(
-            original_statements=shape.direct_statements,
-            shape_names_to_remove=shape_names_to_remove)
-        shape.inverse_statements = self._statements_without_shapes_to_remove(
-            original_statements=shape.inverse_statements,
-            shape_names_to_remove=shape_names_to_remove)
-
-    def _yield_base_shapes_direction_aware(self, acceptance_threshold):
-        for a_class_key in self._class_profile_dict:
-            name = build_shapes_name_for_class_uri(class_uri=a_class_key,
-                                                   shapes_namespace=self._shapes_namespace)
-            number_of_instances = float(self._class_counts_dict[a_class_key])
-
-            direct_statements = self._build_base_direct_statements(acceptance_threshold, a_class_key,
-                                                                   number_of_instances)
-            inverse_statements = self._build_base_inverse_statements(acceptance_threshold=acceptance_threshold,
-                                                                     class_key=a_class_key,
-                                                                     number_of_instances=number_of_instances)
-            yield Shape(name=name,
-                        class_uri=a_class_key,
-                        statements=direct_statements + inverse_statements,
-                        n_instances=int(number_of_instances))
-
-    def set_valid_shape_constraints(self, shape):
-        valid_statements = self._select_valid_statements_of_shape(shape.direct_statements)
-        valid_statements += self._select_valid_statements_of_shape(shape.inverse_statements)
-        self._tune_list_of_valid_statements(valid_statements=valid_statements)
-        shape.statements = valid_statements
-
-    def _build_base_inverse_statements(self, acceptance_threshold, class_key, number_of_instances):
-        result = []
-        for a_prop_key in self._class_profile_dict[class_key][_POS_FEATURES_INVERSE]:
-            for a_type_key in self._class_profile_dict[class_key][_POS_FEATURES_INVERSE][a_prop_key]:
-                for a_cardinality in self._class_profile_dict[class_key][_POS_FEATURES_INVERSE][a_prop_key][a_type_key]:
-                    n_occurences = self._class_profile_dict[class_key][_POS_FEATURES_INVERSE][a_prop_key][a_type_key][a_cardinality]
-                    frequency = self._compute_frequency(number_of_instances,
-                                                        n_occurences)
-                    if frequency >= acceptance_threshold:
-                        result.append(Statement(st_property=a_prop_key,
-                                                st_type=a_type_key,
-                                                cardinality=a_cardinality,
-                                                probability=frequency,
-                                                n_occurences=n_occurences,
-                                                is_inverse=True))
-        return result
-
-    def _build_base_direct_statements(self, acceptance_threshold, class_key, number_of_instances):
-        result = []
-        for a_prop_key in self._class_profile_dict[class_key][_POS_FEATURES_DIRECT]:
-            for a_type_key in self._class_profile_dict[class_key][_POS_FEATURES_DIRECT][a_prop_key]:
-                for a_cardinality in self._class_profile_dict[class_key][_POS_FEATURES_DIRECT][a_prop_key][a_type_key]:
-                    n_occurences = self._class_profile_dict[class_key][_POS_FEATURES_DIRECT][a_prop_key][a_type_key][a_cardinality]
-                    frequency = self._compute_frequency(number_of_instances,
-                                                        n_occurences)
-                    if frequency >= acceptance_threshold:
-                        result.append(Statement(st_property=a_prop_key,
-                                                st_type=a_type_key,
-                                                cardinality=a_cardinality,
-                                                probability=frequency,
-                                                is_inverse=False,
-                                                n_occurences=n_occurences))
-        return result
-
-    # def _set_serializer_object_for_statements(self, statement):
-    #     statement.serializer_object = BaseStatementSerializer(
-    #         instantiation_property_str=self._instantiation_property_str,
-    #         disable_comments=self._disable_comments,
-    #         is_inverse=statement.is_inverse)
-    #
-    # def _get_serializer_for_choice_statement(self):
-    #     return FixedPropChoiceStatementSerializer(
-    #         instantiation_property_str=self._instantiation_property_str,
-    #         disable_comments=self._disable_comments,
-    #         is_inverse=statement.is_inverse)
+from shexer.core.shexing.strategy.abstract_shexing_strategy import AbstractShexingStrategy
+from shexer.utils.shapes import build_shapes_name_for_class_uri
+from shexer.model.statement import Statement
+from shexer.model.shape import Shape
+
+_POS_FEATURES_DIRECT = 0
+_POS_FEATURES_INVERSE = 1
+
+
+class DirectAndInverseShexingStrategy(AbstractShexingStrategy):
+
+    def __init__(self, class_shexer):
+        super().__init__(class_shexer)
+        self._class_profile_dict = self._class_shexer._class_profile_dict
+        self._shapes_namespace = self._class_shexer._shapes_namespace
+        self._class_counts_dict = self._class_shexer._class_counts_dict
+
+    def remove_statements_to_gone_shapes(self, shape, shape_names_to_remove):
+        shape.direct_statements = self._statements_without_shapes_to_remove(
+            original_statements=shape.direct_statements,
+            shape_names_to_remove=shape_names_to_remove)
+        shape.inverse_statements = self._statements_without_shapes_to_remove(
+            original_statements=shape.inverse_statements,
+            shape_names_to_remove=shape_names_to_remove)
+
+    def _yield_base_shapes_direction_aware(self, acceptance_threshold):
+        for a_class_key in self._class_profile_dict:
+            name = build_shapes_name_for_class_uri(class_uri=a_class_key,
+                                                   shapes_namespace=self._shapes_namespace)
+            number_of_instances = float(self._class_counts_dict[a_class_key])
+
+            direct_statements = self._build_base_direct_statements(acceptance_threshold, a_class_key,
+                                                                   number_of_instances)
+            inverse_statements = self._build_base_inverse_statements(acceptance_threshold=acceptance_threshold,
+                                                                     class_key=a_class_key,
+                                                                     number_of_instances=number_of_instances)
+            yield Shape(name=name,
+                        class_uri=a_class_key,
+                        statements=direct_statements + inverse_statements,
+                        n_instances=int(number_of_instances))
+
+    def set_valid_shape_constraints(self, shape):
+        valid_statements = self._select_valid_statements_of_shape(shape.direct_statements)
+        valid_statements += self._select_valid_statements_of_shape(shape.inverse_statements)
+        self._tune_list_of_valid_statements(valid_statements=valid_statements)
+        shape.statements = valid_statements
+
+    def _build_base_inverse_statements(self, acceptance_threshold, class_key, number_of_instances):
+        result = []
+        for a_prop_key in self._class_profile_dict[class_key][_POS_FEATURES_INVERSE]:
+            for a_type_key in self._class_profile_dict[class_key][_POS_FEATURES_INVERSE][a_prop_key]:
+                for a_cardinality in self._class_profile_dict[class_key][_POS_FEATURES_INVERSE][a_prop_key][a_type_key]:
+                    n_occurences = self._class_profile_dict[class_key][_POS_FEATURES_INVERSE][a_prop_key][a_type_key][a_cardinality]
+                    frequency = self._compute_frequency(number_of_instances,
+                                                        n_occurences)
+                    if frequency >= acceptance_threshold:
+                        result.append(Statement(st_property=a_prop_key,
+                                                st_type=a_type_key,
+                                                cardinality=a_cardinality,
+                                                probability=frequency,
+                                                n_occurences=n_occurences,
+                                                is_inverse=True))
+        return result
+
+    def _build_base_direct_statements(self, acceptance_threshold, class_key, number_of_instances):
+        result = []
+        for a_prop_key in self._class_profile_dict[class_key][_POS_FEATURES_DIRECT]:
+            for a_type_key in self._class_profile_dict[class_key][_POS_FEATURES_DIRECT][a_prop_key]:
+                for a_cardinality in self._class_profile_dict[class_key][_POS_FEATURES_DIRECT][a_prop_key][a_type_key]:
+                    n_occurences = self._class_profile_dict[class_key][_POS_FEATURES_DIRECT][a_prop_key][a_type_key][a_cardinality]
+                    frequency = self._compute_frequency(number_of_instances,
+                                                        n_occurences)
+                    if frequency >= acceptance_threshold:
+                        result.append(Statement(st_property=a_prop_key,
+                                                st_type=a_type_key,
+                                                cardinality=a_cardinality,
+                                                probability=frequency,
+                                                is_inverse=False,
+                                                n_occurences=n_occurences))
+        return result
+
+    # def _set_serializer_object_for_statements(self, statement):
+    #     statement.serializer_object = BaseStatementSerializer(
+    #         instantiation_property_str=self._instantiation_property_str,
+    #         disable_comments=self._disable_comments,
+    #         is_inverse=statement.is_inverse)
+    #
+    # def _get_serializer_for_choice_statement(self):
+    #     return FixedPropChoiceStatementSerializer(
+    #         instantiation_property_str=self._instantiation_property_str,
+    #         disable_comments=self._disable_comments,
+    #         is_inverse=statement.is_inverse)
```

### Comparing `shexer-2.5.1/shexer/core/shexing/strategy/direct_shexing_strategy.py` & `shexer-2.5.2/shexer/core/shexing/strategy/direct_shexing_strategy.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,47 +1,47 @@
-from shexer.core.shexing.strategy.abstract_shexing_strategy import AbstractShexingStrategy
-from shexer.utils.shapes import build_shapes_name_for_class_uri
-from shexer.model.statement import Statement
-from shexer.model.shape import Shape
-
-class DirectShexingStrategy(AbstractShexingStrategy):
-
-    def __init__(self, class_shexer):
-        super().__init__(class_shexer)
-        self._class_profile_dict = self._class_shexer._class_profile_dict
-        self._shapes_namespace = self._class_shexer._shapes_namespace
-        self._class_counts_dict = self._class_shexer._class_counts_dict
-
-    def remove_statements_to_gone_shapes(self, shape, shape_names_to_remove):
-        shape.direct_statements = self._statements_without_shapes_to_remove(original_statements=shape.direct_statements,
-                                                                            shape_names_to_remove=shape_names_to_remove)
-
-    def set_valid_shape_constraints(self, shape):
-        valid_statements = self._select_valid_statements_of_shape(shape.direct_statements)
-        self._tune_list_of_valid_statements(valid_statements=valid_statements)
-        shape.statements = valid_statements
-
-
-    def _yield_base_shapes_direction_aware(self, acceptance_threshold):
-        for a_class_key in self._class_profile_dict:
-            name = build_shapes_name_for_class_uri(class_uri=a_class_key,
-                                                   shapes_namespace=self._shapes_namespace)
-            number_of_instances = float(self._class_counts_dict[a_class_key])
-            statements = []
-            for a_prop_key in self._class_profile_dict[a_class_key]:
-                for a_type_key in self._class_profile_dict[a_class_key][a_prop_key]:
-                    for a_cardinality in self._class_profile_dict[a_class_key][a_prop_key][a_type_key]:
-                        n_occurences = self._class_profile_dict[a_class_key][a_prop_key][a_type_key][a_cardinality]
-                        frequency = self._compute_frequency(number_of_instances,
-                                                            n_occurences)
-                        if frequency >= acceptance_threshold:
-                            statements.append(Statement(st_property=a_prop_key,
-                                                        st_type=a_type_key,
-                                                        cardinality=a_cardinality,
-                                                        probability=frequency,
-                                                        n_occurences=n_occurences))
-
-            yield Shape(name=name,
-                        class_uri=a_class_key,
-                        statements=statements,
-                        n_instances=int(number_of_instances))
-
+from shexer.core.shexing.strategy.abstract_shexing_strategy import AbstractShexingStrategy
+from shexer.utils.shapes import build_shapes_name_for_class_uri
+from shexer.model.statement import Statement
+from shexer.model.shape import Shape
+
+class DirectShexingStrategy(AbstractShexingStrategy):
+
+    def __init__(self, class_shexer):
+        super().__init__(class_shexer)
+        self._class_profile_dict = self._class_shexer._class_profile_dict
+        self._shapes_namespace = self._class_shexer._shapes_namespace
+        self._class_counts_dict = self._class_shexer._class_counts_dict
+
+    def remove_statements_to_gone_shapes(self, shape, shape_names_to_remove):
+        shape.direct_statements = self._statements_without_shapes_to_remove(original_statements=shape.direct_statements,
+                                                                            shape_names_to_remove=shape_names_to_remove)
+
+    def set_valid_shape_constraints(self, shape):
+        valid_statements = self._select_valid_statements_of_shape(shape.direct_statements)
+        self._tune_list_of_valid_statements(valid_statements=valid_statements)
+        shape.statements = valid_statements
+
+
+    def _yield_base_shapes_direction_aware(self, acceptance_threshold):
+        for a_class_key in self._class_profile_dict:
+            name = build_shapes_name_for_class_uri(class_uri=a_class_key,
+                                                   shapes_namespace=self._shapes_namespace)
+            number_of_instances = float(self._class_counts_dict[a_class_key])
+            statements = []
+            for a_prop_key in self._class_profile_dict[a_class_key]:
+                for a_type_key in self._class_profile_dict[a_class_key][a_prop_key]:
+                    for a_cardinality in self._class_profile_dict[a_class_key][a_prop_key][a_type_key]:
+                        n_occurences = self._class_profile_dict[a_class_key][a_prop_key][a_type_key][a_cardinality]
+                        frequency = self._compute_frequency(number_of_instances,
+                                                            n_occurences)
+                        if frequency >= acceptance_threshold:
+                            statements.append(Statement(st_property=a_prop_key,
+                                                        st_type=a_type_key,
+                                                        cardinality=a_cardinality,
+                                                        probability=frequency,
+                                                        n_occurences=n_occurences))
+
+            yield Shape(name=name,
+                        class_uri=a_class_key,
+                        statements=statements,
+                        n_instances=int(number_of_instances))
+
```

### Comparing `shexer-2.5.1/shexer/core/shexing/strategy/minimal_iri_strategy/annotate_min_iri_strategy.py` & `shexer-2.5.2/shexer/core/shexing/strategy/minimal_iri_strategy/annotate_min_iri_strategy.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,35 @@
-from shexer.core.shexing.strategy.minimal_iri_strategy.abstract_min_iri_strategy import AbstractMinIriStrategy
-import re
-
-_SEP_CHARS = re.compile("[:/#]")
-
-
-class AnnotateMinIriStrategy(AbstractMinIriStrategy):
-
-    def __init__(self, min_iris_dict):
-        self._min_iris_dict = min_iris_dict
-
-    def annotate_shape_iri(self, shape):
-        self._min_iris_dict.set_shape_min_iri(shape_id=shape.class_uri,
-                                              min_iri=self._determine_suitable_iri_pattern
-                                                  (
-                                                  self._min_iris_dict.shape_min_iri
-                                                      (
-                                                      shape.class_uri
-                                                      )
-                                                  )
-                                              )
-        # shape.iri_pattern = self._determine_suitable_iri_pattern(self._min_iris_dict.shape_min_iri(shape.class_uri))
-        # shape.iri_pattern = self._determine_suitable_iri_pattern(self._min_iris_dict[shape.class_uri])
-
-    def _determine_suitable_iri_pattern(self, longest_common_prefix):
-        backwards_str = longest_common_prefix[::-1]
-        last_sep_char = _SEP_CHARS.search(backwards_str)
-        if last_sep_char is None:
-            return None
-        candidate_min_iri = backwards_str[last_sep_char.start():][::-1]
-        if len(candidate_min_iri) < 3:  # Just too short. Kind of an arbitrary number
-            return None
-        if candidate_min_iri.startswith("http") and len(candidate_min_iri) < 8:  # http:// or https:// + an extra char
-            return None
-        return candidate_min_iri  # Let's say it is a worthy one
+from shexer.core.shexing.strategy.minimal_iri_strategy.abstract_min_iri_strategy import AbstractMinIriStrategy
+import re
+
+_SEP_CHARS = re.compile("[:/#]")
+
+
+class AnnotateMinIriStrategy(AbstractMinIriStrategy):
+
+    def __init__(self, min_iris_dict):
+        self._min_iris_dict = min_iris_dict
+
+    def annotate_shape_iri(self, shape):
+        self._min_iris_dict.set_shape_min_iri(shape_id=shape.class_uri,
+                                              min_iri=self._determine_suitable_iri_pattern
+                                                  (
+                                                  self._min_iris_dict.shape_min_iri
+                                                      (
+                                                      shape.class_uri
+                                                      )
+                                                  )
+                                              )
+        # shape.iri_pattern = self._determine_suitable_iri_pattern(self._min_iris_dict.shape_min_iri(shape.class_uri))
+        # shape.iri_pattern = self._determine_suitable_iri_pattern(self._min_iris_dict[shape.class_uri])
+
+    def _determine_suitable_iri_pattern(self, longest_common_prefix):
+        backwards_str = longest_common_prefix[::-1]
+        last_sep_char = _SEP_CHARS.search(backwards_str)
+        if last_sep_char is None:
+            return None
+        candidate_min_iri = backwards_str[last_sep_char.start():][::-1]
+        if len(candidate_min_iri) < 3:  # Just too short. Kind of an arbitrary number
+            return None
+        if candidate_min_iri.startswith("http") and len(candidate_min_iri) < 8:  # http:// or https:// + an extra char
+            return None
+        return candidate_min_iri  # Let's say it is a worthy one
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/base_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/base_triples_yielder.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,35 +1,35 @@
-
-from shexer.io.line_reader.file_line_reader import FileLineReader
-from shexer.io.line_reader.raw_string_line_reader import RawStringLineReader
-from shexer.io.line_reader.gz_line_reader import GzFileLineReader
-from shexer.io.line_reader.zip_file_line_reader import ZipFileLineReader
-from shexer.io.line_reader.xz_line_reader import XzFileLineReader
-from shexer.utils.obj_references import check_just_one_not_none
-from shexer.consts import ZIP, GZ, XZ
-
-class BaseTriplesYielder(object):
-
-    def __init__(self):
-        pass
-
-    def _decide_line_reader(self, raw_graph, source_file,
-                            compression_mode=None,
-                            zip_base_archive=None):
-        check_just_one_not_none((source_file, "source_file"),
-                                (raw_graph, "raw_graph"))
-        if raw_graph is not None:
-            return RawStringLineReader(raw_string=raw_graph)
-        elif compression_mode is None:
-            return FileLineReader(source_file=source_file)
-        elif compression_mode == GZ:
-            return GzFileLineReader(gz_file=source_file)
-        elif compression_mode == ZIP:
-            return ZipFileLineReader(zip_archive=zip_base_archive,
-                                     zip_target=source_file)
-        elif compression_mode == XZ:
-            return XzFileLineReader(xz_file=source_file)
-        else:
-            raise ValueError("Unsupported compression mode: {}".format(compression_mode))
-
-    def yield_triples(self):
+
+from shexer.io.line_reader.file_line_reader import FileLineReader
+from shexer.io.line_reader.raw_string_line_reader import RawStringLineReader
+from shexer.io.line_reader.gz_line_reader import GzFileLineReader
+from shexer.io.line_reader.zip_file_line_reader import ZipFileLineReader
+from shexer.io.line_reader.xz_line_reader import XzFileLineReader
+from shexer.utils.obj_references import check_just_one_not_none
+from shexer.consts import ZIP, GZ, XZ
+
+class BaseTriplesYielder(object):
+
+    def __init__(self):
+        pass
+
+    def _decide_line_reader(self, raw_graph, source_file,
+                            compression_mode=None,
+                            zip_base_archive=None):
+        check_just_one_not_none((source_file, "source_file"),
+                                (raw_graph, "raw_graph"))
+        if raw_graph is not None:
+            return RawStringLineReader(raw_string=raw_graph)
+        elif compression_mode is None:
+            return FileLineReader(source_file=source_file)
+        elif compression_mode == GZ:
+            return GzFileLineReader(gz_file=source_file)
+        elif compression_mode == ZIP:
+            return ZipFileLineReader(zip_archive=zip_base_archive,
+                                     zip_target=source_file)
+        elif compression_mode == XZ:
+            return XzFileLineReader(xz_file=source_file)
+        else:
+            raise ValueError("Unsupported compression mode: {}".format(compression_mode))
+
+    def yield_triples(self):
         raise NotImplementedError("Implement this method in derived classes")
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/big_ttl_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/big_ttl_triples_yielder.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,407 +1,407 @@
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-from shexer.utils.uri import remove_corners, unprefixize_uri_mandatory
-from shexer.utils.triple_yielders import tune_subj, tune_prop, tune_token
-import re
-
-_OTHER_BLANKS = re.compile("[\r\n\t]")
-_SEVERAL_BLANKS = re.compile("  +")
-_QUOTES_FOR_LITERALS = re.compile('[^\\\]"')
-_INIT_INLINE_COMMENT = re.compile(" #")
-_RDF_TYPE_CONTRACTED = ["a", "rdf:type"]
-_RDF_TYPE_URI = "<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>"
-_BOOLEANS = ["true", "false"]
-_INI_BASE_URIS = ["/", "#"]
-_CLOSURES = [",", ";", "."]
-_S = 0
-_P = 1
-_O = 2
-
-_WAITING_FOR_SUBJ = 0
-_WAITING_FOR_PRED = 1
-_WAITING_FOR_OBJ = 2
-_NOT_WAITING = 4
-
-"""
-TTL parser that yield triples (model objects) without loading the whole graph content in 
-main memory.
-
-WARNING: This parser works with some frequent structural assumptions of turtle files that
-are not part of the standard. You may get unexpected errors or unexpected results dealing
-with files containing lines which represent more than one triple. Also, we assume a totally
-wel--formated input. Bad-formatted may remain undetected and produce wrong triples.
-
-Please, in case you do not need to parse huge files that do not fit in the main memory
-of your computer, use RdflifTriplesYielder instead
-"""
-
-
-class BigTtlTriplesYielder(BaseTriplesYielder):
-
-    def __init__(self, source_file=None, allow_untyped_numbers=True, raw_graph=None,
-                 compression_mode=None, zip_base_archive=None):
-
-        super(BigTtlTriplesYielder, self).__init__()
-        self._source_file = source_file
-        self._raw_graph = raw_graph
-        self._triples_count = 0
-        self._error_triples = 0
-        self._allow_untyped_numbers = allow_untyped_numbers
-        self._compression_mode = compression_mode
-        self._line_reader = self._decide_line_reader(source_file=source_file,
-                                                     raw_graph=raw_graph,
-                                                     compression_mode=compression_mode,
-                                                     zip_base_archive=zip_base_archive)
-        # Support
-        self._prefixes = {}
-        self._base = None
-
-        # To be used while parsing
-        self._state = _WAITING_FOR_SUBJ
-        self._tmp_s = None
-        self._tmp_p = None
-        self._tmp_o = None
-        self._last_triple_jump = None
-
-        self._triple_ready = False
-
-    def yield_triples(self):
-        self._reset_parsing()
-        for a_line in self._line_reader.read_lines():
-            for a_triple in self._process_line_2(a_line):
-                self._triples_count += 1
-                yield (
-                    tune_subj(a_triple[_S],
-                              raise_error_if_no_corners=False),
-                    tune_prop(a_triple[_P],
-                              raise_error_if_no_corners=False),
-                    tune_token(a_triple[_O],
-                               base_namespace=self._base,
-                               allow_untyped_numbers=self._allow_untyped_numbers,
-                               raise_error_if_no_corners=False)
-                )
-            # self._process_line(a_line)
-            # if self._triple_ready:
-            #     self._triples_count += 1
-            #     yield (
-            #         tune_subj(self._tmp_s,
-            #                   raise_error_if_no_corners=False),
-            #         tune_prop(self._tmp_p),
-            #         tune_token(self._tmp_o,
-            #                    base_namespace=self._base,
-            #                    allow_untyped_numbers=self._allow_untyped_numbers,
-            #                    raise_error_if_no_corners=False)
-            #     )
-            #     self._triple_ready = False
-
-
-    def _clean_line(self, str_line):
-        result = _OTHER_BLANKS.sub(" ", str_line)
-        result = _SEVERAL_BLANKS.sub(" ", result)
-        result = result.strip()
-        return result if " #" not in result else self._remove_comments_if_needed(result)
-
-    def _remove_comments_if_needed(self, str_line):
-        """Remove comments in the middle of the line.
-        Lines starting with # wont be erased
-        """
-        if '"' not in str_line:  # Comment mark and no literals, trivial case
-            return str_line[:str_line.find(" #")]
-        # We need to find the begining and end of the literal to avoid erasing
-        # comments within literals (actual content)
-        quotes_indexes = []
-        count_down_quotes = 2
-        for a_match in _QUOTES_FOR_LITERALS.finditer(str_line):
-            quotes_indexes.append(a_match.start(0))
-            count_down_quotes -= 1
-            if count_down_quotes == 0:
-                break
-        for a_match in _INIT_INLINE_COMMENT.finditer(str_line):
-            if a_match.start(0) < quotes_indexes[0] or a_match.start(0) > quotes_indexes[1]:
-                return str_line[:a_match.start(0)]
-        return str_line  # If this point is reached, it means that the potential comments
-                         # are actual content of a string literal
-
-    def _process_line_2(self, str_line):
-        str_line = self._clean_line(str_line)
-        if str_line == "":
-            self._process_empty_line(str_line)
-        elif str_line.startswith("@prefix"):
-            self._process_prefix_line(str_line)
-        elif str_line.startswith("@base"):
-            self._process_base_line(str_line)
-        elif str_line.startswith("#"):
-            self._process_comment_line(str_line)
-        else:
-            for a_triple in self._process_line_with_potential_triples(str_line):
-                yield a_triple
-
-    def _process_line_with_potential_triples(self, a_line):
-        next_token, next_index = self._next_line_token(a_line, 0)
-        while next_token != None:
-            if next_token == ",":
-                yield self._current_triple()
-                self._state = _WAITING_FOR_OBJ
-            elif next_token == ";":
-                yield self._current_triple()
-                self._state = _WAITING_FOR_PRED
-            elif next_token == ".":
-                yield self._current_triple()
-                self._state = _WAITING_FOR_SUBJ
-            else:
-                self._assing_tmp_element_and_promote_state(next_token)
-            next_token, next_index = self._next_line_token(a_line, next_index)
-
-    def _current_triple(self):
-        return self._tmp_s, self._tmp_p, self._tmp_o
-
-    def _assing_tmp_element_and_promote_state(self, token):
-        if self._state == _WAITING_FOR_SUBJ:
-            self._tmp_s = self._parse_elem(token)
-            self._state = _WAITING_FOR_PRED
-        elif self._state == _WAITING_FOR_PRED:
-            self._tmp_p = self._parse_elem(token)
-            self._state = _WAITING_FOR_OBJ
-        elif self._state == _WAITING_FOR_OBJ:
-            self._tmp_o = self._parse_elem(token)
-            self._state = _NOT_WAITING
-        else:
-            raise ValueError("Malformed file. Processing an unexpected token: " + token)
-
-
-    def _next_line_token(self, a_line, start_index):
-        while(start_index < len(a_line) and a_line[start_index] == " "):
-            start_index += 1
-        if start_index >= len(a_line):
-            return None, None
-        if a_line[start_index] in _CLOSURES:
-            return a_line[start_index], start_index + 1
-        elif a_line[start_index] == "<":
-            end_index = a_line.find(">", start_index)
-            return self._parse_cornered_element(cornered_element=a_line[start_index:end_index+1]), end_index + 1
-        elif a_line[start_index] == '"':
-            end_index = self._find_next_quoted_literal_ending(a_line, start_index)
-            return a_line[start_index:end_index+1], end_index + 1
-        else:  # could be a prefixed element, a bnode, a non-string literal... find the next blank anyway
-            end_index = self._find_next_blank(a_line, start_index)
-            return a_line[start_index:end_index], end_index + 1
-
-
-    def _find_next_blank(self, target_str, start_index):
-        pos = target_str.find(" ", start_index)
-        return len(target_str)-1 if pos == -1 else pos
-
-
-    def _find_next_unescaped_quotes(self, target_str, start_index):
-        pos = target_str.find('"', start_index)
-        while pos != -1:
-            if target_str[pos-1] != "\\":
-                return pos  # not escaped
-            # if pos >= 2 and target_str[pos-2] == '\\':
-            #     return pos  # the scape is scaped, so not escaped
-            if self._count_prior_backslashes(an_str=target_str,
-                                             quote_pos=pos) % 2 == 0:
-                return pos # the scape is scaped, so not escaped
-            pos = target_str.find('"', pos+1)
-        if pos == -1:
-            raise ValueError("Is this line malformed? Can`t find quotes matching: " + target_str)
-
-    def _count_prior_backslashes(self, an_str, quote_pos):
-        """
-        We assume that there is at least a backslash at an_str[pos-1], so pos-1 is a non-negative index of an_str
-        """
-        counter = 1
-        quote_pos -= 2
-        while quote_pos >= 0:
-            if an_str[quote_pos] == "\\":
-                counter += 1
-            else:
-                return counter
-            quote_pos -= 1
-        return counter
-
-
-    def _find_next_quoted_literal_ending(self, target_str, start_index):
-        next_quotes = self._find_next_unescaped_quotes(target_str=target_str,
-                                                       start_index=start_index+1)
-        if next_quotes +1 > len(target_str) or target_str[next_quotes + 1] == " ":
-            return next_quotes
-        elif target_str[next_quotes + 1] == "^":
-            return self._find_next_blank(target_str, next_quotes) - 1
-        else:
-            raise ValueError("Malformed literal? It seems like there is a problem of unmatching quotes: " + target_str)
-
-    def _process_line(self, str_line):
-        str_line = self._clean_line(str_line)
-        if str_line == "":
-            self._process_empty_line(str_line)
-        elif '"' in str_line:
-            self._process_line_with_literal(str_line)
-        elif str_line.startswith("@prefix"):
-            self._process_prefix_line(str_line)
-        elif str_line.startswith("@base"):
-            self._process_base_line(str_line)
-        elif str_line.startswith("#"):
-            self._process_comment_line(str_line)
-        elif str_line[-1] in [",", ".", ";"]:
-            if ", " in str_line[:-1]:
-                # If there is a comma in a URI, it can't be followed by a blank
-                self._process_multi_triple_line_commas(str_line)
-            else:
-                self._process_single_triple_line(str_line)
-        elif " " not in str_line:
-            if len(str_line) > 1:  # We are ensuring that this is not a single char, such as "," or "."
-                self._process_isolated_subject(str_line)
-        else:
-            self._process_unknown_line(str_line)
-
-    def _process_line_with_literal(self, line):
-        first_quotes_index = line.find('"')
-        s_o_line = line[:first_quotes_index].strip()
-        s_o_pieces = s_o_line.split(" ")
-        if len(s_o_pieces) == 2:
-            self._tmp_s = self._parse_elem(s_o_pieces[0])
-            self._tmp_p = self._parse_elem(s_o_pieces[1])
-        elif len(s_o_pieces) == 1 and s_o_pieces[0] != "":
-            self._tmp_p = self._parse_elem(s_o_pieces[0])
-        # The last char MUST be in [,.;] since this lines comes stripped.
-        # SO everything between first_quotes_index and line[-1], stripped
-        # should be out target literal (typed or not)
-        self._tmp_o = line[first_quotes_index:-1].rstrip()
-        self._decide_current_triple()
-
-    def _process_prefix_line(self, line):
-        pieces = line.split(" ")
-        prefix = pieces[1] if not pieces[1].endswith(":") else pieces[1][: - 1]
-        base_url = remove_corners(pieces[2])
-        self._prefixes[prefix] = base_url
-
-    def _process_base_line(self, line):
-        pieces = line.split(" ")
-        # base_url = pieces[1] if not pieces[1].endswith(":") else pieces[1][: - 1]
-        # base_url = remove_corners(pieces[2])
-        self._base = remove_corners(pieces[1])
-
-    def _process_comment_line(self, line):
-        pass  # At this point, just ignore it.
-
-    def _process_empty_line(self, line):
-        pass  # At this point, just ignore it.
-
-    def _process_unknown_line(self, line):
-        self._error_triples += 1
-
-
-    def _process_multi_triple_line_commas(self, line):
-        pieces = line.split(" ")
-        index_first_comma = 0
-        for i in range(0, len(pieces)):
-            if pieces[i] == ",":
-                index_first_comma = i
-                break
-        if index_first_comma == 3:
-            self._tmp_s = self._parse_elem(pieces[0])
-            self._tmp_p = self._parse_elem(pieces[1])
-            self._tmp_o = self._parse_elem(pieces[2])
-        elif index_first_comma == 2:
-            self._tmp_p = self._parse_elem(pieces[0])
-            self._tmp_o = self._parse_elem(pieces[1])
-        elif index_first_comma == 1:
-            self._tmp_o = self._parse_elem(pieces[0])
-        # else impossible?
-        self._decide_current_triple()
-
-        for i in range(index_first_comma + 2, len(pieces), 2):
-            self._tmp_o = self._parse_elem(pieces[i - 1])
-            self._decide_current_triple()
-
-    def _process_single_triple_line(self, line):
-        pieces = line.split(" ")
-        if len(pieces) == 4:
-            self._tmp_s = self._parse_elem(pieces[0])
-            self._tmp_p = self._parse_elem(pieces[1])
-            self._tmp_o = self._parse_elem(pieces[2])
-
-        elif len(pieces) == 3:
-            self._tmp_p = self._parse_elem(pieces[0])
-            self._tmp_o = self._parse_elem(pieces[1])
-        elif len(pieces) == 2:
-            self._tmp_o = self._parse_elem(pieces[0])
-        self._decide_current_triple()
-
-    def _process_isolated_subject(self, line):
-        # No splitt. Line is expected to contain a line with no blanks (isolated subject)
-        self._tmp_s = self._parse_elem(line)
-        # No need to decide triple now, incomplete element
-
-    def _decide_current_triple(self):
-        # if self._is_bnode(self._tmp_s):
-        #     self._ignored_triples += 1
-        # elif self._is_bnode(self._tmp_o):
-        #     self._ignored_triples += 1
-        # elif self._is_num_literal(self._tmp_o):
-        #     self._ignored_triples += 1
-        # elif self._is_boolean(self._tmp_o):
-        #     self._ignored_triples += 1
-        # else:
-        self._triple_ready = True
-
-    def _is_boolean(self, raw_element):
-        return True if raw_element in _BOOLEANS else False
-
-    def _is_bnode(self, a_elem):
-        if a_elem[0] == "_":
-            return True
-        return False
-
-    def _is_num_literal(self, elem):
-        try:
-            float(elem)
-            return True
-        except ValueError:
-            return False
-
-    def _parse_elem(self, raw_elem):
-        if raw_elem[0] == "<":
-            return self._parse_cornered_element(raw_elem)
-        elif raw_elem in _RDF_TYPE_CONTRACTED:
-            return _RDF_TYPE_URI
-        elif raw_elem.startswith('"'):  # it's a literal, will be better parsed later
-            return raw_elem
-        elif ":" in raw_elem:
-            if raw_elem.startswith("_:"):
-                return raw_elem
-            return unprefixize_uri_mandatory(target_uri=raw_elem,
-                                             prefix_namespaces_dict=self._prefixes)
-        elif raw_elem in _BOOLEANS or self._is_num_literal(raw_elem):
-            return raw_elem
-            # else?? shouldnt happen, let it break with a nullpoitner
-
-    def _parse_cornered_element(self, cornered_element):
-        if self._base is None:
-            return cornered_element  # There is no base
-        elif cornered_element[1] in _INI_BASE_URIS:
-            return "<" + self._base + cornered_element[2:-1] + ">"
-        elif not cornered_element[1:].startswith("http"):
-            return "<" + self._base + cornered_element[1:-1] + ">"
-        else:
-            return cornered_element  # Nothing to do with base
-
-    @property
-    def yielded_triples(self):
-        return self._triples_count
-
-    @property
-    def error_triples(self):
-        return self._error_triples
-
-    @property
-    def ignored_triples(self):
-        return self._ignored_triples
-
-    def _reset_parsing(self):
-        self._error_triples = 0
-        self._triples_count = 0
-        self._ignored_triples = 0
-        self._state = _WAITING_FOR_SUBJ
-
-
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+from shexer.utils.uri import remove_corners, unprefixize_uri_mandatory
+from shexer.utils.triple_yielders import tune_subj, tune_prop, tune_token
+import re
+
+_OTHER_BLANKS = re.compile("[\r\n\t]")
+_SEVERAL_BLANKS = re.compile("  +")
+_QUOTES_FOR_LITERALS = re.compile('[^\\\]"')
+_INIT_INLINE_COMMENT = re.compile(" #")
+_RDF_TYPE_CONTRACTED = ["a", "rdf:type"]
+_RDF_TYPE_URI = "<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>"
+_BOOLEANS = ["true", "false"]
+_INI_BASE_URIS = ["/", "#"]
+_CLOSURES = [",", ";", "."]
+_S = 0
+_P = 1
+_O = 2
+
+_WAITING_FOR_SUBJ = 0
+_WAITING_FOR_PRED = 1
+_WAITING_FOR_OBJ = 2
+_NOT_WAITING = 4
+
+"""
+TTL parser that yield triples (model objects) without loading the whole graph content in 
+main memory.
+
+WARNING: This parser works with some frequent structural assumptions of turtle files that
+are not part of the standard. You may get unexpected errors or unexpected results dealing
+with files containing lines which represent more than one triple. Also, we assume a totally
+wel--formated input. Bad-formatted may remain undetected and produce wrong triples.
+
+Please, in case you do not need to parse huge files that do not fit in the main memory
+of your computer, use RdflifTriplesYielder instead
+"""
+
+
+class BigTtlTriplesYielder(BaseTriplesYielder):
+
+    def __init__(self, source_file=None, allow_untyped_numbers=True, raw_graph=None,
+                 compression_mode=None, zip_base_archive=None):
+
+        super(BigTtlTriplesYielder, self).__init__()
+        self._source_file = source_file
+        self._raw_graph = raw_graph
+        self._triples_count = 0
+        self._error_triples = 0
+        self._allow_untyped_numbers = allow_untyped_numbers
+        self._compression_mode = compression_mode
+        self._line_reader = self._decide_line_reader(source_file=source_file,
+                                                     raw_graph=raw_graph,
+                                                     compression_mode=compression_mode,
+                                                     zip_base_archive=zip_base_archive)
+        # Support
+        self._prefixes = {}
+        self._base = None
+
+        # To be used while parsing
+        self._state = _WAITING_FOR_SUBJ
+        self._tmp_s = None
+        self._tmp_p = None
+        self._tmp_o = None
+        self._last_triple_jump = None
+
+        self._triple_ready = False
+
+    def yield_triples(self):
+        self._reset_parsing()
+        for a_line in self._line_reader.read_lines():
+            for a_triple in self._process_line_2(a_line):
+                self._triples_count += 1
+                yield (
+                    tune_subj(a_triple[_S],
+                              raise_error_if_no_corners=False),
+                    tune_prop(a_triple[_P],
+                              raise_error_if_no_corners=False),
+                    tune_token(a_triple[_O],
+                               base_namespace=self._base,
+                               allow_untyped_numbers=self._allow_untyped_numbers,
+                               raise_error_if_no_corners=False)
+                )
+            # self._process_line(a_line)
+            # if self._triple_ready:
+            #     self._triples_count += 1
+            #     yield (
+            #         tune_subj(self._tmp_s,
+            #                   raise_error_if_no_corners=False),
+            #         tune_prop(self._tmp_p),
+            #         tune_token(self._tmp_o,
+            #                    base_namespace=self._base,
+            #                    allow_untyped_numbers=self._allow_untyped_numbers,
+            #                    raise_error_if_no_corners=False)
+            #     )
+            #     self._triple_ready = False
+
+
+    def _clean_line(self, str_line):
+        result = _OTHER_BLANKS.sub(" ", str_line)
+        result = _SEVERAL_BLANKS.sub(" ", result)
+        result = result.strip()
+        return result if " #" not in result else self._remove_comments_if_needed(result)
+
+    def _remove_comments_if_needed(self, str_line):
+        """Remove comments in the middle of the line.
+        Lines starting with # wont be erased
+        """
+        if '"' not in str_line:  # Comment mark and no literals, trivial case
+            return str_line[:str_line.find(" #")]
+        # We need to find the begining and end of the literal to avoid erasing
+        # comments within literals (actual content)
+        quotes_indexes = []
+        count_down_quotes = 2
+        for a_match in _QUOTES_FOR_LITERALS.finditer(str_line):
+            quotes_indexes.append(a_match.start(0))
+            count_down_quotes -= 1
+            if count_down_quotes == 0:
+                break
+        for a_match in _INIT_INLINE_COMMENT.finditer(str_line):
+            if a_match.start(0) < quotes_indexes[0] or a_match.start(0) > quotes_indexes[1]:
+                return str_line[:a_match.start(0)]
+        return str_line  # If this point is reached, it means that the potential comments
+                         # are actual content of a string literal
+
+    def _process_line_2(self, str_line):
+        str_line = self._clean_line(str_line)
+        if str_line == "":
+            self._process_empty_line(str_line)
+        elif str_line.startswith("@prefix"):
+            self._process_prefix_line(str_line)
+        elif str_line.startswith("@base"):
+            self._process_base_line(str_line)
+        elif str_line.startswith("#"):
+            self._process_comment_line(str_line)
+        else:
+            for a_triple in self._process_line_with_potential_triples(str_line):
+                yield a_triple
+
+    def _process_line_with_potential_triples(self, a_line):
+        next_token, next_index = self._next_line_token(a_line, 0)
+        while next_token != None:
+            if next_token == ",":
+                yield self._current_triple()
+                self._state = _WAITING_FOR_OBJ
+            elif next_token == ";":
+                yield self._current_triple()
+                self._state = _WAITING_FOR_PRED
+            elif next_token == ".":
+                yield self._current_triple()
+                self._state = _WAITING_FOR_SUBJ
+            else:
+                self._assing_tmp_element_and_promote_state(next_token)
+            next_token, next_index = self._next_line_token(a_line, next_index)
+
+    def _current_triple(self):
+        return self._tmp_s, self._tmp_p, self._tmp_o
+
+    def _assing_tmp_element_and_promote_state(self, token):
+        if self._state == _WAITING_FOR_SUBJ:
+            self._tmp_s = self._parse_elem(token)
+            self._state = _WAITING_FOR_PRED
+        elif self._state == _WAITING_FOR_PRED:
+            self._tmp_p = self._parse_elem(token)
+            self._state = _WAITING_FOR_OBJ
+        elif self._state == _WAITING_FOR_OBJ:
+            self._tmp_o = self._parse_elem(token)
+            self._state = _NOT_WAITING
+        else:
+            raise ValueError("Malformed file. Processing an unexpected token: " + token)
+
+
+    def _next_line_token(self, a_line, start_index):
+        while(start_index < len(a_line) and a_line[start_index] == " "):
+            start_index += 1
+        if start_index >= len(a_line):
+            return None, None
+        if a_line[start_index] in _CLOSURES:
+            return a_line[start_index], start_index + 1
+        elif a_line[start_index] == "<":
+            end_index = a_line.find(">", start_index)
+            return self._parse_cornered_element(cornered_element=a_line[start_index:end_index+1]), end_index + 1
+        elif a_line[start_index] == '"':
+            end_index = self._find_next_quoted_literal_ending(a_line, start_index)
+            return a_line[start_index:end_index+1], end_index + 1
+        else:  # could be a prefixed element, a bnode, a non-string literal... find the next blank anyway
+            end_index = self._find_next_blank(a_line, start_index)
+            return a_line[start_index:end_index], end_index + 1
+
+
+    def _find_next_blank(self, target_str, start_index):
+        pos = target_str.find(" ", start_index)
+        return len(target_str)-1 if pos == -1 else pos
+
+
+    def _find_next_unescaped_quotes(self, target_str, start_index):
+        pos = target_str.find('"', start_index)
+        while pos != -1:
+            if target_str[pos-1] != "\\":
+                return pos  # not escaped
+            # if pos >= 2 and target_str[pos-2] == '\\':
+            #     return pos  # the scape is scaped, so not escaped
+            if self._count_prior_backslashes(an_str=target_str,
+                                             quote_pos=pos) % 2 == 0:
+                return pos # the scape is scaped, so not escaped
+            pos = target_str.find('"', pos+1)
+        if pos == -1:
+            raise ValueError("Is this line malformed? Can`t find quotes matching: " + target_str)
+
+    def _count_prior_backslashes(self, an_str, quote_pos):
+        """
+        We assume that there is at least a backslash at an_str[pos-1], so pos-1 is a non-negative index of an_str
+        """
+        counter = 1
+        quote_pos -= 2
+        while quote_pos >= 0:
+            if an_str[quote_pos] == "\\":
+                counter += 1
+            else:
+                return counter
+            quote_pos -= 1
+        return counter
+
+
+    def _find_next_quoted_literal_ending(self, target_str, start_index):
+        next_quotes = self._find_next_unescaped_quotes(target_str=target_str,
+                                                       start_index=start_index+1)
+        if next_quotes +1 > len(target_str) or target_str[next_quotes + 1] == " ":
+            return next_quotes
+        elif target_str[next_quotes + 1] == "^":
+            return self._find_next_blank(target_str, next_quotes) - 1
+        else:
+            raise ValueError("Malformed literal? It seems like there is a problem of unmatching quotes: " + target_str)
+
+    def _process_line(self, str_line):
+        str_line = self._clean_line(str_line)
+        if str_line == "":
+            self._process_empty_line(str_line)
+        elif '"' in str_line:
+            self._process_line_with_literal(str_line)
+        elif str_line.startswith("@prefix"):
+            self._process_prefix_line(str_line)
+        elif str_line.startswith("@base"):
+            self._process_base_line(str_line)
+        elif str_line.startswith("#"):
+            self._process_comment_line(str_line)
+        elif str_line[-1] in [",", ".", ";"]:
+            if ", " in str_line[:-1]:
+                # If there is a comma in a URI, it can't be followed by a blank
+                self._process_multi_triple_line_commas(str_line)
+            else:
+                self._process_single_triple_line(str_line)
+        elif " " not in str_line:
+            if len(str_line) > 1:  # We are ensuring that this is not a single char, such as "," or "."
+                self._process_isolated_subject(str_line)
+        else:
+            self._process_unknown_line(str_line)
+
+    def _process_line_with_literal(self, line):
+        first_quotes_index = line.find('"')
+        s_o_line = line[:first_quotes_index].strip()
+        s_o_pieces = s_o_line.split(" ")
+        if len(s_o_pieces) == 2:
+            self._tmp_s = self._parse_elem(s_o_pieces[0])
+            self._tmp_p = self._parse_elem(s_o_pieces[1])
+        elif len(s_o_pieces) == 1 and s_o_pieces[0] != "":
+            self._tmp_p = self._parse_elem(s_o_pieces[0])
+        # The last char MUST be in [,.;] since this lines comes stripped.
+        # SO everything between first_quotes_index and line[-1], stripped
+        # should be out target literal (typed or not)
+        self._tmp_o = line[first_quotes_index:-1].rstrip()
+        self._decide_current_triple()
+
+    def _process_prefix_line(self, line):
+        pieces = line.split(" ")
+        prefix = pieces[1] if not pieces[1].endswith(":") else pieces[1][: - 1]
+        base_url = remove_corners(pieces[2])
+        self._prefixes[prefix] = base_url
+
+    def _process_base_line(self, line):
+        pieces = line.split(" ")
+        # base_url = pieces[1] if not pieces[1].endswith(":") else pieces[1][: - 1]
+        # base_url = remove_corners(pieces[2])
+        self._base = remove_corners(pieces[1])
+
+    def _process_comment_line(self, line):
+        pass  # At this point, just ignore it.
+
+    def _process_empty_line(self, line):
+        pass  # At this point, just ignore it.
+
+    def _process_unknown_line(self, line):
+        self._error_triples += 1
+
+
+    def _process_multi_triple_line_commas(self, line):
+        pieces = line.split(" ")
+        index_first_comma = 0
+        for i in range(0, len(pieces)):
+            if pieces[i] == ",":
+                index_first_comma = i
+                break
+        if index_first_comma == 3:
+            self._tmp_s = self._parse_elem(pieces[0])
+            self._tmp_p = self._parse_elem(pieces[1])
+            self._tmp_o = self._parse_elem(pieces[2])
+        elif index_first_comma == 2:
+            self._tmp_p = self._parse_elem(pieces[0])
+            self._tmp_o = self._parse_elem(pieces[1])
+        elif index_first_comma == 1:
+            self._tmp_o = self._parse_elem(pieces[0])
+        # else impossible?
+        self._decide_current_triple()
+
+        for i in range(index_first_comma + 2, len(pieces), 2):
+            self._tmp_o = self._parse_elem(pieces[i - 1])
+            self._decide_current_triple()
+
+    def _process_single_triple_line(self, line):
+        pieces = line.split(" ")
+        if len(pieces) == 4:
+            self._tmp_s = self._parse_elem(pieces[0])
+            self._tmp_p = self._parse_elem(pieces[1])
+            self._tmp_o = self._parse_elem(pieces[2])
+
+        elif len(pieces) == 3:
+            self._tmp_p = self._parse_elem(pieces[0])
+            self._tmp_o = self._parse_elem(pieces[1])
+        elif len(pieces) == 2:
+            self._tmp_o = self._parse_elem(pieces[0])
+        self._decide_current_triple()
+
+    def _process_isolated_subject(self, line):
+        # No splitt. Line is expected to contain a line with no blanks (isolated subject)
+        self._tmp_s = self._parse_elem(line)
+        # No need to decide triple now, incomplete element
+
+    def _decide_current_triple(self):
+        # if self._is_bnode(self._tmp_s):
+        #     self._ignored_triples += 1
+        # elif self._is_bnode(self._tmp_o):
+        #     self._ignored_triples += 1
+        # elif self._is_num_literal(self._tmp_o):
+        #     self._ignored_triples += 1
+        # elif self._is_boolean(self._tmp_o):
+        #     self._ignored_triples += 1
+        # else:
+        self._triple_ready = True
+
+    def _is_boolean(self, raw_element):
+        return True if raw_element in _BOOLEANS else False
+
+    def _is_bnode(self, a_elem):
+        if a_elem[0] == "_":
+            return True
+        return False
+
+    def _is_num_literal(self, elem):
+        try:
+            float(elem)
+            return True
+        except ValueError:
+            return False
+
+    def _parse_elem(self, raw_elem):
+        if raw_elem[0] == "<":
+            return self._parse_cornered_element(raw_elem)
+        elif raw_elem in _RDF_TYPE_CONTRACTED:
+            return _RDF_TYPE_URI
+        elif raw_elem.startswith('"'):  # it's a literal, will be better parsed later
+            return raw_elem
+        elif ":" in raw_elem:
+            if raw_elem.startswith("_:"):
+                return raw_elem
+            return unprefixize_uri_mandatory(target_uri=raw_elem,
+                                             prefix_namespaces_dict=self._prefixes)
+        elif raw_elem in _BOOLEANS or self._is_num_literal(raw_elem):
+            return raw_elem
+            # else?? shouldnt happen, let it break with a nullpoitner
+
+    def _parse_cornered_element(self, cornered_element):
+        if self._base is None:
+            return cornered_element  # There is no base
+        elif cornered_element[1] in _INI_BASE_URIS:
+            return "<" + self._base + cornered_element[2:-1] + ">"
+        elif not cornered_element[1:].startswith("http"):
+            return "<" + self._base + cornered_element[1:-1] + ">"
+        else:
+            return cornered_element  # Nothing to do with base
+
+    @property
+    def yielded_triples(self):
+        return self._triples_count
+
+    @property
+    def error_triples(self):
+        return self._error_triples
+
+    @property
+    def ignored_triples(self):
+        return self._ignored_triples
+
+    def _reset_parsing(self):
+        self._error_triples = 0
+        self._triples_count = 0
+        self._ignored_triples = 0
+        self._state = _WAITING_FOR_SUBJ
+
+
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/filter/filter_namespaces_triple_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/filter/filter_namespaces_triple_yielder.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,19 +1,19 @@
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-from shexer.utils.triple_yielders import check_if_property_belongs_to_namespace_list
-
-class FilterNamespacesTriplesYielder(BaseTriplesYielder):
-
-    def __init__(self, actual_triple_yielder, namespaces_to_ignore):
-        super().__init__()
-        self._actual_triple_yielder = actual_triple_yielder
-        self._namespaces_to_ignore = namespaces_to_ignore
-
-
-    def yield_triples(self):
-        for a_triple in self._actual_triple_yielder.yield_triples():
-            if self._pass_filters(a_triple):
-                yield a_triple
-
-    def _pass_filters(self, a_triple):
-        return not check_if_property_belongs_to_namespace_list(str_prop=str(a_triple[1]),
-                                                               namespaces=self._namespaces_to_ignore)
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+from shexer.utils.triple_yielders import check_if_property_belongs_to_namespace_list
+
+class FilterNamespacesTriplesYielder(BaseTriplesYielder):
+
+    def __init__(self, actual_triple_yielder, namespaces_to_ignore):
+        super().__init__()
+        self._actual_triple_yielder = actual_triple_yielder
+        self._namespaces_to_ignore = namespaces_to_ignore
+
+
+    def yield_triples(self):
+        for a_triple in self._actual_triple_yielder.yield_triples():
+            if self._pass_filters(a_triple):
+                yield a_triple
+
+    def _pass_filters(self, a_triple):
+        return not check_if_property_belongs_to_namespace_list(str_prop=str(a_triple[1]),
+                                                               namespaces=self._namespaces_to_ignore)
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/multi_big_ttl_files_triple_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/multi_big_ttl_files_triple_yielder.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-
-from shexer.io.graph.yielder.big_ttl_triples_yielder import BigTtlTriplesYielder
-from shexer.io.graph.yielder.multifile_base_triples_yielder import MultifileBaseTripleYielder
-
-
-class MultiBigTtlTriplesYielder(MultifileBaseTripleYielder):
-
-    def __init__(self, list_of_files, allow_untyped_numbers=False, compression_mode=None, zip_base_archive=None):
-        super(MultiBigTtlTriplesYielder, self).__init__(list_of_files=list_of_files,
-                                                        allow_untyped_numbers=allow_untyped_numbers,
-                                                        zip_base_archive=zip_base_archive,
-                                                        compression_mode=compression_mode)
-
-    def _constructor_file_yielder(self, a_source_file, parse_namespaces=False):
-        return BigTtlTriplesYielder(source_file=a_source_file,
-                                    allow_untyped_numbers=self._allow_untyped_numbers,
-                                    compression_mode=self._compression_mode,
-                                    zip_base_archive=self._zip_base_archive)
-
-
-
+
+from shexer.io.graph.yielder.big_ttl_triples_yielder import BigTtlTriplesYielder
+from shexer.io.graph.yielder.multifile_base_triples_yielder import MultifileBaseTripleYielder
+
+
+class MultiBigTtlTriplesYielder(MultifileBaseTripleYielder):
+
+    def __init__(self, list_of_files, allow_untyped_numbers=False, compression_mode=None, zip_base_archive=None):
+        super(MultiBigTtlTriplesYielder, self).__init__(list_of_files=list_of_files,
+                                                        allow_untyped_numbers=allow_untyped_numbers,
+                                                        zip_base_archive=zip_base_archive,
+                                                        compression_mode=compression_mode)
+
+    def _constructor_file_yielder(self, a_source_file, parse_namespaces=False):
+        return BigTtlTriplesYielder(source_file=a_source_file,
+                                    allow_untyped_numbers=self._allow_untyped_numbers,
+                                    compression_mode=self._compression_mode,
+                                    zip_base_archive=self._zip_base_archive)
+
+
+
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/multi_nt_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/multi_tsv_nt_triples_yielder.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,20 +1,20 @@
-from shexer.io.graph.yielder.nt_triples_yielder import NtTriplesYielder
-from shexer.io.graph.yielder.multifile_base_triples_yielder import MultifileBaseTripleYielder
-
-
-class MultiNtTriplesYielder(MultifileBaseTripleYielder):
-
-    def __init__(self, list_of_files,
-                 allow_untyped_numbers=False,
-                 compression_mode=None,
-                 zip_base_archive=None):
-        super(MultiNtTriplesYielder, self).__init__(list_of_files=list_of_files,
-                                                    allow_untyped_numbers=allow_untyped_numbers,
-                                                    compression_mode=compression_mode,
-                                                    zip_base_archive=zip_base_archive)
-
-    def _constructor_file_yielder(self, a_source_file, parse_namespaces=False):
-        return NtTriplesYielder(source_file=a_source_file,
-                                allow_untyped_numbers=self._allow_untyped_numbers,
-                                compression_mode=self._compression_mode,
-                                zip_base_archive=self._zip_base_archive)
+from shexer.io.graph.yielder.tsv_nt_triples_yielder import TsvNtTriplesYielder
+from shexer.io.graph.yielder.multifile_base_triples_yielder import MultifileBaseTripleYielder
+
+
+class MultiTsvNtTriplesYielder(MultifileBaseTripleYielder):
+
+    def __init__(self, list_of_files,
+                 allow_untyped_numbers=False,
+                 compression_mode=None,
+                 zip_base_archive=None):
+        super(MultiTsvNtTriplesYielder, self).__init__(list_of_files=list_of_files,
+                                                       allow_untyped_numbers=allow_untyped_numbers,
+                                                       compression_mode=compression_mode,
+                                                       zip_base_archive=zip_base_archive)
+
+    def _constructor_file_yielder(self, a_source_file, parse_namespaces=False):
+        return TsvNtTriplesYielder(source_file=a_source_file,
+                                   allow_untyped_numbers=self._allow_untyped_numbers,
+                                   compression_mode=self._compression_mode,
+                                   zip_base_archive=self._zip_base_archive)
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/multi_rdflib_triple_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/multi_rdflib_triple_yielder.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-from shexer.io.graph.yielder.multifile_base_triples_yielder import MultifileBaseTripleYielder
-from shexer.io.graph.yielder.rdflib_triple_yielder import RdflibParserTripleYielder
-from shexer.consts import TURTLE
-
-
-class MultiRdfLibTripleYielder(MultifileBaseTripleYielder):
-
-    def __init__(self, list_of_files, input_format=TURTLE, allow_untyped_numbers=False,
-                 namespaces_dict=None, compression_mode=None, zip_archive_file=None):
-        super(MultiRdfLibTripleYielder, self).__init__(list_of_files=list_of_files,
-                                                       allow_untyped_numbers=allow_untyped_numbers)
-
-        self._input_format = input_format
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-        self._compression_mode = compression_mode
-        self._zip_archive_file = zip_archive_file
-
-    def _yield_triples_of_last_yielder(self, parse_namespaces=True):
-        for a_triple in self._last_yielder.yield_triples(parse_namespaces):
-            yield a_triple
-
-    def _constructor_file_yielder(self, a_source_file):
-        return RdflibParserTripleYielder(source=a_source_file,
-                                         allow_untyped_numbers=self._allow_untyped_numbers,
-                                         input_format=self._input_format,
-                                         compression_mode=self._compression_mode,
-                                         zip_archive_file=self._zip_archive_file)
-
-    @property
-    def namespaces(self):
-        return self._namespaces_dict  # TODO This is not entirely correct. But this method will be rarely used
-        # and can have a huge performance cost in case the graphs hadnt been parsed yet
+from shexer.io.graph.yielder.multifile_base_triples_yielder import MultifileBaseTripleYielder
+from shexer.io.graph.yielder.rdflib_triple_yielder import RdflibParserTripleYielder
+from shexer.consts import TURTLE
+
+
+class MultiRdfLibTripleYielder(MultifileBaseTripleYielder):
+
+    def __init__(self, list_of_files, input_format=TURTLE, allow_untyped_numbers=False,
+                 namespaces_dict=None, compression_mode=None, zip_archive_file=None):
+        super(MultiRdfLibTripleYielder, self).__init__(list_of_files=list_of_files,
+                                                       allow_untyped_numbers=allow_untyped_numbers)
+
+        self._input_format = input_format
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+        self._compression_mode = compression_mode
+        self._zip_archive_file = zip_archive_file
+
+    def _yield_triples_of_last_yielder(self, parse_namespaces=True):
+        for a_triple in self._last_yielder.yield_triples(parse_namespaces):
+            yield a_triple
+
+    def _constructor_file_yielder(self, a_source_file):
+        return RdflibParserTripleYielder(source=a_source_file,
+                                         allow_untyped_numbers=self._allow_untyped_numbers,
+                                         input_format=self._input_format,
+                                         compression_mode=self._compression_mode,
+                                         zip_archive_file=self._zip_archive_file)
+
+    @property
+    def namespaces(self):
+        return self._namespaces_dict  # TODO This is not entirely correct. But this method will be rarely used
+        # and can have a huge performance cost in case the graphs hadnt been parsed yet
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/multi_zip_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/multi_zip_triples_yielder.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,40 +1,40 @@
-
-
-
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-
-
-class MultiZipTriplesYielder(BaseTriplesYielder):
-
-    def __init__(self, multiyielders):
-        super().__init__()
-        self._multiyielders = multiyielders
-
-        self._triples_yielded_from_used_yielders = 0
-        self._error_triples_from_used_yielders = 0
-        self._last_yielder = None
-
-        self._current_yielder = None
-
-    def yield_triples(self, parse_namespaces=True):
-        self._reset_count()
-        for a_yielder in self._multiyielders:
-            self._current_yielder = a_yielder
-            for a_triple in a_yielder.yield_triples():
-                yield a_triple
-            self._triples_yielded_from_used_yielders += a_yielder.yielded_triples
-            self._error_triples_from_used_yielders += a_yielder.error_triples
-
-    @property
-    def yielded_triples(self):
-        triples_current_yielder = 0 if self._current_yielder is None else self._current_yielder.yielded_triples
-        return self._triples_yielded_from_used_yielders + triples_current_yielder
-
-    @property
-    def error_triples(self):
-        errors_current_yielder = 0 if self._current_yielder is None else self._current_yielder.error_triples
-        return self._error_triples_from_used_yielders + errors_current_yielder
-
-    def _reset_count(self):
-        self._error_triples_from_used_yielders = 0
-        self._triples_yielded_from_used_yielders = 0
+
+
+
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+
+
+class MultiZipTriplesYielder(BaseTriplesYielder):
+
+    def __init__(self, multiyielders):
+        super().__init__()
+        self._multiyielders = multiyielders
+
+        self._triples_yielded_from_used_yielders = 0
+        self._error_triples_from_used_yielders = 0
+        self._last_yielder = None
+
+        self._current_yielder = None
+
+    def yield_triples(self, parse_namespaces=True):
+        self._reset_count()
+        for a_yielder in self._multiyielders:
+            self._current_yielder = a_yielder
+            for a_triple in a_yielder.yield_triples():
+                yield a_triple
+            self._triples_yielded_from_used_yielders += a_yielder.yielded_triples
+            self._error_triples_from_used_yielders += a_yielder.error_triples
+
+    @property
+    def yielded_triples(self):
+        triples_current_yielder = 0 if self._current_yielder is None else self._current_yielder.yielded_triples
+        return self._triples_yielded_from_used_yielders + triples_current_yielder
+
+    @property
+    def error_triples(self):
+        errors_current_yielder = 0 if self._current_yielder is None else self._current_yielder.error_triples
+        return self._error_triples_from_used_yielders + errors_current_yielder
+
+    def _reset_count(self):
+        self._error_triples_from_used_yielders = 0
+        self._triples_yielded_from_used_yielders = 0
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/multifile_base_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/multifile_base_triples_yielder.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,64 +1,64 @@
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-
-
-class MultifileBaseTripleYielder(BaseTriplesYielder):
-
-    def __init__(self, list_of_files,
-                 namespaces_to_ignore=None,
-                 allow_untyped_numbers=False,
-                 compression_mode=None,
-                 zip_base_archive=None):
-        super(BaseTriplesYielder, self).__init__()
-        self._list_of_files = list_of_files
-        self._namespaces_to_ignore = namespaces_to_ignore
-        self._allow_untyped_numbers = allow_untyped_numbers
-        self._compression_mode = compression_mode
-        self._zip_base_archive = zip_base_archive
-
-        self._triples_yielded_from_used_yielders = 0
-        self._error_triples_from_used_yielders = 0
-        self._last_yielder = None
-
-
-    def yield_triples(self, parse_namespaces=True):
-        self._reset_count()
-        for a_source_file in self._list_of_files:
-            for a_triple in self._yield_triples_of_file(a_source_file, parse_namespaces):
-                yield a_triple
-
-    def _yield_triples_of_file(self, a_source_file, parse_namespaces=False):
-        if self._last_yielder is not None:
-            self._triples_yielded_from_used_yielders += self._last_yielder.yielded_triples
-            self._error_triples_from_used_yielders += self._last_yielder.error_triples
-        self._last_yielder = self._constructor_file_yielder(a_source_file=a_source_file)
-        for a_triple in self._yield_triples_of_last_yielder(parse_namespaces):
-            yield a_triple
-
-    @property
-    def yielded_triples(self):
-        triples_current_yielder = 0 if self._last_yielder is None else self._last_yielder.yielded_triples
-        return self._triples_yielded_from_used_yielders + triples_current_yielder
-
-    @property
-    def error_triples(self):
-        errors_current_yielder = 0 if self._last_yielder is None else self._last_yielder.error_triples
-        return self._error_triples_from_used_yielders  + errors_current_yielder
-
-    def _reset_count(self):
-        self._error_triples_from_used_yielders = 0
-        self._triples_yielded_from_used_yielders = 0
-
-    def _constructor_file_yielder(self, a_source_file):
-        raise NotImplementedError("Implement in derived classes")
-        
-    def _yield_triples_of_last_yielder(self, parse_namespaces=True):
-        """
-        This is a default implementation for every yielrder (most of them) which ignores parse_namespaces
-        :param parse_namespaces:
-        :return:
-        """
-        for a_triple in self._last_yielder.yield_triples():
-            yield a_triple
-
-
-
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+
+
+class MultifileBaseTripleYielder(BaseTriplesYielder):
+
+    def __init__(self, list_of_files,
+                 namespaces_to_ignore=None,
+                 allow_untyped_numbers=False,
+                 compression_mode=None,
+                 zip_base_archive=None):
+        super(BaseTriplesYielder, self).__init__()
+        self._list_of_files = list_of_files
+        self._namespaces_to_ignore = namespaces_to_ignore
+        self._allow_untyped_numbers = allow_untyped_numbers
+        self._compression_mode = compression_mode
+        self._zip_base_archive = zip_base_archive
+
+        self._triples_yielded_from_used_yielders = 0
+        self._error_triples_from_used_yielders = 0
+        self._last_yielder = None
+
+
+    def yield_triples(self, parse_namespaces=True):
+        self._reset_count()
+        for a_source_file in self._list_of_files:
+            for a_triple in self._yield_triples_of_file(a_source_file, parse_namespaces):
+                yield a_triple
+
+    def _yield_triples_of_file(self, a_source_file, parse_namespaces=False):
+        if self._last_yielder is not None:
+            self._triples_yielded_from_used_yielders += self._last_yielder.yielded_triples
+            self._error_triples_from_used_yielders += self._last_yielder.error_triples
+        self._last_yielder = self._constructor_file_yielder(a_source_file=a_source_file)
+        for a_triple in self._yield_triples_of_last_yielder(parse_namespaces):
+            yield a_triple
+
+    @property
+    def yielded_triples(self):
+        triples_current_yielder = 0 if self._last_yielder is None else self._last_yielder.yielded_triples
+        return self._triples_yielded_from_used_yielders + triples_current_yielder
+
+    @property
+    def error_triples(self):
+        errors_current_yielder = 0 if self._last_yielder is None else self._last_yielder.error_triples
+        return self._error_triples_from_used_yielders  + errors_current_yielder
+
+    def _reset_count(self):
+        self._error_triples_from_used_yielders = 0
+        self._triples_yielded_from_used_yielders = 0
+
+    def _constructor_file_yielder(self, a_source_file):
+        raise NotImplementedError("Implement in derived classes")
+        
+    def _yield_triples_of_last_yielder(self, parse_namespaces=True):
+        """
+        This is a default implementation for every yielrder (most of them) which ignores parse_namespaces
+        :param parse_namespaces:
+        :return:
+        """
+        for a_triple in self._last_yielder.yield_triples():
+            yield a_triple
+
+
+
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/nt_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/nt_triples_yielder.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,114 +1,114 @@
-from shexer.utils.log import log_to_error
-from shexer.utils.uri import there_is_arroba_after_last_quotes
-from shexer.utils.triple_yielders import tune_prop, tune_token  # , check_if_property_belongs_to_namespace_list
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-
-
-class NtTriplesYielder(BaseTriplesYielder):
-
-    def __init__(self, source_file=None, allow_untyped_numbers=False, raw_graph=None,
-                 compression_mode=None, zip_base_archive=None):
-
-        super(NtTriplesYielder, self).__init__()
-        self._source_file = source_file
-        self._raw_graph = raw_graph
-        self._triples_count = 0
-        self._error_triples = 0
-        self._allow_untyped_numbers = allow_untyped_numbers
-        self._line_reader = self._decide_line_reader(source_file=source_file,
-                                                     raw_graph=raw_graph,
-                                                     compression_mode=compression_mode,
-                                                     zip_base_archive=zip_base_archive)
-        # The following ones are refs to functions. Im avoiding some comparison here.
-        # self.yield_triples = self._yield_triples_not_excluding_namespaces if namespaces_to_ignore is None \
-        #     else self._yield_triples_excluding_namespaces
-
-    def yield_triples(self):
-        self._reset_count()
-        for a_line in self._line_reader.read_lines():
-            tokens = self._look_for_tokens(a_line.strip())
-            if len(tokens) != 3:
-                self._error_triples += 1
-                log_to_error(msg="This line was discarded: " + a_line,
-                             source=self._source_file)
-            else:
-                yield (tune_token(a_token=tokens[0]),
-                       tune_prop(a_token=tokens[1]),
-                       tune_token(a_token=tokens[2],
-                                  allow_untyped_numbers=self._allow_untyped_numbers))
-                self._triples_count += 1
-
-    def _look_for_tokens(self, str_line):
-        result = []
-        current_first_index = 0
-        while current_first_index != len(str_line):
-            if str_line[current_first_index] == "<":
-                last_index = self._look_for_last_index_of_uri_token(str_line, current_first_index)
-                result.append(str_line[current_first_index:last_index + 1])
-                current_first_index = last_index + 1
-            elif str_line[current_first_index] == '"':
-                last_index = self._look_for_last_index_of_literal_token(str_line, current_first_index)
-                result.append(str_line[current_first_index:last_index + 1])
-                current_first_index = last_index + 1
-            elif str_line[current_first_index] == '_':
-                last_index = self._look_for_last_index_of_bnode_token(str_line, current_first_index)
-                result.append(str_line[current_first_index:last_index + 1])
-                current_first_index = last_index + 1
-            elif str_line[current_first_index] == '.':
-                break
-
-            elif str_line[current_first_index].isnumeric():
-                last_index = self._look_for_last_index_of_unlabelled_number_token(str_line, current_first_index)
-                result.append(str_line[current_first_index:last_index + 1])
-                current_first_index = last_index + 1
-            else:
-                current_first_index += 1
-
-        return result
-
-    def _look_for_last_index_of_uri_token(self, target_str, first_index):
-        target_substring = target_str[first_index:]
-        index_sub = target_substring.find(">")
-        return index_sub + (len(target_str) - len(target_substring))
-
-    def _look_for_last_index_of_bnode_token(self, target_str, first_index):
-        target_substring = target_str[first_index:]
-        index_sub = target_substring.find(" ")
-        return index_sub + (len(target_str) - len(target_substring)) - 1
-
-    def _look_for_last_index_of_unlabelled_number_token(self, target_str, first_index):
-        target_substring = target_str[first_index:]
-        index_sub = target_substring.find(" ")
-        return index_sub + (len(target_str) - len(target_substring)) - 1
-
-    def _look_for_last_index_of_literal_token(self, target_str, first_index):
-        target_substring = target_str[first_index:]
-
-        if there_is_arroba_after_last_quotes(target_substring):  # String labelled with language
-            return target_substring[target_substring.rfind("@"):].find(" ") - 1 + target_str.rfind("@")
-        elif "^^" not in target_substring:  # Not typed
-            success = False
-            index_of_quotes = 1
-            while not success:
-                index_of_second_quotes = target_substring[index_of_quotes + 1:].find('"') + index_of_quotes + 1
-                if target_substring[index_of_second_quotes - 1] != "\\":
-                    success = True
-                elif target_substring[index_of_second_quotes - 2] == "\\":  # Case of escaped slash "\\"
-                    success = True
-                index_of_quotes = index_of_second_quotes
-            return index_of_quotes + (len(target_str) - len(target_substring))
-        else:  # Typed
-            return target_substring[target_substring.find("^^"):].find(" ") - 1 + target_str.find("^^")
-
-    @property
-    def yielded_triples(self):
-        return self._triples_count
-
-    @property
-    def error_triples(self):
-        return self._error_triples
-
-    def _reset_count(self):
-        self._error_triples = 0
-        self._triples_count = 0
-
+from shexer.utils.log import log_to_error
+from shexer.utils.uri import there_is_arroba_after_last_quotes
+from shexer.utils.triple_yielders import tune_prop, tune_token  # , check_if_property_belongs_to_namespace_list
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+
+
+class NtTriplesYielder(BaseTriplesYielder):
+
+    def __init__(self, source_file=None, allow_untyped_numbers=False, raw_graph=None,
+                 compression_mode=None, zip_base_archive=None):
+
+        super(NtTriplesYielder, self).__init__()
+        self._source_file = source_file
+        self._raw_graph = raw_graph
+        self._triples_count = 0
+        self._error_triples = 0
+        self._allow_untyped_numbers = allow_untyped_numbers
+        self._line_reader = self._decide_line_reader(source_file=source_file,
+                                                     raw_graph=raw_graph,
+                                                     compression_mode=compression_mode,
+                                                     zip_base_archive=zip_base_archive)
+        # The following ones are refs to functions. Im avoiding some comparison here.
+        # self.yield_triples = self._yield_triples_not_excluding_namespaces if namespaces_to_ignore is None \
+        #     else self._yield_triples_excluding_namespaces
+
+    def yield_triples(self):
+        self._reset_count()
+        for a_line in self._line_reader.read_lines():
+            tokens = self._look_for_tokens(a_line.strip())
+            if len(tokens) != 3:
+                self._error_triples += 1
+                log_to_error(msg="This line was discarded: " + a_line,
+                             source=self._source_file)
+            else:
+                yield (tune_token(a_token=tokens[0]),
+                       tune_prop(a_token=tokens[1]),
+                       tune_token(a_token=tokens[2],
+                                  allow_untyped_numbers=self._allow_untyped_numbers))
+                self._triples_count += 1
+
+    def _look_for_tokens(self, str_line):
+        result = []
+        current_first_index = 0
+        while current_first_index != len(str_line):
+            if str_line[current_first_index] == "<":
+                last_index = self._look_for_last_index_of_uri_token(str_line, current_first_index)
+                result.append(str_line[current_first_index:last_index + 1])
+                current_first_index = last_index + 1
+            elif str_line[current_first_index] == '"':
+                last_index = self._look_for_last_index_of_literal_token(str_line, current_first_index)
+                result.append(str_line[current_first_index:last_index + 1])
+                current_first_index = last_index + 1
+            elif str_line[current_first_index] == '_':
+                last_index = self._look_for_last_index_of_bnode_token(str_line, current_first_index)
+                result.append(str_line[current_first_index:last_index + 1])
+                current_first_index = last_index + 1
+            elif str_line[current_first_index] == '.':
+                break
+
+            elif str_line[current_first_index].isnumeric():
+                last_index = self._look_for_last_index_of_unlabelled_number_token(str_line, current_first_index)
+                result.append(str_line[current_first_index:last_index + 1])
+                current_first_index = last_index + 1
+            else:
+                current_first_index += 1
+
+        return result
+
+    def _look_for_last_index_of_uri_token(self, target_str, first_index):
+        target_substring = target_str[first_index:]
+        index_sub = target_substring.find(">")
+        return index_sub + (len(target_str) - len(target_substring))
+
+    def _look_for_last_index_of_bnode_token(self, target_str, first_index):
+        target_substring = target_str[first_index:]
+        index_sub = target_substring.find(" ")
+        return index_sub + (len(target_str) - len(target_substring)) - 1
+
+    def _look_for_last_index_of_unlabelled_number_token(self, target_str, first_index):
+        target_substring = target_str[first_index:]
+        index_sub = target_substring.find(" ")
+        return index_sub + (len(target_str) - len(target_substring)) - 1
+
+    def _look_for_last_index_of_literal_token(self, target_str, first_index):
+        target_substring = target_str[first_index:]
+
+        if there_is_arroba_after_last_quotes(target_substring):  # String labelled with language
+            return target_substring[target_substring.rfind("@"):].find(" ") - 1 + target_str.rfind("@")
+        elif "^^" not in target_substring:  # Not typed
+            success = False
+            index_of_quotes = 1
+            while not success:
+                index_of_second_quotes = target_substring[index_of_quotes + 1:].find('"') + index_of_quotes + 1
+                if target_substring[index_of_second_quotes - 1] != "\\":
+                    success = True
+                elif target_substring[index_of_second_quotes - 2] == "\\":  # Case of escaped slash "\\"
+                    success = True
+                index_of_quotes = index_of_second_quotes
+            return index_of_quotes + (len(target_str) - len(target_substring))
+        else:  # Typed
+            return target_substring[target_substring.find("^^"):].find(" ") - 1 + target_str.find("^^")
+
+    @property
+    def yielded_triples(self):
+        return self._triples_count
+
+    @property
+    def error_triples(self):
+        return self._error_triples
+
+    def _reset_count(self):
+        self._error_triples = 0
+        self._triples_count = 0
+
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/rdflib_triple_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/rdflib_triple_yielder.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,171 +1,171 @@
-from rdflib.graph import Graph, URIRef, Literal, BNode
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-from shexer.consts import N3, TURTLE, RDF_XML, NT, JSON_LD, ZIP, GZ, XZ
-
-from shexer.model.Literal import Literal as model_Literal
-from shexer.model.IRI import IRI as model_IRI
-from shexer.model.bnode import BNode as model_BNode
-from shexer.model.property import Property as model_Property
-
-from shexer.utils.uri import decide_literal_type
-from shexer.utils.compression import get_content_gz_file, get_content_zip_internal_file, get_content_xz_file
-
-_SUPPORTED_FORMATS = [N3, TURTLE, RDF_XML, NT, JSON_LD]
-
-_XML_WRONG_URI = "http://www.w3.org/XML/1998/namespace"
-
-
-class RdflibTripleYielder(BaseTriplesYielder):
-    def __init__(self, rdflib_graph, namespaces_dict=None):
-        super().__init__()
-        self._rdflib_graph = rdflib_graph
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-        self._triples_count = 0
-
-        self._prefixes_parsed = False
-
-    def yield_triples(self, parse_namespaces=True):
-        self._reset_count()
-        tmp_graph = self._get_tmp_graph()
-        if parse_namespaces:
-            self._integrate_namespaces_from_parsed_graph(tmp_graph, self._namespaces_dict)
-            self._prefixes_parsed = True
-        for sub, pred, obj in tmp_graph:
-            yield (
-                self._turn_rdflib_token_into_model_obj(sub),
-                self._turn_rdflib_prop_into_model_obj(pred),
-                self._turn_rdflib_token_into_model_obj(obj)
-            )
-            self._triples_count += 1
-
-
-
-    def _turn_rdflib_token_into_model_obj(self, rdflib_obj):
-        if type(rdflib_obj) == URIRef:
-            return model_IRI(str(rdflib_obj))
-        elif type(rdflib_obj) == Literal:
-            return self._turn_into_model_literal(rdflib_obj)
-        elif type(rdflib_obj) == BNode:
-            return model_BNode(identifier=str(rdflib_obj))
-        else:
-            raise ValueError("Not recognized type of rdflib element: " + type(rdflib_obj) + " ( " + str(rdflib_obj) + " )")
-
-    def _turn_rdflib_prop_into_model_obj(self, rdflib_obj):
-        if type(rdflib_obj) == URIRef:
-            return model_Property(str(rdflib_obj))
-        else:
-            raise ValueError("Trying to convert into a model property en element which is not "
-                             "supposed to be a property: " + type(rdflib_obj) + " ( " + str(rdflib_obj) + " )")
-
-    def _get_tmp_graph(self):
-        return self._rdflib_graph
-
-    @staticmethod
-    def _integrate_namespaces_from_parsed_graph(a_graph, namespaces_dict):
-
-        for a_prefix_namespace_tuple in a_graph.namespaces():
-            candidate_uri = str(a_prefix_namespace_tuple[1])
-            if candidate_uri not in namespaces_dict:
-                if candidate_uri == _XML_WRONG_URI:  # XML fix...
-                    candidate_uri += "/"             # XML fix...
-                namespaces_dict[candidate_uri] = str(a_prefix_namespace_tuple[0])
-            # There is no else here. In case of conflict between the parsed content and the dict provided by the user,
-            # the user's one have priority
-
-
-    @staticmethod
-    def _turn_into_model_literal(rdflib_literal):
-        content = str(rdflib_literal)
-        if rdflib_literal.language is not None:
-            content = '"' + content + '"@' + rdflib_literal.language
-        return model_Literal(content=content,
-                             elem_type=str(rdflib_literal.datatype)
-                             if rdflib_literal.datatype is not None
-                             else decide_literal_type(content))
-
-
-    @property
-    def yielded_triples(self):
-        return self._triples_count
-
-    @property
-    def error_triples(self):
-        return 0  # With rdflib, a single error will cause to fail the parsing process
-
-
-    @property
-    def namespaces(self):
-        if not self._prefixes_parsed:
-            tmp_graph = self._get_tmp_graph()
-            self._integrate_namespaces_from_parsed_graph(tmp_graph, self._namespaces_dict)
-            self._prefixes_parsed = True
-        return self._namespaces_dict
-
-
-    def _reset_count(self):
-        self._triples_count = 0
-
-
-class RdflibParserTripleYielder(RdflibTripleYielder):
-
-    def __init__(self, input_format=TURTLE, source=None, allow_untyped_numbers=False, raw_graph=None,
-                 namespaces_dict=None, compression_mode=None, zip_archive_file=None):
-        """
-
-        :param input_format:
-        :param source: It can be local (a file path) or remote (an url to download some content)
-        :param namespaces_to_ignore:
-        :param allow_untyped_numbers:
-        :param raw_graph:
-        :param namespaces_dict:
-        """
-
-        super().__init__(rdflib_graph=None,
-                         namespaces_dict=namespaces_dict)
-        self._check_input_format(input_format)
-        self._input_format = input_format
-        self._source = source
-        self._compression_mode = compression_mode
-        self._zip_archive_file = zip_archive_file
-        self._allow_untyped_numbers = allow_untyped_numbers
-        self._raw_graph = raw_graph
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-                                              # This object can be modified (and will be consumed externaly)
-                                              # when parse_namespaces in yiled_triples() is set to True
-
-        self._triples_count = 0
-
-        self._prefixes_parsed = False
-
-
-    def _get_tmp_graph(self):
-        result = Graph()
-        if self._compression_mode is not None:
-            self._parse_compressed_files(result)
-        elif self._source is not None:
-            result.parse(source=self._source, format=self._input_format)
-        else:
-            result.parse(data=self._raw_graph, format=self._input_format)
-        return result
-
-    def _parse_compressed_files(self, rdflib_graph):
-        if self._compression_mode == GZ:
-            rdflib_graph.parse(data=get_content_gz_file(self._source), format=self._input_format)
-        elif self._compression_mode == ZIP:
-            rdflib_graph.parse(data=get_content_zip_internal_file(base_archive=self._zip_archive_file,
-                                                                  target_file=self._source),
-                               format=self._input_format)
-        elif self._compression_mode == XZ:
-            rdflib_graph.parse(data=get_content_xz_file(self._source), format=self._input_format)
-        else:
-            raise ValueError("Unknown compression format")
-
-    @staticmethod
-    def _check_input_format(input_format):
-        if input_format not in _SUPPORTED_FORMATS:
-            raise ValueError("Unsupported input format: " + input_format)
-
-
-
-
-
+from rdflib.graph import Graph, URIRef, Literal, BNode
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+from shexer.consts import N3, TURTLE, RDF_XML, NT, JSON_LD, ZIP, GZ, XZ
+
+from shexer.model.Literal import Literal as model_Literal
+from shexer.model.IRI import IRI as model_IRI
+from shexer.model.bnode import BNode as model_BNode
+from shexer.model.property import Property as model_Property
+
+from shexer.utils.uri import decide_literal_type
+from shexer.utils.compression import get_content_gz_file, get_content_zip_internal_file, get_content_xz_file
+
+_SUPPORTED_FORMATS = [N3, TURTLE, RDF_XML, NT, JSON_LD]
+
+_XML_WRONG_URI = "http://www.w3.org/XML/1998/namespace"
+
+
+class RdflibTripleYielder(BaseTriplesYielder):
+    def __init__(self, rdflib_graph, namespaces_dict=None):
+        super().__init__()
+        self._rdflib_graph = rdflib_graph
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+        self._triples_count = 0
+
+        self._prefixes_parsed = False
+
+    def yield_triples(self, parse_namespaces=True):
+        self._reset_count()
+        tmp_graph = self._get_tmp_graph()
+        if parse_namespaces:
+            self._integrate_namespaces_from_parsed_graph(tmp_graph, self._namespaces_dict)
+            self._prefixes_parsed = True
+        for sub, pred, obj in tmp_graph:
+            yield (
+                self._turn_rdflib_token_into_model_obj(sub),
+                self._turn_rdflib_prop_into_model_obj(pred),
+                self._turn_rdflib_token_into_model_obj(obj)
+            )
+            self._triples_count += 1
+
+
+
+    def _turn_rdflib_token_into_model_obj(self, rdflib_obj):
+        if type(rdflib_obj) == URIRef:
+            return model_IRI(str(rdflib_obj))
+        elif type(rdflib_obj) == Literal:
+            return self._turn_into_model_literal(rdflib_obj)
+        elif type(rdflib_obj) == BNode:
+            return model_BNode(identifier=str(rdflib_obj))
+        else:
+            raise ValueError("Not recognized type of rdflib element: " + type(rdflib_obj) + " ( " + str(rdflib_obj) + " )")
+
+    def _turn_rdflib_prop_into_model_obj(self, rdflib_obj):
+        if type(rdflib_obj) == URIRef:
+            return model_Property(str(rdflib_obj))
+        else:
+            raise ValueError("Trying to convert into a model property en element which is not "
+                             "supposed to be a property: " + type(rdflib_obj) + " ( " + str(rdflib_obj) + " )")
+
+    def _get_tmp_graph(self):
+        return self._rdflib_graph
+
+    @staticmethod
+    def _integrate_namespaces_from_parsed_graph(a_graph, namespaces_dict):
+
+        for a_prefix_namespace_tuple in a_graph.namespaces():
+            candidate_uri = str(a_prefix_namespace_tuple[1])
+            if candidate_uri not in namespaces_dict:
+                if candidate_uri == _XML_WRONG_URI:  # XML fix...
+                    candidate_uri += "/"             # XML fix...
+                namespaces_dict[candidate_uri] = str(a_prefix_namespace_tuple[0])
+            # There is no else here. In case of conflict between the parsed content and the dict provided by the user,
+            # the user's one have priority
+
+
+    @staticmethod
+    def _turn_into_model_literal(rdflib_literal):
+        content = str(rdflib_literal)
+        if rdflib_literal.language is not None:
+            content = '"' + content + '"@' + rdflib_literal.language
+        return model_Literal(content=content,
+                             elem_type=str(rdflib_literal.datatype)
+                             if rdflib_literal.datatype is not None
+                             else decide_literal_type(content))
+
+
+    @property
+    def yielded_triples(self):
+        return self._triples_count
+
+    @property
+    def error_triples(self):
+        return 0  # With rdflib, a single error will cause to fail the parsing process
+
+
+    @property
+    def namespaces(self):
+        if not self._prefixes_parsed:
+            tmp_graph = self._get_tmp_graph()
+            self._integrate_namespaces_from_parsed_graph(tmp_graph, self._namespaces_dict)
+            self._prefixes_parsed = True
+        return self._namespaces_dict
+
+
+    def _reset_count(self):
+        self._triples_count = 0
+
+
+class RdflibParserTripleYielder(RdflibTripleYielder):
+
+    def __init__(self, input_format=TURTLE, source=None, allow_untyped_numbers=False, raw_graph=None,
+                 namespaces_dict=None, compression_mode=None, zip_archive_file=None):
+        """
+
+        :param input_format:
+        :param source: It can be local (a file path) or remote (an url to download some content)
+        :param namespaces_to_ignore:
+        :param allow_untyped_numbers:
+        :param raw_graph:
+        :param namespaces_dict:
+        """
+
+        super().__init__(rdflib_graph=None,
+                         namespaces_dict=namespaces_dict)
+        self._check_input_format(input_format)
+        self._input_format = input_format
+        self._source = source
+        self._compression_mode = compression_mode
+        self._zip_archive_file = zip_archive_file
+        self._allow_untyped_numbers = allow_untyped_numbers
+        self._raw_graph = raw_graph
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+                                              # This object can be modified (and will be consumed externaly)
+                                              # when parse_namespaces in yiled_triples() is set to True
+
+        self._triples_count = 0
+
+        self._prefixes_parsed = False
+
+
+    def _get_tmp_graph(self):
+        result = Graph()
+        if self._compression_mode is not None:
+            self._parse_compressed_files(result)
+        elif self._source is not None:
+            result.parse(source=self._source, format=self._input_format)
+        else:
+            result.parse(data=self._raw_graph, format=self._input_format)
+        return result
+
+    def _parse_compressed_files(self, rdflib_graph):
+        if self._compression_mode == GZ:
+            rdflib_graph.parse(data=get_content_gz_file(self._source), format=self._input_format)
+        elif self._compression_mode == ZIP:
+            rdflib_graph.parse(data=get_content_zip_internal_file(base_archive=self._zip_archive_file,
+                                                                  target_file=self._source),
+                               format=self._input_format)
+        elif self._compression_mode == XZ:
+            rdflib_graph.parse(data=get_content_xz_file(self._source), format=self._input_format)
+        else:
+            raise ValueError("Unknown compression format")
+
+    @staticmethod
+    def _check_input_format(input_format):
+        if input_format not in _SUPPORTED_FORMATS:
+            raise ValueError("Unsupported input format: " + input_format)
+
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/remote/sgraph_from_selectors_triple_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/remote/sgraph_from_selectors_triple_yielder.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,75 +1,75 @@
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-from shexer.consts import RDF_TYPE
-from shexer.utils.triple_yielders import tune_token, tune_prop, tune_subj
-from shexer.utils.uri import add_corners_if_needed, add_corners_if_it_is_an_uri
-
-
-class SgraphFromSelectorsTripleYielder(BaseTriplesYielder):
-
-    def __init__(self, shape_map, depth=1, classes_at_last_level=True, instantiation_property=RDF_TYPE,
-                 strict_syntax_with_corners=False, allow_untyped_numbers=False, inverse_paths=False):
-        super().__init__()
-        self._shape_map = shape_map
-        self._depth = depth
-        self._classes_at_last_level = classes_at_last_level
-        self._instantiation_property = instantiation_property
-        self._strict_syntax_with_corners = strict_syntax_with_corners
-        self._allow_untyped_numbers = allow_untyped_numbers
-        self._inverse_paths = inverse_paths
-
-
-    def yield_triples(self):
-        target_nodes = self._collect_every_target_node()
-        sgraph = self._shape_map.get_sgraph()
-        for a_triple in self._yield_relevant_sgraph_triples(target_nodes, sgraph):
-            yield a_triple
-
-
-    def _collect_every_target_node(self):
-        result = set()
-        for an_item in self._shape_map.yield_items():
-            for a_node in an_item.node_selector.get_target_nodes():
-                result.add(a_node)
-        return list(result)
-
-
-    def _yield_relevant_sgraph_triples(self, target_nodes, sgraph):
-        for a_triple in self._yield_relevant_direct_triples(target_nodes, sgraph):
-            yield a_triple
-        if self._inverse_paths:
-            for a_triple in self._yield_relevant_inverse_triples(target_nodes, sgraph):
-                yield a_triple
-
-    def _yield_relevant_direct_triples(self, target_nodes, sgraph):
-        for s, p, o in sgraph.yield_p_o_triples_of_target_nodes(target_nodes=target_nodes,
-                                                                depth=self._depth,
-                                                                classes_at_last_level=self._classes_at_last_level,
-                                                                instantiation_property=self._instantiation_property,
-                                                                already_visited=None,
-                                                                strict_syntax_with_uri_corners=self._strict_syntax_with_corners):
-            yield (tune_subj(a_token=add_corners_if_it_is_an_uri(s)),
-                   tune_prop(a_token=add_corners_if_needed(p)),
-                   tune_token(a_token=add_corners_if_it_is_an_uri(o),
-                              allow_untyped_numbers=self._allow_untyped_numbers)
-                   )
-
-    def _yield_relevant_inverse_triples(self, target_nodes, sgraph):
-        for s, p, o in sgraph.yield_s_p_triples_of_target_nodes(target_nodes=target_nodes,
-                                                                depth=self._depth,
-                                                                classes_at_last_level=self._classes_at_last_level,
-                                                                instantiation_property=self._instantiation_property,
-                                                                already_visited=None,
-                                                                strict_syntax_with_uri_corners=self._strict_syntax_with_corners):
-            yield (tune_subj(a_token=add_corners_if_it_is_an_uri(s)),
-                   tune_prop(a_token=add_corners_if_needed(p)),
-                   tune_token(a_token=add_corners_if_it_is_an_uri(o),
-                              allow_untyped_numbers=self._allow_untyped_numbers)
-                   )
-
-
-
-
-
-
-
-
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+from shexer.consts import RDF_TYPE
+from shexer.utils.triple_yielders import tune_token, tune_prop, tune_subj
+from shexer.utils.uri import add_corners_if_needed, add_corners_if_it_is_an_uri
+
+
+class SgraphFromSelectorsTripleYielder(BaseTriplesYielder):
+
+    def __init__(self, shape_map, depth=1, classes_at_last_level=True, instantiation_property=RDF_TYPE,
+                 strict_syntax_with_corners=False, allow_untyped_numbers=False, inverse_paths=False):
+        super().__init__()
+        self._shape_map = shape_map
+        self._depth = depth
+        self._classes_at_last_level = classes_at_last_level
+        self._instantiation_property = instantiation_property
+        self._strict_syntax_with_corners = strict_syntax_with_corners
+        self._allow_untyped_numbers = allow_untyped_numbers
+        self._inverse_paths = inverse_paths
+
+
+    def yield_triples(self):
+        target_nodes = self._collect_every_target_node()
+        sgraph = self._shape_map.get_sgraph()
+        for a_triple in self._yield_relevant_sgraph_triples(target_nodes, sgraph):
+            yield a_triple
+
+
+    def _collect_every_target_node(self):
+        result = set()
+        for an_item in self._shape_map.yield_items():
+            for a_node in an_item.node_selector.get_target_nodes():
+                result.add(a_node)
+        return list(result)
+
+
+    def _yield_relevant_sgraph_triples(self, target_nodes, sgraph):
+        for a_triple in self._yield_relevant_direct_triples(target_nodes, sgraph):
+            yield a_triple
+        if self._inverse_paths:
+            for a_triple in self._yield_relevant_inverse_triples(target_nodes, sgraph):
+                yield a_triple
+
+    def _yield_relevant_direct_triples(self, target_nodes, sgraph):
+        for s, p, o in sgraph.yield_p_o_triples_of_target_nodes(target_nodes=target_nodes,
+                                                                depth=self._depth,
+                                                                classes_at_last_level=self._classes_at_last_level,
+                                                                instantiation_property=self._instantiation_property,
+                                                                already_visited=None,
+                                                                strict_syntax_with_uri_corners=self._strict_syntax_with_corners):
+            yield (tune_subj(a_token=add_corners_if_it_is_an_uri(s)),
+                   tune_prop(a_token=add_corners_if_needed(p)),
+                   tune_token(a_token=add_corners_if_it_is_an_uri(o),
+                              allow_untyped_numbers=self._allow_untyped_numbers)
+                   )
+
+    def _yield_relevant_inverse_triples(self, target_nodes, sgraph):
+        for s, p, o in sgraph.yield_s_p_triples_of_target_nodes(target_nodes=target_nodes,
+                                                                depth=self._depth,
+                                                                classes_at_last_level=self._classes_at_last_level,
+                                                                instantiation_property=self._instantiation_property,
+                                                                already_visited=None,
+                                                                strict_syntax_with_uri_corners=self._strict_syntax_with_corners):
+            yield (tune_subj(a_token=add_corners_if_it_is_an_uri(s)),
+                   tune_prop(a_token=add_corners_if_needed(p)),
+                   tune_token(a_token=add_corners_if_it_is_an_uri(o),
+                              allow_untyped_numbers=self._allow_untyped_numbers)
+                   )
+
+
+
+
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer/io/graph/yielder/tsv_nt_triples_yielder.py` & `shexer-2.5.2/shexer/io/graph/yielder/tsv_nt_triples_yielder.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,100 +1,100 @@
-
-from shexer.utils.log import log_to_error
-from shexer.utils.triple_yielders import tune_token, tune_prop
-from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
-
-
-class TsvNtTriplesYielder(BaseTriplesYielder):
-
-    def __init__(self, source_file, allow_untyped_numbers=False, raw_graph=None,
-                 compression_mode=None, zip_base_archive=None):
-        super(TsvNtTriplesYielder, self).__init__()
-        self._source_file = source_file
-        self._triples_count = 0
-        self._error_triples = 0
-        self._allow_untyped_numbers = allow_untyped_numbers
-        self._line_reader = self._decide_line_reader(source_file=source_file,
-                                                     raw_graph=raw_graph,
-                                                     compression_mode=compression_mode,
-                                                     zip_base_archive=zip_base_archive)
-        # self.yield_triples = self._yield_triples_not_excluding_namespaces if namespaces_to_ignore is None\
-        #     else self._yield_triples_excluding_namespaces
-
-
-    def yield_triples(self):
-        self._reset_count()
-        for a_line in self._line_reader.read_lines():
-            tokens = self._look_for_tokens(a_line.strip())
-            if len(tokens) != 3:
-                self._error_triples += 1
-                log_to_error(msg="This line caused error: " + a_line,
-                             source=self._source_file)
-            else:
-                try:
-                    yield (
-                    tune_token(tokens[0]), tune_prop(tokens[1]), tune_token(tokens[2], allow_untyped_numbers=True))
-                    self._triples_count += 1
-                except ValueError as ve:
-                    log_to_error(msg=ve.message + "This line caused error: " + a_line,
-                                 source=self._source_file)
-                # if self._triples_count % 10000 == 0:
-                #     print("Reading..." + self._triples_count)
-
-    def _look_for_tokens(self, str_line):
-        return str_line.split("\t")
-
-    @property
-    def yielded_triples(self):
-        return self._triples_count
-
-    @property
-    def error_triples(self):
-        return self._error_triples
-
-    def _reset_count(self):
-        self._error_triples = 0
-        self._triples_count = 0
-
-    # def yield_triples(self):
-    #     self._reset_parsing()
-    #     for a_line in self._line_reader.read_lines():
-    #         tokens = self._look_for_tokens(a_line.strip())
-    #         if len(tokens) != 3:
-    #             self._error_triples += 1
-    #             log_to_error(msg="This line caused error: " + a_line,
-    #                          source=self._source_file)
-    #         else:
-    #             try:
-    #                 yield (tune_token(tokens[0]),
-    #                        tune_prop(tokens[1]),
-    #                        tune_token(tokens[2], allow_untyped_numbers=self._allow_untyped_numbers))
-    #                 self._triples_count += 1
-    #             except ValueError as ve:
-    #                 log_to_error(msg=ve.message + "This line caused error: " + a_line,
-    #                              source=self._source_file)
-    #             if self._triples_count % 10000 == 0:
-    #                 print("Reading..." + self._triples_count)
-
-    # def _yield_triples_excluding_namespaces(self):
-    #     self._reset_parsing()
-    #     for a_line in self._line_reader.read_lines():
-    #         tokens = self._look_for_tokens(a_line.strip())
-    #         if len(tokens) != 3:
-    #             self._error_triples += 1
-    #             log_to_error(msg="This line caused error: " + a_line,
-    #                          source=self._source_file)
-    #         else:
-    #             try:
-    #                 candidate_triple = (tune_token(tokens[0]),
-    #                                     tune_prop(tokens[1]),
-    #                                     tune_token(tokens[2], allow_untyped_numbers=True))
-    #                 if not check_if_property_belongs_to_namespace_list(str(candidate_triple[1]),
-    #                                                                    namespaces=self._namespaces_to_ignore):
-    #                     yield candidate_triple
-    #
-    #                 self._triples_count += 1
-    #             except ValueError as ve:
-    #                 log_to_error(msg=ve.message + "This line caused error: " + a_line,
-    #                              source=self._source_file)
-    #             if self._triples_count % 10000 == 0:
-    #                 print("Reading..." + self._triples_count)
+
+from shexer.utils.log import log_to_error
+from shexer.utils.triple_yielders import tune_token, tune_prop
+from shexer.io.graph.yielder.base_triples_yielder import BaseTriplesYielder
+
+
+class TsvNtTriplesYielder(BaseTriplesYielder):
+
+    def __init__(self, source_file, allow_untyped_numbers=False, raw_graph=None,
+                 compression_mode=None, zip_base_archive=None):
+        super(TsvNtTriplesYielder, self).__init__()
+        self._source_file = source_file
+        self._triples_count = 0
+        self._error_triples = 0
+        self._allow_untyped_numbers = allow_untyped_numbers
+        self._line_reader = self._decide_line_reader(source_file=source_file,
+                                                     raw_graph=raw_graph,
+                                                     compression_mode=compression_mode,
+                                                     zip_base_archive=zip_base_archive)
+        # self.yield_triples = self._yield_triples_not_excluding_namespaces if namespaces_to_ignore is None\
+        #     else self._yield_triples_excluding_namespaces
+
+
+    def yield_triples(self):
+        self._reset_count()
+        for a_line in self._line_reader.read_lines():
+            tokens = self._look_for_tokens(a_line.strip())
+            if len(tokens) != 3:
+                self._error_triples += 1
+                log_to_error(msg="This line caused error: " + a_line,
+                             source=self._source_file)
+            else:
+                try:
+                    yield (
+                    tune_token(tokens[0]), tune_prop(tokens[1]), tune_token(tokens[2], allow_untyped_numbers=True))
+                    self._triples_count += 1
+                except ValueError as ve:
+                    log_to_error(msg=ve.message + "This line caused error: " + a_line,
+                                 source=self._source_file)
+                # if self._triples_count % 10000 == 0:
+                #     print("Reading..." + self._triples_count)
+
+    def _look_for_tokens(self, str_line):
+        return str_line.split("\t")
+
+    @property
+    def yielded_triples(self):
+        return self._triples_count
+
+    @property
+    def error_triples(self):
+        return self._error_triples
+
+    def _reset_count(self):
+        self._error_triples = 0
+        self._triples_count = 0
+
+    # def yield_triples(self):
+    #     self._reset_parsing()
+    #     for a_line in self._line_reader.read_lines():
+    #         tokens = self._look_for_tokens(a_line.strip())
+    #         if len(tokens) != 3:
+    #             self._error_triples += 1
+    #             log_to_error(msg="This line caused error: " + a_line,
+    #                          source=self._source_file)
+    #         else:
+    #             try:
+    #                 yield (tune_token(tokens[0]),
+    #                        tune_prop(tokens[1]),
+    #                        tune_token(tokens[2], allow_untyped_numbers=self._allow_untyped_numbers))
+    #                 self._triples_count += 1
+    #             except ValueError as ve:
+    #                 log_to_error(msg=ve.message + "This line caused error: " + a_line,
+    #                              source=self._source_file)
+    #             if self._triples_count % 10000 == 0:
+    #                 print("Reading..." + self._triples_count)
+
+    # def _yield_triples_excluding_namespaces(self):
+    #     self._reset_parsing()
+    #     for a_line in self._line_reader.read_lines():
+    #         tokens = self._look_for_tokens(a_line.strip())
+    #         if len(tokens) != 3:
+    #             self._error_triples += 1
+    #             log_to_error(msg="This line caused error: " + a_line,
+    #                          source=self._source_file)
+    #         else:
+    #             try:
+    #                 candidate_triple = (tune_token(tokens[0]),
+    #                                     tune_prop(tokens[1]),
+    #                                     tune_token(tokens[2], allow_untyped_numbers=True))
+    #                 if not check_if_property_belongs_to_namespace_list(str(candidate_triple[1]),
+    #                                                                    namespaces=self._namespaces_to_ignore):
+    #                     yield candidate_triple
+    #
+    #                 self._triples_count += 1
+    #             except ValueError as ve:
+    #                 log_to_error(msg=ve.message + "This line caused error: " + a_line,
+    #                              source=self._source_file)
+    #             if self._triples_count % 10000 == 0:
+    #                 print("Reading..." + self._triples_count)
```

### Comparing `shexer-2.5.1/shexer/io/shacl/formater/shacl_serializer.py` & `shexer-2.5.2/shexer/io/shacl/formater/shacl_serializer.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,367 +1,367 @@
-from shexer.core.profiling.class_profiler import RDF_TYPE_STR
-from shexer.model.shape import STARTING_CHAR_FOR_SHAPE_NAME
-from rdflib import Graph, Namespace, URIRef, RDF, BNode, XSD, Literal
-from shexer.model.statement import POSITIVE_CLOSURE, KLEENE_CLOSURE, OPT_CARDINALITY
-from shexer.utils.uri import XSD_NAMESPACE, LANG_STRING_TYPE
-from shexer.model.const_elem_types import IRI_ELEM_TYPE, LITERAL_ELEM_TYPE, DOT_ELEM_TYPE, BNODE_ELEM_TYPE
-from shexer.io.wikidata import wikidata_annotation
-from wlighter import TURTLE_FORMAT
-
-_EXPECTED_SHAPE_BEGINING = STARTING_CHAR_FOR_SHAPE_NAME + "<"
-_EXPECTED_SHAPE_ENDING = ">"
-
-_SHACL_NAMESPACE = "http://www.w3.org/ns/shacl#"
-
-_SHACL_PRIORITY_PREFIXES = ["sh", "shacl", "sha"]
-
-_R_SHACL_SHAPE_URI = URIRef(_SHACL_NAMESPACE + "NodeShape")
-_R_SHACL_PROPERTY_SHAPE_URI = URIRef(_SHACL_NAMESPACE + "PropertyShape")
-
-_R_SHACL_TARGET_CLASS_PROP = URIRef(_SHACL_NAMESPACE + "targetClass")
-_R_SHACL_PATH_PROP = URIRef(_SHACL_NAMESPACE + "path")
-_R_SHACL_INVERSE_PATH_PROP = URIRef(_SHACL_NAMESPACE + "inversePath")
-_R_SHACL_MIN_COUNT_PROP = URIRef(_SHACL_NAMESPACE + "minCount")
-_R_SHACL_MAX_COUNT_PROP = URIRef(_SHACL_NAMESPACE + "maxCount")
-
-_R_SHACL_PROPERTY_PROP = URIRef(_SHACL_NAMESPACE + "property")
-
-_R_SHACL_DATATYPE_PROP = URIRef(_SHACL_NAMESPACE + "dataType")
-_R_SHACL_NODEKIND_PROP = URIRef(_SHACL_NAMESPACE + "nodeKind")
-_R_SHACL_NODE_PROP = URIRef(_SHACL_NAMESPACE + "node")
-
-_R_SHACL_IN_PROP = URIRef(_SHACL_NAMESPACE + "in")
-
-_R_SHACL_PATTERN_PROP = URIRef(_SHACL_NAMESPACE + "pattern")
-
-_R_SHACL_NODEKIND_IRI = URIRef(_SHACL_NAMESPACE + "IRI")
-_R_SHACL_NODEKIND_LITERAL = URIRef(_SHACL_NAMESPACE + "Literal")
-_R_SHACL_NODEKIND_BNODE = URIRef(_SHACL_NAMESPACE + "BlankNode")
-_R_SHACL_NODEKIND_DOT = None
-
-_R_LANG_STRING = URIRef("http://www.w3.org/2000/01/rdf-schema#langString")
-
-_INTEGER = "i"
-_STRING = "s"
-
-_MACRO_MAPPING = {IRI_ELEM_TYPE: _R_SHACL_NODEKIND_IRI,
-                  LITERAL_ELEM_TYPE: _R_SHACL_NODEKIND_LITERAL,
-                  DOT_ELEM_TYPE: _R_SHACL_NODEKIND_BNODE,
-                  BNODE_ELEM_TYPE: _R_SHACL_NODEKIND_DOT}
-
-
-class ShaclSerializer(object):
-
-    def __init__(self, target_file, shapes_list, namespaces_dict=None, string_return=False,
-                 instantiation_property_str=RDF_TYPE_STR, wikidata_annotation=False,
-                 detect_minimal_iri=False, shape_example_features=None):
-        self._target_file = target_file
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-        self._shapes_list = shapes_list
-        self._string_return = string_return
-        self._instantiation_property_str = instantiation_property_str
-        self._wikidata_annotation = wikidata_annotation
-        self._detect_minimal_iri = detect_minimal_iri
-        self._shape_example_features = shape_example_features
-
-        self._g_shapes = Graph()
-
-        # self._uri_dict = {}
-
-    def serialize_shapes(self):
-        self._add_namespaces()
-        self._add_shapes()
-        return self._produce_output()
-
-    #################### NAMESPACES
-
-    def _add_namespaces(self):
-        self._add_param_namespaces()
-        self._add_shacl_namespace_if_needed()
-
-    def _add_param_namespaces(self):
-        for a_namespace, a_prefix in self._namespaces_dict.items():
-            self._add_namespace(prefix=a_prefix,
-                                namespace_str=a_namespace)
-
-    def _add_namespace(self, prefix, namespace_str):
-        self._g_shapes.bind(prefix=prefix,
-                            namespace=Namespace(namespace_str))
-
-    def _add_shacl_namespace_if_needed(self):
-        if _SHACL_NAMESPACE in self._namespaces_dict:  # shacl already included
-            return
-        curr_prefixes = self._namespaces_dict.values()
-        for a_prefix in _SHACL_PRIORITY_PREFIXES:  # trying default prefixes
-            if a_prefix not in curr_prefixes:
-                self._add_shacl_namespace(a_prefix)
-                return
-        counter = 1  # going for random prefixes, no defs. available
-        candidate_pref = _SHACL_PRIORITY_PREFIXES[0] + str(counter)
-        while candidate_pref in curr_prefixes:
-            counter += 1
-            candidate_pref = _SHACL_PRIORITY_PREFIXES[0] + str(counter)
-        self._add_shacl_namespace(candidate_pref)
-
-    def _add_shacl_namespace(self, shacl_prefix):
-        self._add_namespace(prefix=shacl_prefix,
-                            namespace_str=_SHACL_NAMESPACE)
-        self._namespaces_dict[_SHACL_NAMESPACE] = shacl_prefix
-
-    #################### SHAPES
-
-    def _add_shapes(self):
-        for a_shape in self._shapes_list:
-            self._add_shape(a_shape)
-
-    def _add_shape(self, shape):
-        r_shape_uri = self._generate_shape_uri(shape_name=shape.name)
-        self._add_shape_uri(r_shape_uri=r_shape_uri)
-        self._add_target_class(r_shape_uri=r_shape_uri,
-                               shape=shape)
-        if self._detect_minimal_iri:
-            self._add_min_iri(r_shape_uri=r_shape_uri,
-                              shape=shape)
-        self._add_shape_constraints(shape=shape,
-                                    r_shape_uri=r_shape_uri)
-
-
-    def _add_target_class(self, shape, r_shape_uri):
-        if shape.class_uri is not None:
-            self._add_triple(r_shape_uri,
-                             _R_SHACL_TARGET_CLASS_PROP,
-                             URIRef(shape.class_uri))  # TODO check if this is always an abs. URI, not sure
-
-    def _add_min_iri (self, shape, r_shape_uri):
-        # if shape.iri_pattern is not None:
-        if self._shape_example_features.shape_min_iri(shape_id=shape.class_uri) is not None:
-            self._add_triple(r_shape_uri,
-                             _R_SHACL_PATTERN_PROP,
-                             self._literal_iri_pattern(shape))
-
-    def _literal_iri_pattern(self, shape):
-        return Literal("^{}".format(self._shape_example_features.shape_min_iri(shape_id=shape.class_uri)))
-
-    def _add_shape_constraints(self, shape, r_shape_uri):
-        for a_statement in shape.yield_statements():
-            self._add_constraint(statement=a_statement,
-                                 r_shape_uri=r_shape_uri)
-
-    def _is_instantiation_property(self, str_property):
-        return str_property == self._instantiation_property_str
-
-    def _add_constraint(self, statement, r_shape_uri):
-        if self._is_instantiation_property(statement.st_property):
-            self._add_instantiation_constraint(statement=statement,
-                                               r_shape_uri=r_shape_uri)
-        else:
-            self._add_regular_constraint(statement=statement,
-                                         r_shape_uri=r_shape_uri)
-
-    def _add_exactly_one_cardinality(self, r_constraint_node):
-        self._add_min_occurs(r_constraint_node=r_constraint_node,
-                             min_occurs=1)
-        self._add_max_occurs(r_constraint_node=r_constraint_node,
-                             max_occurs=1)
-
-    def _add_in_instance(self, r_constraint_node, statement):
-        target_node = self._generate_r_uri_for_str_uri(statement.st_type)
-        list_seed_node = self._generate_bnode()
-        self._add_triple(r_constraint_node, _R_SHACL_IN_PROP, list_seed_node)
-        self._add_triple(list_seed_node, RDF.first, target_node)
-        self._add_triple(list_seed_node, RDF.rest, RDF.nil)
-
-    def _add_instantiation_constraint(self, statement, r_shape_uri):
-        r_constraint_node = self._generate_bnode()
-        self._add_bnode_property(r_shape_uri=r_shape_uri,
-                                 r_constraint_node=r_constraint_node)
-        self._add_direct_path(statement=statement,
-                              r_constraint_node=r_constraint_node)
-        self._add_exactly_one_cardinality(r_constraint_node=r_constraint_node)
-        self._add_in_instance(statement=statement,
-                              r_constraint_node=r_constraint_node)
-
-    def _add_regular_constraint(self, statement, r_shape_uri):
-        r_constraint_node = self._generate_bnode()
-        self._add_bnode_property(r_shape_uri=r_shape_uri,
-                                 r_constraint_node=r_constraint_node)
-        self._add_node_type(statement=statement,
-                            r_constraint_node=r_constraint_node)
-        self._add_cardinality(statement=statement,
-                              r_constraint_node=r_constraint_node)
-        self._add_path(statement=statement,
-                       r_constraint_node=r_constraint_node)
-
-    def _add_path(self, statement, r_constraint_node):
-        if not statement.is_inverse:
-            self._add_direct_path(statement=statement,
-                                  r_constraint_node=r_constraint_node)
-        else:
-            self._add_inverse_path(statement=statement,
-                                   r_constraint_node=r_constraint_node)
-
-    def _add_direct_path(self, statement, r_constraint_node):
-        r_property_uri = self._generate_r_uri_for_str_uri(statement.st_property)
-        self._add_triple(r_constraint_node, _R_SHACL_PATH_PROP, r_property_uri)
-
-    def _add_inverse_path(self, statement, r_constraint_node):
-        r_property_uri = self._generate_r_uri_for_str_uri(statement.st_property)
-        inverse_path_node = self._generate_bnode()
-        self._add_triple(r_constraint_node, _R_SHACL_PROPERTY_PROP, inverse_path_node)
-        self._add_triple(inverse_path_node, _R_SHACL_INVERSE_PATH_PROP, r_property_uri)
-
-    def _generate_r_uri_for_str_uri(self, property_str):
-        if property_str.startswith("<") and property_str.endswith(">"):
-            return URIRef(property_str[1:-1])
-        elif property_str.startswith("http://") or property_str.startswith("https://"):
-            return URIRef(property_str)
-        raise ValueError("Having troubles recognizing this URI", property_str, ". "
-                        "Is it well-formed? If you think so, add a GitHub issue. ")
-
-    def _is_a_shape(self, target_type):
-        return target_type.startswith(STARTING_CHAR_FOR_SHAPE_NAME)
-
-    def _is_literal(self, target_type):
-        return target_type == LANG_STRING_TYPE or target_type.startswith(XSD_NAMESPACE)
-
-    def _is_macro(self, target_type):
-        return target_type in _MACRO_MAPPING
-
-    def _add_dataType_literal(self, r_constraint_node, target_type):
-        # if target_type == LANG_STRING_TYPE:
-        #     type_node = _R_LANG_STRING
-        # elif target_type.endswith("integer"):
-        #     type_node = XSD.integer
-        # elif target_type.endswith("float"):
-        #     type_node = XSD.float
-        # elif target_type.endswith("string"):
-        #     type_node = XSD.string
-        # else:
-        #     raise ValueError("Unexpected literal type:" + target_type)
-        self._add_triple(r_constraint_node,
-                         _R_SHACL_DATATYPE_PROP,
-                         URIRef(target_type))
-
-    def _add_node_shape(self, r_constraint_node, target_type):
-        self._add_triple(r_constraint_node,
-                         _R_SHACL_NODE_PROP,
-                         self._generate_shape_uri(shape_name=target_type))
-
-    def _add_nodeKind_macro(self, r_constraint_node, target_type):
-        type_node = _MACRO_MAPPING[target_type]
-        if type_node is not None:
-            self._add_triple(r_constraint_node,
-                             _R_SHACL_NODEKIND_PROP,
-                             type_node)
-
-    def _add_node_type(self, statement, r_constraint_node):
-        #  sh:dataType for literal types
-        #  sh:nodeKind for IRI or similar macros.
-        #  sh:node for a shape
-        # if self._is_literal(statement.st_type):
-        #     self._add_dataType_literal(r_constraint_node=r_constraint_node,
-        #                                target_type=statement.st_type)
-        if self._is_macro(statement.st_type):
-            self._add_nodeKind_macro(r_constraint_node=r_constraint_node,
-                                     target_type=statement.st_type)
-        elif self._is_a_shape(statement.st_type):
-            self._add_node_shape(r_constraint_node=r_constraint_node,
-                                 target_type=statement.st_type)
-        else:  # It should be a literal
-            self._add_dataType_literal(r_constraint_node=r_constraint_node,
-                                       target_type=statement.st_type)
-        # else:
-        #     raise ValueError("Check here: ")
-
-
-    def _min_occurs_from_cardinality(self, cardinality):
-        if cardinality in [KLEENE_CLOSURE, OPT_CARDINALITY]:
-            return None
-        elif cardinality == POSITIVE_CLOSURE:
-            return 1
-        else:
-            return cardinality
-
-    def _max_occurs_from_cardinality(self, cardinality):
-        if cardinality in [KLEENE_CLOSURE, POSITIVE_CLOSURE]:
-            return None
-        elif cardinality == OPT_CARDINALITY:
-            return 1
-        else:
-            return cardinality
-
-    def _generate_r_literal(self, value, l_type):
-        return Literal(value, datatype=self._map_rdflib_datatype(l_type))
-
-    def _map_rdflib_datatype(self, l_type):
-        if l_type == _INTEGER:
-            return XSD.integer
-        elif l_type == _STRING:
-            return XSD.string
-        else:
-            raise ValueError("Having troubles recognizing this literal type", l_type, ". "
-                        "Is it well-formed? If you think so, add a GitHub issue. ")
-
-    def _add_min_occurs(self, r_constraint_node, min_occurs):
-        self._add_triple(r_constraint_node,
-                         _R_SHACL_MIN_COUNT_PROP,
-                         self._generate_r_literal(value=min_occurs,
-                                                  l_type=_INTEGER))
-
-    def _add_max_occurs(self, r_constraint_node, max_occurs):
-        self._add_triple(r_constraint_node,
-                         _R_SHACL_MAX_COUNT_PROP,
-                         self._generate_r_literal(value=max_occurs,
-                                                  l_type=_INTEGER))
-
-    def _add_cardinality(self, statement, r_constraint_node):
-        min_occurs = self._min_occurs_from_cardinality(statement.cardinality)
-        max_occurs = self._max_occurs_from_cardinality(statement.cardinality)
-        if min_occurs is not None:
-            self._add_min_occurs(r_constraint_node=r_constraint_node,
-                                 min_occurs=min_occurs)
-        if max_occurs is not None:
-            self._add_max_occurs(r_constraint_node=r_constraint_node,
-                                 max_occurs=max_occurs)
-
-    def _add_bnode_property(self, r_shape_uri, r_constraint_node):
-        self._add_triple(r_shape_uri, _R_SHACL_PROPERTY_PROP, r_constraint_node)
-        self._add_triple(r_constraint_node, RDF.type, _R_SHACL_PROPERTY_SHAPE_URI)
-
-    def _generate_shape_uri(self, shape_name):
-        if shape_name.startswith(_EXPECTED_SHAPE_BEGINING) and shape_name.endswith(_EXPECTED_SHAPE_ENDING):
-            return URIRef(shape_name[2:-1])  # Excluding  "@<"  and ">
-        raise ValueError("Unknown error, having trouble with a shape label:", shape_name,
-                         "Add a GitHub issue to github with your input to have this review and fixed.")
-
-    def _add_shape_uri(self, r_shape_uri):
-        self._add_triple(r_shape_uri, RDF.type, _R_SHACL_SHAPE_URI)
-
-    def _add_triple(self, s, p, o):
-        self._g_shapes.add((s, p, o))
-
-    @staticmethod
-    def _generate_bnode():
-        return BNode()
-
-    #################### OUTPUT
-
-    def _produce_output(self):
-        if self._wikidata_annotation:
-            return self._produce_wikidata_annotation_output()
-        # destination = None if self._string_return else self._target_file
-        if self._string_return:
-            return self._g_shapes.serialize(format="turtle")
-        else:
-            self._g_shapes.serialize(destination=self._target_file, format="turtle")
-
-
-    def _produce_wikidata_annotation_output(self):
-        result = self._g_shapes.serialize(format="turtle")
-        result = wikidata_annotation(raw_input=result,
-                                     string_return=self._string_return,
-                                     out_file=self._target_file,
-                                     format=TURTLE_FORMAT,
-                                     rdfs_comments=False)
-        if self._string_return:
-            return result
-
+from shexer.core.profiling.class_profiler import RDF_TYPE_STR
+from shexer.model.shape import STARTING_CHAR_FOR_SHAPE_NAME
+from rdflib import Graph, Namespace, URIRef, RDF, BNode, XSD, Literal
+from shexer.model.statement import POSITIVE_CLOSURE, KLEENE_CLOSURE, OPT_CARDINALITY
+from shexer.utils.uri import XSD_NAMESPACE, LANG_STRING_TYPE
+from shexer.model.const_elem_types import IRI_ELEM_TYPE, LITERAL_ELEM_TYPE, DOT_ELEM_TYPE, BNODE_ELEM_TYPE
+from shexer.io.wikidata import wikidata_annotation
+from wlighter import TURTLE_FORMAT
+
+_EXPECTED_SHAPE_BEGINING = STARTING_CHAR_FOR_SHAPE_NAME + "<"
+_EXPECTED_SHAPE_ENDING = ">"
+
+_SHACL_NAMESPACE = "http://www.w3.org/ns/shacl#"
+
+_SHACL_PRIORITY_PREFIXES = ["sh", "shacl", "sha"]
+
+_R_SHACL_SHAPE_URI = URIRef(_SHACL_NAMESPACE + "NodeShape")
+_R_SHACL_PROPERTY_SHAPE_URI = URIRef(_SHACL_NAMESPACE + "PropertyShape")
+
+_R_SHACL_TARGET_CLASS_PROP = URIRef(_SHACL_NAMESPACE + "targetClass")
+_R_SHACL_PATH_PROP = URIRef(_SHACL_NAMESPACE + "path")
+_R_SHACL_INVERSE_PATH_PROP = URIRef(_SHACL_NAMESPACE + "inversePath")
+_R_SHACL_MIN_COUNT_PROP = URIRef(_SHACL_NAMESPACE + "minCount")
+_R_SHACL_MAX_COUNT_PROP = URIRef(_SHACL_NAMESPACE + "maxCount")
+
+_R_SHACL_PROPERTY_PROP = URIRef(_SHACL_NAMESPACE + "property")
+
+_R_SHACL_DATATYPE_PROP = URIRef(_SHACL_NAMESPACE + "dataType")
+_R_SHACL_NODEKIND_PROP = URIRef(_SHACL_NAMESPACE + "nodeKind")
+_R_SHACL_NODE_PROP = URIRef(_SHACL_NAMESPACE + "node")
+
+_R_SHACL_IN_PROP = URIRef(_SHACL_NAMESPACE + "in")
+
+_R_SHACL_PATTERN_PROP = URIRef(_SHACL_NAMESPACE + "pattern")
+
+_R_SHACL_NODEKIND_IRI = URIRef(_SHACL_NAMESPACE + "IRI")
+_R_SHACL_NODEKIND_LITERAL = URIRef(_SHACL_NAMESPACE + "Literal")
+_R_SHACL_NODEKIND_BNODE = URIRef(_SHACL_NAMESPACE + "BlankNode")
+_R_SHACL_NODEKIND_DOT = None
+
+_R_LANG_STRING = URIRef("http://www.w3.org/2000/01/rdf-schema#langString")
+
+_INTEGER = "i"
+_STRING = "s"
+
+_MACRO_MAPPING = {IRI_ELEM_TYPE: _R_SHACL_NODEKIND_IRI,
+                  LITERAL_ELEM_TYPE: _R_SHACL_NODEKIND_LITERAL,
+                  DOT_ELEM_TYPE: _R_SHACL_NODEKIND_BNODE,
+                  BNODE_ELEM_TYPE: _R_SHACL_NODEKIND_DOT}
+
+
+class ShaclSerializer(object):
+
+    def __init__(self, target_file, shapes_list, namespaces_dict=None, string_return=False,
+                 instantiation_property_str=RDF_TYPE_STR, wikidata_annotation=False,
+                 detect_minimal_iri=False, shape_example_features=None):
+        self._target_file = target_file
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+        self._shapes_list = shapes_list
+        self._string_return = string_return
+        self._instantiation_property_str = instantiation_property_str
+        self._wikidata_annotation = wikidata_annotation
+        self._detect_minimal_iri = detect_minimal_iri
+        self._shape_example_features = shape_example_features
+
+        self._g_shapes = Graph()
+
+        # self._uri_dict = {}
+
+    def serialize_shapes(self):
+        self._add_namespaces()
+        self._add_shapes()
+        return self._produce_output()
+
+    #################### NAMESPACES
+
+    def _add_namespaces(self):
+        self._add_param_namespaces()
+        self._add_shacl_namespace_if_needed()
+
+    def _add_param_namespaces(self):
+        for a_namespace, a_prefix in self._namespaces_dict.items():
+            self._add_namespace(prefix=a_prefix,
+                                namespace_str=a_namespace)
+
+    def _add_namespace(self, prefix, namespace_str):
+        self._g_shapes.bind(prefix=prefix,
+                            namespace=Namespace(namespace_str))
+
+    def _add_shacl_namespace_if_needed(self):
+        if _SHACL_NAMESPACE in self._namespaces_dict:  # shacl already included
+            return
+        curr_prefixes = self._namespaces_dict.values()
+        for a_prefix in _SHACL_PRIORITY_PREFIXES:  # trying default prefixes
+            if a_prefix not in curr_prefixes:
+                self._add_shacl_namespace(a_prefix)
+                return
+        counter = 1  # going for random prefixes, no defs. available
+        candidate_pref = _SHACL_PRIORITY_PREFIXES[0] + str(counter)
+        while candidate_pref in curr_prefixes:
+            counter += 1
+            candidate_pref = _SHACL_PRIORITY_PREFIXES[0] + str(counter)
+        self._add_shacl_namespace(candidate_pref)
+
+    def _add_shacl_namespace(self, shacl_prefix):
+        self._add_namespace(prefix=shacl_prefix,
+                            namespace_str=_SHACL_NAMESPACE)
+        self._namespaces_dict[_SHACL_NAMESPACE] = shacl_prefix
+
+    #################### SHAPES
+
+    def _add_shapes(self):
+        for a_shape in self._shapes_list:
+            self._add_shape(a_shape)
+
+    def _add_shape(self, shape):
+        r_shape_uri = self._generate_shape_uri(shape_name=shape.name)
+        self._add_shape_uri(r_shape_uri=r_shape_uri)
+        self._add_target_class(r_shape_uri=r_shape_uri,
+                               shape=shape)
+        if self._detect_minimal_iri:
+            self._add_min_iri(r_shape_uri=r_shape_uri,
+                              shape=shape)
+        self._add_shape_constraints(shape=shape,
+                                    r_shape_uri=r_shape_uri)
+
+
+    def _add_target_class(self, shape, r_shape_uri):
+        if shape.class_uri is not None:
+            self._add_triple(r_shape_uri,
+                             _R_SHACL_TARGET_CLASS_PROP,
+                             URIRef(shape.class_uri))  # TODO check if this is always an abs. URI, not sure
+
+    def _add_min_iri (self, shape, r_shape_uri):
+        # if shape.iri_pattern is not None:
+        if self._shape_example_features.shape_min_iri(shape_id=shape.class_uri) is not None:
+            self._add_triple(r_shape_uri,
+                             _R_SHACL_PATTERN_PROP,
+                             self._literal_iri_pattern(shape))
+
+    def _literal_iri_pattern(self, shape):
+        return Literal("^{}".format(self._shape_example_features.shape_min_iri(shape_id=shape.class_uri)))
+
+    def _add_shape_constraints(self, shape, r_shape_uri):
+        for a_statement in shape.yield_statements():
+            self._add_constraint(statement=a_statement,
+                                 r_shape_uri=r_shape_uri)
+
+    def _is_instantiation_property(self, str_property):
+        return str_property == self._instantiation_property_str
+
+    def _add_constraint(self, statement, r_shape_uri):
+        if self._is_instantiation_property(statement.st_property):
+            self._add_instantiation_constraint(statement=statement,
+                                               r_shape_uri=r_shape_uri)
+        else:
+            self._add_regular_constraint(statement=statement,
+                                         r_shape_uri=r_shape_uri)
+
+    def _add_exactly_one_cardinality(self, r_constraint_node):
+        self._add_min_occurs(r_constraint_node=r_constraint_node,
+                             min_occurs=1)
+        self._add_max_occurs(r_constraint_node=r_constraint_node,
+                             max_occurs=1)
+
+    def _add_in_instance(self, r_constraint_node, statement):
+        target_node = self._generate_r_uri_for_str_uri(statement.st_type)
+        list_seed_node = self._generate_bnode()
+        self._add_triple(r_constraint_node, _R_SHACL_IN_PROP, list_seed_node)
+        self._add_triple(list_seed_node, RDF.first, target_node)
+        self._add_triple(list_seed_node, RDF.rest, RDF.nil)
+
+    def _add_instantiation_constraint(self, statement, r_shape_uri):
+        r_constraint_node = self._generate_bnode()
+        self._add_bnode_property(r_shape_uri=r_shape_uri,
+                                 r_constraint_node=r_constraint_node)
+        self._add_direct_path(statement=statement,
+                              r_constraint_node=r_constraint_node)
+        self._add_exactly_one_cardinality(r_constraint_node=r_constraint_node)
+        self._add_in_instance(statement=statement,
+                              r_constraint_node=r_constraint_node)
+
+    def _add_regular_constraint(self, statement, r_shape_uri):
+        r_constraint_node = self._generate_bnode()
+        self._add_bnode_property(r_shape_uri=r_shape_uri,
+                                 r_constraint_node=r_constraint_node)
+        self._add_node_type(statement=statement,
+                            r_constraint_node=r_constraint_node)
+        self._add_cardinality(statement=statement,
+                              r_constraint_node=r_constraint_node)
+        self._add_path(statement=statement,
+                       r_constraint_node=r_constraint_node)
+
+    def _add_path(self, statement, r_constraint_node):
+        if not statement.is_inverse:
+            self._add_direct_path(statement=statement,
+                                  r_constraint_node=r_constraint_node)
+        else:
+            self._add_inverse_path(statement=statement,
+                                   r_constraint_node=r_constraint_node)
+
+    def _add_direct_path(self, statement, r_constraint_node):
+        r_property_uri = self._generate_r_uri_for_str_uri(statement.st_property)
+        self._add_triple(r_constraint_node, _R_SHACL_PATH_PROP, r_property_uri)
+
+    def _add_inverse_path(self, statement, r_constraint_node):
+        r_property_uri = self._generate_r_uri_for_str_uri(statement.st_property)
+        inverse_path_node = self._generate_bnode()
+        self._add_triple(r_constraint_node, _R_SHACL_PROPERTY_PROP, inverse_path_node)
+        self._add_triple(inverse_path_node, _R_SHACL_INVERSE_PATH_PROP, r_property_uri)
+
+    def _generate_r_uri_for_str_uri(self, property_str):
+        if property_str.startswith("<") and property_str.endswith(">"):
+            return URIRef(property_str[1:-1])
+        elif property_str.startswith("http://") or property_str.startswith("https://"):
+            return URIRef(property_str)
+        raise ValueError("Having troubles recognizing this URI", property_str, ". "
+                        "Is it well-formed? If you think so, add a GitHub issue. ")
+
+    def _is_a_shape(self, target_type):
+        return target_type.startswith(STARTING_CHAR_FOR_SHAPE_NAME)
+
+    def _is_literal(self, target_type):
+        return target_type == LANG_STRING_TYPE or target_type.startswith(XSD_NAMESPACE)
+
+    def _is_macro(self, target_type):
+        return target_type in _MACRO_MAPPING
+
+    def _add_dataType_literal(self, r_constraint_node, target_type):
+        # if target_type == LANG_STRING_TYPE:
+        #     type_node = _R_LANG_STRING
+        # elif target_type.endswith("integer"):
+        #     type_node = XSD.integer
+        # elif target_type.endswith("float"):
+        #     type_node = XSD.float
+        # elif target_type.endswith("string"):
+        #     type_node = XSD.string
+        # else:
+        #     raise ValueError("Unexpected literal type:" + target_type)
+        self._add_triple(r_constraint_node,
+                         _R_SHACL_DATATYPE_PROP,
+                         URIRef(target_type))
+
+    def _add_node_shape(self, r_constraint_node, target_type):
+        self._add_triple(r_constraint_node,
+                         _R_SHACL_NODE_PROP,
+                         self._generate_shape_uri(shape_name=target_type))
+
+    def _add_nodeKind_macro(self, r_constraint_node, target_type):
+        type_node = _MACRO_MAPPING[target_type]
+        if type_node is not None:
+            self._add_triple(r_constraint_node,
+                             _R_SHACL_NODEKIND_PROP,
+                             type_node)
+
+    def _add_node_type(self, statement, r_constraint_node):
+        #  sh:dataType for literal types
+        #  sh:nodeKind for IRI or similar macros.
+        #  sh:node for a shape
+        # if self._is_literal(statement.st_type):
+        #     self._add_dataType_literal(r_constraint_node=r_constraint_node,
+        #                                target_type=statement.st_type)
+        if self._is_macro(statement.st_type):
+            self._add_nodeKind_macro(r_constraint_node=r_constraint_node,
+                                     target_type=statement.st_type)
+        elif self._is_a_shape(statement.st_type):
+            self._add_node_shape(r_constraint_node=r_constraint_node,
+                                 target_type=statement.st_type)
+        else:  # It should be a literal
+            self._add_dataType_literal(r_constraint_node=r_constraint_node,
+                                       target_type=statement.st_type)
+        # else:
+        #     raise ValueError("Check here: ")
+
+
+    def _min_occurs_from_cardinality(self, cardinality):
+        if cardinality in [KLEENE_CLOSURE, OPT_CARDINALITY]:
+            return None
+        elif cardinality == POSITIVE_CLOSURE:
+            return 1
+        else:
+            return cardinality
+
+    def _max_occurs_from_cardinality(self, cardinality):
+        if cardinality in [KLEENE_CLOSURE, POSITIVE_CLOSURE]:
+            return None
+        elif cardinality == OPT_CARDINALITY:
+            return 1
+        else:
+            return cardinality
+
+    def _generate_r_literal(self, value, l_type):
+        return Literal(value, datatype=self._map_rdflib_datatype(l_type))
+
+    def _map_rdflib_datatype(self, l_type):
+        if l_type == _INTEGER:
+            return XSD.integer
+        elif l_type == _STRING:
+            return XSD.string
+        else:
+            raise ValueError("Having troubles recognizing this literal type", l_type, ". "
+                        "Is it well-formed? If you think so, add a GitHub issue. ")
+
+    def _add_min_occurs(self, r_constraint_node, min_occurs):
+        self._add_triple(r_constraint_node,
+                         _R_SHACL_MIN_COUNT_PROP,
+                         self._generate_r_literal(value=min_occurs,
+                                                  l_type=_INTEGER))
+
+    def _add_max_occurs(self, r_constraint_node, max_occurs):
+        self._add_triple(r_constraint_node,
+                         _R_SHACL_MAX_COUNT_PROP,
+                         self._generate_r_literal(value=max_occurs,
+                                                  l_type=_INTEGER))
+
+    def _add_cardinality(self, statement, r_constraint_node):
+        min_occurs = self._min_occurs_from_cardinality(statement.cardinality)
+        max_occurs = self._max_occurs_from_cardinality(statement.cardinality)
+        if min_occurs is not None:
+            self._add_min_occurs(r_constraint_node=r_constraint_node,
+                                 min_occurs=min_occurs)
+        if max_occurs is not None:
+            self._add_max_occurs(r_constraint_node=r_constraint_node,
+                                 max_occurs=max_occurs)
+
+    def _add_bnode_property(self, r_shape_uri, r_constraint_node):
+        self._add_triple(r_shape_uri, _R_SHACL_PROPERTY_PROP, r_constraint_node)
+        self._add_triple(r_constraint_node, RDF.type, _R_SHACL_PROPERTY_SHAPE_URI)
+
+    def _generate_shape_uri(self, shape_name):
+        if shape_name.startswith(_EXPECTED_SHAPE_BEGINING) and shape_name.endswith(_EXPECTED_SHAPE_ENDING):
+            return URIRef(shape_name[2:-1])  # Excluding  "@<"  and ">
+        raise ValueError("Unknown error, having trouble with a shape label:", shape_name,
+                         "Add a GitHub issue to github with your input to have this review and fixed.")
+
+    def _add_shape_uri(self, r_shape_uri):
+        self._add_triple(r_shape_uri, RDF.type, _R_SHACL_SHAPE_URI)
+
+    def _add_triple(self, s, p, o):
+        self._g_shapes.add((s, p, o))
+
+    @staticmethod
+    def _generate_bnode():
+        return BNode()
+
+    #################### OUTPUT
+
+    def _produce_output(self):
+        if self._wikidata_annotation:
+            return self._produce_wikidata_annotation_output()
+        # destination = None if self._string_return else self._target_file
+        if self._string_return:
+            return self._g_shapes.serialize(format="turtle")
+        else:
+            self._g_shapes.serialize(destination=self._target_file, format="turtle")
+
+
+    def _produce_wikidata_annotation_output(self):
+        result = self._g_shapes.serialize(format="turtle")
+        result = wikidata_annotation(raw_input=result,
+                                     string_return=self._string_return,
+                                     out_file=self._target_file,
+                                     format=TURTLE_FORMAT,
+                                     rdfs_comments=False)
+        if self._string_return:
+            return result
+
```

### Comparing `shexer-2.5.1/shexer/io/shape_map/label/shape_map_label_parser.py` & `shexer-2.5.2/shexer/io/shape_map/label/shape_map_label_parser.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,39 +1,39 @@
-from shexer.model.shape import STARTING_CHAR_FOR_SHAPE_NAME
-
-class ShapeMapLabelParser(object):
-
-    def __init__(self, prefix_namespaces_dict=None):
-        self._namespaces_prefix_dict = prefix_namespaces_dict if prefix_namespaces_dict is not None else {}
-
-    def parse_shape_map_label(self, raw_label):
-
-        if self._is_a_prefixed_uri(raw_label):
-            return STARTING_CHAR_FOR_SHAPE_NAME + self._parse_prefixed_label(raw_label)
-        return STARTING_CHAR_FOR_SHAPE_NAME + raw_label
-        # return self._parse_unprefixed_label(raw_label)
-
-
-    def _is_a_prefixed_uri(self, raw_label):
-        if len(raw_label) < 2:
-            return False
-        if raw_label.startswith("<") and raw_label.endswith(">"):
-            return False
-        return True
-
-
-    # def _parse_unprefixed_label(self, raw_label):
-    #     return raw_label[1:-1]
-
-    def _parse_prefixed_label(self, raw_label):
-        index_sep = raw_label.find(":")
-        if index_sep == -1:
-            raise ValueError("Wrong label: expecting a URI surrounded by <> or a prefixed element: " + raw_label)
-        target_prefix = raw_label[:index_sep]
-        if target_prefix in self._namespaces_prefix_dict:
-            return self._namespaces_prefix_dict[target_prefix] + raw_label[index_sep + 1:]
-        else:
-            raise ValueError("Unknown prefix in label: " + raw_label)
-
-
-
-
+from shexer.model.shape import STARTING_CHAR_FOR_SHAPE_NAME
+
+class ShapeMapLabelParser(object):
+
+    def __init__(self, prefix_namespaces_dict=None):
+        self._namespaces_prefix_dict = prefix_namespaces_dict if prefix_namespaces_dict is not None else {}
+
+    def parse_shape_map_label(self, raw_label):
+
+        if self._is_a_prefixed_uri(raw_label):
+            return STARTING_CHAR_FOR_SHAPE_NAME + self._parse_prefixed_label(raw_label)
+        return STARTING_CHAR_FOR_SHAPE_NAME + raw_label
+        # return self._parse_unprefixed_label(raw_label)
+
+
+    def _is_a_prefixed_uri(self, raw_label):
+        if len(raw_label) < 2:
+            return False
+        if raw_label.startswith("<") and raw_label.endswith(">"):
+            return False
+        return True
+
+
+    # def _parse_unprefixed_label(self, raw_label):
+    #     return raw_label[1:-1]
+
+    def _parse_prefixed_label(self, raw_label):
+        index_sep = raw_label.find(":")
+        if index_sep == -1:
+            raise ValueError("Wrong label: expecting a URI surrounded by <> or a prefixed element: " + raw_label)
+        target_prefix = raw_label[:index_sep]
+        if target_prefix in self._namespaces_prefix_dict:
+            return self._namespaces_prefix_dict[target_prefix] + raw_label[index_sep + 1:]
+        else:
+            raise ValueError("Unknown prefix in label: " + raw_label)
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer/io/shape_map/shape_map_parser.py` & `shexer-2.5.2/shexer/io/shape_map/shape_map_parser.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,130 +1,130 @@
-from shexer.utils.file import load_whole_file_content
-from shexer.model.shape_map import ShapeMap, ShapeMapItem
-from shexer.io.shape_map.node_selector.node_selector_parser import NodeSelectorParser
-from shexer.io.shape_map.label.shape_map_label_parser import ShapeMapLabelParser
-from shexer.utils.dict import reverse_keys_and_values
-
-class ShapeMapParser(object):
-
-    def __init__(self, namespaces_prefix_dict, sgraph):
-        reversed_dict = reverse_keys_and_values(namespaces_prefix_dict)
-        self._node_selector_parser = NodeSelectorParser(prefix_namespaces_dict=reversed_dict,
-                                                        sgraph=sgraph)
-        self._label_parser = ShapeMapLabelParser(prefix_namespaces_dict=reversed_dict)
-        self._sgraph = sgraph
-
-    def parse_shape_map(self, source_file=None, raw_content=None):
-        self._check_input(source_file, raw_content)
-        target_content = raw_content
-        if source_file is not None:
-            target_content = load_whole_file_content(source_file)
-        return self._parse_shape_map_from_str(target_content)
-
-    @staticmethod
-    def _check_input(source_file, raw_content):
-        if (source_file is None) == (raw_content is None):
-            raise ValueError("Yoy must provide exactly one kind of input")
-
-    def _parse_shape_map_from_str(self, raw_content):
-        raise NotImplementedError("Implement this in derived classes")
-
-
-####################################################
-
-from shexer.io.json.json_loader import load_string_json
-
-_KEY_NODE_SELECTOR = "nodeSelector"
-_KEY_LABEL = "shapeLabel"
-
-
-class JsonShapeMapParser(ShapeMapParser):
-    """
-    WARNING!! This is a toy parser. We are assuming many wel--formed stuff
-    for the structure of the json itself and for the shape labels.
-    Node selectors are well checked
-
-    Example of expected format:
-    [
-  { "nodeSelector": "<http://data.example/node1>",
-    "shapeLabel": "<http://schema.example/Shape2>"
-    },
-  { "nodeSelector": "<http://data.example/node1>",
-    "shapeLabel": "<http://schema.example/Shape2>"
-    }
-]
-    """
-
-    def __init__(self, namespaces_prefix_dict, sgraph):
-        super().__init__(namespaces_prefix_dict=namespaces_prefix_dict,
-                         sgraph=sgraph)
-
-    def _parse_shape_map_from_str(self, raw_content):
-        result = ShapeMap()
-        json_obj = load_string_json(raw_content)
-        for a_list_elem in json_obj:
-            result.add_item(ShapeMapItem(
-                node_selector=self._node_selector_parser.parse_node_selector(a_list_elem[_KEY_NODE_SELECTOR]),
-                shape_label=self._label_parser.parse_shape_map_label(a_list_elem[_KEY_LABEL])
-            )
-            )
-        return result
-
-
-####################################################
-
-
-from shexer.io.line_reader.raw_string_line_reader import RawStringLineReader
-
-
-class FixedShapeMapParser(ShapeMapParser):
-    """
-    WARNING!!!     This is a toy parser.
-
-    Currently, this parser of Fixed ShapeMap syntax requires each couple selector@label to be in separate lines.
-    Also, It will just assume trailing commas at the end of the line. If they are there, thats OK. If not, it will
-    assume that its just because it is the last element.
-    """
-
-    def __init__(self, namespaces_prefix_dict, sgraph):
-        super().__init__(namespaces_prefix_dict=namespaces_prefix_dict,
-                         sgraph=sgraph)
-
-    def _parse_shape_map_from_str(self, raw_content):
-        result = ShapeMap()
-        for a_line in RawStringLineReader(raw_string=raw_content).read_lines():
-            a_line = a_line.strip()
-            if not self._is_an_empty_line(a_line):
-                result.add_item(self._parse_shape_map_item_from_line(a_line))
-
-        return result
-
-    def _is_an_empty_line(self, line):
-        """
-        It is expecting to receive a line which has already been stripped ()
-        :param line:
-        :return:
-        """
-        if len(line) == 0:
-            return True
-        if line[0] == "#":  # It is a comment
-            return True
-        return False
-
-    def _parse_shape_map_item_from_line(self, line):
-        """
-        It is expecting to receive a line which has already been stripped ()
-        :param line:
-        :return:
-        """
-        line = self._remove_trailing_comma(line)
-        pieces = line.split("@")
-        if len(pieces) != 2:
-            raise ValueError("There must be exactly a '@' char for each couple selector-label")
-        return ShapeMapItem(shape_label=self._label_parser.parse_shape_map_label(pieces[1].strip()),
-                            node_selector=self._node_selector_parser.parse_node_selector(pieces[0].strip()))
-
-    @staticmethod
-    def _remove_trailing_comma(line):
-        if line[-1] == ",":
-            return line[:-1]
-        return line
+from shexer.utils.file import load_whole_file_content
+from shexer.model.shape_map import ShapeMap, ShapeMapItem
+from shexer.io.shape_map.node_selector.node_selector_parser import NodeSelectorParser
+from shexer.io.shape_map.label.shape_map_label_parser import ShapeMapLabelParser
+from shexer.utils.dict import reverse_keys_and_values
+
+class ShapeMapParser(object):
+
+    def __init__(self, namespaces_prefix_dict, sgraph):
+        reversed_dict = reverse_keys_and_values(namespaces_prefix_dict)
+        self._node_selector_parser = NodeSelectorParser(prefix_namespaces_dict=reversed_dict,
+                                                        sgraph=sgraph)
+        self._label_parser = ShapeMapLabelParser(prefix_namespaces_dict=reversed_dict)
+        self._sgraph = sgraph
+
+    def parse_shape_map(self, source_file=None, raw_content=None):
+        self._check_input(source_file, raw_content)
+        target_content = raw_content
+        if source_file is not None:
+            target_content = load_whole_file_content(source_file)
+        return self._parse_shape_map_from_str(target_content)
+
+    @staticmethod
+    def _check_input(source_file, raw_content):
+        if (source_file is None) == (raw_content is None):
+            raise ValueError("Yoy must provide exactly one kind of input")
+
+    def _parse_shape_map_from_str(self, raw_content):
+        raise NotImplementedError("Implement this in derived classes")
+
+
+####################################################
+
+from shexer.io.json.json_loader import load_string_json
+
+_KEY_NODE_SELECTOR = "nodeSelector"
+_KEY_LABEL = "shapeLabel"
+
+
+class JsonShapeMapParser(ShapeMapParser):
+    """
+    WARNING!! This is a toy parser. We are assuming many wel--formed stuff
+    for the structure of the json itself and for the shape labels.
+    Node selectors are well checked
+
+    Example of expected format:
+    [
+  { "nodeSelector": "<http://data.example/node1>",
+    "shapeLabel": "<http://schema.example/Shape2>"
+    },
+  { "nodeSelector": "<http://data.example/node1>",
+    "shapeLabel": "<http://schema.example/Shape2>"
+    }
+]
+    """
+
+    def __init__(self, namespaces_prefix_dict, sgraph):
+        super().__init__(namespaces_prefix_dict=namespaces_prefix_dict,
+                         sgraph=sgraph)
+
+    def _parse_shape_map_from_str(self, raw_content):
+        result = ShapeMap()
+        json_obj = load_string_json(raw_content)
+        for a_list_elem in json_obj:
+            result.add_item(ShapeMapItem(
+                node_selector=self._node_selector_parser.parse_node_selector(a_list_elem[_KEY_NODE_SELECTOR]),
+                shape_label=self._label_parser.parse_shape_map_label(a_list_elem[_KEY_LABEL])
+            )
+            )
+        return result
+
+
+####################################################
+
+
+from shexer.io.line_reader.raw_string_line_reader import RawStringLineReader
+
+
+class FixedShapeMapParser(ShapeMapParser):
+    """
+    WARNING!!!     This is a toy parser.
+
+    Currently, this parser of Fixed ShapeMap syntax requires each couple selector@label to be in separate lines.
+    Also, It will just assume trailing commas at the end of the line. If they are there, thats OK. If not, it will
+    assume that its just because it is the last element.
+    """
+
+    def __init__(self, namespaces_prefix_dict, sgraph):
+        super().__init__(namespaces_prefix_dict=namespaces_prefix_dict,
+                         sgraph=sgraph)
+
+    def _parse_shape_map_from_str(self, raw_content):
+        result = ShapeMap()
+        for a_line in RawStringLineReader(raw_string=raw_content).read_lines():
+            a_line = a_line.strip()
+            if not self._is_an_empty_line(a_line):
+                result.add_item(self._parse_shape_map_item_from_line(a_line))
+
+        return result
+
+    def _is_an_empty_line(self, line):
+        """
+        It is expecting to receive a line which has already been stripped ()
+        :param line:
+        :return:
+        """
+        if len(line) == 0:
+            return True
+        if line[0] == "#":  # It is a comment
+            return True
+        return False
+
+    def _parse_shape_map_item_from_line(self, line):
+        """
+        It is expecting to receive a line which has already been stripped ()
+        :param line:
+        :return:
+        """
+        line = self._remove_trailing_comma(line)
+        pieces = line.split("@")
+        if len(pieces) != 2:
+            raise ValueError("There must be exactly a '@' char for each couple selector-label")
+        return ShapeMapItem(shape_label=self._label_parser.parse_shape_map_label(pieces[1].strip()),
+                            node_selector=self._node_selector_parser.parse_node_selector(pieces[0].strip()))
+
+    @staticmethod
+    def _remove_trailing_comma(line):
+        if line[-1] == ",":
+            return line[:-1]
+        return line
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/shex_serializer.py` & `shexer-2.5.2/shexer/io/shex/formater/shex_serializer.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,221 +1,221 @@
-from shexer.core.profiling.class_profiler import RDF_TYPE_STR
-
-from shexer.model.property import Property
-from shexer.utils.uri import remove_corners, prefixize_uri_if_possible
-from shexer.utils.shapes import prefixize_shape_name_if_possible
-from shexer.io.shex.formater.consts import SPACES_LEVEL_INDENTATION
-from shexer.io.wikidata import wikidata_annotation
-from shexer.io.file import read_file
-from shexer.consts import RATIO_INSTANCES, ABSOLUTE_INSTANCES, MIXED_INSTANCES, ALL_EXAMPLES, SHAPE_EXAMPLES, CONSTRAINT_EXAMPLES
-
-from wlighter import SHEXC_FORMAT
-
-_MODES_REPORT_INSTANCES = [ABSOLUTE_INSTANCES, MIXED_INSTANCES]
-_EXAMPLE_CONSTRAINT_TEMPLATE = "# Node constraint example: '{}'"
-_EXAMPLE_SHAPE_TEMPLATE = "{} Instance example: '{}'"
-
-
-class ShexSerializer(object):
-
-    def __init__(self, target_file, shapes_list, namespaces_dict=None, string_return=False,
-                 instantiation_property_str=RDF_TYPE_STR, disable_comments=False, wikidata_annotation=False,
-                 instances_report_mode=RATIO_INSTANCES, detect_minimal_iri=False, shape_example_features=None,
-                 examples_mode=None, inverse_paths=False):
-        self._target_file = target_file
-        self._shapes_list = shapes_list
-        self._lines_buffer = []
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-        self._string_return = string_return
-        self._instantiation_property_str = self._decide_instantiation_property(instantiation_property_str)
-        self._disable_comments = disable_comments
-        self._wikidata_annotation = wikidata_annotation
-        self._instances_report_mode = instances_report_mode
-        self._detect_minimal_iri = detect_minimal_iri
-        self._examples_mode = examples_mode
-        self._shape_example_features = shape_example_features
-        self._inverse_paths = inverse_paths
-
-        self._string_result = ""
-
-    def serialize_shapes(self):
-
-        self._reset_target_file()
-        self._serialize_namespaces()
-        for a_shape in self._shapes_list:
-            self._serialize_shape(a_shape)
-        self._flush()
-        if self._wikidata_annotation:
-            self._annotate_wikidata_ids_in_result()
-        if self._string_return:
-            return self._string_result
-
-    @staticmethod
-    def _decide_instantiation_property(instantiation_property_str):
-        if instantiation_property_str == None:
-            return RDF_TYPE_STR
-        if type(instantiation_property_str) == Property:
-            return str(instantiation_property_str)
-        if type(instantiation_property_str) == str:
-            return remove_corners(a_uri=instantiation_property_str,
-                                  raise_error_if_no_corners=False)
-        raise ValueError("Unrecognized param type to define instantiation property")
-
-    def _annotate_wikidata_ids_in_result(self):
-        self._string_result = wikidata_annotation(raw_input=self._get_raw_input_for_wikidata_annotation(),
-                                                  string_return=self._string_return,
-                                                  out_file=self._target_file,
-                                                  format=SHEXC_FORMAT,
-                                                  rdfs_comments=True)
-
-    def _get_raw_input_for_wikidata_annotation(self):
-        if self._string_return:
-            return self._string_result
-        return read_file(self._target_file)
-
-    def _serialize_namespaces(self):
-        for a_namespace in self._namespaces_dict:
-            self._write_line(self._prefix_line(a_namespace), 0)
-        self._write_line("", 0)
-
-    def _prefix_line(self, namespace_key):
-        return "PREFIX " + self._namespaces_dict[namespace_key] + ": <" + namespace_key + ">"
-
-    def _serialize_empty_namespace(self):
-        self._write_line("PREFIX : <http://weso.es/shapes/>")
-
-    def _serialize_shape(self, a_shape):
-        self._serialize_shape_name(a_shape)
-        # self._serialize_example(a_shape)
-        self._serialize_opening_of_rules()
-        self._serialize_shape_rules(a_shape)
-        self._serialize_closure_of_rule()
-        self._serialize_shape_gap()
-
-    def _flush(self):
-        self._write_lines_buffer()
-
-    def _write_line(self, a_line, indent_level=0):
-        self._lines_buffer.append(self._indentation_spaces(indent_level) + a_line + "\n")
-        if len(self._lines_buffer) >= 5000:
-            self._write_lines_buffer()
-            self._lines_buffer = []
-
-    def _reset_target_file(self):
-        if self._string_return:
-            return
-        with open(self._target_file, "w") as out_stream:
-            out_stream.write("")  # Is this necessary? maybe enough to open it in 'w' mode?
-
-    def _write_lines_buffer(self):
-        if self._string_return:
-            self._string_result += "".join(self._lines_buffer)
-        else:
-            with open(self._target_file, "a") as out_stream:
-                for a_line in self._lines_buffer:
-                    out_stream.write(a_line)
-
-    def _indentation_spaces(self, indent_level):
-        result = ""
-        for i in range(0, indent_level):
-            result += SPACES_LEVEL_INDENTATION
-        return result
-
-    def _serialize_shape_rules(self, a_shape):
-        if a_shape.n_statements == 0:
-            return
-        self._tune_statement_examples_if_needed(a_shape)
-        statements = [a_statement for a_statement in a_shape.yield_statements()]
-
-        for i in range(0, len(statements) - 1):
-            for line_indent_tuple in statements[i]. \
-                    get_tuples_to_serialize_line_indent_level(is_last_statement_of_shape=False,
-                                                              namespaces_dict=self._namespaces_dict):
-                self._write_line(a_line=line_indent_tuple[0],
-                                 indent_level=line_indent_tuple[1])
-        for line_indent_tuple in statements[len(statements) - 1]. \
-                get_tuples_to_serialize_line_indent_level(is_last_statement_of_shape=True,
-                                                          namespaces_dict=self._namespaces_dict):
-            self._write_line(a_line=line_indent_tuple[0],
-                             indent_level=line_indent_tuple[1])
-
-    def _tune_statement_examples_if_needed(self, a_shape):
-        if self._examples_mode not in [ALL_EXAMPLES, CONSTRAINT_EXAMPLES]:
-            return
-        self._add_statement_examples(a_shape)
-
-    def _add_statement_examples(self, a_shape):
-        for a_statement in a_shape.yield_statements():
-            if a_statement.st_property != self._instantiation_property_str:
-                comment = _EXAMPLE_CONSTRAINT_TEMPLATE.format(
-                    self._get_node_constraint_example_no_inverse(a_shape, a_statement) if not self._inverse_paths
-                    else self._get_node_constraint_example_inverse(a_shape, a_statement)
-                )
-
-                a_statement.add_comment(comment, insert_first=True)
-
-
-
-    def _get_node_constraint_example_no_inverse(self, shape, statement):
-        candidate = self._shape_example_features.get_constraint_example(shape_id=shape.class_uri,
-                                                                        prop=statement.st_property)
-        if candidate.startswith("http"):  # Let's assume this means that it is an URI
-            candidate = prefixize_uri_if_possible(target_uri=candidate,
-                                                  namespaces_prefix_dict=self._namespaces_dict,
-                                                  corners=False)
-        return candidate
-
-    def _get_node_constraint_example_inverse(self, shape, statement):
-        candidate = self._shape_example_features.get_constraint_example(shape_id=shape.class_uri,
-                                                                        prop=statement.st_property,
-                                                                        inverse=statement.is_inverse)
-        if candidate.startswith("https://"):  # Let's assume this means that it is a URI
-            candidate = prefixize_uri_if_possible(target_uri=candidate,
-                                                  namespaces_prefix_dict=self._namespaces_dict,
-                                                  corners=False)
-        return candidate
-
-
-    def _serialize_shape_name(self, a_shape):
-        self._write_line(
-
-            prefixize_shape_name_if_possible(a_shape_name=a_shape.name,
-                                             namespaces_prefix_dict=self._namespaces_dict) +
-            self._minimal_iri(a_shape=a_shape) +
-            self._instance_count(a_shape) +
-            self._serialize_example(a_shape)
-        )
-
-    def _serialize_example(self, a_shape):
-        if self._examples_mode not in [ALL_EXAMPLES, SHAPE_EXAMPLES]:
-            return ""
-        return _EXAMPLE_SHAPE_TEMPLATE.format(
-            " " if self._instances_report_mode in _MODES_REPORT_INSTANCES and not self._disable_comments else "   #",
-            self._shape_example_features.shape_example(shape_id=a_shape.class_uri))
-        # self._write_line(
-        #     a_line=_EXAMPLE_SHAPE_TEMPLATE.format(
-        #         self._shape_example_features.shape_example(shape_id=a_shape.class_uri)),
-        #     indent_level=2)
-
-        # self._instances_report_mode in _MODES_REPORT_INSTANCES and not self._disable_comments
-
-
-    def _minimal_iri(self, a_shape):
-        if not self._detect_minimal_iri or self._shape_example_features.shape_min_iri(a_shape.class_uri) is None:
-            return ""
-        return "  [<{}>~]  AND".format(self._shape_example_features.shape_min_iri(a_shape.class_uri))
-
-    def _instance_count(self, a_shape):
-        return "   # {} instance{}.".format(a_shape.n_instances,
-                                            "" if a_shape.n_instances == 1 else "s") \
-            if self._instances_report_mode in _MODES_REPORT_INSTANCES and not self._disable_comments \
-            else ""
-
-    def _serialize_opening_of_rules(self):
-        self._write_line("{")
-
-    def _serialize_closure_of_rule(self):
-        self._write_line("}")
-
-    def _serialize_shape_gap(self):
-        self._write_line("")
-        self._write_line("")
+from shexer.core.profiling.class_profiler import RDF_TYPE_STR
+
+from shexer.model.property import Property
+from shexer.utils.uri import remove_corners, prefixize_uri_if_possible
+from shexer.utils.shapes import prefixize_shape_name_if_possible
+from shexer.io.shex.formater.consts import SPACES_LEVEL_INDENTATION
+from shexer.io.wikidata import wikidata_annotation
+from shexer.io.file import read_file
+from shexer.consts import RATIO_INSTANCES, ABSOLUTE_INSTANCES, MIXED_INSTANCES, ALL_EXAMPLES, SHAPE_EXAMPLES, CONSTRAINT_EXAMPLES
+
+from wlighter import SHEXC_FORMAT
+
+_MODES_REPORT_INSTANCES = [ABSOLUTE_INSTANCES, MIXED_INSTANCES]
+_EXAMPLE_CONSTRAINT_TEMPLATE = "# Node constraint example: '{}'"
+_EXAMPLE_SHAPE_TEMPLATE = "{} Instance example: '{}'"
+
+
+class ShexSerializer(object):
+
+    def __init__(self, target_file, shapes_list, namespaces_dict=None, string_return=False,
+                 instantiation_property_str=RDF_TYPE_STR, disable_comments=False, wikidata_annotation=False,
+                 instances_report_mode=RATIO_INSTANCES, detect_minimal_iri=False, shape_example_features=None,
+                 examples_mode=None, inverse_paths=False):
+        self._target_file = target_file
+        self._shapes_list = shapes_list
+        self._lines_buffer = []
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+        self._string_return = string_return
+        self._instantiation_property_str = self._decide_instantiation_property(instantiation_property_str)
+        self._disable_comments = disable_comments
+        self._wikidata_annotation = wikidata_annotation
+        self._instances_report_mode = instances_report_mode
+        self._detect_minimal_iri = detect_minimal_iri
+        self._examples_mode = examples_mode
+        self._shape_example_features = shape_example_features
+        self._inverse_paths = inverse_paths
+
+        self._string_result = ""
+
+    def serialize_shapes(self):
+
+        self._reset_target_file()
+        self._serialize_namespaces()
+        for a_shape in self._shapes_list:
+            self._serialize_shape(a_shape)
+        self._flush()
+        if self._wikidata_annotation:
+            self._annotate_wikidata_ids_in_result()
+        if self._string_return:
+            return self._string_result
+
+    @staticmethod
+    def _decide_instantiation_property(instantiation_property_str):
+        if instantiation_property_str == None:
+            return RDF_TYPE_STR
+        if type(instantiation_property_str) == Property:
+            return str(instantiation_property_str)
+        if type(instantiation_property_str) == str:
+            return remove_corners(a_uri=instantiation_property_str,
+                                  raise_error_if_no_corners=False)
+        raise ValueError("Unrecognized param type to define instantiation property")
+
+    def _annotate_wikidata_ids_in_result(self):
+        self._string_result = wikidata_annotation(raw_input=self._get_raw_input_for_wikidata_annotation(),
+                                                  string_return=self._string_return,
+                                                  out_file=self._target_file,
+                                                  format=SHEXC_FORMAT,
+                                                  rdfs_comments=True)
+
+    def _get_raw_input_for_wikidata_annotation(self):
+        if self._string_return:
+            return self._string_result
+        return read_file(self._target_file)
+
+    def _serialize_namespaces(self):
+        for a_namespace in self._namespaces_dict:
+            self._write_line(self._prefix_line(a_namespace), 0)
+        self._write_line("", 0)
+
+    def _prefix_line(self, namespace_key):
+        return "PREFIX " + self._namespaces_dict[namespace_key] + ": <" + namespace_key + ">"
+
+    def _serialize_empty_namespace(self):
+        self._write_line("PREFIX : <http://weso.es/shapes/>")
+
+    def _serialize_shape(self, a_shape):
+        self._serialize_shape_name(a_shape)
+        # self._serialize_example(a_shape)
+        self._serialize_opening_of_rules()
+        self._serialize_shape_rules(a_shape)
+        self._serialize_closure_of_rule()
+        self._serialize_shape_gap()
+
+    def _flush(self):
+        self._write_lines_buffer()
+
+    def _write_line(self, a_line, indent_level=0):
+        self._lines_buffer.append(self._indentation_spaces(indent_level) + a_line + "\n")
+        if len(self._lines_buffer) >= 5000:
+            self._write_lines_buffer()
+            self._lines_buffer = []
+
+    def _reset_target_file(self):
+        if self._string_return:
+            return
+        with open(self._target_file, "w") as out_stream:
+            out_stream.write("")  # Is this necessary? maybe enough to open it in 'w' mode?
+
+    def _write_lines_buffer(self):
+        if self._string_return:
+            self._string_result += "".join(self._lines_buffer)
+        else:
+            with open(self._target_file, "a") as out_stream:
+                for a_line in self._lines_buffer:
+                    out_stream.write(a_line)
+
+    def _indentation_spaces(self, indent_level):
+        result = ""
+        for i in range(0, indent_level):
+            result += SPACES_LEVEL_INDENTATION
+        return result
+
+    def _serialize_shape_rules(self, a_shape):
+        if a_shape.n_statements == 0:
+            return
+        self._tune_statement_examples_if_needed(a_shape)
+        statements = [a_statement for a_statement in a_shape.yield_statements()]
+
+        for i in range(0, len(statements) - 1):
+            for line_indent_tuple in statements[i]. \
+                    get_tuples_to_serialize_line_indent_level(is_last_statement_of_shape=False,
+                                                              namespaces_dict=self._namespaces_dict):
+                self._write_line(a_line=line_indent_tuple[0],
+                                 indent_level=line_indent_tuple[1])
+        for line_indent_tuple in statements[len(statements) - 1]. \
+                get_tuples_to_serialize_line_indent_level(is_last_statement_of_shape=True,
+                                                          namespaces_dict=self._namespaces_dict):
+            self._write_line(a_line=line_indent_tuple[0],
+                             indent_level=line_indent_tuple[1])
+
+    def _tune_statement_examples_if_needed(self, a_shape):
+        if self._examples_mode not in [ALL_EXAMPLES, CONSTRAINT_EXAMPLES]:
+            return
+        self._add_statement_examples(a_shape)
+
+    def _add_statement_examples(self, a_shape):
+        for a_statement in a_shape.yield_statements():
+            if a_statement.st_property != self._instantiation_property_str:
+                comment = _EXAMPLE_CONSTRAINT_TEMPLATE.format(
+                    self._get_node_constraint_example_no_inverse(a_shape, a_statement) if not self._inverse_paths
+                    else self._get_node_constraint_example_inverse(a_shape, a_statement)
+                )
+
+                a_statement.add_comment(comment, insert_first=True)
+
+
+
+    def _get_node_constraint_example_no_inverse(self, shape, statement):
+        candidate = self._shape_example_features.get_constraint_example(shape_id=shape.class_uri,
+                                                                        prop=statement.st_property)
+        if candidate.startswith("http"):  # Let's assume this means that it is an URI
+            candidate = prefixize_uri_if_possible(target_uri=candidate,
+                                                  namespaces_prefix_dict=self._namespaces_dict,
+                                                  corners=False)
+        return candidate
+
+    def _get_node_constraint_example_inverse(self, shape, statement):
+        candidate = self._shape_example_features.get_constraint_example(shape_id=shape.class_uri,
+                                                                        prop=statement.st_property,
+                                                                        inverse=statement.is_inverse)
+        if candidate.startswith("https://"):  # Let's assume this means that it is a URI
+            candidate = prefixize_uri_if_possible(target_uri=candidate,
+                                                  namespaces_prefix_dict=self._namespaces_dict,
+                                                  corners=False)
+        return candidate
+
+
+    def _serialize_shape_name(self, a_shape):
+        self._write_line(
+
+            prefixize_shape_name_if_possible(a_shape_name=a_shape.name,
+                                             namespaces_prefix_dict=self._namespaces_dict) +
+            self._minimal_iri(a_shape=a_shape) +
+            self._instance_count(a_shape) +
+            self._serialize_example(a_shape)
+        )
+
+    def _serialize_example(self, a_shape):
+        if self._examples_mode not in [ALL_EXAMPLES, SHAPE_EXAMPLES]:
+            return ""
+        return _EXAMPLE_SHAPE_TEMPLATE.format(
+            " " if self._instances_report_mode in _MODES_REPORT_INSTANCES and not self._disable_comments else "   #",
+            self._shape_example_features.shape_example(shape_id=a_shape.class_uri))
+        # self._write_line(
+        #     a_line=_EXAMPLE_SHAPE_TEMPLATE.format(
+        #         self._shape_example_features.shape_example(shape_id=a_shape.class_uri)),
+        #     indent_level=2)
+
+        # self._instances_report_mode in _MODES_REPORT_INSTANCES and not self._disable_comments
+
+
+    def _minimal_iri(self, a_shape):
+        if not self._detect_minimal_iri or self._shape_example_features.shape_min_iri(a_shape.class_uri) is None:
+            return ""
+        return "  [<{}>~]  AND".format(self._shape_example_features.shape_min_iri(a_shape.class_uri))
+
+    def _instance_count(self, a_shape):
+        return "   # {} instance{}.".format(a_shape.n_instances,
+                                            "" if a_shape.n_instances == 1 else "s") \
+            if self._instances_report_mode in _MODES_REPORT_INSTANCES and not self._disable_comments \
+            else ""
+
+    def _serialize_opening_of_rules(self):
+        self._write_line("{")
+
+    def _serialize_closure_of_rule(self):
+        self._write_line("}")
+
+    def _serialize_shape_gap(self):
+        self._write_line("")
+        self._write_line("")
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/statement_serializers/base_statement_serializer.py` & `shexer-2.5.2/shexer/io/shex/formater/statement_serializers/base_statement_serializer.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,129 +1,129 @@
-from shexer.io.shex.formater.consts import SPACES_GAP_BETWEEN_TOKENS, \
-    COMMENT_INI, TARGET_LINE_LENGHT, SPACES_GAP_FOR_FREQUENCY, KLEENE_CLOSURE, POSITIVE_CLOSURE, OPT_CARDINALITY
-from shexer.model.IRI import IRI_ELEM_TYPE
-from shexer.model.shape import STARTING_CHAR_FOR_SHAPE_NAME
-from shexer.utils.shapes import prefixize_shape_name_if_possible
-
-_INVERSE_SENSE_SHEXC = "^"
-
-class BaseStatementSerializer(object):
-
-    def __init__(self, instantiation_property_str, frequency_serializer, disable_comments=False, is_inverse=False):
-        self._instantiation_property_str = instantiation_property_str
-        self._disable_comments = disable_comments
-        self._is_inverse = is_inverse
-        self._frequency_serializer = frequency_serializer
-
-    def serialize_statement_with_indent_level(self, a_statement, is_last_statement_of_shape, namespaces_dict):
-        tuples_line_indent = []
-        st_property = BaseStatementSerializer.tune_token(a_statement.st_property, namespaces_dict)
-        st_target_element = self.str_of_target_element(target_element=a_statement.st_type,
-                                                       st_property=a_statement.st_property,
-                                                       namespaces_dict=namespaces_dict)
-        cardinality = BaseStatementSerializer.cardinality_representation(
-            statement=a_statement,
-            out_of_comment=True)
-        result = self._sense_flag() + st_property + SPACES_GAP_BETWEEN_TOKENS + st_target_element + SPACES_GAP_BETWEEN_TOKENS + \
-                 cardinality + BaseStatementSerializer.closure_of_statement(is_last_statement_of_shape)
-
-        if a_statement.cardinality not in [KLEENE_CLOSURE, OPT_CARDINALITY] and not self._disable_comments:
-            result += BaseStatementSerializer.adequate_amount_of_final_spaces(result)
-            result += a_statement.probability_representation()
-        tuples_line_indent.append((result, 1))
-
-        for a_comment in a_statement.comments:
-            tuples_line_indent.append((a_comment, 4))
-
-        return tuples_line_indent
-
-    def str_of_target_element(self, target_element, st_property, namespaces_dict):
-        """
-        Special treatment for instantiation_property. We build a value set with an specific URI
-        :param target_element:
-        :param st_property:
-        :param namespaces_dict:
-        :return:
-        """
-        if st_property == self._instantiation_property_str:
-            return "[" + BaseStatementSerializer.tune_token(target_element, namespaces_dict) + "]"
-        return BaseStatementSerializer.tune_token(target_element, namespaces_dict)
-
-    @staticmethod
-    def tune_token(a_token, namespaces_dict):
-        # TODO:  a lot to correct here for normal behaviour
-        if a_token.startswith(STARTING_CHAR_FOR_SHAPE_NAME):  # Shape
-            # return STARTING_CHAR_FOR_SHAPE_NAME +":" + a_token.replace(STARTING_CHAR_FOR_SHAPE_NAME, "")
-            return STARTING_CHAR_FOR_SHAPE_NAME \
-                   + prefixize_shape_name_if_possible(a_shape_name=a_token,
-                                                      namespaces_prefix_dict=namespaces_dict)
-        if a_token == IRI_ELEM_TYPE:  # iri
-            return a_token
-        if ":" not in a_token:
-            if "<" in a_token:
-                return STARTING_CHAR_FOR_SHAPE_NAME + a_token
-            else:
-                return STARTING_CHAR_FOR_SHAPE_NAME + "<" + a_token + ">"
-        candidate_prefixed = BaseStatementSerializer._prefixize_uri_if_possible(uri=a_token,
-                                                                                namespaces_dict=namespaces_dict)
-        if candidate_prefixed is not None:
-            return candidate_prefixed
-
-        return "<" + a_token + ">"  # Complete URIs
-
-    @staticmethod
-    def _prefixize_uri_if_possible(uri, namespaces_dict):
-        """
-        It returns None it it doesnt find an adequate prefix
-
-        :param uri:
-        :param namespaces_dict:
-        :return:
-        """
-        best_match = None
-        for a_namespace in namespaces_dict:  # Prefixed element (all literals are prefixed elements)
-            if uri.startswith(a_namespace):
-                if "/" not in uri[len(a_namespace):] and \
-                        "#" not in uri[len(a_namespace):]:
-                    best_match = a_namespace
-                    break
-
-        return None if best_match is None else uri.replace(best_match, namespaces_dict[best_match] + ":")
-
-
-    def probability_representation(self, statement):
-        return COMMENT_INI + self._frequency_serializer.serialize_frequency(statement)
-
-    @staticmethod
-    def cardinality_representation(statement, out_of_comment=False):
-        cardinality = statement.cardinality
-        if out_of_comment and cardinality == 1:
-            return ""
-        if cardinality in [POSITIVE_CLOSURE, KLEENE_CLOSURE, OPT_CARDINALITY]:
-            return cardinality
-        else:
-            return "{" + str(cardinality) + "}"
-
-    @staticmethod
-    def closure_of_statement(is_last_statement):
-        if is_last_statement:
-            return ""
-        return ";"
-
-    @staticmethod
-    def adequate_amount_of_final_spaces(current_line):
-        if len(current_line) > TARGET_LINE_LENGHT - 10:
-            return SPACES_GAP_FOR_FREQUENCY
-        result = ""
-        for i in range(0, TARGET_LINE_LENGHT - len(current_line)):
-            result += " "
-        return result
-
-    @staticmethod
-    def turn_statement_into_comment(statement, namespaces_dict):
-        return statement.probability_representation() + \
-               " obj: " + BaseStatementSerializer.tune_token(statement.st_type,
-                                                             namespaces_dict) + \
-               ". Cardinality: " + statement.cardinality_representation()
-
-    def _sense_flag(self):
-        return "" if not self._is_inverse else _INVERSE_SENSE_SHEXC + SPACES_GAP_BETWEEN_TOKENS
+from shexer.io.shex.formater.consts import SPACES_GAP_BETWEEN_TOKENS, \
+    COMMENT_INI, TARGET_LINE_LENGHT, SPACES_GAP_FOR_FREQUENCY, KLEENE_CLOSURE, POSITIVE_CLOSURE, OPT_CARDINALITY
+from shexer.model.IRI import IRI_ELEM_TYPE
+from shexer.model.shape import STARTING_CHAR_FOR_SHAPE_NAME
+from shexer.utils.shapes import prefixize_shape_name_if_possible
+
+_INVERSE_SENSE_SHEXC = "^"
+
+class BaseStatementSerializer(object):
+
+    def __init__(self, instantiation_property_str, frequency_serializer, disable_comments=False, is_inverse=False):
+        self._instantiation_property_str = instantiation_property_str
+        self._disable_comments = disable_comments
+        self._is_inverse = is_inverse
+        self._frequency_serializer = frequency_serializer
+
+    def serialize_statement_with_indent_level(self, a_statement, is_last_statement_of_shape, namespaces_dict):
+        tuples_line_indent = []
+        st_property = BaseStatementSerializer.tune_token(a_statement.st_property, namespaces_dict)
+        st_target_element = self.str_of_target_element(target_element=a_statement.st_type,
+                                                       st_property=a_statement.st_property,
+                                                       namespaces_dict=namespaces_dict)
+        cardinality = BaseStatementSerializer.cardinality_representation(
+            statement=a_statement,
+            out_of_comment=True)
+        result = self._sense_flag() + st_property + SPACES_GAP_BETWEEN_TOKENS + st_target_element + SPACES_GAP_BETWEEN_TOKENS + \
+                 cardinality + BaseStatementSerializer.closure_of_statement(is_last_statement_of_shape)
+
+        if a_statement.cardinality not in [KLEENE_CLOSURE, OPT_CARDINALITY] and not self._disable_comments:
+            result += BaseStatementSerializer.adequate_amount_of_final_spaces(result)
+            result += a_statement.probability_representation()
+        tuples_line_indent.append((result, 1))
+
+        for a_comment in a_statement.comments:
+            tuples_line_indent.append((a_comment, 4))
+
+        return tuples_line_indent
+
+    def str_of_target_element(self, target_element, st_property, namespaces_dict):
+        """
+        Special treatment for instantiation_property. We build a value set with an specific URI
+        :param target_element:
+        :param st_property:
+        :param namespaces_dict:
+        :return:
+        """
+        if st_property == self._instantiation_property_str:
+            return "[" + BaseStatementSerializer.tune_token(target_element, namespaces_dict) + "]"
+        return BaseStatementSerializer.tune_token(target_element, namespaces_dict)
+
+    @staticmethod
+    def tune_token(a_token, namespaces_dict):
+        # TODO:  a lot to correct here for normal behaviour
+        if a_token.startswith(STARTING_CHAR_FOR_SHAPE_NAME):  # Shape
+            # return STARTING_CHAR_FOR_SHAPE_NAME +":" + a_token.replace(STARTING_CHAR_FOR_SHAPE_NAME, "")
+            return STARTING_CHAR_FOR_SHAPE_NAME \
+                   + prefixize_shape_name_if_possible(a_shape_name=a_token,
+                                                      namespaces_prefix_dict=namespaces_dict)
+        if a_token == IRI_ELEM_TYPE:  # iri
+            return a_token
+        if ":" not in a_token:
+            if "<" in a_token:
+                return STARTING_CHAR_FOR_SHAPE_NAME + a_token
+            else:
+                return STARTING_CHAR_FOR_SHAPE_NAME + "<" + a_token + ">"
+        candidate_prefixed = BaseStatementSerializer._prefixize_uri_if_possible(uri=a_token,
+                                                                                namespaces_dict=namespaces_dict)
+        if candidate_prefixed is not None:
+            return candidate_prefixed
+
+        return "<" + a_token + ">"  # Complete URIs
+
+    @staticmethod
+    def _prefixize_uri_if_possible(uri, namespaces_dict):
+        """
+        It returns None it it doesnt find an adequate prefix
+
+        :param uri:
+        :param namespaces_dict:
+        :return:
+        """
+        best_match = None
+        for a_namespace in namespaces_dict:  # Prefixed element (all literals are prefixed elements)
+            if uri.startswith(a_namespace):
+                if "/" not in uri[len(a_namespace):] and \
+                        "#" not in uri[len(a_namespace):]:
+                    best_match = a_namespace
+                    break
+
+        return None if best_match is None else uri.replace(best_match, namespaces_dict[best_match] + ":")
+
+
+    def probability_representation(self, statement):
+        return COMMENT_INI + self._frequency_serializer.serialize_frequency(statement)
+
+    @staticmethod
+    def cardinality_representation(statement, out_of_comment=False):
+        cardinality = statement.cardinality
+        if out_of_comment and cardinality == 1:
+            return ""
+        if cardinality in [POSITIVE_CLOSURE, KLEENE_CLOSURE, OPT_CARDINALITY]:
+            return cardinality
+        else:
+            return "{" + str(cardinality) + "}"
+
+    @staticmethod
+    def closure_of_statement(is_last_statement):
+        if is_last_statement:
+            return ""
+        return ";"
+
+    @staticmethod
+    def adequate_amount_of_final_spaces(current_line):
+        if len(current_line) > TARGET_LINE_LENGHT - 10:
+            return SPACES_GAP_FOR_FREQUENCY
+        result = ""
+        for i in range(0, TARGET_LINE_LENGHT - len(current_line)):
+            result += " "
+        return result
+
+    @staticmethod
+    def turn_statement_into_comment(statement, namespaces_dict):
+        return statement.probability_representation() + \
+               " obj: " + BaseStatementSerializer.tune_token(statement.st_type,
+                                                             namespaces_dict) + \
+               ". Cardinality: " + statement.cardinality_representation()
+
+    def _sense_flag(self):
+        return "" if not self._is_inverse else _INVERSE_SENSE_SHEXC + SPACES_GAP_BETWEEN_TOKENS
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/statement_serializers/fixed_prop_choice_statement_serializer.py` & `shexer-2.5.2/shexer/io/shex/formater/statement_serializers/fixed_prop_choice_statement_serializer.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,39 +1,39 @@
-from shexer.io.shex.formater.statement_serializers.base_statement_serializer import BaseStatementSerializer
-from shexer.io.shex.formater.consts import SPACES_GAP_BETWEEN_TOKENS, KLEENE_CLOSURE, OPT_CARDINALITY
-
-
-class FixedPropChoiceStatementSerializer(BaseStatementSerializer):
-
-    def __init__(self, instantiation_property_str, frequency_serializer, disable_comments=False, is_inverse=False):
-        super(FixedPropChoiceStatementSerializer, self).__init__(instantiation_property_str=instantiation_property_str,
-                                                                 disable_comments=disable_comments,
-                                                                 is_inverse=is_inverse,
-                                                                 frequency_serializer=frequency_serializer)
-
-    def serialize_statement_with_indent_level(self, a_statement, is_last_statement_of_shape, namespaces_dict):
-        tuples_line_indent = []
-        st_property = BaseStatementSerializer.tune_token(a_statement.st_property, namespaces_dict)
-        st_target_elements = []
-        for a_type in a_statement.st_types:
-            st_target_elements.append(self.str_of_target_element(target_element=a_type,
-                                                                 st_property=a_statement.st_property,
-                                                                 namespaces_dict=namespaces_dict))
-
-        content_line = st_property + SPACES_GAP_BETWEEN_TOKENS
-        content_line += (SPACES_GAP_BETWEEN_TOKENS + "OR" + SPACES_GAP_BETWEEN_TOKENS).join(st_target_elements)
-        content_line += SPACES_GAP_BETWEEN_TOKENS + BaseStatementSerializer.cardinality_representation(
-            statement=a_statement,
-            out_of_comment=True)
-        content_line += ";" if not is_last_statement_of_shape else ""
-        tuples_line_indent.append((content_line, 1))
-
-
-        for a_comment in a_statement.comments:
-            tuples_line_indent.append((a_comment, 4))
-        return tuples_line_indent
-
-
-    @staticmethod
-    def turn_statement_into_comment(statement, namespaces_dict):
-        return statement.probability_representation() + \
-               " with cardinality " + statement.cardinality_representation()
+from shexer.io.shex.formater.statement_serializers.base_statement_serializer import BaseStatementSerializer
+from shexer.io.shex.formater.consts import SPACES_GAP_BETWEEN_TOKENS, KLEENE_CLOSURE, OPT_CARDINALITY
+
+
+class FixedPropChoiceStatementSerializer(BaseStatementSerializer):
+
+    def __init__(self, instantiation_property_str, frequency_serializer, disable_comments=False, is_inverse=False):
+        super(FixedPropChoiceStatementSerializer, self).__init__(instantiation_property_str=instantiation_property_str,
+                                                                 disable_comments=disable_comments,
+                                                                 is_inverse=is_inverse,
+                                                                 frequency_serializer=frequency_serializer)
+
+    def serialize_statement_with_indent_level(self, a_statement, is_last_statement_of_shape, namespaces_dict):
+        tuples_line_indent = []
+        st_property = BaseStatementSerializer.tune_token(a_statement.st_property, namespaces_dict)
+        st_target_elements = []
+        for a_type in a_statement.st_types:
+            st_target_elements.append(self.str_of_target_element(target_element=a_type,
+                                                                 st_property=a_statement.st_property,
+                                                                 namespaces_dict=namespaces_dict))
+
+        content_line = st_property + SPACES_GAP_BETWEEN_TOKENS
+        content_line += (SPACES_GAP_BETWEEN_TOKENS + "OR" + SPACES_GAP_BETWEEN_TOKENS).join(st_target_elements)
+        content_line += SPACES_GAP_BETWEEN_TOKENS + BaseStatementSerializer.cardinality_representation(
+            statement=a_statement,
+            out_of_comment=True)
+        content_line += ";" if not is_last_statement_of_shape else ""
+        tuples_line_indent.append((content_line, 1))
+
+
+        for a_comment in a_statement.comments:
+            tuples_line_indent.append((a_comment, 4))
+        return tuples_line_indent
+
+
+    @staticmethod
+    def turn_statement_into_comment(statement, namespaces_dict):
+        return statement.probability_representation() + \
+               " with cardinality " + statement.cardinality_representation()
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/mixed_frequency_strategy.py` & `shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/mixed_frequency_strategy.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.base_frequency_strategy import BaseFrequencyStrategy
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.abs_freq_serializer import AbsFreqSerializer
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.ratio_freq_serializer import RatioFreqSerializer
-
-class MixedFrequencyStrategy(BaseFrequencyStrategy):
-
-    def __init__(self, decimals=-1):
-        self._abs_strategy = AbsFreqSerializer()
-        self._ratio_strategy = RatioFreqSerializer(decimals=decimals)
-
-    def serialize_frequency(self, statement):
-        # The abs_strategy return a trailing dot that we want to skip. That why I use slicing here
-        return self._ratio_strategy.serialize_frequency(statement) + \
-               " (" + self._abs_strategy.serialize_frequency(statement)[:-1] + ")."
-
-
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.base_frequency_strategy import BaseFrequencyStrategy
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.abs_freq_serializer import AbsFreqSerializer
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.ratio_freq_serializer import RatioFreqSerializer
+
+class MixedFrequencyStrategy(BaseFrequencyStrategy):
+
+    def __init__(self, decimals=-1):
+        self._abs_strategy = AbsFreqSerializer()
+        self._ratio_strategy = RatioFreqSerializer(decimals=decimals)
+
+    def serialize_frequency(self, statement):
+        # The abs_strategy return a trailing dot that we want to skip. That why I use slicing here
+        return self._ratio_strategy.serialize_frequency(statement) + \
+               " (" + self._abs_strategy.serialize_frequency(statement)[:-1] + ")."
+
+
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/statement_serializers/frequency_strategy/ratio_freq_serializer.py` & `shexer-2.5.2/shexer/io/shex/formater/statement_serializers/frequency_strategy/ratio_freq_serializer.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,31 +1,31 @@
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.base_frequency_strategy import BaseFrequencyStrategy
-
-class RatioFreqSerializer(BaseFrequencyStrategy):
-
-    def __init__(self, decimals=-1):
-        """
-
-        :param decimals: it indicates the number of decimals to use to express ratios.
-                        When a negative number is provided, decimals won't be controlled
-        """
-        self._decimals=decimals
-        if decimals < 0:
-            self.serialize_frequency = self._serialize_freq_unbounded
-        elif decimals ==0:
-            self.serialize_frequency = self._serialize_freq_int
-        else:
-            self.serialize_frequency = self._serialize_freq_decimals
-
-
-    def serialize_frequency(self, statement):
-        raise NotImplementedError("This function will be initialized with a callback during the __init__")
-
-    def _serialize_freq_unbounded(self, statement):
-        return str(statement.probability * 100) + " %"
-
-    def _serialize_freq_decimals(self, statement):
-        pattern = "{:." + str(self._decimals) +"f} %"
-        return pattern.format(statement.probability*100)
-
-    def _serialize_freq_int(self, statement):
-        return str(int(statement.probability * 100)) + " %"
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.base_frequency_strategy import BaseFrequencyStrategy
+
+class RatioFreqSerializer(BaseFrequencyStrategy):
+
+    def __init__(self, decimals=-1):
+        """
+
+        :param decimals: it indicates the number of decimals to use to express ratios.
+                        When a negative number is provided, decimals won't be controlled
+        """
+        self._decimals=decimals
+        if decimals < 0:
+            self.serialize_frequency = self._serialize_freq_unbounded
+        elif decimals ==0:
+            self.serialize_frequency = self._serialize_freq_int
+        else:
+            self.serialize_frequency = self._serialize_freq_decimals
+
+
+    def serialize_frequency(self, statement):
+        raise NotImplementedError("This function will be initialized with a callback during the __init__")
+
+    def _serialize_freq_unbounded(self, statement):
+        return str(statement.probability * 100) + " %"
+
+    def _serialize_freq_decimals(self, statement):
+        pattern = "{:." + str(self._decimals) +"f} %"
+        return pattern.format(statement.probability*100)
+
+    def _serialize_freq_int(self, statement):
+        return str(int(statement.probability * 100)) + " %"
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/statement_serializers/inverse_statement_serializer.py` & `shexer-2.5.2/shexer/io/shex/formater/statement_serializers/inverse_statement_serializer.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,32 +1,32 @@
-from shexer.io.shex.formater.statement_serializers.base_statement_serializer import BaseStatementSerializer, \
-    SPACES_GAP_BETWEEN_TOKENS
-
-#
-# class InverseStatementSerializer(BaseStatementSerializer):
-#
-#     def __init__(self, ref_statement_serializer):
-#         super().__init__(ref_statement_serializer._instantiation_property_str)
-#         self._ref_statement_serializer = ref_statement_serializer
-#
-#     def serialize_statement_with_indent_level(self, a_statement, is_last_statement_of_shape, namespaces_dict):
-#         base_result = super().serialize_statement_with_indent_level(
-#             a_statement=a_statement,
-#             is_last_statement_of_shape=is_last_statement_of_shape,
-#             namespaces_dict=namespaces_dict)
-#         if len(base_result) == 0:
-#             return base_result
-#         self._add_inverse_sense_to_first_tuple(base_result)
-#         return base_result
-#
-#     def _add_inverse_sense_to_first_tuple(self, statement_str_indent_tuples):
-#         """
-#         This method modifies the input, no return needed.
-#         :param statement_str_indent_tuples:
-#         :return:
-#         """
-#         statement_str_indent_tuples[0][0] = _INVERSE_SENSE_SHEXC + \
-#                                             SPACES_GAP_BETWEEN_TOKENS + \
-#                                             statement_str_indent_tuples[0][0]
-#
-#     def _sense_flag(self):
-#         return _INVERSE_SENSE_SHEXC + SPACES_GAP_BETWEEN_TOKENS
+from shexer.io.shex.formater.statement_serializers.base_statement_serializer import BaseStatementSerializer, \
+    SPACES_GAP_BETWEEN_TOKENS
+
+#
+# class InverseStatementSerializer(BaseStatementSerializer):
+#
+#     def __init__(self, ref_statement_serializer):
+#         super().__init__(ref_statement_serializer._instantiation_property_str)
+#         self._ref_statement_serializer = ref_statement_serializer
+#
+#     def serialize_statement_with_indent_level(self, a_statement, is_last_statement_of_shape, namespaces_dict):
+#         base_result = super().serialize_statement_with_indent_level(
+#             a_statement=a_statement,
+#             is_last_statement_of_shape=is_last_statement_of_shape,
+#             namespaces_dict=namespaces_dict)
+#         if len(base_result) == 0:
+#             return base_result
+#         self._add_inverse_sense_to_first_tuple(base_result)
+#         return base_result
+#
+#     def _add_inverse_sense_to_first_tuple(self, statement_str_indent_tuples):
+#         """
+#         This method modifies the input, no return needed.
+#         :param statement_str_indent_tuples:
+#         :return:
+#         """
+#         statement_str_indent_tuples[0][0] = _INVERSE_SENSE_SHEXC + \
+#                                             SPACES_GAP_BETWEEN_TOKENS + \
+#                                             statement_str_indent_tuples[0][0]
+#
+#     def _sense_flag(self):
+#         return _INVERSE_SENSE_SHEXC + SPACES_GAP_BETWEEN_TOKENS
```

### Comparing `shexer-2.5.1/shexer/io/shex/formater/statement_serializers/st_serializers_factory.py` & `shexer-2.5.2/shexer/io/shex/formater/statement_serializers/st_serializers_factory.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,57 +1,57 @@
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.abs_freq_serializer import AbsFreqSerializer
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.ratio_freq_serializer import RatioFreqSerializer
-from shexer.io.shex.formater.statement_serializers.frequency_strategy.mixed_frequency_strategy import MixedFrequencyStrategy
-from shexer.io.shex.formater.statement_serializers.base_statement_serializer import BaseStatementSerializer
-from shexer.io.shex.formater.statement_serializers.fixed_prop_choice_statement_serializer import FixedPropChoiceStatementSerializer
-from shexer.consts import RATIO_INSTANCES, ABSOLUTE_INSTANCES, MIXED_INSTANCES
-
-class StSerializerFactory(object):
-    """
-    This factory offers public method with Singletons*. They are not really singletons, as a battery
-    of objects are always initialized, no matter which calls the factory receives.
-
-    But the point here is that there is only one isntance of each type of serializer.
-
-    """
-
-    def __init__(self, freq_mode, decimals, instantiation_property_str, disable_comments):
-        self._freq_serializer = self._build_freq_serializer(freq_mode=freq_mode,
-                                                            decimals=decimals)
-
-        self._direct_base = BaseStatementSerializer(
-                instantiation_property_str=instantiation_property_str,
-                disable_comments=disable_comments,
-                is_inverse=False,
-                frequency_serializer=self._freq_serializer)
-        self._inverse_base = BaseStatementSerializer(
-                instantiation_property_str=instantiation_property_str,
-                disable_comments=disable_comments,
-                is_inverse=True,
-                frequency_serializer=self._freq_serializer)
-        self._direct_choice = FixedPropChoiceStatementSerializer(
-                instantiation_property_str=instantiation_property_str,
-                disable_comments=disable_comments,
-                is_inverse=False,
-                frequency_serializer=self._freq_serializer)
-        self._inverse_choice = FixedPropChoiceStatementSerializer(
-                instantiation_property_str=instantiation_property_str,
-                disable_comments=disable_comments,
-                is_inverse=True,
-                frequency_serializer=self._freq_serializer)
-
-    def get_base_serializer(self, is_inverse):
-        return self._direct_base if not is_inverse else self._inverse_base
-
-    def get_choice_serializer(self, is_inverse):
-        return self._direct_choice if not is_inverse else self._inverse_choice
-
-    def _build_freq_serializer(self, freq_mode, decimals):
-        if freq_mode == RATIO_INSTANCES:
-            return RatioFreqSerializer(decimals=decimals)
-        elif freq_mode == ABSOLUTE_INSTANCES:
-            return AbsFreqSerializer()
-        elif freq_mode == MIXED_INSTANCES:
-            return MixedFrequencyStrategy(decimals=decimals)
-        else:
-            raise ValueError("Unrecognized frequency strategy for serialization. "
-                             "Check you used a valid value in the instances_report_mode param")
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.abs_freq_serializer import AbsFreqSerializer
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.ratio_freq_serializer import RatioFreqSerializer
+from shexer.io.shex.formater.statement_serializers.frequency_strategy.mixed_frequency_strategy import MixedFrequencyStrategy
+from shexer.io.shex.formater.statement_serializers.base_statement_serializer import BaseStatementSerializer
+from shexer.io.shex.formater.statement_serializers.fixed_prop_choice_statement_serializer import FixedPropChoiceStatementSerializer
+from shexer.consts import RATIO_INSTANCES, ABSOLUTE_INSTANCES, MIXED_INSTANCES
+
+class StSerializerFactory(object):
+    """
+    This factory offers public method with Singletons*. They are not really singletons, as a battery
+    of objects are always initialized, no matter which calls the factory receives.
+
+    But the point here is that there is only one isntance of each type of serializer.
+
+    """
+
+    def __init__(self, freq_mode, decimals, instantiation_property_str, disable_comments):
+        self._freq_serializer = self._build_freq_serializer(freq_mode=freq_mode,
+                                                            decimals=decimals)
+
+        self._direct_base = BaseStatementSerializer(
+                instantiation_property_str=instantiation_property_str,
+                disable_comments=disable_comments,
+                is_inverse=False,
+                frequency_serializer=self._freq_serializer)
+        self._inverse_base = BaseStatementSerializer(
+                instantiation_property_str=instantiation_property_str,
+                disable_comments=disable_comments,
+                is_inverse=True,
+                frequency_serializer=self._freq_serializer)
+        self._direct_choice = FixedPropChoiceStatementSerializer(
+                instantiation_property_str=instantiation_property_str,
+                disable_comments=disable_comments,
+                is_inverse=False,
+                frequency_serializer=self._freq_serializer)
+        self._inverse_choice = FixedPropChoiceStatementSerializer(
+                instantiation_property_str=instantiation_property_str,
+                disable_comments=disable_comments,
+                is_inverse=True,
+                frequency_serializer=self._freq_serializer)
+
+    def get_base_serializer(self, is_inverse):
+        return self._direct_base if not is_inverse else self._inverse_base
+
+    def get_choice_serializer(self, is_inverse):
+        return self._direct_choice if not is_inverse else self._inverse_choice
+
+    def _build_freq_serializer(self, freq_mode, decimals):
+        if freq_mode == RATIO_INSTANCES:
+            return RatioFreqSerializer(decimals=decimals)
+        elif freq_mode == ABSOLUTE_INSTANCES:
+            return AbsFreqSerializer()
+        elif freq_mode == MIXED_INSTANCES:
+            return MixedFrequencyStrategy(decimals=decimals)
+        else:
+            raise ValueError("Unrecognized frequency strategy for serialization. "
+                             "Check you used a valid value in the instances_report_mode param")
```

### Comparing `shexer-2.5.1/shexer/io/sparql/query.py` & `shexer-2.5.2/shexer/io/sparql/query.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,105 +1,105 @@
-from SPARQLWrapper import SPARQLWrapper, JSON
-from urllib.error import HTTPError
-from time import sleep
-import ssl
-ssl._create_default_https_context = ssl._create_unverified_context
-
-from SPARQLWrapper.SPARQLExceptions import EndPointInternalError
-
-_FAKE_USER_AGENT = "Mozilla/5.0 (Platform; Security; OS-or-CPU; Localization; rv:1.4) Gecko/20030624 Netscape/7.1 (ax)"
-_RESULTS_KEY = "results"
-_BINDINGS_KEY = "bindings"
-_VALUE_KEY = "value"
-_TYPE_KEY = "type"
-_URI_TYPE = "uri"
-
-_XML_LANG_FIELD = "xml:lang"
-
-
-def _add_lang_if_needed(result_dict):
-    result = result_dict[_VALUE_KEY]
-    if _XML_LANG_FIELD in result_dict:
-        result += '"' + result + '"@' + result_dict[_XML_LANG_FIELD]
-    return result
-
-
-def _add_corners_if_needed(target_elem, elem_type):
-    if elem_type == _URI_TYPE and not target_elem.startswith("<"):
-        return "<" + target_elem + ">"
-    return target_elem
-
-
-def query_endpoint_single_variable(endpoint_url, str_query, variable_id, max_retries=10, sleep_time=5, fake_user_agent=True):
-    """
-    It receives an SPARQL query with a single variable and returns a list with the resulting nodes
-
-    :param endpoint_url:
-    :param str_query:
-    :param variable_id:
-    :return:
-    """
-    result_query = _query_endpoint_json_result(endpoint_url=endpoint_url,
-                                               str_query=str_query,
-                                               max_retries=max_retries,
-                                               sleep_time=sleep_time,
-                                               fake_user_agent=fake_user_agent)
-    result = []
-    for row in result_query[_RESULTS_KEY][_BINDINGS_KEY]:
-        an_elem = row[variable_id][_VALUE_KEY]
-        result.append(an_elem)
-    return result
-
-
-def query_endpoint_sp_of_an_o(endpoint_url, str_query, s_id, p_id, max_retries=5, sleep_time=2, fake_user_agent=True):
-    result_query = _query_endpoint_json_result(endpoint_url=endpoint_url,
-                                               str_query=str_query,
-                                               max_retries=max_retries,
-                                               sleep_time=sleep_time,
-                                               fake_user_agent=fake_user_agent)
-    result = []
-    for row in result_query[_RESULTS_KEY][_BINDINGS_KEY]:
-        p_value = _add_corners_if_needed(target_elem=row[p_id][_VALUE_KEY],
-                                         elem_type=row[p_id][_TYPE_KEY])
-        s_value = _add_corners_if_needed(target_elem=_add_lang_if_needed(row[s_id]),
-                                         elem_type=row[s_id][_TYPE_KEY])
-        result.append((s_value, p_value))
-    return result
-
-
-def query_endpoint_po_of_an_s(endpoint_url, str_query, p_id, o_id, max_retries=5, sleep_time=2, fake_user_agent=True):
-
-    result_query = _query_endpoint_json_result(endpoint_url=endpoint_url,
-                                               str_query=str_query,
-                                               max_retries=max_retries,
-                                               sleep_time=sleep_time,
-                                               fake_user_agent=fake_user_agent)
-    result = []
-    for row in result_query[_RESULTS_KEY][_BINDINGS_KEY]:
-        p_value = _add_corners_if_needed(target_elem=row[p_id][_VALUE_KEY],
-                                         elem_type=row[p_id][_TYPE_KEY])
-        o_value = _add_corners_if_needed(target_elem=_add_lang_if_needed(row[o_id]),
-                                         elem_type=row[o_id][_TYPE_KEY])
-        result.append((p_value, o_value))
-    return result
-
-
-
-def _query_endpoint_json_result(endpoint_url, str_query, max_retries=5, sleep_time=2, fake_user_agent=True):
-    first_failure = True
-    sparql = SPARQLWrapper(endpoint_url)
-    if fake_user_agent:
-        sparql.agent = _FAKE_USER_AGENT
-    sparql.setQuery(str_query)
-    sparql.setReturnFormat(JSON)
-    last_error = None
-    while max_retries > 0:
-        try:
-            return sparql.query().convert()
-        except (HTTPError, EndPointInternalError) as e:
-            max_retries -= 1
-            sleep(sleep_time)
-            last_error = e
-            if first_failure and not fake_user_agent:
-                sparql.agent = _FAKE_USER_AGENT
-                first_failure = not first_failure
+from SPARQLWrapper import SPARQLWrapper, JSON
+from urllib.error import HTTPError
+from time import sleep
+import ssl
+ssl._create_default_https_context = ssl._create_unverified_context
+
+from SPARQLWrapper.SPARQLExceptions import EndPointInternalError
+
+_FAKE_USER_AGENT = "Mozilla/5.0 (Platform; Security; OS-or-CPU; Localization; rv:1.4) Gecko/20030624 Netscape/7.1 (ax)"
+_RESULTS_KEY = "results"
+_BINDINGS_KEY = "bindings"
+_VALUE_KEY = "value"
+_TYPE_KEY = "type"
+_URI_TYPE = "uri"
+
+_XML_LANG_FIELD = "xml:lang"
+
+
+def _add_lang_if_needed(result_dict):
+    result = result_dict[_VALUE_KEY]
+    if _XML_LANG_FIELD in result_dict:
+        result += '"' + result + '"@' + result_dict[_XML_LANG_FIELD]
+    return result
+
+
+def _add_corners_if_needed(target_elem, elem_type):
+    if elem_type == _URI_TYPE and not target_elem.startswith("<"):
+        return "<" + target_elem + ">"
+    return target_elem
+
+
+def query_endpoint_single_variable(endpoint_url, str_query, variable_id, max_retries=10, sleep_time=5, fake_user_agent=True):
+    """
+    It receives an SPARQL query with a single variable and returns a list with the resulting nodes
+
+    :param endpoint_url:
+    :param str_query:
+    :param variable_id:
+    :return:
+    """
+    result_query = _query_endpoint_json_result(endpoint_url=endpoint_url,
+                                               str_query=str_query,
+                                               max_retries=max_retries,
+                                               sleep_time=sleep_time,
+                                               fake_user_agent=fake_user_agent)
+    result = []
+    for row in result_query[_RESULTS_KEY][_BINDINGS_KEY]:
+        an_elem = row[variable_id][_VALUE_KEY]
+        result.append(an_elem)
+    return result
+
+
+def query_endpoint_sp_of_an_o(endpoint_url, str_query, s_id, p_id, max_retries=5, sleep_time=2, fake_user_agent=True):
+    result_query = _query_endpoint_json_result(endpoint_url=endpoint_url,
+                                               str_query=str_query,
+                                               max_retries=max_retries,
+                                               sleep_time=sleep_time,
+                                               fake_user_agent=fake_user_agent)
+    result = []
+    for row in result_query[_RESULTS_KEY][_BINDINGS_KEY]:
+        p_value = _add_corners_if_needed(target_elem=row[p_id][_VALUE_KEY],
+                                         elem_type=row[p_id][_TYPE_KEY])
+        s_value = _add_corners_if_needed(target_elem=_add_lang_if_needed(row[s_id]),
+                                         elem_type=row[s_id][_TYPE_KEY])
+        result.append((s_value, p_value))
+    return result
+
+
+def query_endpoint_po_of_an_s(endpoint_url, str_query, p_id, o_id, max_retries=5, sleep_time=2, fake_user_agent=True):
+
+    result_query = _query_endpoint_json_result(endpoint_url=endpoint_url,
+                                               str_query=str_query,
+                                               max_retries=max_retries,
+                                               sleep_time=sleep_time,
+                                               fake_user_agent=fake_user_agent)
+    result = []
+    for row in result_query[_RESULTS_KEY][_BINDINGS_KEY]:
+        p_value = _add_corners_if_needed(target_elem=row[p_id][_VALUE_KEY],
+                                         elem_type=row[p_id][_TYPE_KEY])
+        o_value = _add_corners_if_needed(target_elem=_add_lang_if_needed(row[o_id]),
+                                         elem_type=row[o_id][_TYPE_KEY])
+        result.append((p_value, o_value))
+    return result
+
+
+
+def _query_endpoint_json_result(endpoint_url, str_query, max_retries=5, sleep_time=2, fake_user_agent=True):
+    first_failure = True
+    sparql = SPARQLWrapper(endpoint_url)
+    if fake_user_agent:
+        sparql.agent = _FAKE_USER_AGENT
+    sparql.setQuery(str_query)
+    sparql.setReturnFormat(JSON)
+    last_error = None
+    while max_retries > 0:
+        try:
+            return sparql.query().convert()
+        except (HTTPError, EndPointInternalError) as e:
+            max_retries -= 1
+            sleep(sleep_time)
+            last_error = e
+            if first_failure and not fake_user_agent:
+                sparql.agent = _FAKE_USER_AGENT
+                first_failure = not first_failure
     last_error.msg = "Max number of attempt reached, it is not possible to perform the query. Msg:\n" + last_error.msg
```

### Comparing `shexer-2.5.1/shexer/io/uml/uml_serializer.py` & `shexer-2.5.2/shexer/io/uml/uml_serializer.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,147 +1,147 @@
-from plantuml import PlantUML
-from shexer.utils.shapes import prefixize_shape_name_if_possible
-from shexer.utils.uri import prefixize_uri_if_possible
-from shexer.model.fixed_prop_choice_statement import FixedPropChoiceStatement
-from shexer.consts import RDF_TYPE
-import warnings
-
-
-class UMLSerializer(object):
-
-    def __init__(self, shapes_list, url_server, image_path, namespaces_dict=None, instantiation_property=RDF_TYPE):
-        self._disable_connection_warnings()
-        self._shapes_list = shapes_list
-        self._url_server = url_server
-        self._image_path = image_path
-        self._instantiation_property = instantiation_property
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-
-        self._shape_alias = {}
-
-        self._diagram = None
-
-        self._server_connection = self._init_server_connection()
-
-    def serialize_shapes(self):
-
-        self._reset_diagram()
-
-        self._init_diagram()
-        self._fill_diagram_with_shapes()
-        self._close_diagram()
-        result = self._send_diagram_to_server()
-        self._store_diagram(result)
-
-    def _disable_connection_warnings(self):
-        warnings.filterwarnings("ignore", category=ResourceWarning)
-
-    def _send_diagram_to_server(self):
-        return self._server_connection.processes(self._diagram)
-
-
-    def _store_diagram(self, img_diagram):
-        with open(self._image_path, "wb") as out_stream:
-            out_stream.write(img_diagram)
-
-
-    def _fill_diagram_with_shapes(self):
-        self._declare_shapes_and_atts()
-        self._declare_relations()
-
-    def _declare_relations(self):
-        for a_shape in self._shapes_list:
-            for a_statement in a_shape.yield_statements():
-                if self._is_a_shape_link(a_statement):
-                    origin_name = prefixize_shape_name_if_possible(a_shape_name=a_shape.name,
-                                                                   namespaces_prefix_dict=self._namespaces_dict)
-                    target_name = prefixize_shape_name_if_possible(a_shape_name=a_statement._st_type,
-                                                                   namespaces_prefix_dict=self._namespaces_dict)
-                    target_st = prefixize_uri_if_possible(target_uri=a_statement.st_property,
-                                                          namespaces_prefix_dict=self._namespaces_dict,
-                                                          corners=False)
-                    self._write_line(
-                        f"{self._shape_alias[origin_name]} --> {self._shape_alias[target_name]} : {target_st}")
-
-    def _declare_shapes_and_atts(self):
-        for a_shape in self._shapes_list:
-            self._declare_and_open_shape(a_shape)
-            self._declare_shape_atts(a_shape)
-            self._close_shape()
-
-    def _declare_shape_atts(self, a_shape):
-        for a_statement in a_shape.yield_statements():
-            if not self._is_a_shape_link(a_statement):
-                prop = prefixize_uri_if_possible(target_uri=a_statement.st_property,
-                                                 namespaces_prefix_dict=self._namespaces_dict,
-                                                 corners=False)
-                target_obj = self._serialize_obj_of_non_shape_link(a_statement)
-
-                self._write_line(f"{prop} : {target_obj}"
-                                 + f" {str(a_statement.cardinality) if a_statement.cardinality != 1 else ''}")
-
-
-    def _serialize_obj_of_non_shape_link(self, a_statement):
-        if not type(a_statement) == FixedPropChoiceStatement:
-            result = prefixize_uri_if_possible(target_uri=a_statement.st_type,
-                                         namespaces_prefix_dict=self._namespaces_dict,
-                                         corners=False)
-            if self._is_a_type_declaration(a_statement):
-                result = "[" + result + "]"
-            return result
-        types = []
-        for a_type in a_statement.st_types:
-            if a_type.startswith("@"):
-                types.append("@" + prefixize_uri_if_possible(target_uri=a_type[1:],
-                                                             namespaces_prefix_dict=self._namespaces_dict,
-                                                             corners=True))
-            else:
-                types.append(a_type)  # It should be IRI
-        return " OR ".join(types)
-
-    def _is_a_type_declaration(self, a_statement):
-        return a_statement.st_property == self._instantiation_property
-
-    def _is_a_shape_link(self, statement):
-        if type(statement) == FixedPropChoiceStatement:
-            return False
-        return statement.st_type.startswith("@")
-
-    def _declare_and_open_shape(self, a_shape):
-        target_name = prefixize_shape_name_if_possible(a_shape_name=a_shape.name,
-                                                       namespaces_prefix_dict=self._namespaces_dict)
-        if target_name.startswith(":") or target_name.startswith("<") :
-            self._declare_shape_with_alias(target_name)
-        else:
-            self._declare_shape_without_alias(target_name)
-
-    def _declare_shape_without_alias(self, target_name):
-        self._shape_alias[target_name] = target_name
-        self._write_line(f"object {target_name} {{")
-
-    def _declare_shape_with_alias(self, target_name):
-        if target_name.startswith(":"):
-            alias = target_name[1:]
-        else:
-            alias = target_name[1:-1]
-        self._shape_alias[target_name] = alias
-        self._write_line(f'object "{target_name}" as {alias} {{')
-
-    def _close_shape(self):
-        self._write_line("}", spacing=True)
-
-    def _reset_diagram(self):
-        self._diagram = ""
-
-    def _init_diagram(self):
-        self._write_line("@startuml", spacing=True)
-
-    def _close_diagram(self):
-        self._write_line("@enduml")
-
-    def _write_line(self, text, spacing=False):
-        self._diagram += text + "\n" * (1 if not spacing else 2)
-
-    def _init_server_connection(self):
-        return PlantUML(url=self._url_server)
-
-
+from plantuml import PlantUML
+from shexer.utils.shapes import prefixize_shape_name_if_possible
+from shexer.utils.uri import prefixize_uri_if_possible
+from shexer.model.fixed_prop_choice_statement import FixedPropChoiceStatement
+from shexer.consts import RDF_TYPE
+import warnings
+
+
+class UMLSerializer(object):
+
+    def __init__(self, shapes_list, url_server, image_path, namespaces_dict=None, instantiation_property=RDF_TYPE):
+        self._disable_connection_warnings()
+        self._shapes_list = shapes_list
+        self._url_server = url_server
+        self._image_path = image_path
+        self._instantiation_property = instantiation_property
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+
+        self._shape_alias = {}
+
+        self._diagram = None
+
+        self._server_connection = self._init_server_connection()
+
+    def serialize_shapes(self):
+
+        self._reset_diagram()
+
+        self._init_diagram()
+        self._fill_diagram_with_shapes()
+        self._close_diagram()
+        result = self._send_diagram_to_server()
+        self._store_diagram(result)
+
+    def _disable_connection_warnings(self):
+        warnings.filterwarnings("ignore", category=ResourceWarning)
+
+    def _send_diagram_to_server(self):
+        return self._server_connection.processes(self._diagram)
+
+
+    def _store_diagram(self, img_diagram):
+        with open(self._image_path, "wb") as out_stream:
+            out_stream.write(img_diagram)
+
+
+    def _fill_diagram_with_shapes(self):
+        self._declare_shapes_and_atts()
+        self._declare_relations()
+
+    def _declare_relations(self):
+        for a_shape in self._shapes_list:
+            for a_statement in a_shape.yield_statements():
+                if self._is_a_shape_link(a_statement):
+                    origin_name = prefixize_shape_name_if_possible(a_shape_name=a_shape.name,
+                                                                   namespaces_prefix_dict=self._namespaces_dict)
+                    target_name = prefixize_shape_name_if_possible(a_shape_name=a_statement._st_type,
+                                                                   namespaces_prefix_dict=self._namespaces_dict)
+                    target_st = prefixize_uri_if_possible(target_uri=a_statement.st_property,
+                                                          namespaces_prefix_dict=self._namespaces_dict,
+                                                          corners=False)
+                    self._write_line(
+                        f"{self._shape_alias[origin_name]} --> {self._shape_alias[target_name]} : {target_st}")
+
+    def _declare_shapes_and_atts(self):
+        for a_shape in self._shapes_list:
+            self._declare_and_open_shape(a_shape)
+            self._declare_shape_atts(a_shape)
+            self._close_shape()
+
+    def _declare_shape_atts(self, a_shape):
+        for a_statement in a_shape.yield_statements():
+            if not self._is_a_shape_link(a_statement):
+                prop = prefixize_uri_if_possible(target_uri=a_statement.st_property,
+                                                 namespaces_prefix_dict=self._namespaces_dict,
+                                                 corners=False)
+                target_obj = self._serialize_obj_of_non_shape_link(a_statement)
+
+                self._write_line(f"{prop} : {target_obj}"
+                                 + f" {str(a_statement.cardinality) if a_statement.cardinality != 1 else ''}")
+
+
+    def _serialize_obj_of_non_shape_link(self, a_statement):
+        if not type(a_statement) == FixedPropChoiceStatement:
+            result = prefixize_uri_if_possible(target_uri=a_statement.st_type,
+                                         namespaces_prefix_dict=self._namespaces_dict,
+                                         corners=False)
+            if self._is_a_type_declaration(a_statement):
+                result = "[" + result + "]"
+            return result
+        types = []
+        for a_type in a_statement.st_types:
+            if a_type.startswith("@"):
+                types.append("@" + prefixize_uri_if_possible(target_uri=a_type[1:],
+                                                             namespaces_prefix_dict=self._namespaces_dict,
+                                                             corners=True))
+            else:
+                types.append(a_type)  # It should be IRI
+        return " OR ".join(types)
+
+    def _is_a_type_declaration(self, a_statement):
+        return a_statement.st_property == self._instantiation_property
+
+    def _is_a_shape_link(self, statement):
+        if type(statement) == FixedPropChoiceStatement:
+            return False
+        return statement.st_type.startswith("@")
+
+    def _declare_and_open_shape(self, a_shape):
+        target_name = prefixize_shape_name_if_possible(a_shape_name=a_shape.name,
+                                                       namespaces_prefix_dict=self._namespaces_dict)
+        if target_name.startswith(":") or target_name.startswith("<") :
+            self._declare_shape_with_alias(target_name)
+        else:
+            self._declare_shape_without_alias(target_name)
+
+    def _declare_shape_without_alias(self, target_name):
+        self._shape_alias[target_name] = target_name
+        self._write_line(f"object {target_name} {{")
+
+    def _declare_shape_with_alias(self, target_name):
+        if target_name.startswith(":"):
+            alias = target_name[1:]
+        else:
+            alias = target_name[1:-1]
+        self._shape_alias[target_name] = alias
+        self._write_line(f'object "{target_name}" as {alias} {{')
+
+    def _close_shape(self):
+        self._write_line("}", spacing=True)
+
+    def _reset_diagram(self):
+        self._diagram = ""
+
+    def _init_diagram(self):
+        self._write_line("@startuml", spacing=True)
+
+    def _close_diagram(self):
+        self._write_line("@enduml")
+
+    def _write_line(self, text, spacing=False):
+        self._diagram += text + "\n" * (1 if not spacing else 2)
+
+    def _init_server_connection(self):
+        return PlantUML(url=self._url_server)
+
+
```

### Comparing `shexer-2.5.1/shexer/model/IRI.py` & `shexer-2.5.2/shexer/model/IRI.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,26 +1,26 @@
-from shexer.model.const_elem_types import IRI_ELEM_TYPE
-
-
-class IRI(object):
-
-    def __init__(self, content):
-        self._content = content
-
-    def __str__(self):
-        return self._content
-
-    @property
-    def elem_type(self):
-        return IRI_ELEM_TYPE
-
-    @property
-    def iri(self):
-        return self._content
-
-    def __eq__(self, other):
-        if type(other) != type(self):
-            return False
-        return str(self) == str(other)
-
-    def __ne__(self, other):
+from shexer.model.const_elem_types import IRI_ELEM_TYPE
+
+
+class IRI(object):
+
+    def __init__(self, content):
+        self._content = content
+
+    def __str__(self):
+        return self._content
+
+    @property
+    def elem_type(self):
+        return IRI_ELEM_TYPE
+
+    @property
+    def iri(self):
+        return self._content
+
+    def __eq__(self, other):
+        if type(other) != type(self):
+            return False
+        return str(self) == str(other)
+
+    def __ne__(self, other):
         return not self.__eq__(other)
```

### Comparing `shexer-2.5.1/shexer/model/fixed_prop_choice_statement.py` & `shexer-2.5.2/shexer/model/fixed_prop_choice_statement.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-from shexer.model.statement import Statement
-
-class FixedPropChoiceStatement(Statement):
-
-    def __init__(self, st_property, st_types, cardinality, n_occurences, probability, comments=None,
-                 serializer_object=None, is_inverse=False):
-        super(FixedPropChoiceStatement, self).__init__(st_property=st_property,
-                                                       st_type=None,
-                                                       cardinality=cardinality,
-                                                       n_occurences=n_occurences,
-                                                       probability=probability,
-                                                       comments=comments,
-                                                       serializer_object=serializer_object,
-                                                       is_inverse=is_inverse)
-        self._st_types = st_types
-
-    @property
-    def st_type(self):
-        raise TypeError("Choice statements doesnt have a single type")
-
-    @property
-    def st_types(self):
+from shexer.model.statement import Statement
+
+class FixedPropChoiceStatement(Statement):
+
+    def __init__(self, st_property, st_types, cardinality, n_occurences, probability, comments=None,
+                 serializer_object=None, is_inverse=False):
+        super(FixedPropChoiceStatement, self).__init__(st_property=st_property,
+                                                       st_type=None,
+                                                       cardinality=cardinality,
+                                                       n_occurences=n_occurences,
+                                                       probability=probability,
+                                                       comments=comments,
+                                                       serializer_object=serializer_object,
+                                                       is_inverse=is_inverse)
+        self._st_types = st_types
+
+    @property
+    def st_type(self):
+        raise TypeError("Choice statements doesnt have a single type")
+
+    @property
+    def st_types(self):
         return self._st_types
```

### Comparing `shexer-2.5.1/shexer/model/graph/abstract_sgraph.py` & `shexer-2.5.2/shexer/model/graph/abstract_sgraph.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,137 +1,137 @@
-from shexer.consts import RDF_TYPE
-
-class SGraph(object):
-
-    def __init__(self):
-        pass
-
-    def query_single_variable(self, str_query, variable_id):
-        """
-        It receives an SPARQL query with a single variable and returns a list with the nodes matching that query
-
-        :param str_query:
-        :param variable_id:
-        :return: list
-        """
-        raise NotImplementedError()
-
-    def yield_p_o_triples_of_an_s(self, target_node):
-        """
-        Here it expects unprefixed URIs. So there is no stage of namespaces management to build a query.
-
-        :param target_node:
-        :return:
-        """
-        raise NotImplementedError()
-
-    def yield_s_p_triples_of_an_o(self, target_node):
-        """
-        Here it expects unprefixed URIs. So there is no stage of namespaces management to build a query.
-        :param target_node:
-        :return:
-        """
-        raise NotImplementedError()
-
-    def yield_class_triples_of_an_s(self, target_node, instantiation_property):
-        """
-        Here it expects unprefixed URIs. So there is no stage of namespaces management to build a query.
-
-        :param target_node:
-        :param instantiation_property:
-        :return:
-        """
-        raise NotImplementedError()
-
-    def yield_s_p_triples_of_target_nodes(self, target_nodes, depth, classes_at_last_level=True,
-                                          instantiation_property=RDF_TYPE, already_visited=None,
-                                          strict_syntax_with_uri_corners=True
-                                          ):
-        """
-        If it is provided, the param already_visited can be modified during the execution of this method.
-        The set already_visited can be used to avoid repetition of triples calling this methodd repeatedly
-        for different node selectors in a shape map.
-
-        :param target_nodes:
-        :param depth:
-        :param classes_at_last_level:
-        :param instantiation_property:
-        :param already_visited:
-        :param strict_syntax_with_uri_corners:
-        :return:
-        """
-        current_already_visited = set() if already_visited is None else already_visited
-        list_of_current_target_nodes = target_nodes
-        new_target_nodes = []
-        while depth > 0:
-            for a_node in list_of_current_target_nodes:
-                if a_node not in current_already_visited:
-                    current_already_visited.add(a_node)
-                    for a_triple in self.yield_s_p_triples_of_an_o(a_node):
-                        yield a_triple
-                        if self._is_an_unprefixed_iri(an_iri=a_triple[0],
-                                                      strict_syntax_with_uri_corners=strict_syntax_with_uri_corners):
-                            new_target_nodes.append(a_triple[0])
-            depth -= 1
-            list_of_current_target_nodes = new_target_nodes
-            new_target_nodes = []
-            if depth == 0 and classes_at_last_level:
-                for a_node in list_of_current_target_nodes:
-                    if a_node not in current_already_visited:
-                        for a_triple in self.yield_class_triples_of_an_s(target_node=a_node,
-                                                                         instantiation_property=instantiation_property):
-                            yield a_triple
-
-    def yield_p_o_triples_of_target_nodes(self, target_nodes, depth, classes_at_last_level=True,
-                                          instantiation_property=RDF_TYPE, already_visited=None,
-                                          strict_syntax_with_uri_corners=True):
-        """
-        If it is provided, the param already_visited can be modified during the execution of this method.
-        The set already_visited can be used to avoid repetition of triples calling this methodd repeatedly
-        for different node selectors in a shape map.
-
-        :param target_nodes:
-        :param depth:
-        :param classes_at_last_level:
-        :param instantiation_property:
-        :param already_visited:
-        :param strict_syntax_with_uri_corners:
-        :return:
-        """
-
-        current_already_visited = set() if already_visited is None else already_visited
-        list_of_current_target_nodes = target_nodes
-        new_target_nodes = []
-        while depth > 0:
-            for a_node in list_of_current_target_nodes:
-                if a_node not in current_already_visited:
-                    current_already_visited.add(a_node)
-                    for a_triple in self.yield_p_o_triples_of_an_s(a_node):
-                        yield a_triple
-                        if self._is_an_unprefixed_iri(an_iri=a_triple[2],
-                                                      strict_syntax_with_uri_corners=strict_syntax_with_uri_corners):
-                            new_target_nodes.append(a_triple[2])
-            depth -= 1
-            list_of_current_target_nodes = new_target_nodes
-            new_target_nodes = []
-            if depth == 0 and classes_at_last_level:
-                for a_node in list_of_current_target_nodes:
-                    if a_node not in current_already_visited:
-                        for a_triple in self.yield_class_triples_of_an_s(target_node=a_node,
-                                                                         instantiation_property=instantiation_property):
-                            yield a_triple
-
-    def yield_classes_with_instances(self, instantiation_property=RDF_TYPE):
-        """
-        It yields every class URI that has at least a declared instance
-        :param instantiation_property:
-        :return:
-        """
-        raise NotImplementedError()
-
-
-
-    def _is_an_unprefixed_iri(self, an_iri, strict_syntax_with_uri_corners=True):
-        if strict_syntax_with_uri_corners:
-            return an_iri[0] == "<" and an_iri[-1] == ">"
-        else:
-            return an_iri.startswith("http://")  # Getting kicked in the chicken nuggets is worse than this decision
+from shexer.consts import RDF_TYPE
+
+class SGraph(object):
+
+    def __init__(self):
+        pass
+
+    def query_single_variable(self, str_query, variable_id):
+        """
+        It receives an SPARQL query with a single variable and returns a list with the nodes matching that query
+
+        :param str_query:
+        :param variable_id:
+        :return: list
+        """
+        raise NotImplementedError()
+
+    def yield_p_o_triples_of_an_s(self, target_node):
+        """
+        Here it expects unprefixed URIs. So there is no stage of namespaces management to build a query.
+
+        :param target_node:
+        :return:
+        """
+        raise NotImplementedError()
+
+    def yield_s_p_triples_of_an_o(self, target_node):
+        """
+        Here it expects unprefixed URIs. So there is no stage of namespaces management to build a query.
+        :param target_node:
+        :return:
+        """
+        raise NotImplementedError()
+
+    def yield_class_triples_of_an_s(self, target_node, instantiation_property):
+        """
+        Here it expects unprefixed URIs. So there is no stage of namespaces management to build a query.
+
+        :param target_node:
+        :param instantiation_property:
+        :return:
+        """
+        raise NotImplementedError()
+
+    def yield_s_p_triples_of_target_nodes(self, target_nodes, depth, classes_at_last_level=True,
+                                          instantiation_property=RDF_TYPE, already_visited=None,
+                                          strict_syntax_with_uri_corners=True
+                                          ):
+        """
+        If it is provided, the param already_visited can be modified during the execution of this method.
+        The set already_visited can be used to avoid repetition of triples calling this methodd repeatedly
+        for different node selectors in a shape map.
+
+        :param target_nodes:
+        :param depth:
+        :param classes_at_last_level:
+        :param instantiation_property:
+        :param already_visited:
+        :param strict_syntax_with_uri_corners:
+        :return:
+        """
+        current_already_visited = set() if already_visited is None else already_visited
+        list_of_current_target_nodes = target_nodes
+        new_target_nodes = []
+        while depth > 0:
+            for a_node in list_of_current_target_nodes:
+                if a_node not in current_already_visited:
+                    current_already_visited.add(a_node)
+                    for a_triple in self.yield_s_p_triples_of_an_o(a_node):
+                        yield a_triple
+                        if self._is_an_unprefixed_iri(an_iri=a_triple[0],
+                                                      strict_syntax_with_uri_corners=strict_syntax_with_uri_corners):
+                            new_target_nodes.append(a_triple[0])
+            depth -= 1
+            list_of_current_target_nodes = new_target_nodes
+            new_target_nodes = []
+            if depth == 0 and classes_at_last_level:
+                for a_node in list_of_current_target_nodes:
+                    if a_node not in current_already_visited:
+                        for a_triple in self.yield_class_triples_of_an_s(target_node=a_node,
+                                                                         instantiation_property=instantiation_property):
+                            yield a_triple
+
+    def yield_p_o_triples_of_target_nodes(self, target_nodes, depth, classes_at_last_level=True,
+                                          instantiation_property=RDF_TYPE, already_visited=None,
+                                          strict_syntax_with_uri_corners=True):
+        """
+        If it is provided, the param already_visited can be modified during the execution of this method.
+        The set already_visited can be used to avoid repetition of triples calling this methodd repeatedly
+        for different node selectors in a shape map.
+
+        :param target_nodes:
+        :param depth:
+        :param classes_at_last_level:
+        :param instantiation_property:
+        :param already_visited:
+        :param strict_syntax_with_uri_corners:
+        :return:
+        """
+
+        current_already_visited = set() if already_visited is None else already_visited
+        list_of_current_target_nodes = target_nodes
+        new_target_nodes = []
+        while depth > 0:
+            for a_node in list_of_current_target_nodes:
+                if a_node not in current_already_visited:
+                    current_already_visited.add(a_node)
+                    for a_triple in self.yield_p_o_triples_of_an_s(a_node):
+                        yield a_triple
+                        if self._is_an_unprefixed_iri(an_iri=a_triple[2],
+                                                      strict_syntax_with_uri_corners=strict_syntax_with_uri_corners):
+                            new_target_nodes.append(a_triple[2])
+            depth -= 1
+            list_of_current_target_nodes = new_target_nodes
+            new_target_nodes = []
+            if depth == 0 and classes_at_last_level:
+                for a_node in list_of_current_target_nodes:
+                    if a_node not in current_already_visited:
+                        for a_triple in self.yield_class_triples_of_an_s(target_node=a_node,
+                                                                         instantiation_property=instantiation_property):
+                            yield a_triple
+
+    def yield_classes_with_instances(self, instantiation_property=RDF_TYPE):
+        """
+        It yields every class URI that has at least a declared instance
+        :param instantiation_property:
+        :return:
+        """
+        raise NotImplementedError()
+
+
+
+    def _is_an_unprefixed_iri(self, an_iri, strict_syntax_with_uri_corners=True):
+        if strict_syntax_with_uri_corners:
+            return an_iri[0] == "<" and an_iri[-1] == ">"
+        else:
+            return an_iri.startswith("http://")  # Getting kicked in the chicken nuggets is worse than this decision
```

### Comparing `shexer-2.5.1/shexer/model/graph/endpoint_sgraph.py` & `shexer-2.5.2/shexer/model/graph/endpoint_sgraph.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,142 +1,142 @@
-from shexer.io.sparql.query import \
-    query_endpoint_po_of_an_s, \
-    query_endpoint_single_variable, \
-    query_endpoint_sp_of_an_o
-from shexer.model.graph.abstract_sgraph import SGraph
-from shexer.model.graph.rdflib_sgraph import RdflibSgraph
-from shexer.utils.uri import remove_corners
-from rdflib import Graph
-from shexer.consts import RDF_TYPE
-
-_DEF_SUBJ_VARIABLE = "?s"
-_DEF_SUBJ_ID = "s"
-
-_DEF_PRED_VARIABLE = "?p"
-_DEF_PRED_ID = "p"
-
-_DEF_OBJ_VARIABLE = "?o"
-_DEF_OBJ_ID = "o"
-
-class EndpointSGraph(SGraph):
-
-    def __init__(self, endpoint_url, store_locally=True):
-        super().__init__()
-        self._endpoint_url = endpoint_url
-        self._store_locally = store_locally
-        self._local_sgraph = RdflibSgraph(rdflib_graph=Graph()) if store_locally else None
-        self._subjects_tracked = set() if store_locally else None
-        self._objects_tracked = set() if store_locally else None
-
-
-
-    def query_single_variable(self, str_query, variable_id):
-        return query_endpoint_single_variable(variable_id=variable_id,
-                                              str_query=str_query,
-                                              endpoint_url=self._endpoint_url)
-
-    def serialize_current_local_sgraph(self, path_file, format):
-        if self._local_sgraph is not None:
-            self._local_sgraph.serialize(path=path_file,
-                                         format=format)
-
-
-    def yield_class_triples_of_an_s(self, target_node, instantiation_property):
-        if not self._store_locally:
-            for a_triple in self._yield_remote_class_triples_of_an_s(target_node, instantiation_property):
-                yield a_triple
-        else:
-            for a_triple in self._yield_local_class_triples_of_an_s(target_node, instantiation_property):
-                yield a_triple
-
-    def yield_classes_with_instances(self, instantiation_property=RDF_TYPE):
-        str_query = "SELECT distinct {0} where {{ {1} <{2}> {0} . }}".format(_DEF_OBJ_VARIABLE,
-                                                                             _DEF_SUBJ_VARIABLE,
-                                                                              remove_corners(
-                                                                                  a_uri=instantiation_property,
-                                                                                  raise_error_if_no_corners=False)
-                                                                              )
-        for an_elem in query_endpoint_single_variable(endpoint_url=self._endpoint_url,
-                                                      str_query=str_query,
-                                                      variable_id=_DEF_OBJ_ID):
-            yield str(an_elem)
-
-
-    def _yield_remote_class_triples_of_an_s(self, target_node, instantiation_property):
-        str_query = "SELECT {0} WHERE {{ <{1}> <{2}> {0} . }}".format(_DEF_OBJ_VARIABLE,
-                                                                      remove_corners(a_uri=target_node,
-                                                                                     raise_error_if_no_corners=False),
-                                                                      remove_corners(a_uri=instantiation_property,
-                                                                                     raise_error_if_no_corners=False))
-        for an_elem in query_endpoint_single_variable(endpoint_url=self._endpoint_url,
-                                                      str_query=str_query,
-                                                      variable_id=_DEF_OBJ_ID):
-            yield ("<" + target_node + ">", "<" + instantiation_property + ">", an_elem)
-
-
-    def _yield_local_class_triples_of_an_s(self, target_node, instantiation_property):
-        if target_node not in self._subjects_tracked:
-            for a_triple in self._yield_remote_class_triples_of_an_s(target_node, instantiation_property):
-                self._store_triple_locally(a_triple)
-            self._subjects_tracked.add(target_node)
-        for a_triple in self._local_sgraph.yield_class_triples_of_an_s(target_node, instantiation_property):
-            yield a_triple
-
-
-    def yield_p_o_triples_of_an_s(self, target_node):
-        if not self._store_locally:
-            for a_triple in self._yield_remote_p_o_triples_of_an_s(target_node):
-                yield a_triple
-        else:
-            for a_triple in self._yield_local_p_o_triples_of_an_s(target_node):
-                yield a_triple
-
-    def yield_s_p_triples_of_an_o(self, target_node):
-        if not self._store_locally:
-            for a_triple in self._yield_remote_s_p_triples_of_an_o(target_node):
-                yield a_triple
-        else:
-            for a_triple in self._yield_local_s_p_triples_of_an_o(target_node):
-                yield a_triple
-
-
-    def _yield_remote_p_o_triples_of_an_s(self, target_node):
-        str_query = "SELECT {0} {1} WHERE {{ <{2}> {0} {1} .}} ".format(_DEF_PRED_VARIABLE,
-                                                                        _DEF_OBJ_VARIABLE,
-                                                                        remove_corners(a_uri=target_node,
-                                                                                       raise_error_if_no_corners=False))
-        for a_tuple_po in query_endpoint_po_of_an_s(endpoint_url=self._endpoint_url,
-                                                    str_query=str_query,
-                                                    p_id=_DEF_PRED_ID,
-                                                    o_id=_DEF_OBJ_ID):
-            yield "<" + target_node + ">", a_tuple_po[0], a_tuple_po[1]
-
-    def _yield_remote_s_p_triples_of_an_o(self, target_node):
-        str_query = "SELECT {0} {1} WHERE {{ {0} {1} <{2}> .}}".format(_DEF_SUBJ_VARIABLE,
-                                                                       _DEF_PRED_VARIABLE,
-                                                                       remove_corners(a_uri=target_node,
-                                                                                      raise_error_if_no_corners=False))
-        for a_tuple_sp in query_endpoint_sp_of_an_o(endpoint_url=self._endpoint_url,
-                                                    str_query=str_query,
-                                                    p_id=_DEF_PRED_ID,
-                                                    s_id=_DEF_SUBJ_ID):
-            yield a_tuple_sp[0], a_tuple_sp[1], "<" + target_node + ">"
-
-
-    def _yield_local_p_o_triples_of_an_s(self, target_node):
-        if target_node not in self._subjects_tracked:
-            for a_triple in self._yield_remote_p_o_triples_of_an_s(target_node):
-                self._store_triple_locally(a_triple)
-            self._subjects_tracked.add(target_node)
-        for a_triple in self._local_sgraph.yield_p_o_triples_of_an_s(target_node):
-            yield a_triple
-
-    def _yield_local_s_p_triples_of_an_o(self, target_node):
-        if target_node not in self._objects_tracked:
-            for a_triple in self._yield_remote_s_p_triples_of_an_o(target_node):
-                self._store_triple_locally(a_triple)
-            self._objects_tracked.add(target_node)
-        for a_triple in self._local_sgraph.yield_s_p_triples_of_an_o(target_node):
-            yield a_triple
-
-    def _store_triple_locally(self, a_triple):
+from shexer.io.sparql.query import \
+    query_endpoint_po_of_an_s, \
+    query_endpoint_single_variable, \
+    query_endpoint_sp_of_an_o
+from shexer.model.graph.abstract_sgraph import SGraph
+from shexer.model.graph.rdflib_sgraph import RdflibSgraph
+from shexer.utils.uri import remove_corners
+from rdflib import Graph
+from shexer.consts import RDF_TYPE
+
+_DEF_SUBJ_VARIABLE = "?s"
+_DEF_SUBJ_ID = "s"
+
+_DEF_PRED_VARIABLE = "?p"
+_DEF_PRED_ID = "p"
+
+_DEF_OBJ_VARIABLE = "?o"
+_DEF_OBJ_ID = "o"
+
+class EndpointSGraph(SGraph):
+
+    def __init__(self, endpoint_url, store_locally=True):
+        super().__init__()
+        self._endpoint_url = endpoint_url
+        self._store_locally = store_locally
+        self._local_sgraph = RdflibSgraph(rdflib_graph=Graph()) if store_locally else None
+        self._subjects_tracked = set() if store_locally else None
+        self._objects_tracked = set() if store_locally else None
+
+
+
+    def query_single_variable(self, str_query, variable_id):
+        return query_endpoint_single_variable(variable_id=variable_id,
+                                              str_query=str_query,
+                                              endpoint_url=self._endpoint_url)
+
+    def serialize_current_local_sgraph(self, path_file, format):
+        if self._local_sgraph is not None:
+            self._local_sgraph.serialize(path=path_file,
+                                         format=format)
+
+
+    def yield_class_triples_of_an_s(self, target_node, instantiation_property):
+        if not self._store_locally:
+            for a_triple in self._yield_remote_class_triples_of_an_s(target_node, instantiation_property):
+                yield a_triple
+        else:
+            for a_triple in self._yield_local_class_triples_of_an_s(target_node, instantiation_property):
+                yield a_triple
+
+    def yield_classes_with_instances(self, instantiation_property=RDF_TYPE):
+        str_query = "SELECT distinct {0} where {{ {1} <{2}> {0} . }}".format(_DEF_OBJ_VARIABLE,
+                                                                             _DEF_SUBJ_VARIABLE,
+                                                                              remove_corners(
+                                                                                  a_uri=instantiation_property,
+                                                                                  raise_error_if_no_corners=False)
+                                                                              )
+        for an_elem in query_endpoint_single_variable(endpoint_url=self._endpoint_url,
+                                                      str_query=str_query,
+                                                      variable_id=_DEF_OBJ_ID):
+            yield str(an_elem)
+
+
+    def _yield_remote_class_triples_of_an_s(self, target_node, instantiation_property):
+        str_query = "SELECT {0} WHERE {{ <{1}> <{2}> {0} . }}".format(_DEF_OBJ_VARIABLE,
+                                                                      remove_corners(a_uri=target_node,
+                                                                                     raise_error_if_no_corners=False),
+                                                                      remove_corners(a_uri=instantiation_property,
+                                                                                     raise_error_if_no_corners=False))
+        for an_elem in query_endpoint_single_variable(endpoint_url=self._endpoint_url,
+                                                      str_query=str_query,
+                                                      variable_id=_DEF_OBJ_ID):
+            yield ("<" + target_node + ">", "<" + instantiation_property + ">", an_elem)
+
+
+    def _yield_local_class_triples_of_an_s(self, target_node, instantiation_property):
+        if target_node not in self._subjects_tracked:
+            for a_triple in self._yield_remote_class_triples_of_an_s(target_node, instantiation_property):
+                self._store_triple_locally(a_triple)
+            self._subjects_tracked.add(target_node)
+        for a_triple in self._local_sgraph.yield_class_triples_of_an_s(target_node, instantiation_property):
+            yield a_triple
+
+
+    def yield_p_o_triples_of_an_s(self, target_node):
+        if not self._store_locally:
+            for a_triple in self._yield_remote_p_o_triples_of_an_s(target_node):
+                yield a_triple
+        else:
+            for a_triple in self._yield_local_p_o_triples_of_an_s(target_node):
+                yield a_triple
+
+    def yield_s_p_triples_of_an_o(self, target_node):
+        if not self._store_locally:
+            for a_triple in self._yield_remote_s_p_triples_of_an_o(target_node):
+                yield a_triple
+        else:
+            for a_triple in self._yield_local_s_p_triples_of_an_o(target_node):
+                yield a_triple
+
+
+    def _yield_remote_p_o_triples_of_an_s(self, target_node):
+        str_query = "SELECT {0} {1} WHERE {{ <{2}> {0} {1} .}} ".format(_DEF_PRED_VARIABLE,
+                                                                        _DEF_OBJ_VARIABLE,
+                                                                        remove_corners(a_uri=target_node,
+                                                                                       raise_error_if_no_corners=False))
+        for a_tuple_po in query_endpoint_po_of_an_s(endpoint_url=self._endpoint_url,
+                                                    str_query=str_query,
+                                                    p_id=_DEF_PRED_ID,
+                                                    o_id=_DEF_OBJ_ID):
+            yield "<" + target_node + ">", a_tuple_po[0], a_tuple_po[1]
+
+    def _yield_remote_s_p_triples_of_an_o(self, target_node):
+        str_query = "SELECT {0} {1} WHERE {{ {0} {1} <{2}> .}}".format(_DEF_SUBJ_VARIABLE,
+                                                                       _DEF_PRED_VARIABLE,
+                                                                       remove_corners(a_uri=target_node,
+                                                                                      raise_error_if_no_corners=False))
+        for a_tuple_sp in query_endpoint_sp_of_an_o(endpoint_url=self._endpoint_url,
+                                                    str_query=str_query,
+                                                    p_id=_DEF_PRED_ID,
+                                                    s_id=_DEF_SUBJ_ID):
+            yield a_tuple_sp[0], a_tuple_sp[1], "<" + target_node + ">"
+
+
+    def _yield_local_p_o_triples_of_an_s(self, target_node):
+        if target_node not in self._subjects_tracked:
+            for a_triple in self._yield_remote_p_o_triples_of_an_s(target_node):
+                self._store_triple_locally(a_triple)
+            self._subjects_tracked.add(target_node)
+        for a_triple in self._local_sgraph.yield_p_o_triples_of_an_s(target_node):
+            yield a_triple
+
+    def _yield_local_s_p_triples_of_an_o(self, target_node):
+        if target_node not in self._objects_tracked:
+            for a_triple in self._yield_remote_s_p_triples_of_an_o(target_node):
+                self._store_triple_locally(a_triple)
+            self._objects_tracked.add(target_node)
+        for a_triple in self._local_sgraph.yield_s_p_triples_of_an_o(target_node):
+            yield a_triple
+
+    def _store_triple_locally(self, a_triple):
         self._local_sgraph.add_triple(a_triple)
```

### Comparing `shexer-2.5.1/shexer/model/shape.py` & `shexer-2.5.2/shexer/model/shape.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,106 +1,106 @@
-STARTING_CHAR_FOR_SHAPE_NAME = "@"
-
-
-class Shape(object):
-
-    def __init__(self, name, class_uri, statements, n_instances, iri_pattern=None):
-        self._name = name
-        self._class_uri = class_uri
-        self._statements = statements if statements is not None else []
-        self._n_instances = n_instances
-        # self._inverse_statements = inverse_statements if inverse_statements is not None else []
-        self._sorting_callback = lambda x: x.probability
-        self._n_direct_statements = self._count_direct_statements(statements)
-        self._n_inverse_statements = len(statements) - self._n_direct_statements
-        # self._iri_pattern = iri_pattern
-
-    @property
-    def name(self):
-        return self._name
-
-    @property
-    def class_uri(self):
-        return self._class_uri
-
-    @property
-    def n_statements(self):
-        return len(self._statements)
-
-    @property
-    def n_direct_statements(self):
-        return self._n_direct_statements
-
-    @property
-    def n_inverse_statements(self):
-        return self._n_inverse_statements
-
-    @property
-    def n_instances(self):
-        return self._n_instances
-
-    # @property
-    # def iri_pattern(self):
-    #     return self._iri_pattern
-    #
-    # @iri_pattern.setter
-    # def iri_pattern(self, value):
-    #     self._iri_pattern = value
-
-    @property
-    def statements(self):
-        return self._statements
-
-    @property
-    def direct_statements(self):
-        return [a_statement for a_statement in self._statements if not a_statement.is_inverse]
-
-    @property
-    def inverse_statements(self):
-        return [a_statement for a_statement in self._statements if a_statement.is_inverse]
-
-    @statements.setter
-    def statements(self, value):
-        self._statements = value
-
-    @direct_statements.setter
-    def direct_statements(self, statements):
-        self._statements = [a_statement for a_statement in self._statements if a_statement.is_inverse]
-        for a_statement in statements:
-            self._statements.append(a_statement)
-
-    @inverse_statements.setter
-    def inverse_statements(self, inverse_statements):
-        self._statements = [a_statement for a_statement in self._statements if not a_statement.is_inverse]
-        for a_statement in inverse_statements:
-            self._statements.append(a_statement)
-
-    def yield_direct_statements(self):
-        for a_statement in self._statements:
-            if not a_statement.is_inverse:
-                yield a_statement
-
-    def yield_inverse_statements(self):
-        for a_statement in self._statements:
-            if a_statement.is_inverse:
-                yield a_statement
-
-    def sort_statements(self, callback, reverse=False):
-        self._statements.sort(key=lambda x: callback(x), reverse=reverse)
-
-
-    def yield_statements(self, just_direct=False):
-        if just_direct:
-            for a_statement in self.yield_direct_statements():
-                yield a_statement
-        else:
-            for a_statement in self._statements:
-                yield a_statement
-
-    @staticmethod
-    def _count_direct_statements(statements):
-        counter = 0
-        for a_statement in statements:
-            if not a_statement.is_inverse:
-                counter += 1
-        return counter
-
+STARTING_CHAR_FOR_SHAPE_NAME = "@"
+
+
+class Shape(object):
+
+    def __init__(self, name, class_uri, statements, n_instances, iri_pattern=None):
+        self._name = name
+        self._class_uri = class_uri
+        self._statements = statements if statements is not None else []
+        self._n_instances = n_instances
+        # self._inverse_statements = inverse_statements if inverse_statements is not None else []
+        self._sorting_callback = lambda x: x.probability
+        self._n_direct_statements = self._count_direct_statements(statements)
+        self._n_inverse_statements = len(statements) - self._n_direct_statements
+        # self._iri_pattern = iri_pattern
+
+    @property
+    def name(self):
+        return self._name
+
+    @property
+    def class_uri(self):
+        return self._class_uri
+
+    @property
+    def n_statements(self):
+        return len(self._statements)
+
+    @property
+    def n_direct_statements(self):
+        return self._n_direct_statements
+
+    @property
+    def n_inverse_statements(self):
+        return self._n_inverse_statements
+
+    @property
+    def n_instances(self):
+        return self._n_instances
+
+    # @property
+    # def iri_pattern(self):
+    #     return self._iri_pattern
+    #
+    # @iri_pattern.setter
+    # def iri_pattern(self, value):
+    #     self._iri_pattern = value
+
+    @property
+    def statements(self):
+        return self._statements
+
+    @property
+    def direct_statements(self):
+        return [a_statement for a_statement in self._statements if not a_statement.is_inverse]
+
+    @property
+    def inverse_statements(self):
+        return [a_statement for a_statement in self._statements if a_statement.is_inverse]
+
+    @statements.setter
+    def statements(self, value):
+        self._statements = value
+
+    @direct_statements.setter
+    def direct_statements(self, statements):
+        self._statements = [a_statement for a_statement in self._statements if a_statement.is_inverse]
+        for a_statement in statements:
+            self._statements.append(a_statement)
+
+    @inverse_statements.setter
+    def inverse_statements(self, inverse_statements):
+        self._statements = [a_statement for a_statement in self._statements if not a_statement.is_inverse]
+        for a_statement in inverse_statements:
+            self._statements.append(a_statement)
+
+    def yield_direct_statements(self):
+        for a_statement in self._statements:
+            if not a_statement.is_inverse:
+                yield a_statement
+
+    def yield_inverse_statements(self):
+        for a_statement in self._statements:
+            if a_statement.is_inverse:
+                yield a_statement
+
+    def sort_statements(self, callback, reverse=False):
+        self._statements.sort(key=lambda x: callback(x), reverse=reverse)
+
+
+    def yield_statements(self, just_direct=False):
+        if just_direct:
+            for a_statement in self.yield_direct_statements():
+                yield a_statement
+        else:
+            for a_statement in self._statements:
+                yield a_statement
+
+    @staticmethod
+    def _count_direct_statements(statements):
+        counter = 0
+        for a_statement in statements:
+            if not a_statement.is_inverse:
+                counter += 1
+        return counter
+
```

### Comparing `shexer-2.5.1/shexer/model/statement.py` & `shexer-2.5.2/shexer/model/statement.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,89 +1,89 @@
-POSITIVE_CLOSURE = "+"
-KLEENE_CLOSURE = "*"
-OPT_CARDINALITY = "?"
-
-class Statement(object):
-
-    def __init__(self, st_property, st_type, cardinality, n_occurences,
-                 probability, comments=None, serializer_object=None, is_inverse=False):
-        self._st_property = st_property
-        self._st_type = st_type
-        self._cardinality = cardinality
-        self._n_occurences = n_occurences
-        self._probability = probability
-        self._serializer_object = serializer_object
-        self._comments = [] if comments is None else comments
-        self._is_inverse = is_inverse
-
-    def get_tuples_to_serialize_line_indent_level(self, is_last_statement_of_shape, namespaces_dict):
-        return self._serializer_object.\
-            serialize_statement_with_indent_level(a_statement=self,
-                                                  is_last_statement_of_shape= is_last_statement_of_shape,
-                                                  namespaces_dict=namespaces_dict)
-
-    def probability_representation(self):
-        return self._serializer_object.probability_representation(self)
-
-    def cardinality_representation(self):
-        return self._serializer_object.cardinality_representation(self)
-
-    def comment_representation(self, namespaces_dict):
-        return self._serializer_object.turn_statement_into_comment(self, namespaces_dict=namespaces_dict)
-
-    def add_comment(self, comment, insert_first=False):
-        if not insert_first:
-            self._comments.append(comment)
-        else:
-            self._comments.insert(0, comment)
-
-    def remove_comments(self):
-        self._comments = []
-
-
-    @property
-    def st_property(self):
-        return self._st_property
-
-    @property
-    def st_type(self):
-        return self._st_type
-
-    @property
-    def cardinality(self):
-        return self._cardinality
-
-    @cardinality.setter
-    def cardinality(self, value):
-        self._cardinality = value
-
-    @property
-    def probability(self):
-        return self._probability
-
-    @property
-    def n_occurences(self):
-        return self._n_occurences
-
-    @probability.setter
-    def probability(self, value):
-        self._probability = value
-
-    @property
-    def comments(self):
-        return self._comments
-
-    @property
-    def serializer_object(self):
-        return self._serializer_object
-
-    @serializer_object.setter
-    def serializer_object(self, value):
-        self._serializer_object = value
-
-    @property
-    def is_inverse(self):
-        return self._is_inverse
-
-    @is_inverse.setter
-    def is_inverse(self, value):
-        self._is_inverse = value
+POSITIVE_CLOSURE = "+"
+KLEENE_CLOSURE = "*"
+OPT_CARDINALITY = "?"
+
+class Statement(object):
+
+    def __init__(self, st_property, st_type, cardinality, n_occurences,
+                 probability, comments=None, serializer_object=None, is_inverse=False):
+        self._st_property = st_property
+        self._st_type = st_type
+        self._cardinality = cardinality
+        self._n_occurences = n_occurences
+        self._probability = probability
+        self._serializer_object = serializer_object
+        self._comments = [] if comments is None else comments
+        self._is_inverse = is_inverse
+
+    def get_tuples_to_serialize_line_indent_level(self, is_last_statement_of_shape, namespaces_dict):
+        return self._serializer_object.\
+            serialize_statement_with_indent_level(a_statement=self,
+                                                  is_last_statement_of_shape= is_last_statement_of_shape,
+                                                  namespaces_dict=namespaces_dict)
+
+    def probability_representation(self):
+        return self._serializer_object.probability_representation(self)
+
+    def cardinality_representation(self):
+        return self._serializer_object.cardinality_representation(self)
+
+    def comment_representation(self, namespaces_dict):
+        return self._serializer_object.turn_statement_into_comment(self, namespaces_dict=namespaces_dict)
+
+    def add_comment(self, comment, insert_first=False):
+        if not insert_first:
+            self._comments.append(comment)
+        else:
+            self._comments.insert(0, comment)
+
+    def remove_comments(self):
+        self._comments = []
+
+
+    @property
+    def st_property(self):
+        return self._st_property
+
+    @property
+    def st_type(self):
+        return self._st_type
+
+    @property
+    def cardinality(self):
+        return self._cardinality
+
+    @cardinality.setter
+    def cardinality(self, value):
+        self._cardinality = value
+
+    @property
+    def probability(self):
+        return self._probability
+
+    @property
+    def n_occurences(self):
+        return self._n_occurences
+
+    @probability.setter
+    def probability(self, value):
+        self._probability = value
+
+    @property
+    def comments(self):
+        return self._comments
+
+    @property
+    def serializer_object(self):
+        return self._serializer_object
+
+    @serializer_object.setter
+    def serializer_object(self, value):
+        self._serializer_object = value
+
+    @property
+    def is_inverse(self):
+        return self._is_inverse
+
+    @is_inverse.setter
+    def is_inverse(self, value):
+        self._is_inverse = value
```

### Comparing `shexer-2.5.1/shexer/shaper.py` & `shexer-2.5.2/shexer/shaper.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,478 +1,478 @@
-from shexer.utils.obj_references import check_just_one_not_none
-
-from shexer.consts import SHEXC, SHACL_TURTLE, NT, TSV_SPO, N3, TURTLE, TURTLE_ITER, \
-    RDF_XML, FIXED_SHAPE_MAP, JSON_LD, RDF_TYPE, SHAPES_DEFAULT_NAMESPACE, ZIP, GZ, XZ, \
-    ALL_EXAMPLES, CONSTRAINT_EXAMPLES, SHAPE_EXAMPLES
-from shexer.utils.factories.class_profiler_factory import get_class_profiler
-from shexer.utils.factories.instance_tracker_factory import get_instance_tracker
-from shexer.utils.factories.class_shexer_factory import get_class_shexer
-from shexer.utils.factories.remote_graph_factory import get_remote_graph_if_needed
-from shexer.utils.factories.shape_map_factory import get_shape_map_if_needed
-from shexer.io.profile.formater.abstract_profile_serializer import AbstractProfileSerializer
-from shexer.utils.factories.shape_serializer_factory import get_shape_serializer, get_uml_serializer
-from shexer.utils.namespaces import find_adequate_prefix_for_shapes_namespaces
-from shexer.utils.log import log_msg
-from shexer.consts import RATIO_INSTANCES
-
-
-class Shaper(object):
-
-    def __init__(self, target_classes=None,
-                 file_target_classes=None,
-                 input_format=NT,
-                 instances_file_input=None,
-                 graph_file_input=None,
-                 graph_list_of_files_input=None,
-                 raw_graph=None,
-                 url_graph_input=None,
-                 rdflib_graph=None,
-                 list_of_url_input=None,
-                 namespaces_dict=None,
-                 # namespaces_dict_file=None,
-                 instantiation_property=RDF_TYPE,
-                 namespaces_to_ignore=None,
-                 infer_numeric_types_for_untyped_literals=True,
-                 discard_useless_constraints_with_positive_closure=True,
-                 all_instances_are_compliant_mode=True,
-                 keep_less_specific=True,
-                 all_classes_mode=False,
-                 shape_map_file=None,
-                 shape_map_raw=None,
-                 depth_for_building_subgraph=1,
-                 track_classes_for_entities_at_last_depth_level=False,
-                 strict_syntax_with_corners=False,
-                 url_endpoint=None,
-                 shape_map_format=FIXED_SHAPE_MAP,
-                 shape_qualifiers_mode=False,
-                 namespaces_for_qualifier_props=None,
-                 remove_empty_shapes=True,
-                 disable_comments=False,
-                 disable_or_statements=True,
-                 allow_opt_cardinality=True,
-                 disable_exact_cardinality=False,
-                 shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
-                 limit_remote_instances=-1,
-                 wikidata_annotation=False,
-                 inverse_paths=False,
-                 compression_mode=None,
-                 decimals=-1,
-                 instances_report_mode=RATIO_INSTANCES,
-                 disable_endpoint_cache=False,
-                 detect_minimal_iri=False,
-                 allow_redundant_or=False,
-                 instances_cap=-1,
-                 examples_mode=None
-                 ):
-        """
-
-        :param target_classes:
-        :param file_target_classes:
-        :param input_format:
-        :param instances_file_input:
-        :param graph_file_input:
-        :param graph_list_of_files_input:
-        :param raw_graph:
-        :param url_graph_input:
-        :param rdflib_graph:
-        :param list_of_url_input:
-        :param namespaces_dict:
-        :param instantiation_property:
-        :param namespaces_to_ignore:
-        :param infer_numeric_types_for_untyped_literals:
-        :param discard_useless_constraints_with_positive_closure:
-        :param all_instances_are_compliant_mode:
-        :param keep_less_specific:
-        :param all_classes_mode:
-        :param shape_map_file:
-        :param shape_map_raw:
-        :param depth_for_building_subgraph:
-        :param track_classes_for_entities_at_last_depth_level:
-        :param strict_syntax_with_corners:
-        :param url_endpoint:
-        :param shape_map_format:
-        :param shape_qualifiers_mode:
-        :param namespaces_for_qualifier_props:
-        :param remove_empty_shapes:
-        :param disable_comments:
-        :param disable_or_statements:
-        :param allow_opt_cardinality:
-        :param disable_exact_cardinality:
-        :param shapes_namespace:
-        :param limit_remote_instances:
-        :param wikidata_annotation:
-        :param inverse_paths:
-        :param compression_mode:
-        :param decimals:
-        :param instances_report_mode:
-        :param disable_endpoint_cache:
-        :param detect_minimal_iri:
-        :param allow_redundant_or:
-        :param instances_cap:
-        :param examples_mode:
-        """
-
-        check_just_one_not_none((graph_file_input, "graph_file_input"),
-                                (graph_list_of_files_input, "graph_list_of_files_input"),
-                                (raw_graph, "raw_graph"),
-                                (url_graph_input, "url_input"),
-                                (list_of_url_input, "list_of_url_input"),
-                                (url_endpoint, "url_endpoint"),
-                                (rdflib_graph, "rdflib_graph")
-                                )
-
-        # check_one_or_zero_not_none((namespaces_dict, "namespaces_dict"),
-        #                            (namespaces_dict_file, "namespaces_dict_file"))
-
-        self._check_target_classes(target_classes=target_classes,
-                                   file_target_classes=file_target_classes,
-                                   all_classes_mode=all_classes_mode,
-                                   shape_map_raw=shape_map_raw,
-                                   shape_map_file=shape_map_file)
-
-        self._check_or_config(or_disabled=disable_or_statements,
-                              enable_redundant=allow_redundant_or)
-
-        #TODO ---> Param check of shape_map and graph_via_shape_map
-
-        self._check_input_format(input_format)
-
-        self._check_compression_mode(compression_mode, url_endpoint, url_graph_input, list_of_url_input)
-
-        self._check_examples_mode(examples_mode)
-
-        self._target_classes = target_classes
-        self._file_target_classes = file_target_classes
-        self._input_format = input_format
-        self._instances_file_input = instances_file_input
-        self._graph_file_input = graph_file_input
-        self._graph_list_of_files_input = graph_list_of_files_input
-        self._url_graph_input = url_graph_input
-        self._list_of_url_input = list_of_url_input
-        self._rdflib_graph = rdflib_graph
-        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
-        self._instantiation_property = instantiation_property
-        self._namespaces_to_ignore = namespaces_to_ignore
-        self._infer_numeric_types_for_untyped_literals = infer_numeric_types_for_untyped_literals
-        self._discard_useles_constraints_with_positive_closure = discard_useless_constraints_with_positive_closure
-        self._all_compliant_mode = all_instances_are_compliant_mode
-        self._keep_less_specific = keep_less_specific
-        self._raw_graph = raw_graph
-        self._all_classes_mode = all_classes_mode
-        self._shape_map_file = shape_map_file
-        self._shape_map_raw = shape_map_raw
-        self._decimals = decimals
-        self._instances_report_mode = instances_report_mode
-        self._disable_endpoint_cache=disable_endpoint_cache
-        self._allow_redundant_or = allow_redundant_or
-        self._instances_cap = instances_cap
-
-        self._remove_empty_shapes=remove_empty_shapes
-        self._disable_comments = disable_comments
-        self._disable_or_statements = disable_or_statements
-        self._allow_opt_cardinality = allow_opt_cardinality
-        self._disable_exact_cardinality = disable_exact_cardinality
-        # TODO: REMOVE THE _limit_remote_instances PARAMETER IN FUTURE RELEASES
-        self._limit_remote_instances = limit_remote_instances if instances_cap==-1 else instances_cap
-        self._wikidata_annotation = wikidata_annotation
-        self._inverse_paths = inverse_paths
-        self._detect_minimal_iri = detect_minimal_iri
-        self._examples_mode = examples_mode
-
-        self._compression_mode = compression_mode
-
-        self._depth_for_building_subgraph = depth_for_building_subgraph
-        self._track_classes_for_entities_at_last_depth_level = track_classes_for_entities_at_last_depth_level
-        self._url_endpoint = url_endpoint
-        self._strict_syntax_with_corners = strict_syntax_with_corners
-        self._shape_map_format = shape_map_format
-        self._shape_qualifiers_mode = shape_qualifiers_mode
-        self._namespaces_for_qualifier_props = namespaces_for_qualifier_props
-        self._shapes_namespace = shapes_namespace
-
-        self._add_shapes_namespaces_to_namespaces_dict()
-
-
-        #The following two atts are used for optimizations
-        self._built_remote_graph = get_remote_graph_if_needed(endpoint_url=url_endpoint,
-                                                              store_locally=not disable_endpoint_cache)
-        self._built_shape_map = get_shape_map_if_needed(sm_format=self._shape_map_format,
-                                                        remote_sgraph=self._built_remote_graph,
-                                                        namespaces_prefix_dict=self._namespaces_dict,
-                                                        target_classes=self._target_classes,
-                                                        file_target_classes=self._file_target_classes,
-                                                        shape_map_file=self._shape_map_file,
-                                                        shape_map_raw=self._shape_map_raw,
-                                                        instantiation_property=self._instantiation_property,
-                                                        shape_map_already_built=None,
-                                                        rdflib_graph=self._rdflib_graph,
-                                                        raw_graph=self._raw_graph,
-                                                        input_format=self._input_format,
-                                                        source_file_graph=self._graph_file_input,
-                                                        limit_remote_instances=self._limit_remote_instances)
-
-
-
-        self._instance_tracker = None
-        self._target_classes_dict = None
-        self._class_profiler = None
-        self._profile = None
-        self._class_counts = None
-        self._class_min_iris = None
-        self._class_shexer = None
-        self._shape_list = None
-
-    def profile_graph(self, string_output=False, output_file=None, verbose=False):
-        self._check_correct_output_params(string_output, output_file)
-        if self._target_classes_dict is None:
-            self._launch_instance_tracker(verbose=verbose)
-        if self._profile is None:
-            self._launch_class_profiler(verbose=verbose)
-        log_msg(verbose=verbose,
-                msg="Building_output...")
-        if string_output:
-            return AbstractProfileSerializer(self._profile).get_string_representation()
-        return AbstractProfileSerializer(self._profile).write_profile_to_file(target_file=output_file)
-
-    def shex_graph(self, string_output=False,
-                   output_file=None,
-                   output_format=SHEXC,
-                   acceptance_threshold=0,
-                   verbose=False,
-                   to_uml_path=None):
-        """
-        :param string_output:
-        :param output_file:
-        :param output_format:
-        :param acceptance_threshold:
-        :param verbose:
-        :param to_uml_path:
-        :return:
-        """
-        self._check_correct_output_params(string_output, output_file, to_uml_path)
-        self._check_output_format(output_format)
-        self._check_aceptance_threshold(acceptance_threshold)
-        if self._target_classes_dict is None:
-            self._launch_instance_tracker(verbose=verbose)
-        if self._profile is None:
-            self._launch_class_profiler(verbose=verbose)
-        if self._shape_list is None:
-            self._launch_class_shexer(acceptance_threshold=acceptance_threshold,
-                                      verbose=verbose)
-        log_msg(verbose=verbose,
-                msg="Building_output...")
-
-        if to_uml_path is not None:
-            log_msg(verbose=verbose,
-                    msg="Trying to generat UML diagram...")
-            try:
-                self._generate_uml_diagram(to_uml_path)
-                log_msg(verbose=verbose,
-                        msg="UML diagram generated...")
-            except ResourceWarning as e:  # I think this is related to UMLPlant and I can't close the connection from here
-                pass
-
-        if string_output or output_file is not None:
-            log_msg(verbose=verbose,
-                    msg="Generating text serialization...")
-            serializer = self._build_shapes_serializer(target_file=output_file,
-                                                       string_return=string_output,
-                                                       output_format=output_format)
-
-            return serializer.serialize_shapes()  # If string return is active, returns string.
-
-
-    def _generate_uml_diagram(self, to_uml_path):
-        serializer = get_uml_serializer(shapes_list=self._shape_list,
-                                        image_path=to_uml_path,
-                                        namespaces_dict=self._namespaces_dict)
-        serializer.serialize_shapes()
-
-
-
-
-    def _add_shapes_namespaces_to_namespaces_dict(self):
-        self._namespaces_dict[self._shapes_namespace] = \
-            find_adequate_prefix_for_shapes_namespaces(self._namespaces_dict)
-
-    def _launch_class_profiler(self, verbose=False):
-        if self._class_profiler is None:
-            self._class_profiler = self._build_class_profiler()
-        self._profile, self._class_counts, self._class_min_iris = self._class_profiler.profile_classes(verbose=verbose)
-
-    def _launch_class_shexer(self, acceptance_threshold, verbose=False):
-        if self._class_shexer is None:
-            self._class_shexer = self._build_class_shexer()
-        self._shape_list = self._class_shexer.shex_classes(acceptance_threshold=acceptance_threshold,
-                                                           verbose=verbose)
-
-    def _launch_instance_tracker(self, verbose=False):
-        if self._instance_tracker is None:
-            self._instance_tracker = self._build_instance_tracker()
-        self._target_classes_dict = self._instance_tracker.track_instances(verbose=verbose)
-
-    def _build_class_shexer(self):
-        return get_class_shexer(class_counts=self._class_counts,
-                                class_profile_dict=self._profile,
-                                original_target_classes=self._target_classes,
-                                original_shape_map=self._built_shape_map,
-                                remove_empty_shapes=self._remove_empty_shapes,
-                                discard_useless_constraints_with_positive_closure=
-                                self._discard_useles_constraints_with_positive_closure,
-                                keep_less_specific=self._keep_less_specific,
-                                all_compliant_mode=self._all_compliant_mode,
-                                instantiation_property=self._instantiation_property,
-                                disable_or_statements=self._disable_or_statements,
-                                disable_comments=self._disable_comments,
-                                namespaces_dict=self._namespaces_dict,
-                                allow_opt_cardinality=self._allow_opt_cardinality,
-                                disable_exact_cardinality=self._disable_exact_cardinality,
-                                shapes_namespace=self._shapes_namespace,
-                                inverse_paths=self._inverse_paths,
-                                decimals=self._decimals,
-                                instances_report_mode=self._instances_report_mode,
-                                detect_minimal_iri=self._detect_minimal_iri,
-                                class_min_iris=self._class_min_iris,
-                                allow_redundant_or=self._allow_redundant_or,
-
-                                )
-
-    def _build_shapes_serializer(self, target_file, string_return, output_format):
-        return get_shape_serializer(shapes_list=self._shape_list,
-                                    target_file=target_file,
-                                    string_return=string_return,
-                                    namespaces_dict=self._namespaces_dict,
-                                    output_format=output_format,
-                                    instantiation_property=self._instantiation_property,
-                                    disable_comments=self._disable_comments,
-                                    wikidata_annotation=self._wikidata_annotation,
-                                    instances_report_mode=self._instances_report_mode,
-                                    detect_minimal_iri=self._detect_minimal_iri,
-                                    shape_features_examples=self._class_min_iris,
-                                    examples_mode=self._examples_mode,
-                                    inverse_paths=self._inverse_paths)
-
-    def _build_class_profiler(self):
-        return get_class_profiler(target_classes_dict=self._target_classes_dict,
-                                  source_file=self._graph_file_input,
-                                  list_of_source_files=self._graph_list_of_files_input,
-                                  input_format=self._input_format,
-                                  instantiation_property_str=self._instantiation_property,
-                                  namespaces_to_ignore=self._namespaces_to_ignore,
-                                  infer_numeric_types_for_untyped_literals=self._infer_numeric_types_for_untyped_literals,
-                                  raw_graph=self._raw_graph,
-                                  namespaces_dict=self._namespaces_dict,
-                                  url_input=self._url_graph_input,
-                                  list_of_url_input=self._list_of_url_input,
-                                  rdflib_graph=self._rdflib_graph,
-                                  shape_map_file=self._shape_map_file,
-                                  shape_map_raw=self._shape_map_raw,
-                                  track_classes_for_entities_at_last_depth_level=self._track_classes_for_entities_at_last_depth_level,
-                                  depth_for_building_subgraph=self._depth_for_building_subgraph,
-                                  url_endpoint=self._url_endpoint,
-                                  strict_syntax_with_corners=self._strict_syntax_with_corners,
-                                  target_classes=self._target_classes,
-                                  file_target_classes=self._file_target_classes,
-                                  built_remote_graph=self._built_remote_graph,
-                                  built_shape_map=self._built_shape_map,
-                                  remove_empty_shapes=self._remove_empty_shapes,
-                                  limit_remote_instances=self._limit_remote_instances,
-                                  inverse_paths=self._inverse_paths,
-                                  all_classes_mode=self._all_classes_mode,
-                                  compression_mode=self._compression_mode,
-                                  disable_endpoint_cache=self._disable_endpoint_cache,
-                                  detect_minimal_iri=self._detect_minimal_iri,
-                                  examples_mode=self._examples_mode)
-
-
-    def _build_instance_tracker(self):
-        return get_instance_tracker(instances_file_input=self._instances_file_input,
-                                    graph_file_input=self._graph_file_input,
-                                    graph_list_of_files_input=self._graph_list_of_files_input,
-                                    target_classes=self._target_classes,
-                                    file_target_classes=self._file_target_classes,
-                                    input_format=self._input_format,
-                                    instantiation_property=self._instantiation_property,
-                                    infer_numeric_types_for_untyped_literals=self._infer_numeric_types_for_untyped_literals,
-                                    raw_graph=self._raw_graph,
-                                    all_classes_mode=self._all_classes_mode,
-                                    namespaces_dict=self._namespaces_dict,
-                                    url_input=self._url_graph_input,
-                                    list_of_url_input=self._list_of_url_input,
-                                    rdflib_graph=self._rdflib_graph,
-                                    shape_map_file=self._shape_map_file,
-                                    shape_map_raw=self._shape_map_raw,
-                                    track_classes_for_entities_at_last_depth_level=self._track_classes_for_entities_at_last_depth_level,
-                                    depth_for_building_subgraph=self._depth_for_building_subgraph,
-                                    url_endpoint=self._url_endpoint,
-                                    strict_syntax_with_corners=self._strict_syntax_with_corners,
-                                    shape_map_format=self._shape_map_format,
-                                    namespaces_for_qualifier_props=self._namespaces_for_qualifier_props,
-                                    shape_qualifiers_mode=self._shape_qualifiers_mode,
-                                    built_remote_graph=self._built_remote_graph,
-                                    built_shape_map=self._built_shape_map,
-                                    shapes_namespace=self._shapes_namespace,
-                                    limit_remote_instances=self._limit_remote_instances,
-                                    inverse_paths=self._inverse_paths,
-                                    compression_mode=self._compression_mode,
-                                    disable_endpoint_cache=self._disable_endpoint_cache,
-                                    instances_cap=self._instances_cap)
-
-
-    @staticmethod
-    def _check_correct_output_params(string_output, target_file, to_uml_path):
-        if not string_output and target_file is None and to_uml_path is None:
-            raise ValueError("You must provide a target path , set string output to True and/or give a value to to_uml_path")
-
-    @staticmethod
-    def _check_input_format(input_format):
-        if input_format not in [NT, TSV_SPO, N3, TURTLE, RDF_XML, JSON_LD, TURTLE_ITER]:
-            raise ValueError("Currently unsupported input format: " + input_format)
-
-    @staticmethod
-    def _check_compression_mode(compression_mode, url_endpoint, url_graph_input, list_of_url_input):
-        if compression_mode not in [ZIP, GZ, XZ, None]:
-            raise ValueError("Unknownk compression mode: {}. "
-                             "The currently supported compression formats are {}.".format(
-                compression_mode,
-                ", ".join([ZIP, GZ, XZ])))
-        if compression_mode is not None and (url_endpoint is not None or url_graph_input is not None or list_of_url_input is not None):
-            raise ValueError("You've chosed some compression mode ({}) to work with remote sources."
-                             "Currently, sheXer can only parse compressed local files".format(compression_mode))
-
-
-    @staticmethod
-    def _check_target_classes(target_classes, file_target_classes, all_classes_mode, shape_map_file, shape_map_raw):
-        if not all_classes_mode:
-            check_just_one_not_none((target_classes, "target_classes"),
-                                    (file_target_classes, "file_target_classes"),
-                                    (shape_map_file, "shape_map_file"),
-                                    (shape_map_raw, "shape_map_raw")
-                                    )
-        else:
-            if target_classes is not None or file_target_classes is not None:
-                raise ValueError("You must provide a list of target classes XOR set all_classes_mode to True")
-            # But all_classes mode is compatible with shape_map_selectors. Setting all_classes_mode = True and
-            # providing some selectros will cause shexer to shex both the shapes specified in the selectors
-            # and to create a shape for eahc element with an instance in the target graph
-
-    @staticmethod
-    def _check_output_format(output_format):
-        if output_format not in [SHEXC, SHACL_TURTLE]:
-            raise ValueError("Currently unsupported output format: " + output_format)
-
-    @staticmethod
-    def _check_or_config(or_disabled, enable_redundant):
-        if or_disabled and enable_redundant:
-            raise ValueError("You are indicating that you'd like to have disjunction constraints including the macro "
-                             "IRI, but also that you do not want to have or constraints. Please, check your configuration"
-                             "of the disable_or_statements and allow_redundant_or paremeters")
-
-    @staticmethod
-    def _check_aceptance_threshold(aceptance_threshold):
-        if aceptance_threshold < 0 or aceptance_threshold > 1:
-            raise ValueError("The acceptance threshold must be a value in [0,1]")
-
-    @staticmethod
-    def _check_examples_mode(examples_mode):
-        if examples_mode not in [None, ALL_EXAMPLES, CONSTRAINT_EXAMPLES, SHAPE_EXAMPLES]:
-            raise ValueError("The examples mode param should be set to None or using one of the values in shexer.const, section \"EXAMPLES\" ")
+from shexer.utils.obj_references import check_just_one_not_none
+
+from shexer.consts import SHEXC, SHACL_TURTLE, NT, TSV_SPO, N3, TURTLE, TURTLE_ITER, \
+    RDF_XML, FIXED_SHAPE_MAP, JSON_LD, RDF_TYPE, SHAPES_DEFAULT_NAMESPACE, ZIP, GZ, XZ, \
+    ALL_EXAMPLES, CONSTRAINT_EXAMPLES, SHAPE_EXAMPLES
+from shexer.utils.factories.class_profiler_factory import get_class_profiler
+from shexer.utils.factories.instance_tracker_factory import get_instance_tracker
+from shexer.utils.factories.class_shexer_factory import get_class_shexer
+from shexer.utils.factories.remote_graph_factory import get_remote_graph_if_needed
+from shexer.utils.factories.shape_map_factory import get_shape_map_if_needed
+from shexer.io.profile.formater.abstract_profile_serializer import AbstractProfileSerializer
+from shexer.utils.factories.shape_serializer_factory import get_shape_serializer, get_uml_serializer
+from shexer.utils.namespaces import find_adequate_prefix_for_shapes_namespaces
+from shexer.utils.log import log_msg
+from shexer.consts import RATIO_INSTANCES
+
+
+class Shaper(object):
+
+    def __init__(self, target_classes=None,
+                 file_target_classes=None,
+                 input_format=NT,
+                 instances_file_input=None,
+                 graph_file_input=None,
+                 graph_list_of_files_input=None,
+                 raw_graph=None,
+                 url_graph_input=None,
+                 rdflib_graph=None,
+                 list_of_url_input=None,
+                 namespaces_dict=None,
+                 # namespaces_dict_file=None,
+                 instantiation_property=RDF_TYPE,
+                 namespaces_to_ignore=None,
+                 infer_numeric_types_for_untyped_literals=True,
+                 discard_useless_constraints_with_positive_closure=True,
+                 all_instances_are_compliant_mode=True,
+                 keep_less_specific=True,
+                 all_classes_mode=False,
+                 shape_map_file=None,
+                 shape_map_raw=None,
+                 depth_for_building_subgraph=1,
+                 track_classes_for_entities_at_last_depth_level=False,
+                 strict_syntax_with_corners=False,
+                 url_endpoint=None,
+                 shape_map_format=FIXED_SHAPE_MAP,
+                 shape_qualifiers_mode=False,
+                 namespaces_for_qualifier_props=None,
+                 remove_empty_shapes=True,
+                 disable_comments=False,
+                 disable_or_statements=True,
+                 allow_opt_cardinality=True,
+                 disable_exact_cardinality=False,
+                 shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
+                 limit_remote_instances=-1,
+                 wikidata_annotation=False,
+                 inverse_paths=False,
+                 compression_mode=None,
+                 decimals=-1,
+                 instances_report_mode=RATIO_INSTANCES,
+                 disable_endpoint_cache=False,
+                 detect_minimal_iri=False,
+                 allow_redundant_or=False,
+                 instances_cap=-1,
+                 examples_mode=None
+                 ):
+        """
+
+        :param target_classes:
+        :param file_target_classes:
+        :param input_format:
+        :param instances_file_input:
+        :param graph_file_input:
+        :param graph_list_of_files_input:
+        :param raw_graph:
+        :param url_graph_input:
+        :param rdflib_graph:
+        :param list_of_url_input:
+        :param namespaces_dict:
+        :param instantiation_property:
+        :param namespaces_to_ignore:
+        :param infer_numeric_types_for_untyped_literals:
+        :param discard_useless_constraints_with_positive_closure:
+        :param all_instances_are_compliant_mode:
+        :param keep_less_specific:
+        :param all_classes_mode:
+        :param shape_map_file:
+        :param shape_map_raw:
+        :param depth_for_building_subgraph:
+        :param track_classes_for_entities_at_last_depth_level:
+        :param strict_syntax_with_corners:
+        :param url_endpoint:
+        :param shape_map_format:
+        :param shape_qualifiers_mode:
+        :param namespaces_for_qualifier_props:
+        :param remove_empty_shapes:
+        :param disable_comments:
+        :param disable_or_statements:
+        :param allow_opt_cardinality:
+        :param disable_exact_cardinality:
+        :param shapes_namespace:
+        :param limit_remote_instances:
+        :param wikidata_annotation:
+        :param inverse_paths:
+        :param compression_mode:
+        :param decimals:
+        :param instances_report_mode:
+        :param disable_endpoint_cache:
+        :param detect_minimal_iri:
+        :param allow_redundant_or:
+        :param instances_cap:
+        :param examples_mode:
+        """
+
+        check_just_one_not_none((graph_file_input, "graph_file_input"),
+                                (graph_list_of_files_input, "graph_list_of_files_input"),
+                                (raw_graph, "raw_graph"),
+                                (url_graph_input, "url_input"),
+                                (list_of_url_input, "list_of_url_input"),
+                                (url_endpoint, "url_endpoint"),
+                                (rdflib_graph, "rdflib_graph")
+                                )
+
+        # check_one_or_zero_not_none((namespaces_dict, "namespaces_dict"),
+        #                            (namespaces_dict_file, "namespaces_dict_file"))
+
+        self._check_target_classes(target_classes=target_classes,
+                                   file_target_classes=file_target_classes,
+                                   all_classes_mode=all_classes_mode,
+                                   shape_map_raw=shape_map_raw,
+                                   shape_map_file=shape_map_file)
+
+        self._check_or_config(or_disabled=disable_or_statements,
+                              enable_redundant=allow_redundant_or)
+
+        #TODO ---> Param check of shape_map and graph_via_shape_map
+
+        self._check_input_format(input_format)
+
+        self._check_compression_mode(compression_mode, url_endpoint, url_graph_input, list_of_url_input)
+
+        self._check_examples_mode(examples_mode)
+
+        self._target_classes = target_classes
+        self._file_target_classes = file_target_classes
+        self._input_format = input_format
+        self._instances_file_input = instances_file_input
+        self._graph_file_input = graph_file_input
+        self._graph_list_of_files_input = graph_list_of_files_input
+        self._url_graph_input = url_graph_input
+        self._list_of_url_input = list_of_url_input
+        self._rdflib_graph = rdflib_graph
+        self._namespaces_dict = namespaces_dict if namespaces_dict is not None else {}
+        self._instantiation_property = instantiation_property
+        self._namespaces_to_ignore = namespaces_to_ignore
+        self._infer_numeric_types_for_untyped_literals = infer_numeric_types_for_untyped_literals
+        self._discard_useles_constraints_with_positive_closure = discard_useless_constraints_with_positive_closure
+        self._all_compliant_mode = all_instances_are_compliant_mode
+        self._keep_less_specific = keep_less_specific
+        self._raw_graph = raw_graph
+        self._all_classes_mode = all_classes_mode
+        self._shape_map_file = shape_map_file
+        self._shape_map_raw = shape_map_raw
+        self._decimals = decimals
+        self._instances_report_mode = instances_report_mode
+        self._disable_endpoint_cache=disable_endpoint_cache
+        self._allow_redundant_or = allow_redundant_or
+        self._instances_cap = instances_cap
+
+        self._remove_empty_shapes=remove_empty_shapes
+        self._disable_comments = disable_comments
+        self._disable_or_statements = disable_or_statements
+        self._allow_opt_cardinality = allow_opt_cardinality
+        self._disable_exact_cardinality = disable_exact_cardinality
+        # TODO: REMOVE THE _limit_remote_instances PARAMETER IN FUTURE RELEASES
+        self._limit_remote_instances = limit_remote_instances if instances_cap==-1 else instances_cap
+        self._wikidata_annotation = wikidata_annotation
+        self._inverse_paths = inverse_paths
+        self._detect_minimal_iri = detect_minimal_iri
+        self._examples_mode = examples_mode
+
+        self._compression_mode = compression_mode
+
+        self._depth_for_building_subgraph = depth_for_building_subgraph
+        self._track_classes_for_entities_at_last_depth_level = track_classes_for_entities_at_last_depth_level
+        self._url_endpoint = url_endpoint
+        self._strict_syntax_with_corners = strict_syntax_with_corners
+        self._shape_map_format = shape_map_format
+        self._shape_qualifiers_mode = shape_qualifiers_mode
+        self._namespaces_for_qualifier_props = namespaces_for_qualifier_props
+        self._shapes_namespace = shapes_namespace
+
+        self._add_shapes_namespaces_to_namespaces_dict()
+
+
+        #The following two atts are used for optimizations
+        self._built_remote_graph = get_remote_graph_if_needed(endpoint_url=url_endpoint,
+                                                              store_locally=not disable_endpoint_cache)
+        self._built_shape_map = get_shape_map_if_needed(sm_format=self._shape_map_format,
+                                                        remote_sgraph=self._built_remote_graph,
+                                                        namespaces_prefix_dict=self._namespaces_dict,
+                                                        target_classes=self._target_classes,
+                                                        file_target_classes=self._file_target_classes,
+                                                        shape_map_file=self._shape_map_file,
+                                                        shape_map_raw=self._shape_map_raw,
+                                                        instantiation_property=self._instantiation_property,
+                                                        shape_map_already_built=None,
+                                                        rdflib_graph=self._rdflib_graph,
+                                                        raw_graph=self._raw_graph,
+                                                        input_format=self._input_format,
+                                                        source_file_graph=self._graph_file_input,
+                                                        limit_remote_instances=self._limit_remote_instances)
+
+
+
+        self._instance_tracker = None
+        self._target_classes_dict = None
+        self._class_profiler = None
+        self._profile = None
+        self._class_counts = None
+        self._class_min_iris = None
+        self._class_shexer = None
+        self._shape_list = None
+
+    def profile_graph(self, string_output=False, output_file=None, verbose=False):
+        self._check_correct_output_params(string_output, output_file)
+        if self._target_classes_dict is None:
+            self._launch_instance_tracker(verbose=verbose)
+        if self._profile is None:
+            self._launch_class_profiler(verbose=verbose)
+        log_msg(verbose=verbose,
+                msg="Building_output...")
+        if string_output:
+            return AbstractProfileSerializer(self._profile).get_string_representation()
+        return AbstractProfileSerializer(self._profile).write_profile_to_file(target_file=output_file)
+
+    def shex_graph(self, string_output=False,
+                   output_file=None,
+                   output_format=SHEXC,
+                   acceptance_threshold=0,
+                   verbose=False,
+                   to_uml_path=None):
+        """
+        :param string_output:
+        :param output_file:
+        :param output_format:
+        :param acceptance_threshold:
+        :param verbose:
+        :param to_uml_path:
+        :return:
+        """
+        self._check_correct_output_params(string_output, output_file, to_uml_path)
+        self._check_output_format(output_format)
+        self._check_aceptance_threshold(acceptance_threshold)
+        if self._target_classes_dict is None:
+            self._launch_instance_tracker(verbose=verbose)
+        if self._profile is None:
+            self._launch_class_profiler(verbose=verbose)
+        if self._shape_list is None:
+            self._launch_class_shexer(acceptance_threshold=acceptance_threshold,
+                                      verbose=verbose)
+        log_msg(verbose=verbose,
+                msg="Building_output...")
+
+        if to_uml_path is not None:
+            log_msg(verbose=verbose,
+                    msg="Trying to generat UML diagram...")
+            try:
+                self._generate_uml_diagram(to_uml_path)
+                log_msg(verbose=verbose,
+                        msg="UML diagram generated...")
+            except ResourceWarning as e:  # I think this is related to UMLPlant and I can't close the connection from here
+                pass
+
+        if string_output or output_file is not None:
+            log_msg(verbose=verbose,
+                    msg="Generating text serialization...")
+            serializer = self._build_shapes_serializer(target_file=output_file,
+                                                       string_return=string_output,
+                                                       output_format=output_format)
+
+            return serializer.serialize_shapes()  # If string return is active, returns string.
+
+
+    def _generate_uml_diagram(self, to_uml_path):
+        serializer = get_uml_serializer(shapes_list=self._shape_list,
+                                        image_path=to_uml_path,
+                                        namespaces_dict=self._namespaces_dict)
+        serializer.serialize_shapes()
+
+
+
+
+    def _add_shapes_namespaces_to_namespaces_dict(self):
+        self._namespaces_dict[self._shapes_namespace] = \
+            find_adequate_prefix_for_shapes_namespaces(self._namespaces_dict)
+
+    def _launch_class_profiler(self, verbose=False):
+        if self._class_profiler is None:
+            self._class_profiler = self._build_class_profiler()
+        self._profile, self._class_counts, self._class_min_iris = self._class_profiler.profile_classes(verbose=verbose)
+
+    def _launch_class_shexer(self, acceptance_threshold, verbose=False):
+        if self._class_shexer is None:
+            self._class_shexer = self._build_class_shexer()
+        self._shape_list = self._class_shexer.shex_classes(acceptance_threshold=acceptance_threshold,
+                                                           verbose=verbose)
+
+    def _launch_instance_tracker(self, verbose=False):
+        if self._instance_tracker is None:
+            self._instance_tracker = self._build_instance_tracker()
+        self._target_classes_dict = self._instance_tracker.track_instances(verbose=verbose)
+
+    def _build_class_shexer(self):
+        return get_class_shexer(class_counts=self._class_counts,
+                                class_profile_dict=self._profile,
+                                original_target_classes=self._target_classes,
+                                original_shape_map=self._built_shape_map,
+                                remove_empty_shapes=self._remove_empty_shapes,
+                                discard_useless_constraints_with_positive_closure=
+                                self._discard_useles_constraints_with_positive_closure,
+                                keep_less_specific=self._keep_less_specific,
+                                all_compliant_mode=self._all_compliant_mode,
+                                instantiation_property=self._instantiation_property,
+                                disable_or_statements=self._disable_or_statements,
+                                disable_comments=self._disable_comments,
+                                namespaces_dict=self._namespaces_dict,
+                                allow_opt_cardinality=self._allow_opt_cardinality,
+                                disable_exact_cardinality=self._disable_exact_cardinality,
+                                shapes_namespace=self._shapes_namespace,
+                                inverse_paths=self._inverse_paths,
+                                decimals=self._decimals,
+                                instances_report_mode=self._instances_report_mode,
+                                detect_minimal_iri=self._detect_minimal_iri,
+                                class_min_iris=self._class_min_iris,
+                                allow_redundant_or=self._allow_redundant_or,
+
+                                )
+
+    def _build_shapes_serializer(self, target_file, string_return, output_format):
+        return get_shape_serializer(shapes_list=self._shape_list,
+                                    target_file=target_file,
+                                    string_return=string_return,
+                                    namespaces_dict=self._namespaces_dict,
+                                    output_format=output_format,
+                                    instantiation_property=self._instantiation_property,
+                                    disable_comments=self._disable_comments,
+                                    wikidata_annotation=self._wikidata_annotation,
+                                    instances_report_mode=self._instances_report_mode,
+                                    detect_minimal_iri=self._detect_minimal_iri,
+                                    shape_features_examples=self._class_min_iris,
+                                    examples_mode=self._examples_mode,
+                                    inverse_paths=self._inverse_paths)
+
+    def _build_class_profiler(self):
+        return get_class_profiler(target_classes_dict=self._target_classes_dict,
+                                  source_file=self._graph_file_input,
+                                  list_of_source_files=self._graph_list_of_files_input,
+                                  input_format=self._input_format,
+                                  instantiation_property_str=self._instantiation_property,
+                                  namespaces_to_ignore=self._namespaces_to_ignore,
+                                  infer_numeric_types_for_untyped_literals=self._infer_numeric_types_for_untyped_literals,
+                                  raw_graph=self._raw_graph,
+                                  namespaces_dict=self._namespaces_dict,
+                                  url_input=self._url_graph_input,
+                                  list_of_url_input=self._list_of_url_input,
+                                  rdflib_graph=self._rdflib_graph,
+                                  shape_map_file=self._shape_map_file,
+                                  shape_map_raw=self._shape_map_raw,
+                                  track_classes_for_entities_at_last_depth_level=self._track_classes_for_entities_at_last_depth_level,
+                                  depth_for_building_subgraph=self._depth_for_building_subgraph,
+                                  url_endpoint=self._url_endpoint,
+                                  strict_syntax_with_corners=self._strict_syntax_with_corners,
+                                  target_classes=self._target_classes,
+                                  file_target_classes=self._file_target_classes,
+                                  built_remote_graph=self._built_remote_graph,
+                                  built_shape_map=self._built_shape_map,
+                                  remove_empty_shapes=self._remove_empty_shapes,
+                                  limit_remote_instances=self._limit_remote_instances,
+                                  inverse_paths=self._inverse_paths,
+                                  all_classes_mode=self._all_classes_mode,
+                                  compression_mode=self._compression_mode,
+                                  disable_endpoint_cache=self._disable_endpoint_cache,
+                                  detect_minimal_iri=self._detect_minimal_iri,
+                                  examples_mode=self._examples_mode)
+
+
+    def _build_instance_tracker(self):
+        return get_instance_tracker(instances_file_input=self._instances_file_input,
+                                    graph_file_input=self._graph_file_input,
+                                    graph_list_of_files_input=self._graph_list_of_files_input,
+                                    target_classes=self._target_classes,
+                                    file_target_classes=self._file_target_classes,
+                                    input_format=self._input_format,
+                                    instantiation_property=self._instantiation_property,
+                                    infer_numeric_types_for_untyped_literals=self._infer_numeric_types_for_untyped_literals,
+                                    raw_graph=self._raw_graph,
+                                    all_classes_mode=self._all_classes_mode,
+                                    namespaces_dict=self._namespaces_dict,
+                                    url_input=self._url_graph_input,
+                                    list_of_url_input=self._list_of_url_input,
+                                    rdflib_graph=self._rdflib_graph,
+                                    shape_map_file=self._shape_map_file,
+                                    shape_map_raw=self._shape_map_raw,
+                                    track_classes_for_entities_at_last_depth_level=self._track_classes_for_entities_at_last_depth_level,
+                                    depth_for_building_subgraph=self._depth_for_building_subgraph,
+                                    url_endpoint=self._url_endpoint,
+                                    strict_syntax_with_corners=self._strict_syntax_with_corners,
+                                    shape_map_format=self._shape_map_format,
+                                    namespaces_for_qualifier_props=self._namespaces_for_qualifier_props,
+                                    shape_qualifiers_mode=self._shape_qualifiers_mode,
+                                    built_remote_graph=self._built_remote_graph,
+                                    built_shape_map=self._built_shape_map,
+                                    shapes_namespace=self._shapes_namespace,
+                                    limit_remote_instances=self._limit_remote_instances,
+                                    inverse_paths=self._inverse_paths,
+                                    compression_mode=self._compression_mode,
+                                    disable_endpoint_cache=self._disable_endpoint_cache,
+                                    instances_cap=self._instances_cap)
+
+
+    @staticmethod
+    def _check_correct_output_params(string_output, target_file, to_uml_path):
+        if not string_output and target_file is None and to_uml_path is None:
+            raise ValueError("You must provide a target path , set string output to True and/or give a value to to_uml_path")
+
+    @staticmethod
+    def _check_input_format(input_format):
+        if input_format not in [NT, TSV_SPO, N3, TURTLE, RDF_XML, JSON_LD, TURTLE_ITER]:
+            raise ValueError("Currently unsupported input format: " + input_format)
+
+    @staticmethod
+    def _check_compression_mode(compression_mode, url_endpoint, url_graph_input, list_of_url_input):
+        if compression_mode not in [ZIP, GZ, XZ, None]:
+            raise ValueError("Unknownk compression mode: {}. "
+                             "The currently supported compression formats are {}.".format(
+                compression_mode,
+                ", ".join([ZIP, GZ, XZ])))
+        if compression_mode is not None and (url_endpoint is not None or url_graph_input is not None or list_of_url_input is not None):
+            raise ValueError("You've chosed some compression mode ({}) to work with remote sources."
+                             "Currently, sheXer can only parse compressed local files".format(compression_mode))
+
+
+    @staticmethod
+    def _check_target_classes(target_classes, file_target_classes, all_classes_mode, shape_map_file, shape_map_raw):
+        if not all_classes_mode:
+            check_just_one_not_none((target_classes, "target_classes"),
+                                    (file_target_classes, "file_target_classes"),
+                                    (shape_map_file, "shape_map_file"),
+                                    (shape_map_raw, "shape_map_raw")
+                                    )
+        else:
+            if target_classes is not None or file_target_classes is not None:
+                raise ValueError("You must provide a list of target classes XOR set all_classes_mode to True")
+            # But all_classes mode is compatible with shape_map_selectors. Setting all_classes_mode = True and
+            # providing some selectros will cause shexer to shex both the shapes specified in the selectors
+            # and to create a shape for eahc element with an instance in the target graph
+
+    @staticmethod
+    def _check_output_format(output_format):
+        if output_format not in [SHEXC, SHACL_TURTLE]:
+            raise ValueError("Currently unsupported output format: " + output_format)
+
+    @staticmethod
+    def _check_or_config(or_disabled, enable_redundant):
+        if or_disabled and enable_redundant:
+            raise ValueError("You are indicating that you'd like to have disjunction constraints including the macro "
+                             "IRI, but also that you do not want to have or constraints. Please, check your configuration"
+                             "of the disable_or_statements and allow_redundant_or paremeters")
+
+    @staticmethod
+    def _check_aceptance_threshold(aceptance_threshold):
+        if aceptance_threshold < 0 or aceptance_threshold > 1:
+            raise ValueError("The acceptance threshold must be a value in [0,1]")
+
+    @staticmethod
+    def _check_examples_mode(examples_mode):
+        if examples_mode not in [None, ALL_EXAMPLES, CONSTRAINT_EXAMPLES, SHAPE_EXAMPLES]:
+            raise ValueError("The examples mode param should be set to None or using one of the values in shexer.const, section \"EXAMPLES\" ")
```

### Comparing `shexer-2.5.1/shexer/utils/factories/class_profiler_factory.py` & `shexer-2.5.2/shexer/utils/factories/class_profiler_factory.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,73 +1,73 @@
-from shexer.utils.factories.triple_yielders_factory import get_triple_yielder
-from shexer.core.profiling.class_profiler import ClassProfiler
-from shexer.utils.target_elements import tune_target_classes_if_needed
-from shexer.utils.dict import reverse_keys_and_values
-
-
-def get_class_profiler(target_classes_dict, source_file, list_of_source_files, input_format,
-                       instantiation_property_str,
-                       namespaces_to_ignore=None,
-                       infer_numeric_types_for_untyped_literals=False,
-                       raw_graph=None,
-                       namespaces_dict=None,
-                       url_input=None,
-                       list_of_url_input=None,
-                       rdflib_graph=None,
-                       shape_map_file=None,
-                       shape_map_raw=None,
-                       track_classes_for_entities_at_last_depth_level=True,
-                       depth_for_building_subgraph=1,
-                       url_endpoint=None,
-                       strict_syntax_with_corners=False,
-                       target_classes=None,
-                       file_target_classes=None,
-                       built_remote_graph=None,
-                       built_shape_map=None,
-                       remove_empty_shapes=True,
-                       limit_remote_instances=-1,
-                       inverse_paths=False,
-                       all_classes_mode=False,
-                       compression_mode=None,
-                       disable_endpoint_cache=None,
-                       detect_minimal_iri=False,
-                       examples_mode=None):
-    yielder = get_triple_yielder(source_file=source_file,
-                                 list_of_source_files=list_of_source_files,
-                                 input_format=input_format,
-                                 namespaces_to_ignore=namespaces_to_ignore,
-                                 raw_graph=raw_graph,
-                                 allow_untyped_numbers=infer_numeric_types_for_untyped_literals,
-                                 namespaces_dict=namespaces_dict,
-                                 url_input=url_input,
-                                 list_of_url_input=list_of_url_input,
-                                 rdflib_graph=rdflib_graph,
-                                 shape_map_file=shape_map_file,
-                                 shape_map_raw=shape_map_raw,
-                                 track_classes_for_entities_at_last_depth_level=track_classes_for_entities_at_last_depth_level,
-                                 depth_for_building_subgraph=depth_for_building_subgraph,
-                                 url_endpoint=url_endpoint,
-                                 instantiation_property=instantiation_property_str,
-                                 strict_syntax_with_corners=strict_syntax_with_corners,
-                                 target_classes=target_classes,
-                                 file_target_classes=file_target_classes,
-                                 built_remote_graph=built_remote_graph,
-                                 built_shape_map=built_shape_map,
-                                 limit_remote_instances=limit_remote_instances,
-                                 inverse_paths=inverse_paths,
-                                 all_classes_mode=all_classes_mode,
-                                 compression_mode=compression_mode,
-                                 disable_endpoint_cache=disable_endpoint_cache)
-
-    return ClassProfiler(triples_yielder=yielder,
-                         instances_dict=target_classes_dict,
-                         instantiation_property_str=instantiation_property_str,
-                         original_target_classes=None
-                         if target_classes is None
-                         else tune_target_classes_if_needed(
-                             list_target_classes=target_classes,
-                             prefix_namespaces_dict=reverse_keys_and_values(namespaces_dict)),
-                         original_shape_map=built_shape_map,
-                         remove_empty_shapes=remove_empty_shapes,
-                         inverse_paths=inverse_paths,
-                         detect_minimal_iri=detect_minimal_iri,
-                         examples_mode=examples_mode)
+from shexer.utils.factories.triple_yielders_factory import get_triple_yielder
+from shexer.core.profiling.class_profiler import ClassProfiler
+from shexer.utils.target_elements import tune_target_classes_if_needed
+from shexer.utils.dict import reverse_keys_and_values
+
+
+def get_class_profiler(target_classes_dict, source_file, list_of_source_files, input_format,
+                       instantiation_property_str,
+                       namespaces_to_ignore=None,
+                       infer_numeric_types_for_untyped_literals=False,
+                       raw_graph=None,
+                       namespaces_dict=None,
+                       url_input=None,
+                       list_of_url_input=None,
+                       rdflib_graph=None,
+                       shape_map_file=None,
+                       shape_map_raw=None,
+                       track_classes_for_entities_at_last_depth_level=True,
+                       depth_for_building_subgraph=1,
+                       url_endpoint=None,
+                       strict_syntax_with_corners=False,
+                       target_classes=None,
+                       file_target_classes=None,
+                       built_remote_graph=None,
+                       built_shape_map=None,
+                       remove_empty_shapes=True,
+                       limit_remote_instances=-1,
+                       inverse_paths=False,
+                       all_classes_mode=False,
+                       compression_mode=None,
+                       disable_endpoint_cache=None,
+                       detect_minimal_iri=False,
+                       examples_mode=None):
+    yielder = get_triple_yielder(source_file=source_file,
+                                 list_of_source_files=list_of_source_files,
+                                 input_format=input_format,
+                                 namespaces_to_ignore=namespaces_to_ignore,
+                                 raw_graph=raw_graph,
+                                 allow_untyped_numbers=infer_numeric_types_for_untyped_literals,
+                                 namespaces_dict=namespaces_dict,
+                                 url_input=url_input,
+                                 list_of_url_input=list_of_url_input,
+                                 rdflib_graph=rdflib_graph,
+                                 shape_map_file=shape_map_file,
+                                 shape_map_raw=shape_map_raw,
+                                 track_classes_for_entities_at_last_depth_level=track_classes_for_entities_at_last_depth_level,
+                                 depth_for_building_subgraph=depth_for_building_subgraph,
+                                 url_endpoint=url_endpoint,
+                                 instantiation_property=instantiation_property_str,
+                                 strict_syntax_with_corners=strict_syntax_with_corners,
+                                 target_classes=target_classes,
+                                 file_target_classes=file_target_classes,
+                                 built_remote_graph=built_remote_graph,
+                                 built_shape_map=built_shape_map,
+                                 limit_remote_instances=limit_remote_instances,
+                                 inverse_paths=inverse_paths,
+                                 all_classes_mode=all_classes_mode,
+                                 compression_mode=compression_mode,
+                                 disable_endpoint_cache=disable_endpoint_cache)
+
+    return ClassProfiler(triples_yielder=yielder,
+                         instances_dict=target_classes_dict,
+                         instantiation_property_str=instantiation_property_str,
+                         original_target_classes=None
+                         if target_classes is None
+                         else tune_target_classes_if_needed(
+                             list_target_classes=target_classes,
+                             prefix_namespaces_dict=reverse_keys_and_values(namespaces_dict)),
+                         original_shape_map=built_shape_map,
+                         remove_empty_shapes=remove_empty_shapes,
+                         inverse_paths=inverse_paths,
+                         detect_minimal_iri=detect_minimal_iri,
+                         examples_mode=examples_mode)
```

### Comparing `shexer-2.5.1/shexer/utils/factories/class_shexer_factory.py` & `shexer-2.5.2/shexer/utils/factories/class_shexer_factory.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,50 +1,50 @@
-from shexer.core.shexing.class_shexer import ClassShexer
-from shexer.consts import RDF_TYPE, SHAPES_DEFAULT_NAMESPACE, RATIO_INSTANCES
-
-
-def get_class_shexer(class_counts,
-                     class_profile_dict,
-                     remove_empty_shapes=True,
-                     original_target_classes=None,
-                     original_shape_map=None,
-                     discard_useless_constraints_with_positive_closure=True,
-                     keep_less_specific=True,
-                     all_compliant_mode=True,
-                     instantiation_property=RDF_TYPE,
-                     disable_or_statements=True,
-                     disable_comments=False,
-                     namespaces_dict=None,
-                     allow_opt_cardinality=True,
-                     disable_exact_cardinality=False,
-                     shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
-                     inverse_paths=False,
-                     decimals=-1,
-                     instances_report_mode=RATIO_INSTANCES,
-                     detect_minimal_iri=False,
-                     class_min_iris=None,
-                     allow_redundant_or=False):
-
-    return ClassShexer(
-        class_counts_dict=class_counts,
-        class_profile_dict=class_profile_dict,
-        class_profile_json_file=None,
-        remove_empty_shapes=remove_empty_shapes,
-        original_target_classes=original_target_classes,
-        original_shape_map=original_shape_map,
-        discard_useless_constraints_with_positive_closure=discard_useless_constraints_with_positive_closure,
-        keep_less_specific=keep_less_specific,
-        all_compliant_mode=all_compliant_mode,
-        instantiation_property=instantiation_property,
-        disable_or_statements=disable_or_statements,
-        disable_comments=disable_comments,
-        namespaces_dict=namespaces_dict,
-        allow_opt_cardinality=allow_opt_cardinality,
-        disable_exact_cardinality=disable_exact_cardinality,
-        shapes_namespace=shapes_namespace,
-        inverse_paths=inverse_paths,
-        instances_report_mode=instances_report_mode,
-        decimals=decimals,
-        detect_minimal_iri=detect_minimal_iri,
-        class_min_iris_dict=class_min_iris,
-        allow_redundant_or=allow_redundant_or
-    )
+from shexer.core.shexing.class_shexer import ClassShexer
+from shexer.consts import RDF_TYPE, SHAPES_DEFAULT_NAMESPACE, RATIO_INSTANCES
+
+
+def get_class_shexer(class_counts,
+                     class_profile_dict,
+                     remove_empty_shapes=True,
+                     original_target_classes=None,
+                     original_shape_map=None,
+                     discard_useless_constraints_with_positive_closure=True,
+                     keep_less_specific=True,
+                     all_compliant_mode=True,
+                     instantiation_property=RDF_TYPE,
+                     disable_or_statements=True,
+                     disable_comments=False,
+                     namespaces_dict=None,
+                     allow_opt_cardinality=True,
+                     disable_exact_cardinality=False,
+                     shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
+                     inverse_paths=False,
+                     decimals=-1,
+                     instances_report_mode=RATIO_INSTANCES,
+                     detect_minimal_iri=False,
+                     class_min_iris=None,
+                     allow_redundant_or=False):
+
+    return ClassShexer(
+        class_counts_dict=class_counts,
+        class_profile_dict=class_profile_dict,
+        class_profile_json_file=None,
+        remove_empty_shapes=remove_empty_shapes,
+        original_target_classes=original_target_classes,
+        original_shape_map=original_shape_map,
+        discard_useless_constraints_with_positive_closure=discard_useless_constraints_with_positive_closure,
+        keep_less_specific=keep_less_specific,
+        all_compliant_mode=all_compliant_mode,
+        instantiation_property=instantiation_property,
+        disable_or_statements=disable_or_statements,
+        disable_comments=disable_comments,
+        namespaces_dict=namespaces_dict,
+        allow_opt_cardinality=allow_opt_cardinality,
+        disable_exact_cardinality=disable_exact_cardinality,
+        shapes_namespace=shapes_namespace,
+        inverse_paths=inverse_paths,
+        instances_report_mode=instances_report_mode,
+        decimals=decimals,
+        detect_minimal_iri=detect_minimal_iri,
+        class_min_iris_dict=class_min_iris,
+        allow_redundant_or=allow_redundant_or
+    )
```

### Comparing `shexer-2.5.1/shexer/utils/factories/h_tree.py` & `shexer-2.5.2/shexer/utils/factories/h_tree.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,22 +1,22 @@
-
-from shexer.model.hierarchy_tree import HTree, HNode, HMacro
-from shexer.model.Macro import Macro
-from shexer.model.const_elem_types import DOT_ELEM_TYPE, IRI_ELEM_TYPE, LITERAL_ELEM_TYPE
-
-
-def get_basic_h_tree():
-    result = HTree()
-    dot_node = HNode(hcontent=HMacro(value=Macro(macro_const=DOT_ELEM_TYPE)),
-                     htree=result)
-    result.root = dot_node
-    literal_node = HNode(hcontent=HMacro(value=Macro(macro_const=LITERAL_ELEM_TYPE)),
-                         htree=result)
-    iri_node = HNode(hcontent=HMacro(value=Macro(macro_const=IRI_ELEM_TYPE)),
-                     htree=result)
-
-    dot_node.add_child(literal_node)
-    dot_node.add_child(iri_node)
-    return result
-
-
-
+
+from shexer.model.hierarchy_tree import HTree, HNode, HMacro
+from shexer.model.Macro import Macro
+from shexer.model.const_elem_types import DOT_ELEM_TYPE, IRI_ELEM_TYPE, LITERAL_ELEM_TYPE
+
+
+def get_basic_h_tree():
+    result = HTree()
+    dot_node = HNode(hcontent=HMacro(value=Macro(macro_const=DOT_ELEM_TYPE)),
+                     htree=result)
+    result.root = dot_node
+    literal_node = HNode(hcontent=HMacro(value=Macro(macro_const=LITERAL_ELEM_TYPE)),
+                         htree=result)
+    iri_node = HNode(hcontent=HMacro(value=Macro(macro_const=IRI_ELEM_TYPE)),
+                     htree=result)
+
+    dot_node.add_child(literal_node)
+    dot_node.add_child(iri_node)
+    return result
+
+
+
```

### Comparing `shexer-2.5.1/shexer/utils/factories/instance_tracker_factory.py` & `shexer-2.5.2/shexer/utils/factories/instance_tracker_factory.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,204 +1,204 @@
-from shexer.consts import NT, FIXED_SHAPE_MAP, SHAPES_DEFAULT_NAMESPACE
-from shexer.utils.factories.triple_yielders_factory import get_triple_yielder, tune_target_classes_if_needed, \
-    read_target_classes_from_file
-from shexer.core.instances.instance_tracker import InstanceTracker
-from shexer.core.instances.mappings.shape_map_instance_tracker import ShapeMapInstanceTracker
-from shexer.core.instances.mix.mixed_instance_tracker import MixedInstanceTracker
-from shexer.utils.factories.iri_factory import create_IRIs_from_string_list
-from shexer.utils.factories.shape_map_parser_factory import get_shape_map_parser
-from shexer.model.graph.endpoint_sgraph import EndpointSGraph
-from shexer.model.graph.rdflib_sgraph import RdflibSgraph
-from shexer.utils.dict import reverse_keys_and_values
-
-
-def get_instance_tracker(instances_file_input=None, graph_file_input=None,
-                         graph_list_of_files_input=None, target_classes=None,
-                         file_target_classes=None, input_format=NT,
-                         instantiation_property=None,
-                         infer_numeric_types_for_untyped_literals=None,
-                         namespaces_to_ignore=None,
-                         raw_graph=None,
-                         all_classes_mode=False,
-                         namespaces_dict=None,
-                         url_input=None,
-                         list_of_url_input=None,
-                         rdflib_graph=None,
-                         shape_map_file=None,
-                         shape_map_raw=None,
-                         shape_map_format=FIXED_SHAPE_MAP,
-                         track_classes_for_entities_at_last_depth_level=True,
-                         depth_for_building_subgraph=1,
-                         url_endpoint=None,
-                         strict_syntax_with_corners=False,
-                         namespaces_for_qualifier_props=None,
-                         shape_qualifiers_mode=False,
-                         built_remote_graph=None,
-                         built_shape_map=None,
-                         shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
-                         limit_remote_instances=-1,
-                         inverse_paths=False,
-                         compression_mode=None,
-                         disable_endpoint_cache=False,
-                         instances_cap=-1
-                         ):
-    """
-
-    :param instances_file_input:
-    :param graph_file_input:
-    :param graph_list_of_files_input:
-    :param target_classes:
-    :param file_target_classes:
-    :param input_format:
-    :param instantiation_property:
-    :param namespaces_to_ignore:
-    :param raw_graph:
-    :param all_classes_mode:
-    :param namespaces_dict:
-    :param url_input:
-    :param list_of_url_input:
-    :param shape_map_file:
-    :param shape_map_raw:
-    :param shape_map_format:
-    :param track_classes_for_entities_at_last_depth_level:
-    :param depth_for_building_subgraph:
-    :param url_endpoint:
-    :param strict_syntax_with_corners:
-    :param namespaces_for_qualifier_props:
-    :param shape_qualifiers_mode:
-    :param built_remote_graph:
-    :param built_shape_map:
-    :return:
-    """
-
-    prefix_namespaces_dict = reverse_keys_and_values(namespaces_dict)
-    instance_yielder = None  # Old-schooler
-    if instances_file_input is not None:
-        instance_yielder = get_triple_yielder(source_file=instances_file_input,
-                                              input_format=input_format,
-                                              namespaces_to_ignore=namespaces_to_ignore,
-                                              raw_graph=raw_graph,
-                                              namespaces_dict=namespaces_dict,
-                                              allow_untyped_numbers=infer_numeric_types_for_untyped_literals,
-                                              url_input=url_input,
-                                              list_of_url_input=list_of_url_input,
-                                              rdflib_graph=rdflib_graph,
-                                              instantiation_property=instantiation_property,
-                                              shape_map_file=shape_map_file,
-                                              shape_map_raw=shape_map_raw,
-                                              track_classes_for_entities_at_last_depth_level=
-                                              track_classes_for_entities_at_last_depth_level,
-                                              depth_for_building_subgraph=depth_for_building_subgraph,
-                                              url_endpoint=url_endpoint,
-                                              strict_syntax_with_corners=strict_syntax_with_corners,
-                                              target_classes=target_classes,
-                                              file_target_classes=file_target_classes,
-                                              built_remote_graph=built_remote_graph,
-                                              built_shape_map=built_shape_map,
-                                              limit_remote_instances=limit_remote_instances,
-                                              inverse_paths=inverse_paths,
-                                              all_classes_mode=all_classes_mode,
-                                              compression_mode=compression_mode,
-                                              disable_endpoint_cache=disable_endpoint_cache
-                                              )
-    else:
-        instance_yielder = get_triple_yielder(source_file=graph_file_input,
-                                              list_of_source_files=graph_list_of_files_input,
-                                              input_format=input_format,
-                                              namespaces_to_ignore=namespaces_to_ignore,
-                                              raw_graph=raw_graph,
-                                              namespaces_dict=namespaces_dict,
-                                              allow_untyped_numbers=infer_numeric_types_for_untyped_literals,
-                                              url_input=url_input,
-                                              list_of_url_input=list_of_url_input,
-                                              rdflib_graph=rdflib_graph,
-                                              instantiation_property=instantiation_property,
-                                              shape_map_file=shape_map_file,
-                                              shape_map_raw=shape_map_raw,
-                                              track_classes_for_entities_at_last_depth_level=track_classes_for_entities_at_last_depth_level,
-                                              depth_for_building_subgraph=depth_for_building_subgraph,
-                                              url_endpoint=url_endpoint,
-                                              strict_syntax_with_corners=strict_syntax_with_corners,
-                                              target_classes=target_classes,
-                                              file_target_classes=file_target_classes,
-                                              built_remote_graph=built_remote_graph,
-                                              built_shape_map=built_shape_map,
-                                              limit_remote_instances=limit_remote_instances,
-                                              inverse_paths=inverse_paths,
-                                              all_classes_mode=all_classes_mode,
-                                              compression_mode=compression_mode,
-                                              disable_endpoint_cache=disable_endpoint_cache
-                                              )
-
-    selectors_tracker = None
-    pure_instances_tracker = None
-
-    if _are_there_selectors(shape_map_file, shape_map_raw):
-        sgraph = _get_adequate_sgraph(endpoint_url=url_endpoint,
-                                      raw_graph=raw_graph,
-                                      graph_file_input=graph_file_input,
-                                      url_input=url_input,
-                                      graph_format=input_format,
-                                      built_remote_graph=built_remote_graph,
-                                      disable_endpoint_cache=disable_endpoint_cache)
-        valid_shape_map = built_shape_map
-        if built_shape_map is None:
-            shape_map_parser = get_shape_map_parser(format=shape_map_format,
-                                                    sgraph=sgraph,
-                                                    namespaces_prefix_dict=namespaces_dict)
-            valid_shape_map = shape_map_parser.parse_shape_map(source_file=shape_map_file,
-                                                               raw_content=shape_map_raw)
-        selectors_tracker = ShapeMapInstanceTracker(shape_map=valid_shape_map)
-    if _are_there_some_target_classes(target_classes, file_target_classes, all_classes_mode, shape_qualifiers_mode):
-        model_classes = None
-        if file_target_classes or target_classes is not None:
-            list_of_str_target_classes = tune_target_classes_if_needed(
-                list_target_classes=target_classes,
-                prefix_namespaces_dict=prefix_namespaces_dict) if target_classes is not None else read_target_classes_from_file(
-                file_target_classes=file_target_classes,
-                prefix_namespaces_dict=prefix_namespaces_dict)
-            model_classes = get_list_of_model_classes(list_of_str_target_classes)
-
-        pure_instances_tracker = InstanceTracker(target_classes=model_classes,
-                                                 triples_yielder=instance_yielder,
-                                                 instantiation_property=instantiation_property,
-                                                 all_classes_mode=all_classes_mode,
-                                                 track_hierarchies=False,
-                                                 namespaces_for_qualifier_props=namespaces_for_qualifier_props,
-                                                 shape_qualifiers_mode=shape_qualifiers_mode,
-                                                 shapes_namespace=shapes_namespace,
-                                                 instances_cap=instances_cap)
-
-    return _decide_tracker_to_return(selectors_tracker, pure_instances_tracker)
-
-
-def _get_adequate_sgraph(endpoint_url, graph_file_input, url_input, graph_format,
-                         raw_graph, built_remote_graph, disable_endpoint_cache):
-    if endpoint_url is not None:
-        return built_remote_graph if built_remote_graph is not None else EndpointSGraph(endpoint_url=endpoint_url,
-                                                                                        store_locally=not disable_endpoint_cache)
-    else:
-        return RdflibSgraph(source_file=graph_file_input if graph_file_input is not None else url_input,
-                            raw_graph=raw_graph,
-                            format=graph_format)
-
-
-def _decide_tracker_to_return(selectors_tracker, pure_instances_tracker):
-    if selectors_tracker is not None and pure_instances_tracker is not None:
-        return MixedInstanceTracker(list_of_instance_trackers=[selectors_tracker, pure_instances_tracker])
-    return selectors_tracker if selectors_tracker is not None else pure_instances_tracker
-
-
-def _are_there_selectors(shape_map_file, shape_map_raw):
-    if shape_map_file is None and shape_map_raw is None:
-        return False
-    return True
-
-
-def _are_there_some_target_classes(target_classes, file_target_classes, all_classes_mode, shape_qualifiers_mode):
-    if target_classes is None and file_target_classes is None and not all_classes_mode and not shape_qualifiers_mode:
-        return False
-    return True
-
-
-def get_list_of_model_classes(list_of_str_target_classes):
-    return create_IRIs_from_string_list(list_of_str_target_classes)
+from shexer.consts import NT, FIXED_SHAPE_MAP, SHAPES_DEFAULT_NAMESPACE
+from shexer.utils.factories.triple_yielders_factory import get_triple_yielder, tune_target_classes_if_needed, \
+    read_target_classes_from_file
+from shexer.core.instances.instance_tracker import InstanceTracker
+from shexer.core.instances.mappings.shape_map_instance_tracker import ShapeMapInstanceTracker
+from shexer.core.instances.mix.mixed_instance_tracker import MixedInstanceTracker
+from shexer.utils.factories.iri_factory import create_IRIs_from_string_list
+from shexer.utils.factories.shape_map_parser_factory import get_shape_map_parser
+from shexer.model.graph.endpoint_sgraph import EndpointSGraph
+from shexer.model.graph.rdflib_sgraph import RdflibSgraph
+from shexer.utils.dict import reverse_keys_and_values
+
+
+def get_instance_tracker(instances_file_input=None, graph_file_input=None,
+                         graph_list_of_files_input=None, target_classes=None,
+                         file_target_classes=None, input_format=NT,
+                         instantiation_property=None,
+                         infer_numeric_types_for_untyped_literals=None,
+                         namespaces_to_ignore=None,
+                         raw_graph=None,
+                         all_classes_mode=False,
+                         namespaces_dict=None,
+                         url_input=None,
+                         list_of_url_input=None,
+                         rdflib_graph=None,
+                         shape_map_file=None,
+                         shape_map_raw=None,
+                         shape_map_format=FIXED_SHAPE_MAP,
+                         track_classes_for_entities_at_last_depth_level=True,
+                         depth_for_building_subgraph=1,
+                         url_endpoint=None,
+                         strict_syntax_with_corners=False,
+                         namespaces_for_qualifier_props=None,
+                         shape_qualifiers_mode=False,
+                         built_remote_graph=None,
+                         built_shape_map=None,
+                         shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
+                         limit_remote_instances=-1,
+                         inverse_paths=False,
+                         compression_mode=None,
+                         disable_endpoint_cache=False,
+                         instances_cap=-1
+                         ):
+    """
+
+    :param instances_file_input:
+    :param graph_file_input:
+    :param graph_list_of_files_input:
+    :param target_classes:
+    :param file_target_classes:
+    :param input_format:
+    :param instantiation_property:
+    :param namespaces_to_ignore:
+    :param raw_graph:
+    :param all_classes_mode:
+    :param namespaces_dict:
+    :param url_input:
+    :param list_of_url_input:
+    :param shape_map_file:
+    :param shape_map_raw:
+    :param shape_map_format:
+    :param track_classes_for_entities_at_last_depth_level:
+    :param depth_for_building_subgraph:
+    :param url_endpoint:
+    :param strict_syntax_with_corners:
+    :param namespaces_for_qualifier_props:
+    :param shape_qualifiers_mode:
+    :param built_remote_graph:
+    :param built_shape_map:
+    :return:
+    """
+
+    prefix_namespaces_dict = reverse_keys_and_values(namespaces_dict)
+    instance_yielder = None  # Old-schooler
+    if instances_file_input is not None:
+        instance_yielder = get_triple_yielder(source_file=instances_file_input,
+                                              input_format=input_format,
+                                              namespaces_to_ignore=namespaces_to_ignore,
+                                              raw_graph=raw_graph,
+                                              namespaces_dict=namespaces_dict,
+                                              allow_untyped_numbers=infer_numeric_types_for_untyped_literals,
+                                              url_input=url_input,
+                                              list_of_url_input=list_of_url_input,
+                                              rdflib_graph=rdflib_graph,
+                                              instantiation_property=instantiation_property,
+                                              shape_map_file=shape_map_file,
+                                              shape_map_raw=shape_map_raw,
+                                              track_classes_for_entities_at_last_depth_level=
+                                              track_classes_for_entities_at_last_depth_level,
+                                              depth_for_building_subgraph=depth_for_building_subgraph,
+                                              url_endpoint=url_endpoint,
+                                              strict_syntax_with_corners=strict_syntax_with_corners,
+                                              target_classes=target_classes,
+                                              file_target_classes=file_target_classes,
+                                              built_remote_graph=built_remote_graph,
+                                              built_shape_map=built_shape_map,
+                                              limit_remote_instances=limit_remote_instances,
+                                              inverse_paths=inverse_paths,
+                                              all_classes_mode=all_classes_mode,
+                                              compression_mode=compression_mode,
+                                              disable_endpoint_cache=disable_endpoint_cache
+                                              )
+    else:
+        instance_yielder = get_triple_yielder(source_file=graph_file_input,
+                                              list_of_source_files=graph_list_of_files_input,
+                                              input_format=input_format,
+                                              namespaces_to_ignore=namespaces_to_ignore,
+                                              raw_graph=raw_graph,
+                                              namespaces_dict=namespaces_dict,
+                                              allow_untyped_numbers=infer_numeric_types_for_untyped_literals,
+                                              url_input=url_input,
+                                              list_of_url_input=list_of_url_input,
+                                              rdflib_graph=rdflib_graph,
+                                              instantiation_property=instantiation_property,
+                                              shape_map_file=shape_map_file,
+                                              shape_map_raw=shape_map_raw,
+                                              track_classes_for_entities_at_last_depth_level=track_classes_for_entities_at_last_depth_level,
+                                              depth_for_building_subgraph=depth_for_building_subgraph,
+                                              url_endpoint=url_endpoint,
+                                              strict_syntax_with_corners=strict_syntax_with_corners,
+                                              target_classes=target_classes,
+                                              file_target_classes=file_target_classes,
+                                              built_remote_graph=built_remote_graph,
+                                              built_shape_map=built_shape_map,
+                                              limit_remote_instances=limit_remote_instances,
+                                              inverse_paths=inverse_paths,
+                                              all_classes_mode=all_classes_mode,
+                                              compression_mode=compression_mode,
+                                              disable_endpoint_cache=disable_endpoint_cache
+                                              )
+
+    selectors_tracker = None
+    pure_instances_tracker = None
+
+    if _are_there_selectors(shape_map_file, shape_map_raw):
+        sgraph = _get_adequate_sgraph(endpoint_url=url_endpoint,
+                                      raw_graph=raw_graph,
+                                      graph_file_input=graph_file_input,
+                                      url_input=url_input,
+                                      graph_format=input_format,
+                                      built_remote_graph=built_remote_graph,
+                                      disable_endpoint_cache=disable_endpoint_cache)
+        valid_shape_map = built_shape_map
+        if built_shape_map is None:
+            shape_map_parser = get_shape_map_parser(format=shape_map_format,
+                                                    sgraph=sgraph,
+                                                    namespaces_prefix_dict=namespaces_dict)
+            valid_shape_map = shape_map_parser.parse_shape_map(source_file=shape_map_file,
+                                                               raw_content=shape_map_raw)
+        selectors_tracker = ShapeMapInstanceTracker(shape_map=valid_shape_map)
+    if _are_there_some_target_classes(target_classes, file_target_classes, all_classes_mode, shape_qualifiers_mode):
+        model_classes = None
+        if file_target_classes or target_classes is not None:
+            list_of_str_target_classes = tune_target_classes_if_needed(
+                list_target_classes=target_classes,
+                prefix_namespaces_dict=prefix_namespaces_dict) if target_classes is not None else read_target_classes_from_file(
+                file_target_classes=file_target_classes,
+                prefix_namespaces_dict=prefix_namespaces_dict)
+            model_classes = get_list_of_model_classes(list_of_str_target_classes)
+
+        pure_instances_tracker = InstanceTracker(target_classes=model_classes,
+                                                 triples_yielder=instance_yielder,
+                                                 instantiation_property=instantiation_property,
+                                                 all_classes_mode=all_classes_mode,
+                                                 track_hierarchies=False,
+                                                 namespaces_for_qualifier_props=namespaces_for_qualifier_props,
+                                                 shape_qualifiers_mode=shape_qualifiers_mode,
+                                                 shapes_namespace=shapes_namespace,
+                                                 instances_cap=instances_cap)
+
+    return _decide_tracker_to_return(selectors_tracker, pure_instances_tracker)
+
+
+def _get_adequate_sgraph(endpoint_url, graph_file_input, url_input, graph_format,
+                         raw_graph, built_remote_graph, disable_endpoint_cache):
+    if endpoint_url is not None:
+        return built_remote_graph if built_remote_graph is not None else EndpointSGraph(endpoint_url=endpoint_url,
+                                                                                        store_locally=not disable_endpoint_cache)
+    else:
+        return RdflibSgraph(source_file=graph_file_input if graph_file_input is not None else url_input,
+                            raw_graph=raw_graph,
+                            format=graph_format)
+
+
+def _decide_tracker_to_return(selectors_tracker, pure_instances_tracker):
+    if selectors_tracker is not None and pure_instances_tracker is not None:
+        return MixedInstanceTracker(list_of_instance_trackers=[selectors_tracker, pure_instances_tracker])
+    return selectors_tracker if selectors_tracker is not None else pure_instances_tracker
+
+
+def _are_there_selectors(shape_map_file, shape_map_raw):
+    if shape_map_file is None and shape_map_raw is None:
+        return False
+    return True
+
+
+def _are_there_some_target_classes(target_classes, file_target_classes, all_classes_mode, shape_qualifiers_mode):
+    if target_classes is None and file_target_classes is None and not all_classes_mode and not shape_qualifiers_mode:
+        return False
+    return True
+
+
+def get_list_of_model_classes(list_of_str_target_classes):
+    return create_IRIs_from_string_list(list_of_str_target_classes)
```

### Comparing `shexer-2.5.1/shexer/utils/factories/shape_map_factory.py` & `shexer-2.5.2/shexer/utils/factories/shape_map_factory.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,29 +1,29 @@
-from shexer.utils.factories.triple_yielders_factory import produce_shape_map_according_to_input
-from shexer.model.graph.rdflib_sgraph import RdflibSgraph
-
-
-def get_shape_map_if_needed(sm_format, remote_sgraph, namespaces_prefix_dict, target_classes,
-                            file_target_classes, shape_map_file, shape_map_raw,
-                            instantiation_property, shape_map_already_built=None,
-                            rdflib_graph=None, raw_graph=None, source_file_graph=None, input_format=None,
-                            limit_remote_instances=-1):
-    if shape_map_file is None and shape_map_raw is None:
-        return None
-    if shape_map_already_built:
-        return shape_map_already_built
-
-    sgraph = remote_sgraph if remote_sgraph is not None else RdflibSgraph(rdflib_graph=rdflib_graph,
-                                                                          raw_graph=raw_graph,
-                                                                          source_file=source_file_graph,
-                                                                          format=input_format)
-
-    return produce_shape_map_according_to_input(sm_format=sm_format,
-                                                sgraph=sgraph,
-                                                namespaces_prefix_dict=namespaces_prefix_dict,
-                                                target_classes=target_classes,
-                                                file_target_classes=file_target_classes,
-                                                shape_map_file=shape_map_file,
-                                                shape_map_raw=shape_map_raw,
-                                                instantiation_property=instantiation_property,
-                                                shape_map_already_built=shape_map_already_built,
+from shexer.utils.factories.triple_yielders_factory import produce_shape_map_according_to_input
+from shexer.model.graph.rdflib_sgraph import RdflibSgraph
+
+
+def get_shape_map_if_needed(sm_format, remote_sgraph, namespaces_prefix_dict, target_classes,
+                            file_target_classes, shape_map_file, shape_map_raw,
+                            instantiation_property, shape_map_already_built=None,
+                            rdflib_graph=None, raw_graph=None, source_file_graph=None, input_format=None,
+                            limit_remote_instances=-1):
+    if shape_map_file is None and shape_map_raw is None:
+        return None
+    if shape_map_already_built:
+        return shape_map_already_built
+
+    sgraph = remote_sgraph if remote_sgraph is not None else RdflibSgraph(rdflib_graph=rdflib_graph,
+                                                                          raw_graph=raw_graph,
+                                                                          source_file=source_file_graph,
+                                                                          format=input_format)
+
+    return produce_shape_map_according_to_input(sm_format=sm_format,
+                                                sgraph=sgraph,
+                                                namespaces_prefix_dict=namespaces_prefix_dict,
+                                                target_classes=target_classes,
+                                                file_target_classes=file_target_classes,
+                                                shape_map_file=shape_map_file,
+                                                shape_map_raw=shape_map_raw,
+                                                instantiation_property=instantiation_property,
+                                                shape_map_already_built=shape_map_already_built,
                                                 limit_remote_instances=limit_remote_instances)
```

### Comparing `shexer-2.5.1/shexer/utils/factories/shape_serializer_factory.py` & `shexer-2.5.2/shexer/utils/factories/shape_serializer_factory.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,42 +1,42 @@
-from shexer.consts import SHEXC, SHACL_TURTLE
-from shexer.io.shex.formater.shex_serializer import ShexSerializer
-from shexer.io.shacl.formater.shacl_serializer import ShaclSerializer
-from shexer.io.uml.uml_serializer import UMLSerializer
-from shexer.consts import RATIO_INSTANCES, UML_PLANT_SERVER
-
-
-def get_shape_serializer(output_format, shapes_list, target_file=None, string_return=False, namespaces_dict=None,
-                         instantiation_property=None, disable_comments=False, wikidata_annotation=False,
-                         instances_report_mode=RATIO_INSTANCES, detect_minimal_iri=False, shape_features_examples=None,
-                         examples_mode=None, inverse_paths=False):
-    if output_format == SHEXC:
-        return ShexSerializer(target_file=target_file,
-                              shapes_list=shapes_list,
-                              namespaces_dict=namespaces_dict,
-                              string_return=string_return,
-                              instantiation_property_str=instantiation_property,
-                              disable_comments=disable_comments,
-                              wikidata_annotation=wikidata_annotation,
-                              instances_report_mode=instances_report_mode,
-                              detect_minimal_iri=detect_minimal_iri,
-                              shape_example_features=shape_features_examples,
-                              examples_mode=examples_mode,
-                              inverse_paths=inverse_paths)
-    elif output_format == SHACL_TURTLE:
-        return ShaclSerializer(target_file=target_file,
-                               shapes_list=shapes_list,
-                               namespaces_dict=namespaces_dict,
-                               string_return=string_return,
-                               instantiation_property_str=instantiation_property,
-                               wikidata_annotation=wikidata_annotation,
-                               shape_example_features=shape_features_examples,
-                               detect_minimal_iri=detect_minimal_iri)
-    else:
-        raise ValueError("Currently unsupported format in 'output_format': " + output_format)
-
-
-def get_uml_serializer(shapes_list, image_path, url_server=UML_PLANT_SERVER, namespaces_dict=None,):
-    return UMLSerializer(shapes_list=shapes_list,
-                         url_server=url_server,
-                         image_path=image_path,
+from shexer.consts import SHEXC, SHACL_TURTLE
+from shexer.io.shex.formater.shex_serializer import ShexSerializer
+from shexer.io.shacl.formater.shacl_serializer import ShaclSerializer
+from shexer.io.uml.uml_serializer import UMLSerializer
+from shexer.consts import RATIO_INSTANCES, UML_PLANT_SERVER
+
+
+def get_shape_serializer(output_format, shapes_list, target_file=None, string_return=False, namespaces_dict=None,
+                         instantiation_property=None, disable_comments=False, wikidata_annotation=False,
+                         instances_report_mode=RATIO_INSTANCES, detect_minimal_iri=False, shape_features_examples=None,
+                         examples_mode=None, inverse_paths=False):
+    if output_format == SHEXC:
+        return ShexSerializer(target_file=target_file,
+                              shapes_list=shapes_list,
+                              namespaces_dict=namespaces_dict,
+                              string_return=string_return,
+                              instantiation_property_str=instantiation_property,
+                              disable_comments=disable_comments,
+                              wikidata_annotation=wikidata_annotation,
+                              instances_report_mode=instances_report_mode,
+                              detect_minimal_iri=detect_minimal_iri,
+                              shape_example_features=shape_features_examples,
+                              examples_mode=examples_mode,
+                              inverse_paths=inverse_paths)
+    elif output_format == SHACL_TURTLE:
+        return ShaclSerializer(target_file=target_file,
+                               shapes_list=shapes_list,
+                               namespaces_dict=namespaces_dict,
+                               string_return=string_return,
+                               instantiation_property_str=instantiation_property,
+                               wikidata_annotation=wikidata_annotation,
+                               shape_example_features=shape_features_examples,
+                               detect_minimal_iri=detect_minimal_iri)
+    else:
+        raise ValueError("Currently unsupported format in 'output_format': " + output_format)
+
+
+def get_uml_serializer(shapes_list, image_path, url_server=UML_PLANT_SERVER, namespaces_dict=None,):
+    return UMLSerializer(shapes_list=shapes_list,
+                         url_server=url_server,
+                         image_path=image_path,
                          namespaces_dict=namespaces_dict)
```

### Comparing `shexer-2.5.1/shexer/utils/factories/triple_yielders_factory.py` & `shexer-2.5.2/shexer/utils/factories/triple_yielders_factory.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,315 +1,315 @@
-from shexer.io.graph.yielder.multi_nt_triples_yielder import MultiNtTriplesYielder
-from shexer.io.graph.yielder.nt_triples_yielder import NtTriplesYielder
-from shexer.io.graph.yielder.tsv_nt_triples_yielder import TsvNtTriplesYielder
-from shexer.io.graph.yielder.multi_tsv_nt_triples_yielder import MultiTsvNtTriplesYielder
-from shexer.io.graph.yielder.rdflib_triple_yielder import RdflibParserTripleYielder, RdflibTripleYielder
-from shexer.io.graph.yielder.multi_rdflib_triple_yielder import MultiRdfLibTripleYielder
-from shexer.io.graph.yielder.remote.sgraph_from_selectors_triple_yielder import SgraphFromSelectorsTripleYielder
-from shexer.io.graph.yielder.filter.filter_namespaces_triple_yielder import FilterNamespacesTriplesYielder
-from shexer.io.graph.yielder.big_ttl_triples_yielder import BigTtlTriplesYielder
-from shexer.io.graph.yielder.multi_big_ttl_files_triple_yielder import MultiBigTtlTriplesYielder
-from shexer.io.graph.yielder.multi_zip_triples_yielder import MultiZipTriplesYielder
-from shexer.utils.factories.shape_map_parser_factory import get_shape_map_parser
-from shexer.model.graph.endpoint_sgraph import EndpointSGraph
-from shexer.utils.translators.list_of_classes_to_shape_map import ListOfClassesToShapeMap
-from shexer.utils.target_elements import tune_target_classes_if_needed
-from shexer.utils.dict import reverse_keys_and_values
-from shexer.utils.compression import list_of_zip_internal_files
-from zipfile import ZipFile
-
-from shexer.consts import NT, TSV_SPO, N3, TURTLE, RDF_XML, FIXED_SHAPE_MAP, JSON_LD, TURTLE_ITER, ZIP
-
-
-def produce_shape_map_according_to_input(sm_format, sgraph, namespaces_prefix_dict, target_classes,
-                                         file_target_classes, shape_map_file, shape_map_raw,
-                                         instantiation_property, shape_map_already_built=None,
-                                         limit_remote_instances=-1, all_classes_mode=False):
-    if shape_map_already_built is not None:
-        return shape_map_already_built
-    prefix_namespaces_dict = reverse_keys_and_values(namespaces_prefix_dict)
-    if shape_map_raw is not None or shape_map_file is not None:
-        shape_map_parser = get_shape_map_parser(format=sm_format,
-                                                sgraph=sgraph,
-                                                namespaces_prefix_dict=namespaces_prefix_dict)
-
-        return shape_map_parser.parse_shape_map(source_file=shape_map_file,
-                                                raw_content=shape_map_raw)
-    else:
-        translator = ListOfClassesToShapeMap(sgraph=sgraph,
-                                             prefix_namespaces_dict=prefix_namespaces_dict)
-        if all_classes_mode:
-            return translator.str_class_list_to_shape_map_sparql_selectors(str_list=[a_class for
-                                                                                     a_class in
-                                                                                     sgraph.yield_classes_with_instances()],
-                                                                           instantiation_property=instantiation_property,
-                                                                           limit_remote_instances=limit_remote_instances)
-        else:
-            target_classes = tune_target_classes_if_needed(list_target_classes=target_classes,
-                                                           prefix_namespaces_dict=prefix_namespaces_dict) \
-                if target_classes is not None \
-                else read_target_classes_from_file(file_target_classes=file_target_classes,
-                                                   prefix_namespaces_dict=prefix_namespaces_dict)
-
-            return translator.str_class_list_to_shape_map_sparql_selectors(str_list=target_classes,
-                                                                           instantiation_property=instantiation_property,
-                                                                           limit_remote_instances=limit_remote_instances)
-
-
-def get_triple_yielder(source_file=None, list_of_source_files=None, input_format=NT, namespaces_to_ignore=None,
-                       allow_untyped_numbers=False, raw_graph=None, namespaces_dict=None, url_input=None,
-                       list_of_url_input=None, rdflib_graph=None, shape_map_file=None, shape_map_raw=None,
-                       shape_map_format=FIXED_SHAPE_MAP,
-                       track_classes_for_entities_at_last_depth_level=True, depth_for_building_subgraph=1,
-                       url_endpoint=None, instantiation_property=None, strict_syntax_with_corners=False,
-                       target_classes=None, file_target_classes=None, built_remote_graph=None,
-                       built_shape_map=None, limit_remote_instances=-1, inverse_paths=False, all_classes_mode=False,
-                       compression_mode=None, disable_endpoint_cache=False):
-    zip_base_archives = _get_base_zip_archive_if_needed(source_file, list_of_source_files, compression_mode)
-    result = None
-    if url_endpoint is not None:
-        result = _yielder_for_url_endpoint(built_remote_graph=built_remote_graph,
-                                           url_endpoint=url_endpoint,
-                                           built_shape_map=built_shape_map,
-                                           shape_map_format=shape_map_format,
-                                           namespaces_dict=namespaces_dict,
-                                           target_classes=target_classes,
-                                           file_target_classes=file_target_classes,
-                                           shape_map_file=shape_map_file,
-                                           shape_map_raw=shape_map_raw,
-                                           instantiation_property=instantiation_property,
-                                           limit_remote_instances=limit_remote_instances,
-                                           all_classes_mode=all_classes_mode,
-                                           depth_for_building_subgraph=depth_for_building_subgraph,
-                                           track_classes_for_entities_at_last_depth_level=track_classes_for_entities_at_last_depth_level,
-                                           strict_syntax_with_corners=strict_syntax_with_corners,
-                                           allow_untyped_numbers=allow_untyped_numbers,
-                                           inverse_paths=inverse_paths,
-                                           disable_endpoint_cache=disable_endpoint_cache)
-
-    elif url_input is not None or list_of_url_input is not None:  # Always use rdflib to parse remote graphs
-        result = _yielder_for_url_input(url_input=url_input,
-                                        allow_untyped_numbers=allow_untyped_numbers,
-                                        raw_graph=raw_graph,
-                                        input_format=input_format,
-                                        namespaces_dict=namespaces_dict,
-                                        list_of_url_input=list_of_url_input)
-    elif rdflib_graph is not None:
-        result = RdflibTripleYielder(rdflib_graph=rdflib_graph,
-                                     namespaces_dict=namespaces_dict)
-    elif input_format == NT:
-        result = _yielder_for_nt(source_file=source_file,
-                                 raw_graph=raw_graph,
-                                 allow_untyped_numbers=allow_untyped_numbers,
-                                 list_of_source_files=list_of_source_files,
-                                 compression_mode=compression_mode,
-                                 zip_base_archives=zip_base_archives)
-    elif input_format == TSV_SPO:
-        result = _yielder_for_tsv_spo(source_file=source_file,
-                                      allow_untyped_numbers=allow_untyped_numbers,
-                                      raw_graph=raw_graph,
-                                      list_of_files=list_of_source_files,
-                                      compression_mode=compression_mode,
-                                      zip_base_archives=zip_base_archives)
-    elif input_format == TURTLE_ITER:
-        result = _yielder_for_turtle_iter(source_file=source_file,
-                                          allow_untyped_numbers=allow_untyped_numbers,
-                                          raw_graph=raw_graph,
-                                          list_of_files=list_of_source_files,
-                                          compression_mode=compression_mode,
-                                          zip_base_archives=zip_base_archives)
-    elif input_format in [N3, RDF_XML, JSON_LD, TURTLE]:
-        result = _yielder_for_rdflib_parser(source_file=source_file,
-                                            allow_untyped_numbers=allow_untyped_numbers,
-                                            raw_graph=raw_graph,
-                                            input_format=input_format,
-                                            namespaces_dict=namespaces_dict,
-                                            list_of_source_files=list_of_source_files,
-                                            compression_mode=compression_mode,
-                                            zip_base_archives=zip_base_archives)
-    else:
-        raise ValueError("Not supported format: " + input_format)
-
-    if namespaces_to_ignore is None:
-        return result
-    else:
-        return FilterNamespacesTriplesYielder(actual_triple_yielder=result,
-                                              namespaces_to_ignore=namespaces_to_ignore)
-
-
-def _yielder_for_compressed_inputs(base_yielders):
-    if len(base_yielders) == 1:
-        result = base_yielders[0]
-        return base_yielders[0]
-    return MultiZipTriplesYielder(multiyielders=base_yielders)
-
-
-def _yielder_for_rdflib_parser(source_file, allow_untyped_numbers, raw_graph,
-                               input_format, namespaces_dict, list_of_source_files,
-                               compression_mode, zip_base_archives):
-    if zip_base_archives is not None:
-        # return MultiRdfLibTripleYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
-        #                                 allow_untyped_numbers=allow_untyped_numbers,
-        #                                 input_format=input_format,
-        #                                 namespaces_dict=namespaces_dict,
-        #                                 compression_mode=compression_mode,
-        #                                 zip_archive_file=zip_base_archives)
-        return _yielder_for_compressed_inputs(
-            base_yielders=[MultiRdfLibTripleYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
-                                                    allow_untyped_numbers=allow_untyped_numbers,
-                                                    input_format=input_format,
-                                                    namespaces_dict=namespaces_dict,
-                                                    compression_mode=compression_mode,
-                                                    zip_archive_file=a_zip_file) for a_zip_file in
-                           zip_base_archives])
-
-    elif source_file is not None or raw_graph is not None:
-        return RdflibParserTripleYielder(source=source_file,
-                                         allow_untyped_numbers=allow_untyped_numbers,
-                                         raw_graph=raw_graph,
-                                         input_format=input_format,
-                                         namespaces_dict=namespaces_dict,
-                                         compression_mode=compression_mode)
-
-    else:
-        return MultiRdfLibTripleYielder(list_of_files=list_of_source_files,
-                                        allow_untyped_numbers=allow_untyped_numbers,
-                                        input_format=input_format,
-                                        namespaces_dict=namespaces_dict,
-                                        compression_mode=compression_mode)
-
-
-def _yielder_for_turtle_iter(source_file, raw_graph, allow_untyped_numbers, list_of_files,
-                             compression_mode, zip_base_archives):
-    if zip_base_archives is not None:
-        # return MultiBigTtlTriplesYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
-        #                                  compression_mode=compression_mode,
-        #                                  allow_untyped_numbers=allow_untyped_numbers,
-        #                                  zip_base_archives=zip_base_archives)
-        return _yielder_for_compressed_inputs(
-            [MultiBigTtlTriplesYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
-                                       compression_mode=compression_mode,
-                                       allow_untyped_numbers=allow_untyped_numbers,
-                                       zip_base_archive=a_zip_file) for a_zip_file in zip_base_archives])
-    elif source_file is not None or raw_graph is not None:
-        return BigTtlTriplesYielder(source_file=source_file,
-                                    allow_untyped_numbers=allow_untyped_numbers,
-                                    raw_graph=raw_graph,
-                                    compression_mode=compression_mode)
-    else:
-        return MultiBigTtlTriplesYielder(list_of_files=list_of_files,
-                                         allow_untyped_numbers=allow_untyped_numbers,
-                                         compression_mode=compression_mode)
-
-
-def _yielder_for_tsv_spo(source_file, raw_graph, allow_untyped_numbers, list_of_files,
-                         compression_mode, zip_base_archives):
-    if zip_base_archives is not None:
-        # return MultiTsvNtTriplesYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
-        #                                 compression_mode=compression_mode,
-        #                                 allow_untyped_numbers=allow_untyped_numbers,
-        #                                 zip_base_archives=zip_base_archives)
-        return _yielder_for_compressed_inputs(
-            [MultiTsvNtTriplesYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
-                                      compression_mode=compression_mode,
-                                      allow_untyped_numbers=allow_untyped_numbers,
-                                      zip_base_archive=a_zip_file) for a_zip_file in zip_base_archives])
-    elif source_file is not None or raw_graph is not None:
-        return TsvNtTriplesYielder(source_file=source_file,
-                                   allow_untyped_numbers=allow_untyped_numbers,
-                                   raw_graph=raw_graph,
-                                   compression_mode=compression_mode)
-    else:
-        return MultiTsvNtTriplesYielder(list_of_files=list_of_files,
-                                        allow_untyped_numbers=allow_untyped_numbers,
-                                        compression_mode=compression_mode)
-
-
-def read_target_classes_from_file(file_target_classes, prefix_namespaces_dict):
-    result = []
-    with open(file_target_classes, "r") as in_stream:
-        for a_line in in_stream:
-            candidate = a_line.strip()
-            if candidate != "":
-                result.append(candidate)
-    return tune_target_classes_if_needed(list_target_classes=result,
-                                         prefix_namespaces_dict=prefix_namespaces_dict)
-
-
-def _yielder_for_url_endpoint(built_remote_graph, url_endpoint, built_shape_map, shape_map_format,
-                              namespaces_dict, target_classes, file_target_classes, shape_map_file,
-                              shape_map_raw, instantiation_property, limit_remote_instances, all_classes_mode,
-                              depth_for_building_subgraph, track_classes_for_entities_at_last_depth_level,
-                              strict_syntax_with_corners, allow_untyped_numbers, inverse_paths, disable_endpoint_cache):
-    sgrpah = built_remote_graph if built_remote_graph is not None else EndpointSGraph(endpoint_url=url_endpoint,
-                                                                                      store_locally=not disable_endpoint_cache)
-
-    shape_map = built_shape_map
-    if built_shape_map is None:
-        shape_map = produce_shape_map_according_to_input(sm_format=shape_map_format,
-                                                         sgraph=sgrpah,
-                                                         namespaces_prefix_dict=namespaces_dict,
-                                                         target_classes=target_classes,
-                                                         file_target_classes=file_target_classes,
-                                                         shape_map_file=shape_map_file,
-                                                         shape_map_raw=shape_map_raw,
-                                                         instantiation_property=instantiation_property,
-                                                         limit_remote_instances=limit_remote_instances,
-                                                         all_classes_mode=all_classes_mode)
-    return SgraphFromSelectorsTripleYielder(shape_map=shape_map,
-                                            depth=depth_for_building_subgraph,
-                                            classes_at_last_level=track_classes_for_entities_at_last_depth_level,
-                                            instantiation_property=instantiation_property,
-                                            strict_syntax_with_corners=strict_syntax_with_corners,
-                                            allow_untyped_numbers=allow_untyped_numbers,
-                                            inverse_paths=inverse_paths)
-
-
-def _yielder_for_url_input(url_input, allow_untyped_numbers, raw_graph,
-                           input_format, namespaces_dict, list_of_url_input):
-    if url_input:
-        return RdflibParserTripleYielder(source=url_input,
-                                         allow_untyped_numbers=allow_untyped_numbers,
-                                         raw_graph=raw_graph,
-                                         input_format=input_format,
-                                         namespaces_dict=namespaces_dict)
-    else:  # elif list_of_url_input:
-        return MultiRdfLibTripleYielder(list_of_files=list_of_url_input,
-                                        allow_untyped_numbers=allow_untyped_numbers,
-                                        input_format=input_format,
-                                        namespaces_dict=namespaces_dict)
-
-
-def _yielder_for_nt(source_file, raw_graph, allow_untyped_numbers,
-                    list_of_source_files, compression_mode,
-                    zip_base_archives):
-    if (source_file is not None or raw_graph is not None) and zip_base_archives is None:
-        return NtTriplesYielder(source_file=source_file,
-                                allow_untyped_numbers=allow_untyped_numbers,
-                                raw_graph=raw_graph,
-                                compression_mode=compression_mode)
-    elif zip_base_archives is not None:
-        # return MultiNtTriplesYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
-        #                              allow_untyped_numbers=allow_untyped_numbers,
-        #                              compression_mode=compression_mode,
-        #                              zip_base_archives=zip_base_archives)
-        return _yielder_for_compressed_inputs(
-            [MultiNtTriplesYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
-                                   allow_untyped_numbers=allow_untyped_numbers,
-                                   compression_mode=compression_mode,
-                                   zip_base_archive=a_zip_file) for a_zip_file in zip_base_archives])
-
-    else:
-        return MultiNtTriplesYielder(list_of_files=list_of_source_files,
-                                     allow_untyped_numbers=allow_untyped_numbers,
-                                     compression_mode=compression_mode)
-
-
-def _get_base_zip_archive_if_needed(source_file, list_of_source_files, compression_mode):
-    if compression_mode != ZIP:
-        return None
-    if source_file is not None:
-        return [ZipFile(source_file, 'r')]
-    result = []
-    for a_source_file in list_of_source_files:
-        result.append(ZipFile(a_source_file, 'r'))
-    return result
+from shexer.io.graph.yielder.multi_nt_triples_yielder import MultiNtTriplesYielder
+from shexer.io.graph.yielder.nt_triples_yielder import NtTriplesYielder
+from shexer.io.graph.yielder.tsv_nt_triples_yielder import TsvNtTriplesYielder
+from shexer.io.graph.yielder.multi_tsv_nt_triples_yielder import MultiTsvNtTriplesYielder
+from shexer.io.graph.yielder.rdflib_triple_yielder import RdflibParserTripleYielder, RdflibTripleYielder
+from shexer.io.graph.yielder.multi_rdflib_triple_yielder import MultiRdfLibTripleYielder
+from shexer.io.graph.yielder.remote.sgraph_from_selectors_triple_yielder import SgraphFromSelectorsTripleYielder
+from shexer.io.graph.yielder.filter.filter_namespaces_triple_yielder import FilterNamespacesTriplesYielder
+from shexer.io.graph.yielder.big_ttl_triples_yielder import BigTtlTriplesYielder
+from shexer.io.graph.yielder.multi_big_ttl_files_triple_yielder import MultiBigTtlTriplesYielder
+from shexer.io.graph.yielder.multi_zip_triples_yielder import MultiZipTriplesYielder
+from shexer.utils.factories.shape_map_parser_factory import get_shape_map_parser
+from shexer.model.graph.endpoint_sgraph import EndpointSGraph
+from shexer.utils.translators.list_of_classes_to_shape_map import ListOfClassesToShapeMap
+from shexer.utils.target_elements import tune_target_classes_if_needed
+from shexer.utils.dict import reverse_keys_and_values
+from shexer.utils.compression import list_of_zip_internal_files
+from zipfile import ZipFile
+
+from shexer.consts import NT, TSV_SPO, N3, TURTLE, RDF_XML, FIXED_SHAPE_MAP, JSON_LD, TURTLE_ITER, ZIP
+
+
+def produce_shape_map_according_to_input(sm_format, sgraph, namespaces_prefix_dict, target_classes,
+                                         file_target_classes, shape_map_file, shape_map_raw,
+                                         instantiation_property, shape_map_already_built=None,
+                                         limit_remote_instances=-1, all_classes_mode=False):
+    if shape_map_already_built is not None:
+        return shape_map_already_built
+    prefix_namespaces_dict = reverse_keys_and_values(namespaces_prefix_dict)
+    if shape_map_raw is not None or shape_map_file is not None:
+        shape_map_parser = get_shape_map_parser(format=sm_format,
+                                                sgraph=sgraph,
+                                                namespaces_prefix_dict=namespaces_prefix_dict)
+
+        return shape_map_parser.parse_shape_map(source_file=shape_map_file,
+                                                raw_content=shape_map_raw)
+    else:
+        translator = ListOfClassesToShapeMap(sgraph=sgraph,
+                                             prefix_namespaces_dict=prefix_namespaces_dict)
+        if all_classes_mode:
+            return translator.str_class_list_to_shape_map_sparql_selectors(str_list=[a_class for
+                                                                                     a_class in
+                                                                                     sgraph.yield_classes_with_instances()],
+                                                                           instantiation_property=instantiation_property,
+                                                                           limit_remote_instances=limit_remote_instances)
+        else:
+            target_classes = tune_target_classes_if_needed(list_target_classes=target_classes,
+                                                           prefix_namespaces_dict=prefix_namespaces_dict) \
+                if target_classes is not None \
+                else read_target_classes_from_file(file_target_classes=file_target_classes,
+                                                   prefix_namespaces_dict=prefix_namespaces_dict)
+
+            return translator.str_class_list_to_shape_map_sparql_selectors(str_list=target_classes,
+                                                                           instantiation_property=instantiation_property,
+                                                                           limit_remote_instances=limit_remote_instances)
+
+
+def get_triple_yielder(source_file=None, list_of_source_files=None, input_format=NT, namespaces_to_ignore=None,
+                       allow_untyped_numbers=False, raw_graph=None, namespaces_dict=None, url_input=None,
+                       list_of_url_input=None, rdflib_graph=None, shape_map_file=None, shape_map_raw=None,
+                       shape_map_format=FIXED_SHAPE_MAP,
+                       track_classes_for_entities_at_last_depth_level=True, depth_for_building_subgraph=1,
+                       url_endpoint=None, instantiation_property=None, strict_syntax_with_corners=False,
+                       target_classes=None, file_target_classes=None, built_remote_graph=None,
+                       built_shape_map=None, limit_remote_instances=-1, inverse_paths=False, all_classes_mode=False,
+                       compression_mode=None, disable_endpoint_cache=False):
+    zip_base_archives = _get_base_zip_archive_if_needed(source_file, list_of_source_files, compression_mode)
+    result = None
+    if url_endpoint is not None:
+        result = _yielder_for_url_endpoint(built_remote_graph=built_remote_graph,
+                                           url_endpoint=url_endpoint,
+                                           built_shape_map=built_shape_map,
+                                           shape_map_format=shape_map_format,
+                                           namespaces_dict=namespaces_dict,
+                                           target_classes=target_classes,
+                                           file_target_classes=file_target_classes,
+                                           shape_map_file=shape_map_file,
+                                           shape_map_raw=shape_map_raw,
+                                           instantiation_property=instantiation_property,
+                                           limit_remote_instances=limit_remote_instances,
+                                           all_classes_mode=all_classes_mode,
+                                           depth_for_building_subgraph=depth_for_building_subgraph,
+                                           track_classes_for_entities_at_last_depth_level=track_classes_for_entities_at_last_depth_level,
+                                           strict_syntax_with_corners=strict_syntax_with_corners,
+                                           allow_untyped_numbers=allow_untyped_numbers,
+                                           inverse_paths=inverse_paths,
+                                           disable_endpoint_cache=disable_endpoint_cache)
+
+    elif url_input is not None or list_of_url_input is not None:  # Always use rdflib to parse remote graphs
+        result = _yielder_for_url_input(url_input=url_input,
+                                        allow_untyped_numbers=allow_untyped_numbers,
+                                        raw_graph=raw_graph,
+                                        input_format=input_format,
+                                        namespaces_dict=namespaces_dict,
+                                        list_of_url_input=list_of_url_input)
+    elif rdflib_graph is not None:
+        result = RdflibTripleYielder(rdflib_graph=rdflib_graph,
+                                     namespaces_dict=namespaces_dict)
+    elif input_format == NT:
+        result = _yielder_for_nt(source_file=source_file,
+                                 raw_graph=raw_graph,
+                                 allow_untyped_numbers=allow_untyped_numbers,
+                                 list_of_source_files=list_of_source_files,
+                                 compression_mode=compression_mode,
+                                 zip_base_archives=zip_base_archives)
+    elif input_format == TSV_SPO:
+        result = _yielder_for_tsv_spo(source_file=source_file,
+                                      allow_untyped_numbers=allow_untyped_numbers,
+                                      raw_graph=raw_graph,
+                                      list_of_files=list_of_source_files,
+                                      compression_mode=compression_mode,
+                                      zip_base_archives=zip_base_archives)
+    elif input_format == TURTLE_ITER:
+        result = _yielder_for_turtle_iter(source_file=source_file,
+                                          allow_untyped_numbers=allow_untyped_numbers,
+                                          raw_graph=raw_graph,
+                                          list_of_files=list_of_source_files,
+                                          compression_mode=compression_mode,
+                                          zip_base_archives=zip_base_archives)
+    elif input_format in [N3, RDF_XML, JSON_LD, TURTLE]:
+        result = _yielder_for_rdflib_parser(source_file=source_file,
+                                            allow_untyped_numbers=allow_untyped_numbers,
+                                            raw_graph=raw_graph,
+                                            input_format=input_format,
+                                            namespaces_dict=namespaces_dict,
+                                            list_of_source_files=list_of_source_files,
+                                            compression_mode=compression_mode,
+                                            zip_base_archives=zip_base_archives)
+    else:
+        raise ValueError("Not supported format: " + input_format)
+
+    if namespaces_to_ignore is None:
+        return result
+    else:
+        return FilterNamespacesTriplesYielder(actual_triple_yielder=result,
+                                              namespaces_to_ignore=namespaces_to_ignore)
+
+
+def _yielder_for_compressed_inputs(base_yielders):
+    if len(base_yielders) == 1:
+        result = base_yielders[0]
+        return base_yielders[0]
+    return MultiZipTriplesYielder(multiyielders=base_yielders)
+
+
+def _yielder_for_rdflib_parser(source_file, allow_untyped_numbers, raw_graph,
+                               input_format, namespaces_dict, list_of_source_files,
+                               compression_mode, zip_base_archives):
+    if zip_base_archives is not None:
+        # return MultiRdfLibTripleYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
+        #                                 allow_untyped_numbers=allow_untyped_numbers,
+        #                                 input_format=input_format,
+        #                                 namespaces_dict=namespaces_dict,
+        #                                 compression_mode=compression_mode,
+        #                                 zip_archive_file=zip_base_archives)
+        return _yielder_for_compressed_inputs(
+            base_yielders=[MultiRdfLibTripleYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
+                                                    allow_untyped_numbers=allow_untyped_numbers,
+                                                    input_format=input_format,
+                                                    namespaces_dict=namespaces_dict,
+                                                    compression_mode=compression_mode,
+                                                    zip_archive_file=a_zip_file) for a_zip_file in
+                           zip_base_archives])
+
+    elif source_file is not None or raw_graph is not None:
+        return RdflibParserTripleYielder(source=source_file,
+                                         allow_untyped_numbers=allow_untyped_numbers,
+                                         raw_graph=raw_graph,
+                                         input_format=input_format,
+                                         namespaces_dict=namespaces_dict,
+                                         compression_mode=compression_mode)
+
+    else:
+        return MultiRdfLibTripleYielder(list_of_files=list_of_source_files,
+                                        allow_untyped_numbers=allow_untyped_numbers,
+                                        input_format=input_format,
+                                        namespaces_dict=namespaces_dict,
+                                        compression_mode=compression_mode)
+
+
+def _yielder_for_turtle_iter(source_file, raw_graph, allow_untyped_numbers, list_of_files,
+                             compression_mode, zip_base_archives):
+    if zip_base_archives is not None:
+        # return MultiBigTtlTriplesYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
+        #                                  compression_mode=compression_mode,
+        #                                  allow_untyped_numbers=allow_untyped_numbers,
+        #                                  zip_base_archives=zip_base_archives)
+        return _yielder_for_compressed_inputs(
+            [MultiBigTtlTriplesYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
+                                       compression_mode=compression_mode,
+                                       allow_untyped_numbers=allow_untyped_numbers,
+                                       zip_base_archive=a_zip_file) for a_zip_file in zip_base_archives])
+    elif source_file is not None or raw_graph is not None:
+        return BigTtlTriplesYielder(source_file=source_file,
+                                    allow_untyped_numbers=allow_untyped_numbers,
+                                    raw_graph=raw_graph,
+                                    compression_mode=compression_mode)
+    else:
+        return MultiBigTtlTriplesYielder(list_of_files=list_of_files,
+                                         allow_untyped_numbers=allow_untyped_numbers,
+                                         compression_mode=compression_mode)
+
+
+def _yielder_for_tsv_spo(source_file, raw_graph, allow_untyped_numbers, list_of_files,
+                         compression_mode, zip_base_archives):
+    if zip_base_archives is not None:
+        # return MultiTsvNtTriplesYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
+        #                                 compression_mode=compression_mode,
+        #                                 allow_untyped_numbers=allow_untyped_numbers,
+        #                                 zip_base_archives=zip_base_archives)
+        return _yielder_for_compressed_inputs(
+            [MultiTsvNtTriplesYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
+                                      compression_mode=compression_mode,
+                                      allow_untyped_numbers=allow_untyped_numbers,
+                                      zip_base_archive=a_zip_file) for a_zip_file in zip_base_archives])
+    elif source_file is not None or raw_graph is not None:
+        return TsvNtTriplesYielder(source_file=source_file,
+                                   allow_untyped_numbers=allow_untyped_numbers,
+                                   raw_graph=raw_graph,
+                                   compression_mode=compression_mode)
+    else:
+        return MultiTsvNtTriplesYielder(list_of_files=list_of_files,
+                                        allow_untyped_numbers=allow_untyped_numbers,
+                                        compression_mode=compression_mode)
+
+
+def read_target_classes_from_file(file_target_classes, prefix_namespaces_dict):
+    result = []
+    with open(file_target_classes, "r") as in_stream:
+        for a_line in in_stream:
+            candidate = a_line.strip()
+            if candidate != "":
+                result.append(candidate)
+    return tune_target_classes_if_needed(list_target_classes=result,
+                                         prefix_namespaces_dict=prefix_namespaces_dict)
+
+
+def _yielder_for_url_endpoint(built_remote_graph, url_endpoint, built_shape_map, shape_map_format,
+                              namespaces_dict, target_classes, file_target_classes, shape_map_file,
+                              shape_map_raw, instantiation_property, limit_remote_instances, all_classes_mode,
+                              depth_for_building_subgraph, track_classes_for_entities_at_last_depth_level,
+                              strict_syntax_with_corners, allow_untyped_numbers, inverse_paths, disable_endpoint_cache):
+    sgrpah = built_remote_graph if built_remote_graph is not None else EndpointSGraph(endpoint_url=url_endpoint,
+                                                                                      store_locally=not disable_endpoint_cache)
+
+    shape_map = built_shape_map
+    if built_shape_map is None:
+        shape_map = produce_shape_map_according_to_input(sm_format=shape_map_format,
+                                                         sgraph=sgrpah,
+                                                         namespaces_prefix_dict=namespaces_dict,
+                                                         target_classes=target_classes,
+                                                         file_target_classes=file_target_classes,
+                                                         shape_map_file=shape_map_file,
+                                                         shape_map_raw=shape_map_raw,
+                                                         instantiation_property=instantiation_property,
+                                                         limit_remote_instances=limit_remote_instances,
+                                                         all_classes_mode=all_classes_mode)
+    return SgraphFromSelectorsTripleYielder(shape_map=shape_map,
+                                            depth=depth_for_building_subgraph,
+                                            classes_at_last_level=track_classes_for_entities_at_last_depth_level,
+                                            instantiation_property=instantiation_property,
+                                            strict_syntax_with_corners=strict_syntax_with_corners,
+                                            allow_untyped_numbers=allow_untyped_numbers,
+                                            inverse_paths=inverse_paths)
+
+
+def _yielder_for_url_input(url_input, allow_untyped_numbers, raw_graph,
+                           input_format, namespaces_dict, list_of_url_input):
+    if url_input:
+        return RdflibParserTripleYielder(source=url_input,
+                                         allow_untyped_numbers=allow_untyped_numbers,
+                                         raw_graph=raw_graph,
+                                         input_format=input_format,
+                                         namespaces_dict=namespaces_dict)
+    else:  # elif list_of_url_input:
+        return MultiRdfLibTripleYielder(list_of_files=list_of_url_input,
+                                        allow_untyped_numbers=allow_untyped_numbers,
+                                        input_format=input_format,
+                                        namespaces_dict=namespaces_dict)
+
+
+def _yielder_for_nt(source_file, raw_graph, allow_untyped_numbers,
+                    list_of_source_files, compression_mode,
+                    zip_base_archives):
+    if (source_file is not None or raw_graph is not None) and zip_base_archives is None:
+        return NtTriplesYielder(source_file=source_file,
+                                allow_untyped_numbers=allow_untyped_numbers,
+                                raw_graph=raw_graph,
+                                compression_mode=compression_mode)
+    elif zip_base_archives is not None:
+        # return MultiNtTriplesYielder(list_of_files=list_of_zip_internal_files(zip_base_archive),
+        #                              allow_untyped_numbers=allow_untyped_numbers,
+        #                              compression_mode=compression_mode,
+        #                              zip_base_archives=zip_base_archives)
+        return _yielder_for_compressed_inputs(
+            [MultiNtTriplesYielder(list_of_files=list_of_zip_internal_files(a_zip_file),
+                                   allow_untyped_numbers=allow_untyped_numbers,
+                                   compression_mode=compression_mode,
+                                   zip_base_archive=a_zip_file) for a_zip_file in zip_base_archives])
+
+    else:
+        return MultiNtTriplesYielder(list_of_files=list_of_source_files,
+                                     allow_untyped_numbers=allow_untyped_numbers,
+                                     compression_mode=compression_mode)
+
+
+def _get_base_zip_archive_if_needed(source_file, list_of_source_files, compression_mode):
+    if compression_mode != ZIP:
+        return None
+    if source_file is not None:
+        return [ZipFile(source_file, 'r')]
+    result = []
+    for a_source_file in list_of_source_files:
+        result.append(ZipFile(a_source_file, 'r'))
+    return result
```

### Comparing `shexer-2.5.1/shexer/utils/obj_references.py` & `shexer-2.5.2/shexer/utils/obj_references.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-
-def check_just_one_not_none(*value_refname):
-    nones=0
-    for a_tuple in value_refname:
-        if a_tuple[0] is not None:
-            nones += 1
-    if nones != 1:
-        raise ValueError(error_message_for_non_compatible_references([a_tuple[1] for a_tuple in value_refname]))
-
-
-def check_one_or_zero_not_none(*value_refname):
-    nones=0
-    for a_tuple in value_refname:
-        if a_tuple[0] is not None:
-            nones += 1
-    if nones > 1:
-        raise ValueError(error_message_for_non_compatible_references(
-            list_of_ref_names=[a_tuple[1] for a_tuple in value_refname],
-            one_mandatory=False))
-
-
-def error_message_for_non_compatible_references(list_of_ref_names, one_mandatory=True):
-    if one_mandatory:
-        return "You must provide one and only one of the following params: " + str(list_of_ref_names)
-    return "You must provide one as most of the following params: " + str(list_of_ref_names)
-
-
+
+def check_just_one_not_none(*value_refname):
+    nones=0
+    for a_tuple in value_refname:
+        if a_tuple[0] is not None:
+            nones += 1
+    if nones != 1:
+        raise ValueError(error_message_for_non_compatible_references([a_tuple[1] for a_tuple in value_refname]))
+
+
+def check_one_or_zero_not_none(*value_refname):
+    nones=0
+    for a_tuple in value_refname:
+        if a_tuple[0] is not None:
+            nones += 1
+    if nones > 1:
+        raise ValueError(error_message_for_non_compatible_references(
+            list_of_ref_names=[a_tuple[1] for a_tuple in value_refname],
+            one_mandatory=False))
+
+
+def error_message_for_non_compatible_references(list_of_ref_names, one_mandatory=True):
+    if one_mandatory:
+        return "You must provide one and only one of the following params: " + str(list_of_ref_names)
+    return "You must provide one as most of the following params: " + str(list_of_ref_names)
+
+
```

### Comparing `shexer-2.5.1/shexer/utils/structures/dicts.py` & `shexer-2.5.2/shexer/utils/structures/dicts.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,88 +1,88 @@
-
-_MIN_IRI_POS = 0
-_EXAMPLE_ENTITY_POS = 1
-_PROP_FEATURES_POS = 2
-
-
-_POS_DIRECT = 0
-_POS_INVERSE = 1
-
-
-class ShapeExampleFeaturesDict(object):
-
-    def __init__(self, track_inverse_features):
-        self._base_dict = {}
-        self._track_inverse_features = track_inverse_features
-        self._init_example_tracking_methods()
-
-
-    def _init_example_tracking_methods(self):
-        if self._track_inverse_features:
-            self.has_constraint_example = self._has_constraint_example_inverse
-            self.set_constraint_example = self._set_constraint_example_inverse
-            self.get_constraint_example = self._get_constraint_example_inverse
-        else:
-            self.has_constraint_example = self._has_constraint_example_no_inverse
-            self.set_constraint_example = self._set_constraint_example_no_inverse
-            self.get_constraint_example = self._get_constraint_example_no_inverse
-
-
-    def set_shape_min_iri(self, shape_id, min_iri):
-        if shape_id not in self._base_dict:
-            self._init_shape(shape_id)
-        self._base_dict[shape_id][_MIN_IRI_POS] = min_iri
-
-    def shape_min_iri(self, shape_id):
-        return self._base_dict[shape_id][_MIN_IRI_POS]
-
-    def set_shape_example(self, shape_id, example_iri):
-        if shape_id not in self._base_dict:
-            self._init_shape(shape_id)
-        self._base_dict[shape_id][_EXAMPLE_ENTITY_POS] = example_iri
-
-    def shape_example(self, shape_id):
-        if shape_id not in self._base_dict:
-            return False
-        return self._base_dict[shape_id][_EXAMPLE_ENTITY_POS]
-
-    def _init_shape(self, shape_id):
-        self._base_dict[shape_id] = [None, None, {} if not self._track_inverse_features else [{}, {}]]
-
-
-    def has_constraint_example(self, shape_id, prop_id):
-        raise NotImplementedError()
-
-    def _has_constraint_example_abstract(self):
-        raise NotImplementedError()
-
-    def set_constraint_example(self, shape_id, prop, example):
-        raise NotImplementedError()
-
-    def get_constraint_example(self, shape_id, prop):
-        raise NotImplementedError()
-
-    def _get_constraint_example_no_inverse(self, shape_id, prop):
-        return self._base_dict[shape_id][_PROP_FEATURES_POS][prop]
-
-    def _get_constraint_example_inverse(self, shape_id, prop, inverse):
-        return self._base_dict[shape_id][_PROP_FEATURES_POS][_POS_INVERSE if inverse else _POS_DIRECT][prop]
-
-    def _set_constraint_example_no_inverse(self, shape_id, prop_id, example):
-        if shape_id not in self._base_dict:
-            self._init_shape(shape_id)
-        self._base_dict[shape_id][_PROP_FEATURES_POS][prop_id] = example
-
-    def _set_constraint_example_inverse(self, shape_id, prop_id, example, inverse):
-        if shape_id not in self._base_dict:
-            self._init_shape(shape_id)
-        self._base_dict[shape_id][_PROP_FEATURES_POS][_POS_INVERSE if inverse else _POS_DIRECT][prop_id] = example
-
-    def _has_constraint_example_no_inverse(self, shape_id, prop_id):
-        if shape_id not in self._base_dict:
-            return False
-        return prop_id in self._base_dict[shape_id][_PROP_FEATURES_POS]
-
-    def _has_constraint_example_inverse(self, shape_id, prop_id, inverse):
-        if shape_id not in self._base_dict:
-            return False
+
+_MIN_IRI_POS = 0
+_EXAMPLE_ENTITY_POS = 1
+_PROP_FEATURES_POS = 2
+
+
+_POS_DIRECT = 0
+_POS_INVERSE = 1
+
+
+class ShapeExampleFeaturesDict(object):
+
+    def __init__(self, track_inverse_features):
+        self._base_dict = {}
+        self._track_inverse_features = track_inverse_features
+        self._init_example_tracking_methods()
+
+
+    def _init_example_tracking_methods(self):
+        if self._track_inverse_features:
+            self.has_constraint_example = self._has_constraint_example_inverse
+            self.set_constraint_example = self._set_constraint_example_inverse
+            self.get_constraint_example = self._get_constraint_example_inverse
+        else:
+            self.has_constraint_example = self._has_constraint_example_no_inverse
+            self.set_constraint_example = self._set_constraint_example_no_inverse
+            self.get_constraint_example = self._get_constraint_example_no_inverse
+
+
+    def set_shape_min_iri(self, shape_id, min_iri):
+        if shape_id not in self._base_dict:
+            self._init_shape(shape_id)
+        self._base_dict[shape_id][_MIN_IRI_POS] = min_iri
+
+    def shape_min_iri(self, shape_id):
+        return self._base_dict[shape_id][_MIN_IRI_POS]
+
+    def set_shape_example(self, shape_id, example_iri):
+        if shape_id not in self._base_dict:
+            self._init_shape(shape_id)
+        self._base_dict[shape_id][_EXAMPLE_ENTITY_POS] = example_iri
+
+    def shape_example(self, shape_id):
+        if shape_id not in self._base_dict:
+            return False
+        return self._base_dict[shape_id][_EXAMPLE_ENTITY_POS]
+
+    def _init_shape(self, shape_id):
+        self._base_dict[shape_id] = [None, None, {} if not self._track_inverse_features else [{}, {}]]
+
+
+    def has_constraint_example(self, shape_id, prop_id):
+        raise NotImplementedError()
+
+    def _has_constraint_example_abstract(self):
+        raise NotImplementedError()
+
+    def set_constraint_example(self, shape_id, prop, example):
+        raise NotImplementedError()
+
+    def get_constraint_example(self, shape_id, prop):
+        raise NotImplementedError()
+
+    def _get_constraint_example_no_inverse(self, shape_id, prop):
+        return self._base_dict[shape_id][_PROP_FEATURES_POS][prop]
+
+    def _get_constraint_example_inverse(self, shape_id, prop, inverse):
+        return self._base_dict[shape_id][_PROP_FEATURES_POS][_POS_INVERSE if inverse else _POS_DIRECT][prop]
+
+    def _set_constraint_example_no_inverse(self, shape_id, prop_id, example):
+        if shape_id not in self._base_dict:
+            self._init_shape(shape_id)
+        self._base_dict[shape_id][_PROP_FEATURES_POS][prop_id] = example
+
+    def _set_constraint_example_inverse(self, shape_id, prop_id, example, inverse):
+        if shape_id not in self._base_dict:
+            self._init_shape(shape_id)
+        self._base_dict[shape_id][_PROP_FEATURES_POS][_POS_INVERSE if inverse else _POS_DIRECT][prop_id] = example
+
+    def _has_constraint_example_no_inverse(self, shape_id, prop_id):
+        if shape_id not in self._base_dict:
+            return False
+        return prop_id in self._base_dict[shape_id][_PROP_FEATURES_POS]
+
+    def _has_constraint_example_inverse(self, shape_id, prop_id, inverse):
+        if shape_id not in self._base_dict:
+            return False
         return  prop_id in self._base_dict[shape_id][_PROP_FEATURES_POS][_POS_INVERSE if inverse else _POS_DIRECT]
```

### Comparing `shexer-2.5.1/shexer/utils/target_elements.py` & `shexer-2.5.2/shexer/utils/target_elements.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,27 +1,27 @@
-from shexer.utils.shapes import build_shapes_name_for_class_uri
-from shexer.utils.uri import remove_corners, unprefixize_uri_if_possible
-
-
-def tune_target_classes_if_needed(list_target_classes, prefix_namespaces_dict):
-    result = []
-    for a_original_class in list_target_classes:
-        if a_original_class.startswith("<"):
-            result.append(remove_corners(a_uri=a_original_class))
-        else:
-            result.append(unprefixize_uri_if_possible(target_uri=a_original_class,
-                                                      prefix_namespaces_dict=prefix_namespaces_dict,
-                                                      include_corners=False))
-    return result
-
-def determine_original_target_nodes_if_needed(remove_empty_shapes, original_target_classes, original_shape_map, shapes_namespace):
-    if not remove_empty_shapes:
-        return None  # We dont need this structure if there are no shapes to remove.
-    result = set()
-    if original_target_classes is not None:
-        for a_class in original_target_classes:
-            result.add(build_shapes_name_for_class_uri(class_uri=a_class,
-                                                       shapes_namespace=shapes_namespace))
-    if original_shape_map is not None:
-        for an_item in original_shape_map.yield_items():
-            result.add(an_item.shape_label)
+from shexer.utils.shapes import build_shapes_name_for_class_uri
+from shexer.utils.uri import remove_corners, unprefixize_uri_if_possible
+
+
+def tune_target_classes_if_needed(list_target_classes, prefix_namespaces_dict):
+    result = []
+    for a_original_class in list_target_classes:
+        if a_original_class.startswith("<"):
+            result.append(remove_corners(a_uri=a_original_class))
+        else:
+            result.append(unprefixize_uri_if_possible(target_uri=a_original_class,
+                                                      prefix_namespaces_dict=prefix_namespaces_dict,
+                                                      include_corners=False))
+    return result
+
+def determine_original_target_nodes_if_needed(remove_empty_shapes, original_target_classes, original_shape_map, shapes_namespace):
+    if not remove_empty_shapes:
+        return None  # We dont need this structure if there are no shapes to remove.
+    result = set()
+    if original_target_classes is not None:
+        for a_class in original_target_classes:
+            result.add(build_shapes_name_for_class_uri(class_uri=a_class,
+                                                       shapes_namespace=shapes_namespace))
+    if original_shape_map is not None:
+        for an_item in original_shape_map.yield_items():
+            result.add(an_item.shape_label)
     return result
```

### Comparing `shexer-2.5.1/shexer/utils/translators/list_of_classes_to_shape_map.py` & `shexer-2.5.2/shexer/utils/translators/list_of_classes_to_shape_map.py`

 * *Ordering differences only*

 * *Files 6% similar despite different names*

```diff
@@ -1,50 +1,50 @@
-from shexer.model.shape_map import ShapeMap, ShapeMapItem
-from shexer.io.shape_map.node_selector.node_selector_parser import NodeSelectorParser
-
-
-class ListOfClassesToShapeMap(object):
-
-    def __init__(self, sgraph, prefix_namespaces_dict):
-        self._sgraph = sgraph
-        self._selector_parser = NodeSelectorParser(prefix_namespaces_dict=prefix_namespaces_dict,
-                                                   sgraph=sgraph)
-
-    def str_class_list_to_shape_map_sparql_selectors(self, str_list, instantiation_property, limit_remote_instances):
-        result = ShapeMap()
-        instantiation_property = str(instantiation_property)
-        for str_class in str_list:
-            raw_selector = self._get_raw_selector_to_catch_instances_of_class_uri(class_uri=str_class,
-                                                                                  instantiation_property=instantiation_property,
-                                                                                  limit_remote_instances=limit_remote_instances)
-            result.add_item(ShapeMapItem(node_selector=self._get_node_selector_object_for_raw_selector(raw_selector),
-                                         shape_label=self._get_shape_label_for_class_uri(str_class)))
-        return result
-
-    def model_class_list_to_shape_map_sparql_selectors(self, obj_list, instantiation_property, limit_remote_instances):
-        return self.str_class_list_to_shape_map_sparql_selectors(str_list=[str(an_elem) for an_elem in obj_list],
-                                                                 instantiation_property=instantiation_property,
-                                                                 limit_remote_instances=limit_remote_instances)
-
-    def _get_shape_label_for_class_uri(self, class_uri):
-        if "#" in class_uri and class_uri[-1] != "#":
-            return class_uri[class_uri.rfind("#") + 1:]
-        if "/" in class_uri:
-            if class_uri[-1] != "/":
-                return class_uri[class_uri.rfind("/") + 1:]
-            else:
-                return class_uri[class_uri[:-1].rfind("/") + 1:]
-        else:
-            return class_uri
-
-    def _get_raw_selector_to_catch_instances_of_class_uri(self, class_uri, instantiation_property, limit_remote_instances):
-        return 'SPARQL "select ?s where {{ ?s <{prop}> <{class_uri}> }} {limit}"'.format(
-            class_uri=class_uri,
-            prop=instantiation_property,
-            limit="" if limit_remote_instances < 0 else "LIMIT " + str(limit_remote_instances)
-        )
-        # return '{' + 'FOCUS <{prop}> <{class_uri}>'.format(class_uri=class_uri, prop=instantiation_property) + '}'
-
-    def _get_node_selector_object_for_raw_selector(self, raw_selector):
-        return self._selector_parser.parse_node_selector(raw_selector=raw_selector)
-
-
+from shexer.model.shape_map import ShapeMap, ShapeMapItem
+from shexer.io.shape_map.node_selector.node_selector_parser import NodeSelectorParser
+
+
+class ListOfClassesToShapeMap(object):
+
+    def __init__(self, sgraph, prefix_namespaces_dict):
+        self._sgraph = sgraph
+        self._selector_parser = NodeSelectorParser(prefix_namespaces_dict=prefix_namespaces_dict,
+                                                   sgraph=sgraph)
+
+    def str_class_list_to_shape_map_sparql_selectors(self, str_list, instantiation_property, limit_remote_instances):
+        result = ShapeMap()
+        instantiation_property = str(instantiation_property)
+        for str_class in str_list:
+            raw_selector = self._get_raw_selector_to_catch_instances_of_class_uri(class_uri=str_class,
+                                                                                  instantiation_property=instantiation_property,
+                                                                                  limit_remote_instances=limit_remote_instances)
+            result.add_item(ShapeMapItem(node_selector=self._get_node_selector_object_for_raw_selector(raw_selector),
+                                         shape_label=self._get_shape_label_for_class_uri(str_class)))
+        return result
+
+    def model_class_list_to_shape_map_sparql_selectors(self, obj_list, instantiation_property, limit_remote_instances):
+        return self.str_class_list_to_shape_map_sparql_selectors(str_list=[str(an_elem) for an_elem in obj_list],
+                                                                 instantiation_property=instantiation_property,
+                                                                 limit_remote_instances=limit_remote_instances)
+
+    def _get_shape_label_for_class_uri(self, class_uri):
+        if "#" in class_uri and class_uri[-1] != "#":
+            return class_uri[class_uri.rfind("#") + 1:]
+        if "/" in class_uri:
+            if class_uri[-1] != "/":
+                return class_uri[class_uri.rfind("/") + 1:]
+            else:
+                return class_uri[class_uri[:-1].rfind("/") + 1:]
+        else:
+            return class_uri
+
+    def _get_raw_selector_to_catch_instances_of_class_uri(self, class_uri, instantiation_property, limit_remote_instances):
+        return 'SPARQL "select ?s where {{ ?s <{prop}> <{class_uri}> }} {limit}"'.format(
+            class_uri=class_uri,
+            prop=instantiation_property,
+            limit="" if limit_remote_instances < 0 else "LIMIT " + str(limit_remote_instances)
+        )
+        # return '{' + 'FOCUS <{prop}> <{class_uri}>'.format(class_uri=class_uri, prop=instantiation_property) + '}'
+
+    def _get_node_selector_object_for_raw_selector(self, raw_selector):
+        return self._selector_parser.parse_node_selector(raw_selector=raw_selector)
+
+
```

### Comparing `shexer-2.5.1/shexer/utils/triple_yielders.py` & `shexer-2.5.2/shexer/utils/triple_yielders.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,76 +1,76 @@
-from shexer.model.IRI import IRI
-from shexer.model.property import Property
-from shexer.model.Literal import Literal
-from shexer.model.bnode import BNode
-from shexer.utils.uri import remove_corners, parse_literal, parse_unquoted_literal, FLOAT_TYPE, INTEGER_TYPE
-
-
-def check_if_property_belongs_to_namespace_list(str_prop, namespaces):
-    """
-    It return True if the property balongs to some namespace directly, i.e.,
-    without adding any hierarchical element before reaching the name of the property itself.
-    Example:
-    Property http:example.org/prop, namespace http:example.org/ ---> True
-    Property http:example.org/properties/prop, namespace http:example.org/ ---> False
-    :param str_prop:
-    :param namespaces:
-    :return:
-    """
-    for a_namespace in namespaces:
-        if str_prop.startswith(a_namespace):
-            if "/" not in str_prop[len(a_namespace):] and "#" not in str_prop[len(a_namespace):]:
-                return True
-    return False
-
-
-def tune_subj(a_token, raise_error_if_no_corners=True):
-    if a_token.startswith("<"):
-        return IRI(remove_corners(a_uri=a_token,
-                                  raise_error_if_no_corners=raise_error_if_no_corners))
-    elif a_token.startswith("_:"):
-        return BNode(identifier=a_token[2:])
-    elif a_token.strip() == "[]":
-        return BNode(identifier=a_token)
-
-    else:  # ???
-        raise ValueError("Unrecognized token in subject position: " + a_token)
-
-
-def tune_token(a_token, allow_untyped_numbers=False, raise_error_if_no_corners=True, base_namespace=None):
-    if a_token.startswith("<"):
-        return IRI(remove_corners(a_uri=a_token,
-                                  raise_error_if_no_corners=raise_error_if_no_corners))
-    elif a_token.startswith('"'):
-        content, elem_type = parse_literal(an_elem=a_token,
-                                           base_namespace=base_namespace)
-        return Literal(content=content,
-                       elem_type=elem_type)
-    elif a_token.startswith("_:"):
-        return BNode(identifier=a_token[2:])
-    elif a_token.strip() == "[]":
-        return BNode(identifier=a_token)
-    if allow_untyped_numbers:
-        try:
-            candidate_float = float(a_token)
-            if _is_integer(candidate_float):
-                return Literal(content=a_token.strip(),
-                               elem_type=INTEGER_TYPE)
-            return Literal(content=a_token.strip(),
-                           elem_type=FLOAT_TYPE)
-        except:
-            pass
-
-    content, elem_type = parse_unquoted_literal(a_token)
-    return Literal(content=content,
-                   elem_type=elem_type)
-
-
-def _is_integer(float_number):
-    if float_number % 1.0 == 0:
-        return True
-    return False
-
-
-def tune_prop(a_token, raise_error_if_no_corners=True):
-    return Property(remove_corners(a_uri=a_token,
-                                   raise_error_if_no_corners=raise_error_if_no_corners))
+from shexer.model.IRI import IRI
+from shexer.model.property import Property
+from shexer.model.Literal import Literal
+from shexer.model.bnode import BNode
+from shexer.utils.uri import remove_corners, parse_literal, parse_unquoted_literal, FLOAT_TYPE, INTEGER_TYPE
+
+
+def check_if_property_belongs_to_namespace_list(str_prop, namespaces):
+    """
+    It return True if the property balongs to some namespace directly, i.e.,
+    without adding any hierarchical element before reaching the name of the property itself.
+    Example:
+    Property http:example.org/prop, namespace http:example.org/ ---> True
+    Property http:example.org/properties/prop, namespace http:example.org/ ---> False
+    :param str_prop:
+    :param namespaces:
+    :return:
+    """
+    for a_namespace in namespaces:
+        if str_prop.startswith(a_namespace):
+            if "/" not in str_prop[len(a_namespace):] and "#" not in str_prop[len(a_namespace):]:
+                return True
+    return False
+
+
+def tune_subj(a_token, raise_error_if_no_corners=True):
+    if a_token.startswith("<"):
+        return IRI(remove_corners(a_uri=a_token,
+                                  raise_error_if_no_corners=raise_error_if_no_corners))
+    elif a_token.startswith("_:"):
+        return BNode(identifier=a_token[2:])
+    elif a_token.strip() == "[]":
+        return BNode(identifier=a_token)
+
+    else:  # ???
+        raise ValueError("Unrecognized token in subject position: " + a_token)
+
+
+def tune_token(a_token, allow_untyped_numbers=False, raise_error_if_no_corners=True, base_namespace=None):
+    if a_token.startswith("<"):
+        return IRI(remove_corners(a_uri=a_token,
+                                  raise_error_if_no_corners=raise_error_if_no_corners))
+    elif a_token.startswith('"'):
+        content, elem_type = parse_literal(an_elem=a_token,
+                                           base_namespace=base_namespace)
+        return Literal(content=content,
+                       elem_type=elem_type)
+    elif a_token.startswith("_:"):
+        return BNode(identifier=a_token[2:])
+    elif a_token.strip() == "[]":
+        return BNode(identifier=a_token)
+    if allow_untyped_numbers:
+        try:
+            candidate_float = float(a_token)
+            if _is_integer(candidate_float):
+                return Literal(content=a_token.strip(),
+                               elem_type=INTEGER_TYPE)
+            return Literal(content=a_token.strip(),
+                           elem_type=FLOAT_TYPE)
+        except:
+            pass
+
+    content, elem_type = parse_unquoted_literal(a_token)
+    return Literal(content=content,
+                   elem_type=elem_type)
+
+
+def _is_integer(float_number):
+    if float_number % 1.0 == 0:
+        return True
+    return False
+
+
+def tune_prop(a_token, raise_error_if_no_corners=True):
+    return Property(remove_corners(a_uri=a_token,
+                                   raise_error_if_no_corners=raise_error_if_no_corners))
```

### Comparing `shexer-2.5.1/shexer/utils/uri.py` & `shexer-2.5.2/shexer/utils/uri.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,160 +1,160 @@
-
-XSD_NAMESPACE = "http://www.w3.org/2001/XMLSchema#"
-XSD_PREFIX = "xsd"
-
-RDF_SYNTAX_NAMESPACE = "http://www.w3.org/1999/02/22-rdf-syntax-ns#"
-RDF_PREFIX = "rdf"
-RDF_TYPE = "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"
-
-DT_NAMESPACE = "http://dbpedia.org/datatype/"
-DT_PREFIX = "dt"
-
-OPENGIS_NAMESPACE = "http://www.opengis.net/ont/geosparql#"
-OPENGIS_PREFIX = "geo"
-
-LANG_STRING_TYPE = "http://www.w3.org/1999/02/22-rdf-syntax-ns#langString"
-STRING_TYPE = "http://www.w3.org/2001/XMLSchema#string"
-FLOAT_TYPE = "http://www.w3.org/2001/XMLSchema#float"
-INTEGER_TYPE = "http://www.w3.org/2001/XMLSchema#integer"
-
-
-def _add_prefix(unprefixed_elem, prefix):
-    return prefix + ":" + unprefixed_elem
-
-
-def remove_corners(a_uri, raise_error_if_no_corners=True):
-    if a_uri.startswith("<") and a_uri.endswith(">"):
-        return a_uri[1:-1]
-    if raise_error_if_no_corners:
-        raise ValueError("Wrong parameter of function: '" + a_uri + "'")
-    else:
-        return a_uri
-
-
-def add_corners(a_uri):
-    return "<" + a_uri + ">"
-
-def add_corners_if_needed(a_uri):
-    if a_uri.startswith("<"):
-        return a_uri
-    return add_corners(a_uri)
-
-def longest_common_prefix(uri1, uri2):
-    """
-    It returns an str containing the longest possible common initial part of uri1 and uri2
-
-    :param uri1:
-    :param uri2:
-
-    :return:
-    """
-
-    if len(uri1) == 0 or len(uri2) == 0:
-        return ""
-    shortest = len(uri1) if len(uri1) < len(uri2) else len(uri2)
-    for i in range(shortest):
-        if uri1[i] != uri2[i]:
-            return uri1[:i]
-    return uri1[:shortest]
-
-def add_corners_if_it_is_an_uri(a_candidate_uri):
-    if a_candidate_uri.startswith("http://") or a_candidate_uri.startswith("https://"):  # TODO, check this!
-        return "<" + a_candidate_uri + ">"
-    return a_candidate_uri
-
-
-def decide_literal_type(a_literal, base_namespace=None):
-    if there_is_arroba_after_last_quotes(a_literal):
-        return LANG_STRING_TYPE
-    elif "\"^^" not in a_literal:
-        return STRING_TYPE
-    elif "xsd:" in a_literal:
-        return XSD_NAMESPACE + a_literal[a_literal.find("xsd:") + 4:]
-    elif "rdf:" in a_literal:
-        return RDF_SYNTAX_NAMESPACE + a_literal[a_literal.find("rdf:")+ 4:]
-    elif "dt:" in a_literal:
-        return DT_NAMESPACE + a_literal[a_literal.find("dt:")+ 3:]
-    elif "geo:" in a_literal:
-        return OPENGIS_NAMESPACE + a_literal[a_literal.find("geo:") + 4:]
-    elif XSD_NAMESPACE in a_literal or RDF_SYNTAX_NAMESPACE in a_literal \
-            or DT_NAMESPACE in a_literal or OPENGIS_NAMESPACE in a_literal:
-        return a_literal[a_literal.find("\"^^")+4:-1]
-    elif a_literal.strip().endswith(">"):
-        candidate_type = a_literal[a_literal.find("\"^^") + 4:-1]  # plain uri, no corners
-        if base_namespace is not None and not candidate_type.startswith("http"):
-            return base_namespace + candidate_type
-        return candidate_type
-    else:
-        raise RuntimeError("Unrecognized literal type:" + a_literal)
-
-
-def is_a_correct_uri(target_uri, prefix_namespace_dict):
-    """
-    TODO: Here I am assuming that there is no forbiden char ( " < > # % { } | \ ^ ~ [ ] ` )
-    :param target_uri:
-    :param prefix_namespace_dict:
-    :return:
-    """
-    if target_uri[0] == "<" and target_uri[-1] == ">":
-        return True
-    for a_prefix in prefix_namespace_dict:
-        if target_uri.startswith(a_prefix + ":"):
-            return True
-        return False
-
-
-def there_is_arroba_after_last_quotes(target_str):
-    if target_str.rfind("@") > target_str.rfind('"'):
-        return True
-    return False
-
-
-def parse_literal(an_elem, base_namespace=None):
-    content = an_elem[1:an_elem.find('"', 1)]
-    elem_type = decide_literal_type(a_literal=an_elem,
-                                    base_namespace=base_namespace)
-    return content, elem_type
-
-def parse_unquoted_literal(an_elem):
-    elem_type = decide_literal_type(an_elem)
-    return an_elem, elem_type
-
-
-def unprefixize_uri_if_possible(target_uri, prefix_namespaces_dict, include_corners=True):
-    for a_prefix in prefix_namespaces_dict:
-        if target_uri.startswith(a_prefix+":"):
-            result = target_uri.replace(a_prefix+":", prefix_namespaces_dict[a_prefix])
-            if include_corners:
-                result = add_corners(result)
-            return result
-    return target_uri
-
-def unprefixize_uri_mandatory(target_uri, prefix_namespaces_dict, include_corners=True):
-    for a_prefix in prefix_namespaces_dict:
-        if target_uri.startswith(a_prefix+":"):
-            result = target_uri.replace(a_prefix+":", prefix_namespaces_dict[a_prefix])
-            if include_corners:
-                result = add_corners(result)
-            return result
-    raise ValueError("Unrecognized prefix in the following element" + target_uri)
-
-
-def prefixize_uri_if_possible(target_uri, namespaces_prefix_dict, corners=True):
-    best_match = None
-    candidate_uri = remove_corners(target_uri) if corners else target_uri
-    for a_namespace in namespaces_prefix_dict:  # Prefixed element (all literals are prefixed elements)
-        if candidate_uri.startswith(a_namespace):
-            if "/" not in candidate_uri[len(a_namespace):] and \
-                "#" not in candidate_uri[len(a_namespace):]:
-                best_match = a_namespace
-                break
-            # if best_match is None or len(best_match) < len(a_namespace):
-            #     best_match = a_namespace
-
-    return target_uri if best_match is None else candidate_uri.replace(best_match, namespaces_prefix_dict[best_match] + ":")
-
-
-
-
-
-
+
+XSD_NAMESPACE = "http://www.w3.org/2001/XMLSchema#"
+XSD_PREFIX = "xsd"
+
+RDF_SYNTAX_NAMESPACE = "http://www.w3.org/1999/02/22-rdf-syntax-ns#"
+RDF_PREFIX = "rdf"
+RDF_TYPE = "http://www.w3.org/1999/02/22-rdf-syntax-ns#type"
+
+DT_NAMESPACE = "http://dbpedia.org/datatype/"
+DT_PREFIX = "dt"
+
+OPENGIS_NAMESPACE = "http://www.opengis.net/ont/geosparql#"
+OPENGIS_PREFIX = "geo"
+
+LANG_STRING_TYPE = "http://www.w3.org/1999/02/22-rdf-syntax-ns#langString"
+STRING_TYPE = "http://www.w3.org/2001/XMLSchema#string"
+FLOAT_TYPE = "http://www.w3.org/2001/XMLSchema#float"
+INTEGER_TYPE = "http://www.w3.org/2001/XMLSchema#integer"
+
+
+def _add_prefix(unprefixed_elem, prefix):
+    return prefix + ":" + unprefixed_elem
+
+
+def remove_corners(a_uri, raise_error_if_no_corners=True):
+    if a_uri.startswith("<") and a_uri.endswith(">"):
+        return a_uri[1:-1]
+    if raise_error_if_no_corners:
+        raise ValueError("Wrong parameter of function: '" + a_uri + "'")
+    else:
+        return a_uri
+
+
+def add_corners(a_uri):
+    return "<" + a_uri + ">"
+
+def add_corners_if_needed(a_uri):
+    if a_uri.startswith("<"):
+        return a_uri
+    return add_corners(a_uri)
+
+def longest_common_prefix(uri1, uri2):
+    """
+    It returns an str containing the longest possible common initial part of uri1 and uri2
+
+    :param uri1:
+    :param uri2:
+
+    :return:
+    """
+
+    if len(uri1) == 0 or len(uri2) == 0:
+        return ""
+    shortest = len(uri1) if len(uri1) < len(uri2) else len(uri2)
+    for i in range(shortest):
+        if uri1[i] != uri2[i]:
+            return uri1[:i]
+    return uri1[:shortest]
+
+def add_corners_if_it_is_an_uri(a_candidate_uri):
+    if a_candidate_uri.startswith("http://") or a_candidate_uri.startswith("https://"):  # TODO, check this!
+        return "<" + a_candidate_uri + ">"
+    return a_candidate_uri
+
+
+def decide_literal_type(a_literal, base_namespace=None):
+    if there_is_arroba_after_last_quotes(a_literal):
+        return LANG_STRING_TYPE
+    elif "\"^^" not in a_literal:
+        return STRING_TYPE
+    elif "xsd:" in a_literal:
+        return XSD_NAMESPACE + a_literal[a_literal.find("xsd:") + 4:]
+    elif "rdf:" in a_literal:
+        return RDF_SYNTAX_NAMESPACE + a_literal[a_literal.find("rdf:")+ 4:]
+    elif "dt:" in a_literal:
+        return DT_NAMESPACE + a_literal[a_literal.find("dt:")+ 3:]
+    elif "geo:" in a_literal:
+        return OPENGIS_NAMESPACE + a_literal[a_literal.find("geo:") + 4:]
+    elif XSD_NAMESPACE in a_literal or RDF_SYNTAX_NAMESPACE in a_literal \
+            or DT_NAMESPACE in a_literal or OPENGIS_NAMESPACE in a_literal:
+        return a_literal[a_literal.find("\"^^")+4:-1]
+    elif a_literal.strip().endswith(">"):
+        candidate_type = a_literal[a_literal.find("\"^^") + 4:-1]  # plain uri, no corners
+        if base_namespace is not None and not candidate_type.startswith("http"):
+            return base_namespace + candidate_type
+        return candidate_type
+    else:
+        raise RuntimeError("Unrecognized literal type:" + a_literal)
+
+
+def is_a_correct_uri(target_uri, prefix_namespace_dict):
+    """
+    TODO: Here I am assuming that there is no forbiden char ( " < > # % { } | \ ^ ~ [ ] ` )
+    :param target_uri:
+    :param prefix_namespace_dict:
+    :return:
+    """
+    if target_uri[0] == "<" and target_uri[-1] == ">":
+        return True
+    for a_prefix in prefix_namespace_dict:
+        if target_uri.startswith(a_prefix + ":"):
+            return True
+        return False
+
+
+def there_is_arroba_after_last_quotes(target_str):
+    if target_str.rfind("@") > target_str.rfind('"'):
+        return True
+    return False
+
+
+def parse_literal(an_elem, base_namespace=None):
+    content = an_elem[1:an_elem.find('"', 1)]
+    elem_type = decide_literal_type(a_literal=an_elem,
+                                    base_namespace=base_namespace)
+    return content, elem_type
+
+def parse_unquoted_literal(an_elem):
+    elem_type = decide_literal_type(an_elem)
+    return an_elem, elem_type
+
+
+def unprefixize_uri_if_possible(target_uri, prefix_namespaces_dict, include_corners=True):
+    for a_prefix in prefix_namespaces_dict:
+        if target_uri.startswith(a_prefix+":"):
+            result = target_uri.replace(a_prefix+":", prefix_namespaces_dict[a_prefix])
+            if include_corners:
+                result = add_corners(result)
+            return result
+    return target_uri
+
+def unprefixize_uri_mandatory(target_uri, prefix_namespaces_dict, include_corners=True):
+    for a_prefix in prefix_namespaces_dict:
+        if target_uri.startswith(a_prefix+":"):
+            result = target_uri.replace(a_prefix+":", prefix_namespaces_dict[a_prefix])
+            if include_corners:
+                result = add_corners(result)
+            return result
+    raise ValueError("Unrecognized prefix in the following element" + target_uri)
+
+
+def prefixize_uri_if_possible(target_uri, namespaces_prefix_dict, corners=True):
+    best_match = None
+    candidate_uri = remove_corners(target_uri) if corners else target_uri
+    for a_namespace in namespaces_prefix_dict:  # Prefixed element (all literals are prefixed elements)
+        if candidate_uri.startswith(a_namespace):
+            if "/" not in candidate_uri[len(a_namespace):] and \
+                "#" not in candidate_uri[len(a_namespace):]:
+                best_match = a_namespace
+                break
+            # if best_match is None or len(best_match) < len(a_namespace):
+            #     best_match = a_namespace
+
+    return target_uri if best_match is None else candidate_uri.replace(best_match, namespaces_prefix_dict[best_match] + ":")
+
+
+
+
+
+
```

### Comparing `shexer-2.5.1/shexer.egg-info/PKG-INFO` & `shexer-2.5.2/shexer.egg-info/PKG-INFO`

 * *Files 4% similar despite different names*

```diff
@@ -1,266 +1,260 @@
-Metadata-Version: 2.1
-Name: shexer
-Version: 2.5.1
-Summary: Automatic schema extraction for RDF graphs
-Home-page: https://github.com/DaniFdezAlvarez/shexer
-Download-URL: https://github.com/DaniFdezAlvarez/shexer/archive/2.5.1.tar.gz
-Author: Daniel Fernandez-Alvarez
-Author-email: danifdezalvarez@gmail.com
-Keywords: testing,shexer,shexerp3,rdf,shex,shacl,schema
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Classifier: Intended Audience :: Science/Research
-Classifier: Intended Audience :: Information Technology
-Classifier: Topic :: Software Development :: Libraries :: Python Modules
-Description-Content-Type: text/markdown
-License-File: LICENSE
-Requires-Dist: Flask
-Requires-Dist: Flask-Cors
-Requires-Dist: rdflib
-Requires-Dist: SPARQLWrapper
-Requires-Dist: wlighter
-Requires-Dist: plantuml
-
-# sheXer
-
-This library can be used to perform automatic extraction of shape expressions (ShEx) or Shapes Constraint Language (SHACL) for a target RDF grpah. Please, feel free to add an issue to this repository if you find any bug in sheXer or if you have a feature request.
-
-
-Language:
-
-[![Pyversions](https://img.shields.io/pypi/pyversions/shexer.svg)](https://pypi.python.org/pypi/shexer)
-
-## Citation
-
-Use this work in case you want to cite this software: [Automatic extraction of shapes using sheXer](https://doi.org/10.1016/j.knosys.2021.107975).
-
-If you want to read the paper but cannot access the full-content using the previous link, there is a [preprint available in Researchgate](https://www.researchgate.net/publication/357146819_Automatic_extraction_of_shapes_using_sheXer).
-
-
-However, please, be aware that this software capabilities' have evolved and improved since the publication of the mentioned paper.
-
-## Installation
-
-sheXer can be installed using pip:
-
-    $ pip install shexer
-	
-Iy you want to install sheXer by source, all its external dependencies are listed in the file requirements.txt. You can install them all as well using pip:
-
-    $ pip install -r requirements.txt
-
-sheXer includes a package to deploy a wer service exposing sheXer with a REST API. In case you are not interested in deploying this web service, you don't need to install any dependency related to Flask.
-
-
-## Features
-
-* **Process huge sources**. sheXer does not need to load the whole content of the graph in main memory at any time, so big graphs can be processed in average hardware. Currently this is available just for some input formats: n-triples (choose const.NT as for input_format), and turtle (choose const.TURTLE_ITER).
-
-* **Several ways to provide input data**, consisting of a target graph and some target shapes. Tha graph can be provided via raw string content, local/remote file(s), or tracking on the fly some triples from a SPARQL endpoint. There are defined interfaces in case you want to implement some other way to provide input information. 
-
-* **Several ways to select your target shapes**. You may want to generate shapes for each class in the graph or maybe just for some of them. You may want to generate a shape for some custom node agrupations. Or maybe you are extracting some shapes from a big grpah and you just want to explore the neighborhood of some seed nodes.  For custom node aggrupations sheXer supports ShEx's shape maps syntax, and it provides configuration params to target different classes or graph depths. 
-
-* **Valid ShEx and SHACL**. The produced shapes are compilant with the current specification of ShEx2 and SHACL.
-
-* **UML**. Ypu can also generate UML-like views of the extracted schemas.
-
-* **Threshold of tolerance**. The constraints inferred for each shape may not be compatible with every node associated to the shapes. With this threshold you can indicate the minimun percentage of nodes that should conform with a constraint c. If c does not reach the indicated ratio, its associated information will not appear in the final shape.
-
-* **Informative comments** (just for ShEx, by now). Each constraint inferred is associated to one or more comments. Those comments include different types of information, such as the ratio of nodes that actually conform with a given constraint. You can keep this informative comments or exclude them from the results.
-
-* **Sorted constraints** (just for ShEx, by now). For a given constraint, sheXer keeps the ratio of nodes that conform with it. This is used as a score of trustworthiness. The constraints in a shape are sorted w.r.t. this score.
-
-* **Literals recognition**. All kinds of typed literals are recognized and treated separately when inferring the constraints. In case a literal is not explicitly associated with a type in the original KG, xsd:string is used by default. By default, when sheXer finds an untyped literal it tries to infer its type when it is a number. Support to some other untyped literals, such as geolocated points, may be included in future releases.
-
-* **Shapes interlinkage**: sheXer is able to detect links between shapes when there is a link between two nodes and those nodes are used to extract some shape. When it detects triples linking a node that does not belong to any other shape, then it uses the macro IRI instead.
-
-* **Special treatment of rdf:type** (or the specified instantiation property). When the predicate of a triple is rdf:type, sheXer creates a constraint whose object is a value set containing a single element. This is the actual object of the original triple.
-
-* **Cardinality management**. Some of the triples of a given instance may fit in an infinite number of constraint triples with the same predicate and object but different cardinality. For example, if a given instance has a single label specified by rdfs:label, that makes it fit with infinite triple constraints with the schema {rdfs:label xsd:string C}, where C can be any cardinality that includes the posibility of a single occurrence: {1}, + , {1,2}, {1,3}, {1,4},... Currently, sheXer admints exact cardinalities ({2}, {3}..), kleene closure (\*), positive closure (+), and optional cardinality (?).
-
-* **Inverse paths**. sheXer can extract constraints related to incomming links. Shapes are usually described using contraints realted to outgoing links, i.d., triples in which the node is the subject. However, sheXer can extract also constraints where the node is the object.
-
-* **Configurable priority of cardinalities**. sheXer can be configured to prioritize the less specific cardinality or the most specific one if its trustworthiness score is high enough.
-
-* **Example serialization**. sheXer is able to produce outputs that include examples of instances among the input data matching each shape and/or examples of node constraints matching each constraint of each shape. Currently, this feature works only with ShEx outputs.
-
-* **All compliant mode**: You can produce shapes that conform with every instance using to extract them. This is done by using cadinalities \* or ? for every constraint extracted that does not conform with EVERY instance. You may prefer to avoid these cardinalities and keep constraints that may not conform with every instance, but include the most frequent features of the instances. Both settings are available in sheXer.
-
-* **Management of empty shapes**. You may get some shapes with no constraints, either because there where no isntances to explore or because the extracted features were not as common as requested with the threshold of tolerance. You can configure sheXer to automatically erase those shapes and every mention to them from the results. 
-
-* **Adaptation to Wikidata model**. sheXer includes configuration params to handle Wikidata's data model regarding qualifiers, so you can automatically extract the schema of qualifier nodes too. You can also produce content where each Wikidata ID is associated with  its label in comments, as sheXer is integrated with [wLighter](https://github.com/DaniFdezAlvarez/wLighter).
-
-
-## Experimental results
-
-In the folder [experiments](https://github.com/DaniFdezAlvarez/shexer/tree/develop/experiments), you can see some results of applying this tool over different graphs with different configurations.
-
-## Example code
-
-The following code takes the graph in _raw\_graph_ and extracts shapes for instances of the classes <http://example.org/Person> and <http://example.org/Gender>. The input file format in n-triples and the results are serialized in ShExC to the file shaper_example.shex.
-
-```python
-from shexer.shaper import Shaper
-from shexer.consts import NT, SHEXC, SHACL_TURTLE
-
-target_classes = [
-    "http://example.org/Person",
-    "http://example.org/Gender"
-]
-
-namespaces_dict = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
-                   "http://example.org/": "ex",
-                   "http://weso.es/shapes/": "",
-                   "http://www.w3.org/2001/XMLSchema#": "xsd"
-                   }
-
-raw_graph = """
-<http://example.org/sarah> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
-<http://example.org/sarah> <http://example.org/age> "30"^^<http://www.w3.org/2001/XMLSchema#int> .
-<http://example.org/sarah> <http://example.org/name> "Sarah" .
-<http://example.org/sarah> <http://example.org/gender> <http://example.org/Female> .
-<http://example.org/sarah> <http://example.org/occupation> <http://example.org/Doctor> .
-<http://example.org/sarah> <http://example.org/brother> <http://example.org/Jim> .
-
-<http://example.org/jim> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
-<http://example.org/jim> <http://example.org/age> "28"^^<http://www.w3.org/2001/XMLSchema#int> .
-<http://example.org/jim> <http://example.org/name> "Jimbo".
-<http://example.org/jim> <http://example.org/surname> "Mendes".
-<http://example.org/jim> <http://example.org/gender> <http://example.org/Male> .
-
-<http://example.org/Male> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Male> <http://www.w3.org/2000/01/rdf-schema#label> "Male" .
-<http://example.org/Female> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Female> <http://www.w3.org/2000/01/rdf-schema#label> "Female" .
-<http://example.org/Other> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
-<http://example.org/Other> <http://www.w3.org/2000/01/rdf-schema#label> "Other gender" .
-"""
-
-
-
-input_nt_file = "target_graph.nt"
-
-shaper = Shaper(target_classes=target_classes,
-                raw_graph=raw_graph,
-                input_format=NT,
-                namespaces_dict=namespaces_dict,  # Default: no prefixes
-                instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type")  # Default rdf:type
-
-output_file = "shaper_example.shex"
-
-shaper.shex_graph(output_file=output_file,
-                  acceptance_threshold=0.1)
-
-print("Done!")
-
-```
-
-By default, sheXer generates ShExC. If you want to produce SHACL, indicate it as a param in the shex_graph method as follows:
-
-```python
-# Use the same imports and param definition of the previous example code
-
-output_file = "shaper_example.ttl"
-
-shaper.shex_graph(output_file=output_file,
-                  acceptance_threshold=0.1,
-                  output_format=SHACL_TURTLE)
-
-print("Done!")
-
-```
-
-You can also find some examples of how to process Wikidata with sheXer in [this Jupyter notebook](https://github.com/DaniFdezAlvarez/shexer/blob/master/doc/shexer_wikidata_tutorial.ipynb).
-
-
-## The Class Shaper
-
-Most of the features provided by this software are reachable using the class Shaper. As it is shown in the previous example code, one must get an instance of Shaper with some params and execute a method to perform the schema extraction.
-
-### init
-The __init__ method of Shaper includes many params, being optional most of them. Don't panic due to the high number of params. You just need to focus on three main questions:
-
-* How are you going to provide the graph to the library? Via a raw string, a local file, a downloadable content, an SPARQL endpoint...
-* Which shapes do you want to extract? A group of target classes, every class in the graph, or custom node groupings specified with shape maps (in a string, in a file...)?
-* Do you want to configure some special feature to tune the extraction process? Priority to less specific constraints, all-compliant mode, disbale comments...
-
-You'll find a param in the __init__ of Shaper to provide the information in the way you want. Use it using a keyword when creating your instance of Shaper (as in the example code of this document) and just forget about the rest. Shaper has a default value for them all.
-
-The following list describes each param of the __init__ of Shaper:
-
-#### Params to define target shapes:
-You must indicate al least one way to identify target instances and the shapes that should be generated. Some of this params are compatible, some others are not. For example, sheXer do not allow to indicate target classes and to activate all-classes mode, as it is contradictory. However, you can provide a shape map to make custom node aggrupations and use all_classes mode too, so you obtain shapes for those groupings and for each class.
-
-* target_classes (default None): a list containing URIs (string) of the classes whose shape must be extracted. 
-* file_target_classes (default None): a path to a file containing the URIs of the classes whose shape must be extracted. 
-* all_classes_mode (default False): when it is set to True, you do not net to provide a list of target classes. sheXer will produce a shape for each class with at least one instance. 
-* shape_map_raw (default None): use it to provide custom groupings of nodes using a shape map as a raw string.
-* shape_map_file (default None): use it to provide a path to a local file containing custom groupings of nodes using a shape map.
-
-#### Params to provide the input
-You must provide at least an input: a file, a string, an endpoint, a remote graph... you may also want to tune some other aspects, such as the format of the input or namespace-prefix pairs to be used.
-
-
-* instances_file_input (default None): in case you have a separate file in which instantiation relations can be found, provide its path here. If you dont provide any value, the shaper will look for instances in the graph used as input.
-* graph_file_input (default None): a path to the file in which the target graph can be found.
-* graph_list_of_files_input (default None): in case your graph is separated in several files (all of them with the same format), provide a list of string paths to those files here.
-* raw_graph (default None): a simple raw string containing the target graph.
-* url_graph_input (default None): use it to provide a URL of some downloadable RDF content available online to be used as target graph.
-* list_of_url_input (default None): use it to provide several URLs of downloadable RDF content available online to be used as target graph.
-* url_endpoint (default None): it expects the URL of an SPARQL endpoint. Use it if you want to get some relevant triples form that endpoint instead of providing a whole RDF graph. In this case, the triples will be those ones whose subject is one of the nodes used to build the shapes (instances of a target class, result of a node selector in a shape map).
-* instances_cap (default -1): when this param is set to a positive value, sheXer will only use a maximun of instance_cap instances to get extract each shape. This may cause some lost of information, but if the sample of instances used is representative enough, your results won't be that different but you'll save main memory and execution time. 
-* depth_for_building_subgraph (default 1): use this param just in case you are working against a SPARQL endpoint. This integer indicates the max distance from any seed node to consider in order to track a subgraph from the endpoint. Please, remind that a high depth can cause a massive number of queries and have a high performance cost. 
-* track_classes_for_entities_at_last_depth_level (default True): use this param just in case you are working against a SPARQL endpoint. If it set to True, it makes a step further to the distance to the seed nodes indicated in the param depth. However, it will just look for triples related to typing, not the whole neighborhood of the nodes in the last level of depth.
-* limit_remote_instances *DEPRECATED* (default -1). Use this param if you are working against an endpoint using the param target_classes. If it is set to a positive number, sheXer will just get limit_remote_instances instances for each class from the endpoint (by adding LIMIT at the end of the sparql query). This is useful when working with big sources with tons on instances, causing too many or too heavy SPARQL queries to retrieve  all the content. NOTE: This parameter only affects computation consuming SPARQL endpoints. On the other hand, the parameter instances_cap works for any case, including SPARQL endpoints. Due to retrocompatibility reasons, limit_remote_instances still works, but it will be removed in future sheXer releases.
-* disable_endpoint_cache (default False). By default, if sheXer is told to consume triples from an endpoint, it will make some SPARQL queries and store the results in a local graph. If this parameter is set to True, sheXer won't save that content locally. This will help to reduce main memory usage, but will decrease the performance, as sheXer will need to make more SPARQL queries to the endpoint.
-* namespaces_dict (default None): dictionary in which the keys are namespaces and the values are their expected prefixes in the outputs. 
-* input_format (default "NT"): the format of the graph which is going to be computed. The default value is const.NT. IMPORTANT: currently, sheXer does not guess input format, so ensure you specify the format here in case you are not providing n-triples content. In case you provide a combined input (several files, several URLs...) they all should have the same format. If you work against an endpoit, then this param do not have any effect.
-* compression_mode (default None). Only when you are working with local files, if they are compressed, you do not need to uncompress to parse them. Currently supported formats are ZIP, GZ, and XZ. Set compression_format to "zip", "gz", or "xz" to work with such files. Each gz or xz file will be assumed to contain a single graph file. Each zip file will be assumed to be a directory containing one or more graph files. In case the zip contains several files, they will be all parsed and merged (they should have the same format, indicated with input_format). In every case, sheXer won't write any uncompressed content to your disk.
-
-#### Params to tune the shexing process
-
-All this parameters have a default value so you do not need to use any of them. But you can modify the schema extraction in many different ways.
-
-* instantiation_property (default rdf:type): full URI (no prefixes) of the property linking instances and classes (ex: P31 in Wikidata's ontology)
-* namespaces_to_ignore (default None): list of namespaces of properties used in the target graph which are going to be ignored. For example, if you set namespaces_to_ignore to \[http://example.org/\], every triple whose predicate belongs to that namespace will not be computed. It just excludes properties whose name is a direct child of the namespace. For example, triples with <http:/example.org/foo> will be ignored, but triples with <http://example.org/anotherLevel/foo> will be computed.
-* infer_numeric_types_for_untyped_literals (default False): when it is set to True, if the parser finds a triple whose object in a number untyped (something like 56 instead of "56"^^xsd:int), it will accept it and consider it an int if it has decimals or a float if it does not. If it is set to False, triples like that will raise a parsing error.
-* discard_useles_constraints_with_positive_closure (default True): if it is set to True, when two constraints have been extracted with identical property and object, and one of them has '+' cardinality while the other one has a specific number of occurrences (example: {1}, {2}...), if they both have the same rate of compliance among the instances, the constraint with the '+' cardinality is discarded.
-* all_instances_are_compliant_mode (default True): when set to True, every inferred constraint which is not valid for all the instances of the class associated to the shape, then the cardinality of that constraint is changed to '\*' or '?'. With this, every instance conforms to the shape associated with its class. When it is set to False, no cardinality is changed, so there may be instances that do not conform to the inferred shape.
-* keep_less_specific (default True): when it is set to True, for a group of constraints with the same property and object but different cardinality, the one with less specific cardinality ('+') will be preserved, and the rest of constraints used to provide info in comments. When it is set to False, the preserved constraint will be the one with an integer as cardinality and the highest rate of conformance with the instances of the class.
-* disable_or_statements (default True): when set to False, sheXer tries to infer constraints with the operator oneOf (|) in case there are constraints with the same property but different object. By default, sheXer groups those constraint in a isngle one having the less general object possible. For instance, when the objects are different shapes, it merges the constraints a single one whose object is IRI.
-* allow_redundant_or (default False): when this is set to True, the example described for the disable_or_statements behaves differently. Let's say we have a set of candidate constraints whose property is the same but whose object differs: one have IRI, and two other have different shape labels (:A and :B). Whith allow_redundant_or=False, sheXer generates a single constraint with IRI and moves the information about the rest of discarded constraints with more specific objects to comments. However, with allow_redundant_or=True, the constraint generated will have a node constraint with a disjunction such as IRI OR @A OR @B. From the point of view of validation, as IRI subsumes :A and :B, this has no effect. However, some user whose extracted shapes are used to generate further products find this feature useful.   
-* allow_opt_cardinality (default True). When all-compliant mode is active, if there is a constraint which does not conform with every isntance but its maximun cardinality for any instance is {1}, it uses the optional cardinality (?). When set to False, it uses Kleene closure instead.
-* disable_opt_cardinality (dafault False). When set to True, it prevents any constraint to have a higher cardinality higher than one, even if every instance has that cardinality. For example, a constraint such as *ex:alias xsd:string {3}* will be changed to *ex:alias xsd:string +*.
-* shape_qualifiers_mode (default False). When it is set to True, it assumes a data model similar to Wikidata's one, where entity nodes are linked with qualifiers (BNodes) instead of the actual object meant by the triple. It is used to produce legible shapes for those special BNodes.
-* namespaces_for_qualifier_props (default None). Provide here a list of namespace in which the indirect properties used to link an entity with a qualifier node can be found. A reasonable configuration for Wikidata is namespaces_for_qualifier_props = \["http://www.wikidata.org/prop/"\] .
-* inverse_paths (default False). When it is set to True, sheXer will produce constraints with inverse_paths too. This is, constraints referring to triples in which the target node acst as object. Direct and inverse paths will be sorted in the final results w.r.t. their trutsworthiness score.
-* detect_minimal_iri (default False). When it is set to True, each shape will be associated with a regex pattern. That pattern expresses the initial part of the IRI that is common to every isntance used to extract a given shape. This pattern is only serialized when it is a "worthy" one (long enough, not just "http://", etc.).
-
-
-#### Params to tune some features of the output
-Again, all these params have a default value and you don't need to worry about them unless you want to tune the output.
-
-* remove_empty_shapes (default: True). When set to True, the result does not contain any empty shape nor any mention to it. If a shape A has a constraint pointing to a shape B and B is empty, then the constraint is modified and the macro IRI is used instead of B.
-* disable_comments (dafault: False). When set to True, the results do not contain comments.
-* shapes_namespace (default: http://weso.es/shapes/). This property allows you to change the namespace in which the shape labels are created in case you do not want to use the default one. The prefix of this namespace will be the empty prefix unless the empty prefix is already being used by other namespace. In that case, sheXer looks for other preferred prefixes, or will generate a random one if any of the default ones is available. 
-* wikidata_annotation (default: False). This param can be used when the output will contain Wikidata IDs. Using the library [wLighter](https://github.com/DaniFdezAlvarez/wLighter), the ourput is annotated with comments that associate a given every Wikidata ID with its English label. 
-* instances_report_mode (default, const.RATIO_INSTANCES). With this parameter, you can configure how is the information about instances complying to each expression shown. By default, sheXer shows a percetage of instances. If you set this parameter to const.ABSOLUTE_INSTANCES, then the comments will contain the exact number of complying instances instead of the ratio. sheXer will write a comment next to the shape label so you can also know how many isntances were used to extract a shape. If you set the parameter to const.MIXED_INSTANCES, the comments will contain both relative and absolute information.
-* decimals (default: -1). With this parameter you can configure the numnber of decimals to be used when writing ratios in comments. A negative numnber means that ratios will be written using its top precission. If you set this parameter to a natural number (including 0), then such number will be the number of decimals used. sheXer will round (not truncate) the original ratio to that precission.
-* examples_mode (default: None). You can set this parameter to one of the values included in the '#EXAMPLES' section of shexer.consts. If you choose SHAPE_EXAMPLES, sheXer will write the URI of an instance matching each shape extracted as a comment next to the shape label. If you choose CONSTRAINT_EXAMPLES, sheXer will write a comment including an example of node constraint matching each triple constraint of each shape (each value is used by an instance example with the triple constraint's property). If you choose ALL_EXAMPLES, sheXer will do both things. When the value of this parameter is None, sheXer will not serialize examples in comments.
-
-
-### Method __shex\_graph__
-
-The method __shex\_graph__  of shexer triggers all the inference process and gives back a result. It receives several parameters, being optional some of them:
-
-* string_output (default False): when it is set to True, the method returns a string representation of the inferred shapes. It must be set to True iff output_file is None.
-* output_file (default None): it specifies the path of the file in which the inferred shapes will be written. It must have a value different to None iff string_output is False.
-* output_format (default "ShExC"): format in which the inferred shapes will be serialized. The values currently supported are const.SHEXC and const.SHACLE_TURTLE.
-* aceptance_threshold (default 0): Given a certain inferred constraint __c__ for a shape __s__, the ammount of instances which conform to this constraint (ignoring constraints with '\*' cardinality) should be at least __aceptance\_threshold__. If this does not happen, then __c__ will not be included in __s__.
-* verbose (dafault False): when it is set to True, the extraction process will print log messages through the standard output.
-* to_uml_path (default None). This parameter expects to receive a disk path. If you provide a value here, sheXer will generate a UML diagram containing the extracted scheme and will save it in the path indicated as a PNG image. WARNING: you should be connected to Internet in  order to make this work.
-
-
+Metadata-Version: 2.1
+Name: shexer
+Version: 2.5.2
+Summary: Automatic schema extraction for RDF graphs
+Home-page: https://github.com/DaniFdezAlvarez/shexer
+Download-URL: https://github.com/DaniFdezAlvarez/shexer/archive/2.5.2.tar.gz
+Author: Daniel Fernandez-Alvarez
+Author-email: danifdezalvarez@gmail.com
+Keywords: testing,shexer,shexerp3,rdf,shex,shacl,schema
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Intended Audience :: Science/Research
+Classifier: Intended Audience :: Information Technology
+Classifier: Topic :: Software Development :: Libraries :: Python Modules
+Description-Content-Type: text/markdown
+License-File: LICENSE
+
+# sheXer
+
+This library can be used to perform automatic extraction of shape expressions (ShEx) or Shapes Constraint Language (SHACL) for a target RDF grpah. Please, feel free to add an issue to this repository if you find any bug in sheXer or if you have a feature request.
+
+
+Language:
+
+[![Pyversions](https://img.shields.io/pypi/pyversions/shexer.svg)](https://pypi.python.org/pypi/shexer)
+
+## Citation
+
+Use this work in case you want to cite this software: [Automatic extraction of shapes using sheXer](https://doi.org/10.1016/j.knosys.2021.107975).
+
+If you want to read the paper but cannot access the full-content using the previous link, there is a [preprint available in Researchgate](https://www.researchgate.net/publication/357146819_Automatic_extraction_of_shapes_using_sheXer).
+
+
+However, please, be aware that this software capabilities' have evolved and improved since the publication of the mentioned paper.
+
+## Installation
+
+sheXer can be installed using pip:
+
+    $ pip install shexer
+	
+Iy you want to install sheXer by source, all its external dependencies are listed in the file requirements.txt. You can install them all as well using pip:
+
+    $ pip install -r requirements.txt
+
+sheXer includes a package to deploy a wer service exposing sheXer with a REST API. In case you are not interested in deploying this web service, you don't need to install any dependency related to Flask.
+
+
+## Features
+
+* **Process huge sources**. sheXer does not need to load the whole content of the graph in main memory at any time, so big graphs can be processed in average hardware. Currently this is available just for some input formats: n-triples (choose const.NT as for input_format), and turtle (choose const.TURTLE_ITER).
+
+* **Several ways to provide input data**, consisting of a target graph and some target shapes. Tha graph can be provided via raw string content, local/remote file(s), or tracking on the fly some triples from a SPARQL endpoint. There are defined interfaces in case you want to implement some other way to provide input information. 
+
+* **Several ways to select your target shapes**. You may want to generate shapes for each class in the graph or maybe just for some of them. You may want to generate a shape for some custom node agrupations. Or maybe you are extracting some shapes from a big grpah and you just want to explore the neighborhood of some seed nodes.  For custom node aggrupations sheXer supports ShEx's shape maps syntax, and it provides configuration params to target different classes or graph depths. 
+
+* **Valid ShEx and SHACL**. The produced shapes are compilant with the current specification of ShEx2 and SHACL.
+
+* **UML**. Ypu can also generate UML-like views of the extracted schemas.
+
+* **Threshold of tolerance**. The constraints inferred for each shape may not be compatible with every node associated to the shapes. With this threshold you can indicate the minimun percentage of nodes that should conform with a constraint c. If c does not reach the indicated ratio, its associated information will not appear in the final shape.
+
+* **Informative comments** (just for ShEx, by now). Each constraint inferred is associated to one or more comments. Those comments include different types of information, such as the ratio of nodes that actually conform with a given constraint. You can keep this informative comments or exclude them from the results.
+
+* **Sorted constraints** (just for ShEx, by now). For a given constraint, sheXer keeps the ratio of nodes that conform with it. This is used as a score of trustworthiness. The constraints in a shape are sorted w.r.t. this score.
+
+* **Literals recognition**. All kinds of typed literals are recognized and treated separately when inferring the constraints. In case a literal is not explicitly associated with a type in the original KG, xsd:string is used by default. By default, when sheXer finds an untyped literal it tries to infer its type when it is a number. Support to some other untyped literals, such as geolocated points, may be included in future releases.
+
+* **Shapes interlinkage**: sheXer is able to detect links between shapes when there is a link between two nodes and those nodes are used to extract some shape. When it detects triples linking a node that does not belong to any other shape, then it uses the macro IRI instead.
+
+* **Special treatment of rdf:type** (or the specified instantiation property). When the predicate of a triple is rdf:type, sheXer creates a constraint whose object is a value set containing a single element. This is the actual object of the original triple.
+
+* **Cardinality management**. Some of the triples of a given instance may fit in an infinite number of constraint triples with the same predicate and object but different cardinality. For example, if a given instance has a single label specified by rdfs:label, that makes it fit with infinite triple constraints with the schema {rdfs:label xsd:string C}, where C can be any cardinality that includes the posibility of a single occurrence: {1}, + , {1,2}, {1,3}, {1,4},... Currently, sheXer admints exact cardinalities ({2}, {3}..), kleene closure (\*), positive closure (+), and optional cardinality (?).
+
+* **Inverse paths**. sheXer can extract constraints related to incomming links. Shapes are usually described using contraints realted to outgoing links, i.d., triples in which the node is the subject. However, sheXer can extract also constraints where the node is the object.
+
+* **Configurable priority of cardinalities**. sheXer can be configured to prioritize the less specific cardinality or the most specific one if its trustworthiness score is high enough.
+
+* **Example serialization**. sheXer is able to produce outputs that include examples of instances among the input data matching each shape and/or examples of node constraints matching each constraint of each shape. Currently, this feature works only with ShEx outputs.
+
+* **All compliant mode**: You can produce shapes that conform with every instance using to extract them. This is done by using cadinalities \* or ? for every constraint extracted that does not conform with EVERY instance. You may prefer to avoid these cardinalities and keep constraints that may not conform with every instance, but include the most frequent features of the instances. Both settings are available in sheXer.
+
+* **Management of empty shapes**. You may get some shapes with no constraints, either because there where no isntances to explore or because the extracted features were not as common as requested with the threshold of tolerance. You can configure sheXer to automatically erase those shapes and every mention to them from the results. 
+
+* **Adaptation to Wikidata model**. sheXer includes configuration params to handle Wikidata's data model regarding qualifiers, so you can automatically extract the schema of qualifier nodes too. You can also produce content where each Wikidata ID is associated with  its label in comments, as sheXer is integrated with [wLighter](https://github.com/DaniFdezAlvarez/wLighter).
+
+
+## Experimental results
+
+In the folder [experiments](https://github.com/DaniFdezAlvarez/shexer/tree/develop/experiments), you can see some results of applying this tool over different graphs with different configurations.
+
+## Example code
+
+The following code takes the graph in _raw\_graph_ and extracts shapes for instances of the classes <http://example.org/Person> and <http://example.org/Gender>. The input file format in n-triples and the results are serialized in ShExC to the file shaper_example.shex.
+
+```python
+from shexer.shaper import Shaper
+from shexer.consts import NT, SHEXC, SHACL_TURTLE
+
+target_classes = [
+    "http://example.org/Person",
+    "http://example.org/Gender"
+]
+
+namespaces_dict = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
+                   "http://example.org/": "ex",
+                   "http://weso.es/shapes/": "",
+                   "http://www.w3.org/2001/XMLSchema#": "xsd"
+                   }
+
+raw_graph = """
+<http://example.org/sarah> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
+<http://example.org/sarah> <http://example.org/age> "30"^^<http://www.w3.org/2001/XMLSchema#int> .
+<http://example.org/sarah> <http://example.org/name> "Sarah" .
+<http://example.org/sarah> <http://example.org/gender> <http://example.org/Female> .
+<http://example.org/sarah> <http://example.org/occupation> <http://example.org/Doctor> .
+<http://example.org/sarah> <http://example.org/brother> <http://example.org/Jim> .
+
+<http://example.org/jim> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Person> .
+<http://example.org/jim> <http://example.org/age> "28"^^<http://www.w3.org/2001/XMLSchema#int> .
+<http://example.org/jim> <http://example.org/name> "Jimbo".
+<http://example.org/jim> <http://example.org/surname> "Mendes".
+<http://example.org/jim> <http://example.org/gender> <http://example.org/Male> .
+
+<http://example.org/Male> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Male> <http://www.w3.org/2000/01/rdf-schema#label> "Male" .
+<http://example.org/Female> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Female> <http://www.w3.org/2000/01/rdf-schema#label> "Female" .
+<http://example.org/Other> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://example.org/Gender> .
+<http://example.org/Other> <http://www.w3.org/2000/01/rdf-schema#label> "Other gender" .
+"""
+
+
+
+input_nt_file = "target_graph.nt"
+
+shaper = Shaper(target_classes=target_classes,
+                raw_graph=raw_graph,
+                input_format=NT,
+                namespaces_dict=namespaces_dict,  # Default: no prefixes
+                instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type")  # Default rdf:type
+
+output_file = "shaper_example.shex"
+
+shaper.shex_graph(output_file=output_file,
+                  acceptance_threshold=0.1)
+
+print("Done!")
+
+```
+
+By default, sheXer generates ShExC. If you want to produce SHACL, indicate it as a param in the shex_graph method as follows:
+
+```python
+# Use the same imports and param definition of the previous example code
+
+output_file = "shaper_example.ttl"
+
+shaper.shex_graph(output_file=output_file,
+                  acceptance_threshold=0.1,
+                  output_format=SHACL_TURTLE)
+
+print("Done!")
+
+```
+
+You can also find some examples of how to process Wikidata with sheXer in [this Jupyter notebook](https://github.com/DaniFdezAlvarez/shexer/blob/master/doc/shexer_wikidata_tutorial.ipynb).
+
+
+## The Class Shaper
+
+Most of the features provided by this software are reachable using the class Shaper. As it is shown in the previous example code, one must get an instance of Shaper with some params and execute a method to perform the schema extraction.
+
+### init
+The __init__ method of Shaper includes many params, being optional most of them. Don't panic due to the high number of params. You just need to focus on three main questions:
+
+* How are you going to provide the graph to the library? Via a raw string, a local file, a downloadable content, an SPARQL endpoint...
+* Which shapes do you want to extract? A group of target classes, every class in the graph, or custom node groupings specified with shape maps (in a string, in a file...)?
+* Do you want to configure some special feature to tune the extraction process? Priority to less specific constraints, all-compliant mode, disbale comments...
+
+You'll find a param in the __init__ of Shaper to provide the information in the way you want. Use it using a keyword when creating your instance of Shaper (as in the example code of this document) and just forget about the rest. Shaper has a default value for them all.
+
+The following list describes each param of the __init__ of Shaper:
+
+#### Params to define target shapes:
+You must indicate al least one way to identify target instances and the shapes that should be generated. Some of this params are compatible, some others are not. For example, sheXer do not allow to indicate target classes and to activate all-classes mode, as it is contradictory. However, you can provide a shape map to make custom node aggrupations and use all_classes mode too, so you obtain shapes for those groupings and for each class.
+
+* target_classes (default None): a list containing URIs (string) of the classes whose shape must be extracted. 
+* file_target_classes (default None): a path to a file containing the URIs of the classes whose shape must be extracted. 
+* all_classes_mode (default False): when it is set to True, you do not net to provide a list of target classes. sheXer will produce a shape for each class with at least one instance. 
+* shape_map_raw (default None): use it to provide custom groupings of nodes using a shape map as a raw string.
+* shape_map_file (default None): use it to provide a path to a local file containing custom groupings of nodes using a shape map.
+
+#### Params to provide the input
+You must provide at least an input: a file, a string, an endpoint, a remote graph... you may also want to tune some other aspects, such as the format of the input or namespace-prefix pairs to be used.
+
+
+* instances_file_input (default None): in case you have a separate file in which instantiation relations can be found, provide its path here. If you dont provide any value, the shaper will look for instances in the graph used as input.
+* graph_file_input (default None): a path to the file in which the target graph can be found.
+* graph_list_of_files_input (default None): in case your graph is separated in several files (all of them with the same format), provide a list of string paths to those files here.
+* raw_graph (default None): a simple raw string containing the target graph.
+* url_graph_input (default None): use it to provide a URL of some downloadable RDF content available online to be used as target graph.
+* list_of_url_input (default None): use it to provide several URLs of downloadable RDF content available online to be used as target graph.
+* url_endpoint (default None): it expects the URL of an SPARQL endpoint. Use it if you want to get some relevant triples form that endpoint instead of providing a whole RDF graph. In this case, the triples will be those ones whose subject is one of the nodes used to build the shapes (instances of a target class, result of a node selector in a shape map).
+* instances_cap (default -1): when this param is set to a positive value, sheXer will only use a maximun of instance_cap instances to get extract each shape. This may cause some lost of information, but if the sample of instances used is representative enough, your results won't be that different but you'll save main memory and execution time. 
+* depth_for_building_subgraph (default 1): use this param just in case you are working against a SPARQL endpoint. This integer indicates the max distance from any seed node to consider in order to track a subgraph from the endpoint. Please, remind that a high depth can cause a massive number of queries and have a high performance cost. 
+* track_classes_for_entities_at_last_depth_level (default True): use this param just in case you are working against a SPARQL endpoint. If it set to True, it makes a step further to the distance to the seed nodes indicated in the param depth. However, it will just look for triples related to typing, not the whole neighborhood of the nodes in the last level of depth.
+* limit_remote_instances *DEPRECATED* (default -1). Use this param if you are working against an endpoint using the param target_classes. If it is set to a positive number, sheXer will just get limit_remote_instances instances for each class from the endpoint (by adding LIMIT at the end of the sparql query). This is useful when working with big sources with tons on instances, causing too many or too heavy SPARQL queries to retrieve  all the content. NOTE: This parameter only affects computation consuming SPARQL endpoints. On the other hand, the parameter instances_cap works for any case, including SPARQL endpoints. Due to retrocompatibility reasons, limit_remote_instances still works, but it will be removed in future sheXer releases.
+* disable_endpoint_cache (default False). By default, if sheXer is told to consume triples from an endpoint, it will make some SPARQL queries and store the results in a local graph. If this parameter is set to True, sheXer won't save that content locally. This will help to reduce main memory usage, but will decrease the performance, as sheXer will need to make more SPARQL queries to the endpoint.
+* namespaces_dict (default None): dictionary in which the keys are namespaces and the values are their expected prefixes in the outputs. 
+* input_format (default "NT"): the format of the graph which is going to be computed. The default value is const.NT. IMPORTANT: currently, sheXer does not guess input format, so ensure you specify the format here in case you are not providing n-triples content. In case you provide a combined input (several files, several URLs...) they all should have the same format. If you work against an endpoit, then this param do not have any effect.
+* compression_mode (default None). Only when you are working with local files, if they are compressed, you do not need to uncompress to parse them. Currently supported formats are ZIP, GZ, and XZ. Set compression_format to "zip", "gz", or "xz" to work with such files. Each gz or xz file will be assumed to contain a single graph file. Each zip file will be assumed to be a directory containing one or more graph files. In case the zip contains several files, they will be all parsed and merged (they should have the same format, indicated with input_format). In every case, sheXer won't write any uncompressed content to your disk.
+
+#### Params to tune the shexing process
+
+All this parameters have a default value so you do not need to use any of them. But you can modify the schema extraction in many different ways.
+
+* instantiation_property (default rdf:type): full URI (no prefixes) of the property linking instances and classes (ex: P31 in Wikidata's ontology)
+* namespaces_to_ignore (default None): list of namespaces of properties used in the target graph which are going to be ignored. For example, if you set namespaces_to_ignore to \[http://example.org/\], every triple whose predicate belongs to that namespace will not be computed. It just excludes properties whose name is a direct child of the namespace. For example, triples with <http:/example.org/foo> will be ignored, but triples with <http://example.org/anotherLevel/foo> will be computed.
+* infer_numeric_types_for_untyped_literals (default False): when it is set to True, if the parser finds a triple whose object in a number untyped (something like 56 instead of "56"^^xsd:int), it will accept it and consider it an int if it has decimals or a float if it does not. If it is set to False, triples like that will raise a parsing error.
+* discard_useles_constraints_with_positive_closure (default True): if it is set to True, when two constraints have been extracted with identical property and object, and one of them has '+' cardinality while the other one has a specific number of occurrences (example: {1}, {2}...), if they both have the same rate of compliance among the instances, the constraint with the '+' cardinality is discarded.
+* all_instances_are_compliant_mode (default True): when set to True, every inferred constraint which is not valid for all the instances of the class associated to the shape, then the cardinality of that constraint is changed to '\*' or '?'. With this, every instance conforms to the shape associated with its class. When it is set to False, no cardinality is changed, so there may be instances that do not conform to the inferred shape.
+* keep_less_specific (default True): when it is set to True, for a group of constraints with the same property and object but different cardinality, the one with less specific cardinality ('+') will be preserved, and the rest of constraints used to provide info in comments. When it is set to False, the preserved constraint will be the one with an integer as cardinality and the highest rate of conformance with the instances of the class.
+* disable_or_statements (default True): when set to False, sheXer tries to infer constraints with the operator oneOf (|) in case there are constraints with the same property but different object. By default, sheXer groups those constraint in a isngle one having the less general object possible. For instance, when the objects are different shapes, it merges the constraints a single one whose object is IRI.
+* allow_redundant_or (default False): when this is set to True, the example described for the disable_or_statements behaves differently. Let's say we have a set of candidate constraints whose property is the same but whose object differs: one have IRI, and two other have different shape labels (:A and :B). Whith allow_redundant_or=False, sheXer generates a single constraint with IRI and moves the information about the rest of discarded constraints with more specific objects to comments. However, with allow_redundant_or=True, the constraint generated will have a node constraint with a disjunction such as IRI OR @A OR @B. From the point of view of validation, as IRI subsumes :A and :B, this has no effect. However, some user whose extracted shapes are used to generate further products find this feature useful.   
+* allow_opt_cardinality (default True). When all-compliant mode is active, if there is a constraint which does not conform with every isntance but its maximun cardinality for any instance is {1}, it uses the optional cardinality (?). When set to False, it uses Kleene closure instead.
+* disable_opt_cardinality (dafault False). When set to True, it prevents any constraint to have a higher cardinality higher than one, even if every instance has that cardinality. For example, a constraint such as *ex:alias xsd:string {3}* will be changed to *ex:alias xsd:string +*.
+* shape_qualifiers_mode (default False). When it is set to True, it assumes a data model similar to Wikidata's one, where entity nodes are linked with qualifiers (BNodes) instead of the actual object meant by the triple. It is used to produce legible shapes for those special BNodes.
+* namespaces_for_qualifier_props (default None). Provide here a list of namespace in which the indirect properties used to link an entity with a qualifier node can be found. A reasonable configuration for Wikidata is namespaces_for_qualifier_props = \["http://www.wikidata.org/prop/"\] .
+* inverse_paths (default False). When it is set to True, sheXer will produce constraints with inverse_paths too. This is, constraints referring to triples in which the target node acst as object. Direct and inverse paths will be sorted in the final results w.r.t. their trutsworthiness score.
+* detect_minimal_iri (default False). When it is set to True, each shape will be associated with a regex pattern. That pattern expresses the initial part of the IRI that is common to every isntance used to extract a given shape. This pattern is only serialized when it is a "worthy" one (long enough, not just "http://", etc.).
+
+
+#### Params to tune some features of the output
+Again, all these params have a default value and you don't need to worry about them unless you want to tune the output.
+
+* remove_empty_shapes (default: True). When set to True, the result does not contain any empty shape nor any mention to it. If a shape A has a constraint pointing to a shape B and B is empty, then the constraint is modified and the macro IRI is used instead of B.
+* disable_comments (dafault: False). When set to True, the results do not contain comments.
+* shapes_namespace (default: http://weso.es/shapes/). This property allows you to change the namespace in which the shape labels are created in case you do not want to use the default one. The prefix of this namespace will be the empty prefix unless the empty prefix is already being used by other namespace. In that case, sheXer looks for other preferred prefixes, or will generate a random one if any of the default ones is available. 
+* wikidata_annotation (default: False). This param can be used when the output will contain Wikidata IDs. Using the library [wLighter](https://github.com/DaniFdezAlvarez/wLighter), the ourput is annotated with comments that associate a given every Wikidata ID with its English label. 
+* instances_report_mode (default, const.RATIO_INSTANCES). With this parameter, you can configure how is the information about instances complying to each expression shown. By default, sheXer shows a percetage of instances. If you set this parameter to const.ABSOLUTE_INSTANCES, then the comments will contain the exact number of complying instances instead of the ratio. sheXer will write a comment next to the shape label so you can also know how many isntances were used to extract a shape. If you set the parameter to const.MIXED_INSTANCES, the comments will contain both relative and absolute information.
+* decimals (default: -1). With this parameter you can configure the numnber of decimals to be used when writing ratios in comments. A negative numnber means that ratios will be written using its top precission. If you set this parameter to a natural number (including 0), then such number will be the number of decimals used. sheXer will round (not truncate) the original ratio to that precission.
+* examples_mode (default: None). You can set this parameter to one of the values included in the '#EXAMPLES' section of shexer.consts. If you choose SHAPE_EXAMPLES, sheXer will write the URI of an instance matching each shape extracted as a comment next to the shape label. If you choose CONSTRAINT_EXAMPLES, sheXer will write a comment including an example of node constraint matching each triple constraint of each shape (each value is used by an instance example with the triple constraint's property). If you choose ALL_EXAMPLES, sheXer will do both things. When the value of this parameter is None, sheXer will not serialize examples in comments.
+
+
+### Method __shex\_graph__
+
+The method __shex\_graph__  of shexer triggers all the inference process and gives back a result. It receives several parameters, being optional some of them:
+
+* string_output (default False): when it is set to True, the method returns a string representation of the inferred shapes. It must be set to True iff output_file is None.
+* output_file (default None): it specifies the path of the file in which the inferred shapes will be written. It must have a value different to None iff string_output is False.
+* output_format (default "ShExC"): format in which the inferred shapes will be serialized. The values currently supported are const.SHEXC and const.SHACLE_TURTLE.
+* aceptance_threshold (default 0): Given a certain inferred constraint __c__ for a shape __s__, the ammount of instances which conform to this constraint (ignoring constraints with '\*' cardinality) should be at least __aceptance\_threshold__. If this does not happen, then __c__ will not be included in __s__.
+* verbose (dafault False): when it is set to True, the extraction process will print log messages through the standard output.
+* to_uml_path (default None). This parameter expects to receive a disk path. If you provide a value here, sheXer will generate a UML diagram containing the extracted scheme and will save it in the path indicated as a PNG image. WARNING: you should be connected to Internet in  order to make this work.
+
+
```

### Comparing `shexer-2.5.1/shexer.egg-info/SOURCES.txt` & `shexer-2.5.2/shexer.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,19 @@
 LICENSE
 README.md
 setup.cfg
 setup.py
+local_code/TEST_XZ_READING.py
+local_code/__init__.py
+local_code/beyza_test.py
+local_code/img_example.py
+local_code/split_non_split_thats_the_question.py
+local_code/tictactoe.py
+local_code/whatever.py
+local_code/yasunori_Test.py
 shexer/__init__.py
 shexer/consts.py
 shexer/shaper.py
 shexer.egg-info/PKG-INFO
 shexer.egg-info/SOURCES.txt
 shexer.egg-info/dependency_links.txt
 shexer.egg-info/requires.txt
```

### Comparing `shexer-2.5.1/test/t_utils.py` & `shexer-2.5.2/test/t_utils.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,318 +1,318 @@
-from rdflib import Graph
-from rdflib.compare import to_isomorphic, graph_diff
-import re
-from os.path import isfile, exists as file_exists
-from os import remove
-
-_BLANKS = re.compile("[ \t]+")
-_LINE_JUMPS = re.compile("\n+")
-
-_PREFIX = "PREFIX"
-_BEG_SHAPE = "{"
-_END_SHAPE = "}"
-_BEG_OR = "("
-_END_OR = ")"
-_OR = " OR "
-
-
-def get_namespaces_and_shapes_from_str(str_target, or_shapes=False):
-    if or_shapes:
-        return get_namespaces_and_shapes_from_str_with_or(str_target)
-    namespaces = []
-    shapes = {}
-    last_line = ""
-    current_shape = None
-
-    for a_line in str_target.split("\n"):
-        if a_line.startswith(_PREFIX):
-            namespaces.append(a_line)
-        elif a_line.startswith(_BEG_SHAPE):
-            current_shape = last_line
-            shapes[last_line] = []
-        elif a_line.startswith(_END_SHAPE):
-            current_shape = None
-        elif current_shape is not None:
-            shapes[current_shape].append(
-                a_line.replace(";", "").strip())  # Avoid trailing ";", that can be there or not
-
-        last_line = a_line  # Always execute
-
-    return namespaces, shapes
-
-
-def get_namespaces_and_shapes_from_str_with_or(str_target):
-    namespaces = []
-    shapes = {}
-    last_line = ""
-    current_shape = None
-
-    or_mode = False
-    current_or = None
-
-    for a_line in str_target.split("\n"):
-        a_line = a_line.strip()
-        if a_line.startswith(_PREFIX):
-            namespaces.append(a_line)
-        elif a_line.startswith(_BEG_SHAPE):
-            current_shape = last_line
-            shapes[last_line] = []
-        elif a_line.startswith(_END_SHAPE):
-            current_shape = None
-        elif a_line.startswith(_BEG_OR):
-            or_mode = True
-            current_or = ""
-        elif or_mode:
-            if not a_line.startswith(_END_OR):
-                current_or = current_or + a_line
-            else:
-                or_mode = False
-                shapes[current_shape].append(current_or)
-
-        elif current_shape is not None:
-            shapes[current_shape].append(
-                a_line.replace(";", "").strip())  # Avoid trailing ";", that can be there or not
-
-        last_line = a_line  # Always execute
-
-    return namespaces, shapes
-
-
-def unordered_lists_match(list1, list2):
-    return set(list1) == set(list2)
-
-
-def ordered_lists_match(list1, list2):
-    return list1 == list2
-
-
-def unordered_sets_match(sets1, sets2):
-    for a_set1 in sets1:
-        if a_set1 not in sets2:
-            return False
-    return True
-
-
-def ordered_sets_match(sets1, sets2):
-    if len(sets1) != len(sets2):
-        return False
-    for i in range(len(sets1)):
-        if sets1[i] != sets2[i]:
-            return False
-    return True
-
-
-def simple_and_or_str_constraints(
-        str_constraints):  # TODO Fix here. Receive a dict, not a list. check call to this method
-    simple_c = []
-    or_c = []
-    for a_c in str_constraints:
-        if _OR in a_c:
-            or_c.append(a_c)
-        else:
-            simple_c.append(a_c)
-    return simple_c, or_c
-
-
-def ordered_or_constraints_match(or_list_1, or_list_2):
-    if len(or_list_1) != len(or_list_2):
-        return False
-    for i in range(len(or_list_1)):
-        or_list_1[i] = set(or_list_1[i].split(_OR))
-        or_list_2[i] = set(or_list_2[i].split(_OR))
-    return ordered_sets_match(or_list_1, or_list_2)
-
-
-def unordered_or_constraints_match(or_list_1, or_list_2):
-    if len(or_list_1) != len(or_list_2):
-        return False
-
-    for i in range(len(or_list_1)):
-        or_list_1[i] = set(or_list_1[i].split("  "))
-        or_list_2[i] = set(or_list_2[i].split("  "))
-    return unordered_sets_match(or_list_1, or_list_2)
-
-
-def or_shapes_comparison(shapes1, shapes2, check_order):
-    for a_key_label in shapes1:
-        if a_key_label not in shapes2:
-            return False
-        simple_constraints1, or_constraints1 = simple_and_or_str_constraints(shapes1[a_key_label])
-        simple_constraints2, or_constraints2 = simple_and_or_str_constraints(shapes2[a_key_label])
-        if not check_order:
-            if not unordered_lists_match(simple_constraints1, simple_constraints2):
-                return False
-            if not unordered_or_constraints_match(or_constraints1, or_constraints2):
-                return False
-        else:
-            if not ordered_lists_match(simple_constraints1, simple_constraints2):
-                return False
-            if not ordered_or_constraints_match(or_constraints1, or_constraints2):
-                return False
-    return True
-
-
-def namespaces_match(names1, names2):
-    return unordered_lists_match(names1, names2)
-
-
-def unsorted_constraints_comparison(shapes1, shapes2):
-    for a_key_label in shapes1:
-        if a_key_label not in shapes2:
-            return False
-        if not unordered_lists_match(shapes1[a_key_label], shapes2[a_key_label]):
-            return False
-    return True
-
-
-def sorted_constraints_comparison(shapes1, shapes2):
-    for a_key_label in shapes1:
-        if a_key_label not in shapes2:
-            return False
-        if not ordered_lists_match(shapes1[a_key_label], shapes2[a_key_label]):
-            return False
-    return True
-
-
-def simple_constraints_comparison(shapes1, shapes2, check_order=False):
-    if not check_order:
-        return unsorted_constraints_comparison(shapes1, shapes2)
-    else:
-        return sorted_constraints_comparison(shapes1, shapes2)
-
-
-def shapes_match(shapes1, shapes2, or_shapes=False, check_order=False):
-    if len(shapes1) != len(shapes2):
-        return False
-    if or_shapes:
-        return or_shapes_comparison(shapes1, shapes2, check_order)
-    return simple_constraints_comparison(shapes1, shapes2, check_order)
-
-
-def complex_shape_comparison(str1, str2, or_shapes=False, check_order=False):
-    namespaces1, shapes1 = get_namespaces_and_shapes_from_str(str1, or_shapes)
-    namespaces2, shapes2 = get_namespaces_and_shapes_from_str(str2, or_shapes)
-
-    if not namespaces_match(namespaces1, namespaces2):
-        return False
-    return shapes_match(shapes1, shapes2, or_shapes, check_order)
-
-
-def normalize_str(str_target):
-    result = str_target.strip()
-    result = _BLANKS.sub(result, " ")
-    return _LINE_JUMPS.sub(result, "\n")
-
-
-def tunned_str_comparison(str1, str2, or_shapes=False, check_order=False):
-    if normalize_str(str1) == normalize_str(str2):
-        return True
-    else:
-        return complex_shape_comparison(str1, str2, or_shapes, check_order)
-
-
-def file_vs_str_tunned_comparison(file_path, str_target, or_shapes=False, check_order=False):
-    with open(file_path, "r") as in_stream:
-        content = in_stream.read()
-    return tunned_str_comparison(content, str_target, or_shapes, check_order)
-
-
-def file_vs_str_exact_comparison(file_path, target_str):
-    with open(file_path, "r") as in_stream:
-        return in_stream.read().strip() == target_str.strip()
-
-def filter_prefixes_str_shex(target_str):
-    result = []
-    lines = target_str.split("\n")
-    counter = 0
-    while len(lines) > counter:
-        if not lines[counter].startswith("PREFIX"):
-            break
-        counter += 1
-    return "\n".join(lines[counter:]).strip() if counter > 0 else target_str
-
-def file_vs_str_shex_exact_comparison_excluding_prefixes(file_path, str_target):
-    with open(file_path, "r") as in_stream:
-        target_file_content = filter_prefixes_str_shex(in_stream.read().strip())
-        target_str_content = filter_prefixes_str_shex(str_target.strip())
-
-        return target_file_content == target_str_content
-
-
-
-
-def file_vs_file_tunned_comparison(file_path1, file_path2, or_shapes=False):
-    with open(file_path1, "r") as in_stream:
-        content1 = in_stream.read()
-    with open(file_path2, "r") as in_stream:
-        content2 = in_stream.read()
-    return tunned_str_comparison(content1, content2, or_shapes)
-
-
-def number_of_shapes(target_str):
-    counter = 0
-    for a_line in target_str.split("\n"):
-        if a_line.startswith(_BEG_SHAPE):
-            counter += 1
-    return counter
-
-
-def shape_contains_constraint(target_str, shape, constraint):
-    constraint = constraint.replace(";", "").strip()
-    lines = target_str.split("\n")
-    seeking_mode = False
-    for i in range(len(lines)):
-        if seeking_mode:
-            if lines[i].replace(";", "").strip() == constraint:
-                return True
-            if lines[i].startswith(_END_SHAPE):
-                return False
-        if lines[i].startswith(_BEG_SHAPE) and shape == lines[i - 1].strip():
-            seeking_mode = True
-    return False
-
-
-def graph_comparison_rdflib(g1, g2):
-    iso1 = to_isomorphic(g1)
-    iso2 = to_isomorphic(g2)
-    both, in1, in2 = graph_diff(iso1, iso2)
-    return len(both) == len(g1) and len(in1) == 0 and len(in2) == 0
-
-
-def graph_comparison_file_vs_str(file_path, str_target, format="turtle"):
-    g1 = Graph()
-    g1.parse(data=str_target, format=format)
-
-    g2 = Graph()
-    g2.parse(source=file_path, format=format)
-
-    return graph_comparison_rdflib(g1, g2)
-
-
-def text_contains_lines(text, list_lines):
-    text = _BLANKS.sub(" ", text)
-    for a_line in list_lines:
-        a_line = _BLANKS.sub(" ", a_line)
-        if a_line not in text:
-            return False
-        return True
-
-
-def no_sharp_in_shepe_names(str_shapes):
-    _, shapes = get_namespaces_and_shapes_from_str(str_shapes, or_shapes=False)
-    for a_key_label in shapes:
-        if '#' in a_key_label:
-            return False
-    return True
-
-
-def check_file_exist(file_path):
-    if not isfile(file_path):
-        raise FileExistsError(f"The expected file was not found in disk: {file_path}")
-
-
-def delete_file(file_path):
-    if file_exists(file_path):
-        try:
-            remove(file_path)
-        except:
-            pass
+from rdflib import Graph
+from rdflib.compare import to_isomorphic, graph_diff
+import re
+from os.path import isfile, exists as file_exists
+from os import remove
+
+_BLANKS = re.compile("[ \t]+")
+_LINE_JUMPS = re.compile("\n+")
+
+_PREFIX = "PREFIX"
+_BEG_SHAPE = "{"
+_END_SHAPE = "}"
+_BEG_OR = "("
+_END_OR = ")"
+_OR = " OR "
+
+
+def get_namespaces_and_shapes_from_str(str_target, or_shapes=False):
+    if or_shapes:
+        return get_namespaces_and_shapes_from_str_with_or(str_target)
+    namespaces = []
+    shapes = {}
+    last_line = ""
+    current_shape = None
+
+    for a_line in str_target.split("\n"):
+        if a_line.startswith(_PREFIX):
+            namespaces.append(a_line)
+        elif a_line.startswith(_BEG_SHAPE):
+            current_shape = last_line
+            shapes[last_line] = []
+        elif a_line.startswith(_END_SHAPE):
+            current_shape = None
+        elif current_shape is not None:
+            shapes[current_shape].append(
+                a_line.replace(";", "").strip())  # Avoid trailing ";", that can be there or not
+
+        last_line = a_line  # Always execute
+
+    return namespaces, shapes
+
+
+def get_namespaces_and_shapes_from_str_with_or(str_target):
+    namespaces = []
+    shapes = {}
+    last_line = ""
+    current_shape = None
+
+    or_mode = False
+    current_or = None
+
+    for a_line in str_target.split("\n"):
+        a_line = a_line.strip()
+        if a_line.startswith(_PREFIX):
+            namespaces.append(a_line)
+        elif a_line.startswith(_BEG_SHAPE):
+            current_shape = last_line
+            shapes[last_line] = []
+        elif a_line.startswith(_END_SHAPE):
+            current_shape = None
+        elif a_line.startswith(_BEG_OR):
+            or_mode = True
+            current_or = ""
+        elif or_mode:
+            if not a_line.startswith(_END_OR):
+                current_or = current_or + a_line
+            else:
+                or_mode = False
+                shapes[current_shape].append(current_or)
+
+        elif current_shape is not None:
+            shapes[current_shape].append(
+                a_line.replace(";", "").strip())  # Avoid trailing ";", that can be there or not
+
+        last_line = a_line  # Always execute
+
+    return namespaces, shapes
+
+
+def unordered_lists_match(list1, list2):
+    return set(list1) == set(list2)
+
+
+def ordered_lists_match(list1, list2):
+    return list1 == list2
+
+
+def unordered_sets_match(sets1, sets2):
+    for a_set1 in sets1:
+        if a_set1 not in sets2:
+            return False
+    return True
+
+
+def ordered_sets_match(sets1, sets2):
+    if len(sets1) != len(sets2):
+        return False
+    for i in range(len(sets1)):
+        if sets1[i] != sets2[i]:
+            return False
+    return True
+
+
+def simple_and_or_str_constraints(
+        str_constraints):  # TODO Fix here. Receive a dict, not a list. check call to this method
+    simple_c = []
+    or_c = []
+    for a_c in str_constraints:
+        if _OR in a_c:
+            or_c.append(a_c)
+        else:
+            simple_c.append(a_c)
+    return simple_c, or_c
+
+
+def ordered_or_constraints_match(or_list_1, or_list_2):
+    if len(or_list_1) != len(or_list_2):
+        return False
+    for i in range(len(or_list_1)):
+        or_list_1[i] = set(or_list_1[i].split(_OR))
+        or_list_2[i] = set(or_list_2[i].split(_OR))
+    return ordered_sets_match(or_list_1, or_list_2)
+
+
+def unordered_or_constraints_match(or_list_1, or_list_2):
+    if len(or_list_1) != len(or_list_2):
+        return False
+
+    for i in range(len(or_list_1)):
+        or_list_1[i] = set(or_list_1[i].split("  "))
+        or_list_2[i] = set(or_list_2[i].split("  "))
+    return unordered_sets_match(or_list_1, or_list_2)
+
+
+def or_shapes_comparison(shapes1, shapes2, check_order):
+    for a_key_label in shapes1:
+        if a_key_label not in shapes2:
+            return False
+        simple_constraints1, or_constraints1 = simple_and_or_str_constraints(shapes1[a_key_label])
+        simple_constraints2, or_constraints2 = simple_and_or_str_constraints(shapes2[a_key_label])
+        if not check_order:
+            if not unordered_lists_match(simple_constraints1, simple_constraints2):
+                return False
+            if not unordered_or_constraints_match(or_constraints1, or_constraints2):
+                return False
+        else:
+            if not ordered_lists_match(simple_constraints1, simple_constraints2):
+                return False
+            if not ordered_or_constraints_match(or_constraints1, or_constraints2):
+                return False
+    return True
+
+
+def namespaces_match(names1, names2):
+    return unordered_lists_match(names1, names2)
+
+
+def unsorted_constraints_comparison(shapes1, shapes2):
+    for a_key_label in shapes1:
+        if a_key_label not in shapes2:
+            return False
+        if not unordered_lists_match(shapes1[a_key_label], shapes2[a_key_label]):
+            return False
+    return True
+
+
+def sorted_constraints_comparison(shapes1, shapes2):
+    for a_key_label in shapes1:
+        if a_key_label not in shapes2:
+            return False
+        if not ordered_lists_match(shapes1[a_key_label], shapes2[a_key_label]):
+            return False
+    return True
+
+
+def simple_constraints_comparison(shapes1, shapes2, check_order=False):
+    if not check_order:
+        return unsorted_constraints_comparison(shapes1, shapes2)
+    else:
+        return sorted_constraints_comparison(shapes1, shapes2)
+
+
+def shapes_match(shapes1, shapes2, or_shapes=False, check_order=False):
+    if len(shapes1) != len(shapes2):
+        return False
+    if or_shapes:
+        return or_shapes_comparison(shapes1, shapes2, check_order)
+    return simple_constraints_comparison(shapes1, shapes2, check_order)
+
+
+def complex_shape_comparison(str1, str2, or_shapes=False, check_order=False):
+    namespaces1, shapes1 = get_namespaces_and_shapes_from_str(str1, or_shapes)
+    namespaces2, shapes2 = get_namespaces_and_shapes_from_str(str2, or_shapes)
+
+    if not namespaces_match(namespaces1, namespaces2):
+        return False
+    return shapes_match(shapes1, shapes2, or_shapes, check_order)
+
+
+def normalize_str(str_target):
+    result = str_target.strip()
+    result = _BLANKS.sub(result, " ")
+    return _LINE_JUMPS.sub(result, "\n")
+
+
+def tunned_str_comparison(str1, str2, or_shapes=False, check_order=False):
+    if normalize_str(str1) == normalize_str(str2):
+        return True
+    else:
+        return complex_shape_comparison(str1, str2, or_shapes, check_order)
+
+
+def file_vs_str_tunned_comparison(file_path, str_target, or_shapes=False, check_order=False):
+    with open(file_path, "r") as in_stream:
+        content = in_stream.read()
+    return tunned_str_comparison(content, str_target, or_shapes, check_order)
+
+
+def file_vs_str_exact_comparison(file_path, target_str):
+    with open(file_path, "r") as in_stream:
+        return in_stream.read().strip() == target_str.strip()
+
+def filter_prefixes_str_shex(target_str):
+    result = []
+    lines = target_str.split("\n")
+    counter = 0
+    while len(lines) > counter:
+        if not lines[counter].startswith("PREFIX"):
+            break
+        counter += 1
+    return "\n".join(lines[counter:]).strip() if counter > 0 else target_str
+
+def file_vs_str_shex_exact_comparison_excluding_prefixes(file_path, str_target):
+    with open(file_path, "r") as in_stream:
+        target_file_content = filter_prefixes_str_shex(in_stream.read().strip())
+        target_str_content = filter_prefixes_str_shex(str_target.strip())
+
+        return target_file_content == target_str_content
+
+
+
+
+def file_vs_file_tunned_comparison(file_path1, file_path2, or_shapes=False):
+    with open(file_path1, "r") as in_stream:
+        content1 = in_stream.read()
+    with open(file_path2, "r") as in_stream:
+        content2 = in_stream.read()
+    return tunned_str_comparison(content1, content2, or_shapes)
+
+
+def number_of_shapes(target_str):
+    counter = 0
+    for a_line in target_str.split("\n"):
+        if a_line.startswith(_BEG_SHAPE):
+            counter += 1
+    return counter
+
+
+def shape_contains_constraint(target_str, shape, constraint):
+    constraint = constraint.replace(";", "").strip()
+    lines = target_str.split("\n")
+    seeking_mode = False
+    for i in range(len(lines)):
+        if seeking_mode:
+            if lines[i].replace(";", "").strip() == constraint:
+                return True
+            if lines[i].startswith(_END_SHAPE):
+                return False
+        if lines[i].startswith(_BEG_SHAPE) and shape == lines[i - 1].strip():
+            seeking_mode = True
+    return False
+
+
+def graph_comparison_rdflib(g1, g2):
+    iso1 = to_isomorphic(g1)
+    iso2 = to_isomorphic(g2)
+    both, in1, in2 = graph_diff(iso1, iso2)
+    return len(both) == len(g1) and len(in1) == 0 and len(in2) == 0
+
+
+def graph_comparison_file_vs_str(file_path, str_target, format="turtle"):
+    g1 = Graph()
+    g1.parse(data=str_target, format=format)
+
+    g2 = Graph()
+    g2.parse(source=file_path, format=format)
+
+    return graph_comparison_rdflib(g1, g2)
+
+
+def text_contains_lines(text, list_lines):
+    text = _BLANKS.sub(" ", text)
+    for a_line in list_lines:
+        a_line = _BLANKS.sub(" ", a_line)
+        if a_line not in text:
+            return False
+        return True
+
+
+def no_sharp_in_shepe_names(str_shapes):
+    _, shapes = get_namespaces_and_shapes_from_str(str_shapes, or_shapes=False)
+    for a_key_label in shapes:
+        if '#' in a_key_label:
+            return False
+    return True
+
+
+def check_file_exist(file_path):
+    if not isfile(file_path):
+        raise FileExistsError(f"The expected file was not found in disk: {file_path}")
+
+
+def delete_file(file_path):
+    if file_exists(file_path):
+        try:
+            remove(file_path)
+        except:
+            pass
```

### Comparing `shexer-2.5.1/test/test_allow_opt_cardinality.py` & `shexer-2.5.2/test/test_allow_opt_cardinality.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,35 +1,35 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "opt_cardinality" + pth.sep  # We just need something with another instantiation property
-
-
-class TestAllowOptCardinality(unittest.TestCase):
-
-    def test_opt_enabled(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "g4_opt_cardinality.ttl",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            allow_opt_cardinality=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g4_opt_enabled.shex",
-                                                      str_target=str_result))
-
-    def test_opt_disabled(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "g4_opt_cardinality.ttl",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            allow_opt_cardinality=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g4_opt_disabled.shex",
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "opt_cardinality" + pth.sep  # We just need something with another instantiation property
+
+
+class TestAllowOptCardinality(unittest.TestCase):
+
+    def test_opt_enabled(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "g4_opt_cardinality.ttl",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            allow_opt_cardinality=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g4_opt_enabled.shex",
+                                                      str_target=str_result))
+
+    def test_opt_disabled(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "g4_opt_cardinality.ttl",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            allow_opt_cardinality=False)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g4_opt_disabled.shex",
                                                       str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_allow_redundant_or.py` & `shexer-2.5.2/test/test_allow_redundant_or.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,65 +1,65 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "disable_or" + pth.sep
-
-class TestAllowRedundantOr(unittest.TestCase):
-
-    def test_or_enabled_choice_useful_IRI_redundant_disabled(self):
-        shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=True,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        disable_or_statements=False,
-                        allow_redundant_or=False)
-        str_result = shaper.shex_graph(string_output=True)
-        # In case the choice includes the IRI macro, then no OR should appear
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_disabled.shex",
-                                                      str_target=str_result,
-                                                      or_shapes=True))
-
-    def test_or_enabled_choice_useful_IRI_redundant_enabled(self):
-        shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=True,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        disable_or_statements=False,
-                        allow_redundant_or=True)
-        str_result = shaper.shex_graph(string_output=True)
-        # In case the choice includes the IRI macro, then no OR should appear
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "redundant_enabled_useful_IRI.shex",
-                                                      str_target=str_result,
-                                                      or_shapes=True))
-
-    def test_or_enabled_choice_expendable_IRI_redundant_enabled(self):
-        shaper = Shaper(graph_file_input=_BASE_DIR + "g_or_example_expandable_IRI.ttl",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=True,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        disable_or_statements=False,
-                        allow_redundant_or=True)
-        str_result = shaper.shex_graph(string_output=True)
-        # In case the choice includes the IRI macro, then no OR should appear
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_enabled.shex",  # IRI should not be included
-                                                      str_target=str_result,
-                                                      or_shapes=True))
-
-    def test_or_disabled_redundant_enabled(self):
-        try:
-            shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
-                            namespaces_dict=default_namespaces(),
-                            all_classes_mode=True,
-                            input_format=TURTLE,
-                            disable_comments=True,
-                            disable_or_statements=True,
-                            allow_redundant_or=True)
-            self.fail("This shouldn't execute, the configuration or_disabled + allow_redundant makes no sense")
-        except ValueError:
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "disable_or" + pth.sep
+
+class TestAllowRedundantOr(unittest.TestCase):
+
+    def test_or_enabled_choice_useful_IRI_redundant_disabled(self):
+        shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        disable_or_statements=False,
+                        allow_redundant_or=False)
+        str_result = shaper.shex_graph(string_output=True)
+        # In case the choice includes the IRI macro, then no OR should appear
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_disabled.shex",
+                                                      str_target=str_result,
+                                                      or_shapes=True))
+
+    def test_or_enabled_choice_useful_IRI_redundant_enabled(self):
+        shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        disable_or_statements=False,
+                        allow_redundant_or=True)
+        str_result = shaper.shex_graph(string_output=True)
+        # In case the choice includes the IRI macro, then no OR should appear
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "redundant_enabled_useful_IRI.shex",
+                                                      str_target=str_result,
+                                                      or_shapes=True))
+
+    def test_or_enabled_choice_expendable_IRI_redundant_enabled(self):
+        shaper = Shaper(graph_file_input=_BASE_DIR + "g_or_example_expandable_IRI.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        disable_or_statements=False,
+                        allow_redundant_or=True)
+        str_result = shaper.shex_graph(string_output=True)
+        # In case the choice includes the IRI macro, then no OR should appear
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_enabled.shex",  # IRI should not be included
+                                                      str_target=str_result,
+                                                      or_shapes=True))
+
+    def test_or_disabled_redundant_enabled(self):
+        try:
+            shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
+                            namespaces_dict=default_namespaces(),
+                            all_classes_mode=True,
+                            input_format=TURTLE,
+                            disable_comments=True,
+                            disable_or_statements=True,
+                            allow_redundant_or=True)
+            self.fail("This shouldn't execute, the configuration or_disabled + allow_redundant makes no sense")
+        except ValueError:
             pass
```

### Comparing `shexer-2.5.1/test/test_bugs/test_no_sharp_in_auto_shape_names.py` & `shexer-2.5.2/test/test_bugs/test_no_sharp_in_auto_shape_names.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,24 +1,24 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces
-from test.t_utils import no_sharp_in_shepe_names
-import os.path as pth
-
-from shexer.consts import TURTLE
-
-
-
-_BASE_DIR = BASE_FILES + "no_sharp" + pth.sep  # We just need something with another instantiation property
-
-
-class TestNoSharpInShapeNames(unittest.TestCase):
-
-    def test_all_classes_no_sharps(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "sharp_chances.ttl",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces
+from test.t_utils import no_sharp_in_shepe_names
+import os.path as pth
+
+from shexer.consts import TURTLE
+
+
+
+_BASE_DIR = BASE_FILES + "no_sharp" + pth.sep  # We just need something with another instantiation property
+
+
+class TestNoSharpInShapeNames(unittest.TestCase):
+
+    def test_all_classes_no_sharps(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "sharp_chances.ttl",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
         self.assertTrue(no_sharp_in_shepe_names(str_result))
```

### Comparing `shexer-2.5.1/test/test_bugs/test_no_sharp_nor_slash_due_to_prefixing.py` & `shexer-2.5.2/test/test_bugs/test_no_sharp_nor_slash_due_to_prefixing.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1_NT, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-
-from shexer.consts import TURTLE
-
-
-
-_BASE_DIR = BASE_FILES + "no_slash_prefixed" + pth.sep  # We just need something with another instantiation property
-
-
-class TestNoSharpNorSlashDueToPrefixing(unittest.TestCase):
-
-    def test_shorter_prefixes_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1_NT,
-            namespaces_dict={"http://example.org/": "ex",
-            "http://www.w3.org/XML/1998/": "xml",
-            "http://www.w3.org/1999/02/": "rdf",
-            "http://www.w3.org/2000/01#": "rdfs",
-            "http://www.w3.org/2001#": "xsd",
-            "http://xmlns.com/foaf/": "foaf"
-            },
-            all_classes_mode=True,
-            disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_no_prefix_except_shapes.shex",
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1_NT, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+
+from shexer.consts import TURTLE
+
+
+
+_BASE_DIR = BASE_FILES + "no_slash_prefixed" + pth.sep  # We just need something with another instantiation property
+
+
+class TestNoSharpNorSlashDueToPrefixing(unittest.TestCase):
+
+    def test_shorter_prefixes_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1_NT,
+            namespaces_dict={"http://example.org/": "ex",
+            "http://www.w3.org/XML/1998/": "xml",
+            "http://www.w3.org/1999/02/": "rdf",
+            "http://www.w3.org/2000/01#": "rdfs",
+            "http://www.w3.org/2001#": "xsd",
+            "http://xmlns.com/foaf/": "foaf"
+            },
+            all_classes_mode=True,
+            disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_no_prefix_except_shapes.shex",
                                                       str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_compression_mode.py` & `shexer-2.5.2/test/test_compression_mode.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,364 +1,364 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-
-from shexer.consts import TURTLE_ITER, GZ, ZIP, XZ, N3, TURTLE, RDF_XML, TSV_SPO, NT, JSON_LD
-
-
-
-_BASE_DIR = BASE_FILES + "compression" + pth.sep
-
-
-class TestCompressionMode(unittest.TestCase):
-
-    ######################### GZ
-
-    def test_ttl_iter_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.ttl.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_n3_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.n3.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=N3,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_json_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.json.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=JSON_LD,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_ttl_rdflib_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.ttl.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_xml_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.xml.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=RDF_XML,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_tsv_spo_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.tsv.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TSV_SPO,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_nt_gz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.nt.gz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=NT,
-            disable_comments=True,
-            compression_mode=GZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    ############# zip
-
-    def test_ttl_iter_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.ttl.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_n3_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.n3.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=N3,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_ttl_rdflib_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.ttl.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_xml_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.xml.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=RDF_XML,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_tsv_spo_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.tsv.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TSV_SPO,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_nt_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.nt.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=NT,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_json_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.json.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=JSON_LD,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-
-    ########################  xz
-
-    def test_ttl_iter_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.ttl.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_n3_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.n3.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=N3,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_json_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.json.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=JSON_LD,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_ttl_rdflib_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.ttl.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_xml_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.xml.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=RDF_XML,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_tsv_spo_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.tsv.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TSV_SPO,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_nt_xz(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t_graph_1.nt.xz",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=NT,
-            disable_comments=True,
-            compression_mode=XZ
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    ########################  Wrong params
-
-    def test_unknown_mode(self):
-        try:
-            shaper = Shaper(
-                graph_file_input=_BASE_DIR + "t_graph_1.json.zip",
-                namespaces_dict=default_namespaces(),
-                all_classes_mode=True,
-                input_format=JSON_LD,
-                disable_comments=True,
-                compression_mode="RAR"
-            )
-            self.fail("It shouldn`t allow to use an unknown compression format")
-        except ValueError:
-            pass  # thats ok
-        except:
-            self.fail("The exception should be a ValueError")
-
-    def test_remote_source(self):
-        shape_map_raw = "SPARQL'select ?p where " \
-                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-                        "LIMIT 1'@<Flag>"
-        try:
-            shaper = Shaper(shape_map_raw=shape_map_raw,
-                            url_endpoint="https://query.wikidata.org/sparql",
-                            namespaces_dict=default_namespaces(),
-                            instantiation_property="http://www.wikidata.org/prop/direct/P31",
-                            disable_comments=True,
-                            depth_for_building_subgraph=1,
-                            track_classes_for_entities_at_last_depth_level=False,
-                            all_classes_mode=False,
-                            compression_mode=ZIP)
-            self.fail("It should allow to use compression with a remote source")
-        except ValueError:
-            pass
-        except:
-            self.fail("The exception should be a ValueError")
-
-
-    ##################### SEVERAL FILES IN ZIP
-
-    def test_nt_zip(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR + "t1_graph_partials_1_2_3__3.nt.zip",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=NT,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    ##################### SEVERAL ZIPS
-
-    def test_nt_zip(self):
-        shaper = Shaper(
-            graph_list_of_files_input=[_BASE_DIR + "t1_graph_partials_1_2__3.nt.zip",
-                                       _BASE_DIR + "t1_graph_partials_3__3.nt.zip"],
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=NT,
-            disable_comments=True,
-            compression_mode=ZIP
-        )
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+
+from shexer.consts import TURTLE_ITER, GZ, ZIP, XZ, N3, TURTLE, RDF_XML, TSV_SPO, NT, JSON_LD
+
+
+
+_BASE_DIR = BASE_FILES + "compression" + pth.sep
+
+
+class TestCompressionMode(unittest.TestCase):
+
+    ######################### GZ
+
+    def test_ttl_iter_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.ttl.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_n3_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.n3.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=N3,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_json_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.json.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=JSON_LD,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_ttl_rdflib_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.ttl.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_xml_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.xml.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=RDF_XML,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_tsv_spo_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.tsv.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TSV_SPO,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_nt_gz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.nt.gz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=NT,
+            disable_comments=True,
+            compression_mode=GZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    ############# zip
+
+    def test_ttl_iter_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.ttl.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_n3_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.n3.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=N3,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_ttl_rdflib_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.ttl.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_xml_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.xml.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=RDF_XML,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_tsv_spo_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.tsv.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TSV_SPO,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_nt_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.nt.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=NT,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_json_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.json.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=JSON_LD,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+
+    ########################  xz
+
+    def test_ttl_iter_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.ttl.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_n3_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.n3.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=N3,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_json_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.json.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=JSON_LD,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_ttl_rdflib_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.ttl.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_xml_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.xml.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=RDF_XML,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_tsv_spo_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.tsv.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TSV_SPO,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_nt_xz(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t_graph_1.nt.xz",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=NT,
+            disable_comments=True,
+            compression_mode=XZ
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    ########################  Wrong params
+
+    def test_unknown_mode(self):
+        try:
+            shaper = Shaper(
+                graph_file_input=_BASE_DIR + "t_graph_1.json.zip",
+                namespaces_dict=default_namespaces(),
+                all_classes_mode=True,
+                input_format=JSON_LD,
+                disable_comments=True,
+                compression_mode="RAR"
+            )
+            self.fail("It shouldn`t allow to use an unknown compression format")
+        except ValueError:
+            pass  # thats ok
+        except:
+            self.fail("The exception should be a ValueError")
+
+    def test_remote_source(self):
+        shape_map_raw = "SPARQL'select ?p where " \
+                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+                        "LIMIT 1'@<Flag>"
+        try:
+            shaper = Shaper(shape_map_raw=shape_map_raw,
+                            url_endpoint="https://query.wikidata.org/sparql",
+                            namespaces_dict=default_namespaces(),
+                            instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                            disable_comments=True,
+                            depth_for_building_subgraph=1,
+                            track_classes_for_entities_at_last_depth_level=False,
+                            all_classes_mode=False,
+                            compression_mode=ZIP)
+            self.fail("It should allow to use compression with a remote source")
+        except ValueError:
+            pass
+        except:
+            self.fail("The exception should be a ValueError")
+
+
+    ##################### SEVERAL FILES IN ZIP
+
+    def test_nt_zip(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "t1_graph_partials_1_2_3__3.nt.zip",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=NT,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    ##################### SEVERAL ZIPS
+
+    def test_nt_zip(self):
+        shaper = Shaper(
+            graph_list_of_files_input=[_BASE_DIR + "t1_graph_partials_1_2__3.nt.zip",
+                                       _BASE_DIR + "t1_graph_partials_3__3.nt.zip"],
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=NT,
+            disable_comments=True,
+            compression_mode=ZIP
+        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_depth_for_building_subgraph.py` & `shexer-2.5.2/test/test_depth_for_building_subgraph.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,90 +1,90 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import default_namespaces
-from test.t_utils import number_of_shapes, shape_contains_constraint
-
-
-class TestDepthBuildingSubGraph(unittest.TestCase):
-
-    """
-    These test cannot be too precise, since they are made against "live" content in Wikidata.
-    Also, two of them are commented, as they consume too much time to finish
-
-    """
-
-    def test_1_not_all_classes_format(self):
-        shape_map_raw = "SPARQL'select ?p where " \
-                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-                        "LIMIT 10'@<Flag>"
-        shaper = Shaper(shape_map_raw=shape_map_raw,
-                        url_endpoint="https://query.wikidata.org/sparql",
-                        namespaces_dict=default_namespaces(),
-                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
-                        disable_comments=True,
-                        depth_for_building_subgraph=1,
-                        track_classes_for_entities_at_last_depth_level=False,
-                        all_classes_mode=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) == 1)
-        self.assertTrue(shape_contains_constraint(target_str=str_result,
-                                                  shape="<Flag>",
-                                                  constraint="<http://www.wikidata.org/prop/direct/P31>  "
-                                                             "[<http://www.wikidata.org/entity/Q14660>]"))
-
-    def test_1_all_classes_format(self):
-        shape_map_raw = "SPARQL'select ?p where " \
-                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-                        "LIMIT 10'@<Flag>"
-        shaper = Shaper(shape_map_raw=shape_map_raw,
-                        url_endpoint="https://query.wikidata.org/sparql",
-                        namespaces_dict=default_namespaces(),
-                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
-                        disable_comments=True,
-                        depth_for_building_subgraph=1,
-                        track_classes_for_entities_at_last_depth_level=False,
-                        all_classes_mode=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) > 1)
-        self.assertTrue(number_of_shapes(str_result) < 10)
-        self.assertTrue(shape_contains_constraint(target_str=str_result,
-                                                  shape="<Flag>",
-                                                  constraint="<http://www.wikidata.org/prop/direct/P31>  "
-                                                             "[<http://www.wikidata.org/entity/Q14660>]"))
-
-    # def test_2_not_all_classes_format(self):
-    #     shape_map_raw = "SPARQL'select ?p where " \
-    #                     "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-    #                     "LIMIT 10'@<Flag>"
-    #     shaper = Shaper(shape_map_raw=shape_map_raw,
-    #                     url_endpoint="https://query.wikidata.org/sparql",
-    #                     namespaces_dict=default_namespaces(),
-    #                     instantiation_property="http://www.wikidata.org/prop/direct/P31",
-    #                     disable_comments=True,
-    #                     depth_for_building_subgraph=2,
-    #                     track_classes_for_entities_at_last_depth_level=False,
-    #                     all_classes_mode=False)
-    #     str_result = shaper.shex_graph(string_output=True)
-    #     self.assertTrue(number_of_shapes(str_result) == 1)
-    #     self.assertTrue(shape_contains_constraint(target_str=str_result,
-    #                                               shape="<Flag>",
-    #                                               constraint="<http://www.wikidata.org/prop/direct/P31>  "
-    #                                                          "[<http://www.wikidata.org/entity/Q14660>]"))
-    #
-    # def test_2_all_classes_format(self):
-    #     shape_map_raw = "SPARQL'select ?p where " \
-    #                     "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-    #                     "LIMIT 10'@<Flag>"
-    #     shaper = Shaper(shape_map_raw=shape_map_raw,
-    #                     url_endpoint="https://query.wikidata.org/sparql",
-    #                     namespaces_dict=default_namespaces(),
-    #                     instantiation_property="http://www.wikidata.org/prop/direct/P31",
-    #                     disable_comments=True,
-    #                     depth_for_building_subgraph=2,
-    #                     track_classes_for_entities_at_last_depth_level=False,
-    #                     all_classes_mode=True)
-    #     str_result = shaper.shex_graph(string_output=True)
-    #     self.assertTrue(number_of_shapes(str_result) > 10)
-    #     self.assertTrue(shape_contains_constraint(target_str=str_result,
-    #                                               shape="<Flag>",
-    #                                               constraint="<http://www.wikidata.org/prop/direct/P31>  "
+import unittest
+from shexer.shaper import Shaper
+from test.const import default_namespaces
+from test.t_utils import number_of_shapes, shape_contains_constraint
+
+
+class TestDepthBuildingSubGraph(unittest.TestCase):
+
+    """
+    These test cannot be too precise, since they are made against "live" content in Wikidata.
+    Also, two of them are commented, as they consume too much time to finish
+
+    """
+
+    def test_1_not_all_classes_format(self):
+        shape_map_raw = "SPARQL'select ?p where " \
+                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+                        "LIMIT 10'@<Flag>"
+        shaper = Shaper(shape_map_raw=shape_map_raw,
+                        url_endpoint="https://query.wikidata.org/sparql",
+                        namespaces_dict=default_namespaces(),
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        disable_comments=True,
+                        depth_for_building_subgraph=1,
+                        track_classes_for_entities_at_last_depth_level=False,
+                        all_classes_mode=False)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(number_of_shapes(str_result) == 1)
+        self.assertTrue(shape_contains_constraint(target_str=str_result,
+                                                  shape="<Flag>",
+                                                  constraint="<http://www.wikidata.org/prop/direct/P31>  "
+                                                             "[<http://www.wikidata.org/entity/Q14660>]"))
+
+    def test_1_all_classes_format(self):
+        shape_map_raw = "SPARQL'select ?p where " \
+                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+                        "LIMIT 10'@<Flag>"
+        shaper = Shaper(shape_map_raw=shape_map_raw,
+                        url_endpoint="https://query.wikidata.org/sparql",
+                        namespaces_dict=default_namespaces(),
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        disable_comments=True,
+                        depth_for_building_subgraph=1,
+                        track_classes_for_entities_at_last_depth_level=False,
+                        all_classes_mode=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(number_of_shapes(str_result) > 1)
+        self.assertTrue(number_of_shapes(str_result) < 10)
+        self.assertTrue(shape_contains_constraint(target_str=str_result,
+                                                  shape="<Flag>",
+                                                  constraint="<http://www.wikidata.org/prop/direct/P31>  "
+                                                             "[<http://www.wikidata.org/entity/Q14660>]"))
+
+    # def test_2_not_all_classes_format(self):
+    #     shape_map_raw = "SPARQL'select ?p where " \
+    #                     "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+    #                     "LIMIT 10'@<Flag>"
+    #     shaper = Shaper(shape_map_raw=shape_map_raw,
+    #                     url_endpoint="https://query.wikidata.org/sparql",
+    #                     namespaces_dict=default_namespaces(),
+    #                     instantiation_property="http://www.wikidata.org/prop/direct/P31",
+    #                     disable_comments=True,
+    #                     depth_for_building_subgraph=2,
+    #                     track_classes_for_entities_at_last_depth_level=False,
+    #                     all_classes_mode=False)
+    #     str_result = shaper.shex_graph(string_output=True)
+    #     self.assertTrue(number_of_shapes(str_result) == 1)
+    #     self.assertTrue(shape_contains_constraint(target_str=str_result,
+    #                                               shape="<Flag>",
+    #                                               constraint="<http://www.wikidata.org/prop/direct/P31>  "
+    #                                                          "[<http://www.wikidata.org/entity/Q14660>]"))
+    #
+    # def test_2_all_classes_format(self):
+    #     shape_map_raw = "SPARQL'select ?p where " \
+    #                     "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+    #                     "LIMIT 10'@<Flag>"
+    #     shaper = Shaper(shape_map_raw=shape_map_raw,
+    #                     url_endpoint="https://query.wikidata.org/sparql",
+    #                     namespaces_dict=default_namespaces(),
+    #                     instantiation_property="http://www.wikidata.org/prop/direct/P31",
+    #                     disable_comments=True,
+    #                     depth_for_building_subgraph=2,
+    #                     track_classes_for_entities_at_last_depth_level=False,
+    #                     all_classes_mode=True)
+    #     str_result = shaper.shex_graph(string_output=True)
+    #     self.assertTrue(number_of_shapes(str_result) > 10)
+    #     self.assertTrue(shape_contains_constraint(target_str=str_result,
+    #                                               shape="<Flag>",
+    #                                               constraint="<http://www.wikidata.org/prop/direct/P31>  "
     #                                                          "[<http://www.wikidata.org/entity/Q14660>]"))
```

### Comparing `shexer-2.5.1/test/test_disable_comments.py` & `shexer-2.5.2/test/test_disable_comments.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,30 +1,30 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_exact_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "disable_comments" + pth.sep
-
-class TestGraphFileInput(unittest.TestCase):
-
-    def test_disable(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g2.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g2_disable.shex"))
-
-    def test_enable(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g2.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g2_enable.shex"))
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces
+from test.t_utils import file_vs_str_exact_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "disable_comments" + pth.sep
+
+class TestGraphFileInput(unittest.TestCase):
+
+    def test_disable(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g2.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g2_disable.shex"))
+
+    def test_enable(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g2.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=False)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g2_enable.shex"))
```

### Comparing `shexer-2.5.1/test/test_discard_and_compliant.py` & `shexer-2.5.2/test/test_discard_and_compliant.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,66 +1,66 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "discard_and_compliant" + pth.sep
-
-class TestDiscardUselessConstraintsAndCompliantMode(unittest.TestCase):
-
-    def test_no_compilant_no_discard(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        discard_useless_constraints_with_positive_closure=False,
-                        all_instances_are_compliant_mode=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "no_compliant_no_discard.shex",
-                                                      str_target=str_result))
-
-    def test_compilant_no_discard(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        discard_useless_constraints_with_positive_closure=False,
-                        all_instances_are_compliant_mode=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "compliant_no_discard.shex",
-                                                      str_target=str_result))
-
-    def test_no_compilant_discard(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        discard_useless_constraints_with_positive_closure=True,
-                        all_instances_are_compliant_mode=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "no_compliant_discard.shex",
-                                                      str_target=str_result))
-
-    def test_compilant_discard(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        discard_useless_constraints_with_positive_closure=True,  # default value
-                        all_instances_are_compliant_mode=True)  # default value
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "discard_and_compliant" + pth.sep
+
+class TestDiscardUselessConstraintsAndCompliantMode(unittest.TestCase):
+
+    def test_no_compilant_no_discard(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        discard_useless_constraints_with_positive_closure=False,
+                        all_instances_are_compliant_mode=False)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "no_compliant_no_discard.shex",
+                                                      str_target=str_result))
+
+    def test_compilant_no_discard(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        discard_useless_constraints_with_positive_closure=False,
+                        all_instances_are_compliant_mode=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "compliant_no_discard.shex",
+                                                      str_target=str_result))
+
+    def test_no_compilant_discard(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        discard_useless_constraints_with_positive_closure=True,
+                        all_instances_are_compliant_mode=False)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "no_compliant_discard.shex",
+                                                      str_target=str_result))
+
+    def test_compilant_discard(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        discard_useless_constraints_with_positive_closure=True,  # default value
+                        all_instances_are_compliant_mode=True)  # default value
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
                                                       str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_file_target_classes.py` & `shexer-2.5.2/test/test_shacl/test_annotation.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,43 +1,44 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-
-_BASE_DIR = BASE_FILES + "target_classes" + pth.sep
-
-class TestFileTargetClasses(unittest.TestCase):
-
-    def test_one_target(self):
-        shaper = Shaper(file_target_classes=_BASE_DIR + "input_classes_one_target.tsv",
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "one_target.shex",
-                                                      str_target=str_result))
-
-
-    def test_several_targets(self):
-        shaper = Shaper(file_target_classes=_BASE_DIR + "input_classes_two_targets.tsv",
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "two_targets.shex",
-                                                      str_target=str_result))
-
-    # NOT SUPPORTED YET
-    #
-    def test_one_target_prefixed_targets(self):
-        shaper = Shaper(file_target_classes=_BASE_DIR + "input_classes_one_target_prefixed.tsv",  # Not written yet
-                        namespaces_dict={"http://xmlns.com/foaf/0.1/" : "foaf"},
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "one_target.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES
+from test.t_utils import graph_comparison_file_vs_str, text_contains_lines
+import os.path as pth
+from shexer.consts import SHACL_TURTLE
+
+_BASE_DIR = BASE_FILES + "wikidata_annotation" + pth.sep
+
+
+class TestAnnotation(unittest.TestCase):
+
+
+    def test_no_annotation(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "wiki_example.ttl",
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        input_format="turtle",
+                        disable_comments=True,
+                        )
+        str_result = shaper.shex_graph(string_output=True,
+                                       output_format=SHACL_TURTLE)
+        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "wiki_example_noanot_shacl.ttl",
+                                                     str_target=str_result))
+
+    def test_annotation(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "wiki_example.ttl",
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        input_format="turtle",
+                        disable_comments=True,
+                        wikidata_annotation=True
+                        )
+        str_result = shaper.shex_graph(string_output=True,
+                                       output_format=SHACL_TURTLE)
+        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "wiki_example_noanot_shacl.ttl",
+                                                     str_target=str_result))
+        self.assertTrue(text_contains_lines(text=str_result,
+                                            list_lines=[
+                                                "# P31  -->  instance of",
+                                                "# Q11689315  -->  hipopotams",
+                                                "# Q215627  -->  person",
+                                                "# Q5  -->  human"
+                                            ]))
```

### Comparing `shexer-2.5.1/test/test_graph_file_input.py` & `shexer-2.5.2/test/test_graph_file_input.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,34 +1,34 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, G1_NT, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "general" + pth.sep
-
-class TestGraphFileInput(unittest.TestCase):
-
-    def test_some_format(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-
-    def test_no_format(self):  # Should be nt
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, G1_NT, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "general" + pth.sep
+
+class TestGraphFileInput(unittest.TestCase):
+
+    def test_some_format(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+
+    def test_no_format(self):  # Should be nt
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_NT,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
                                                       str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_infer_numeric_types_for_untyped_literals.py` & `shexer-2.5.2/test/test_url_graph.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,36 +1,37 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import NT
-
-_BASE_DIR = BASE_FILES + "untyped_numbers" + pth.sep
-
-class TestInferNumericTypesForUntypedLiterals(unittest.TestCase):
-
-    def test_untyped_int(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=_BASE_DIR + "g1_untyped_age.nt",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        infer_numeric_types_for_untyped_literals=True,
-                        input_format=NT,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_untyped_int_and_float(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=_BASE_DIR + "g1_untyped_age.nt",  # TODO CHANGE THIS AND MORE
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        infer_numeric_types_for_untyped_literals=True,
-                        input_format=NT,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import NT, TURTLE
+
+_BASE_DIR = BASE_FILES + "general" + pth.sep
+
+class TestUrlGraphFormat(unittest.TestCase):
+
+    def test_ttl(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        url_graph_input="https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+
+    def test_nt(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        url_graph_input="https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.nt",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=NT,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+
```

### Comparing `shexer-2.5.1/test/test_input_format.py` & `shexer-2.5.2/test/test_input_format.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,154 +1,154 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, G1_JSON_LD, G1_NT, G1_TSVO_SPO, G1_XML, G1_N3, \
-    default_namespaces, G1_TTL_WITH_BASE, G1_TTL_WITH_USELESS_BNODE, G1_TTL_WITH_ABSOLUTES, \
-    G1_TTL_WITH_SCAPED_QUOTES
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import NT, TSV_SPO, RDF_XML, JSON_LD, N3, TURTLE, TURTLE_ITER
-
-_BASE_DIR = BASE_FILES + "general" + pth.sep
-
-class TestInputFormat(unittest.TestCase):
-
-    def test_ttl(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-
-    def test_nt(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-
-    def test_n3(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_N3,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=N3,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_tsv_spo(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_TSVO_SPO,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TSV_SPO,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_xml(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_XML,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=RDF_XML,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-
-    def test_json_ld(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_JSON_LD,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=JSON_LD,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_ttl_iter(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE_ITER,
-                        disable_comments=True,
-                        infer_numeric_types_for_untyped_literals=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_ttl_iter_with_base(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_TTL_WITH_BASE,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE_ITER,
-                        disable_comments=True,
-                        infer_numeric_types_for_untyped_literals=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-
-    def test_ttl_iter_with_bnode(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_TTL_WITH_USELESS_BNODE,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE_ITER,
-                        disable_comments=True,
-                        infer_numeric_types_for_untyped_literals=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_ttl_iter_with_absolute_IRIs(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_TTL_WITH_ABSOLUTES,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE_ITER,
-                        disable_comments=True,
-                        infer_numeric_types_for_untyped_literals=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_ttl_iter_with_scaped_quotes(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_TTL_WITH_SCAPED_QUOTES,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE_ITER,
-                        disable_comments=True,
-                        infer_numeric_types_for_untyped_literals=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, G1_JSON_LD, G1_NT, G1_TSVO_SPO, G1_XML, G1_N3, \
+    default_namespaces, G1_TTL_WITH_BASE, G1_TTL_WITH_USELESS_BNODE, G1_TTL_WITH_ABSOLUTES, \
+    G1_TTL_WITH_SCAPED_QUOTES
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import NT, TSV_SPO, RDF_XML, JSON_LD, N3, TURTLE, TURTLE_ITER
+
+_BASE_DIR = BASE_FILES + "general" + pth.sep
+
+class TestInputFormat(unittest.TestCase):
+
+    def test_ttl(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+
+    def test_nt(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_NT,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=NT,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+
+    def test_n3(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_N3,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=N3,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_tsv_spo(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_TSVO_SPO,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TSV_SPO,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_xml(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_XML,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=RDF_XML,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+
+    def test_json_ld(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_JSON_LD,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=JSON_LD,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_ttl_iter(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE_ITER,
+                        disable_comments=True,
+                        infer_numeric_types_for_untyped_literals=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_ttl_iter_with_base(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_TTL_WITH_BASE,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE_ITER,
+                        disable_comments=True,
+                        infer_numeric_types_for_untyped_literals=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+
+    def test_ttl_iter_with_bnode(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_TTL_WITH_USELESS_BNODE,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE_ITER,
+                        disable_comments=True,
+                        infer_numeric_types_for_untyped_literals=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_ttl_iter_with_absolute_IRIs(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_TTL_WITH_ABSOLUTES,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE_ITER,
+                        disable_comments=True,
+                        infer_numeric_types_for_untyped_literals=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_ttl_iter_with_scaped_quotes(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_TTL_WITH_SCAPED_QUOTES,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE_ITER,
+                        disable_comments=True,
+                        infer_numeric_types_for_untyped_literals=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
```

### Comparing `shexer-2.5.1/test/test_instances_cap.py` & `shexer-2.5.2/test/test_instances_cap.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,109 +1,109 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE_ITER
-
-
-_BASE_DIR = BASE_FILES + "instances_cap" + pth.sep
-
-
-class TestInstancesCap(unittest.TestCase):
-    """
-    We must use a deterministic input format, such as NT or TURTLE_ITER (something non rdflib-based)
-    to test this. Otherwhise, the instance(s) chosen for each test could be different in different
-    executions of the tests
-
-    """
-
-    def test_no_cap_all_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=-1)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_cap_1_all_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=1)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_cap_1.shex",
-                                                      str_target=str_result))
-
-    def test_cap_3_all_g1(self):  # exceeds one class limit (of instances), doest reach the other class limit
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=3)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_cap_3.shex",
-                                                      str_target=str_result))
-
-    def test_cap_5_all_g1(self):  # exceeds every class limit (of instances), doest reach the other class limit
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=5)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_cap_1_one_target_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=False,
-            target_classes=["foaf:Person"],
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=1)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "target_person_cap_1.shex",
-                                                      str_target=str_result))
-
-
-    def test_cap_5_one_target_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=False,
-            target_classes=["foaf:Person"],
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=5)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "target_person_cap_5.shex",
-                                                      str_target=str_result))
-
-    def test_cap_1_all_targets_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=False,
-            target_classes=["foaf:Person", "foaf:Document"],
-            input_format=TURTLE_ITER,
-            disable_comments=True,
-            instances_cap=1)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_cap_1.shex",
-                                                      str_target=str_result))
-
-
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE_ITER
+
+
+_BASE_DIR = BASE_FILES + "instances_cap" + pth.sep
+
+
+class TestInstancesCap(unittest.TestCase):
+    """
+    We must use a deterministic input format, such as NT or TURTLE_ITER (something non rdflib-based)
+    to test this. Otherwhise, the instance(s) chosen for each test could be different in different
+    executions of the tests
+
+    """
+
+    def test_no_cap_all_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=-1)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_cap_1_all_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=1)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_cap_1.shex",
+                                                      str_target=str_result))
+
+    def test_cap_3_all_g1(self):  # exceeds one class limit (of instances), doest reach the other class limit
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=3)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_cap_3.shex",
+                                                      str_target=str_result))
+
+    def test_cap_5_all_g1(self):  # exceeds every class limit (of instances), doest reach the other class limit
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=5)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_cap_1_one_target_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=False,
+            target_classes=["foaf:Person"],
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=1)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "target_person_cap_1.shex",
+                                                      str_target=str_result))
+
+
+    def test_cap_5_one_target_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=False,
+            target_classes=["foaf:Person"],
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=5)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "target_person_cap_5.shex",
+                                                      str_target=str_result))
+
+    def test_cap_1_all_targets_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=False,
+            target_classes=["foaf:Person", "foaf:Document"],
+            input_format=TURTLE_ITER,
+            disable_comments=True,
+            instances_cap=1)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_cap_1.shex",
+                                                      str_target=str_result))
+
+
+
```

### Comparing `shexer-2.5.1/test/test_instances_file_input.py` & `shexer-2.5.2/test/test_graph_list_of_file_inputs.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,60 +1,62 @@
-import unittest
-from shexer.shaper import Shaper
-from shexer.consts import NT
-from test.const import G1_NT, BASE_FILES, BASE_FILES_GENERAL, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-
-_BASE_DIR = BASE_FILES + "instances_file_input" + pth.sep
-
-class TestInstancesFileInput(unittest.TestCase):
-
-    def test_all_classes_all_instances(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True,
-                        instances_file_input=_BASE_DIR + "g1_all_instances.nt")
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_all_classes_some_instances(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True,
-                        instances_file_input=_BASE_DIR + "g1_some_instances.nt")
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "all_classes_some_instances.shex",
-                                                      str_target=str_result))
-
-    def test_some_classes_some_instances(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True,
-                        instances_file_input=_BASE_DIR + "g1_some_instances.nt")
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "some_classes_some_instances.shex",
-                                                      str_target=str_result))
-
-    def test_some_classes_all_instances(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True,
-                        instances_file_input=_BASE_DIR + "g1_all_instances.nt")
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "some_classes_all_instances.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, G1_NT, default_namespaces, BASE_FILES_GENERAL
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import NT, TURTLE
+
+_BASE_DIR = BASE_FILES + "graph_list_of_files_input" + pth.sep
+
+class TestGraphListOfFilesInput(unittest.TestCase):
+
+    def test_one_turtle(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_list_of_files_input=[G1],
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+
+    def test_one_nt(self):  # Should be nt
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_list_of_files_input=[G1_NT],
+                        namespaces_dict=default_namespaces(),
+                        input_format=NT,
+                        all_classes_mode=False,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_several_nt(self):  # Should be nt
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_list_of_files_input=[_BASE_DIR + "g1_p1.nt",
+                                                   _BASE_DIR + "g1_p2.nt"],
+                        namespaces_dict=default_namespaces(),
+                        input_format=NT,
+                        all_classes_mode=False,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+
+    def test_several_turtle(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_list_of_files_input=[_BASE_DIR + "g1_p1.ttl",
+                                                   _BASE_DIR + "g1_p2.ttl"],
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_instances_report.py` & `shexer-2.5.2/test/test_instances_report.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,73 +1,73 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_exact_comparison
-import os.path as pth
-from shexer.consts import TURTLE, MIXED_INSTANCES, ABSOLUTE_INSTANCES, RATIO_INSTANCES
-
-_BASE_DIR = BASE_FILES + "freq_reports" + pth.sep
-
-class TestGraphFileInput(unittest.TestCase):
-
-
-    def test_comments_disabled(self):
-        """
-        Even if a instances report mode is configured, with comments disabled there shouldnt be any
-        other content than the pure shape
-
-        :return:
-        """
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=True,
-                        instances_report_mode=ABSOLUTE_INSTANCES)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g_person_comments_disabled.shex"))
-
-    def test_ratio_mode(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=False,
-                        instances_report_mode=RATIO_INSTANCES)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g_person_every_decimal.shex"))
-
-    def test_absolute_mode(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=False,
-                        instances_report_mode=ABSOLUTE_INSTANCES)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g_person_absolute_instances.shex"))
-
-    def test_absolute_mode_unbound_dec(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=False,
-                        instances_report_mode=MIXED_INSTANCES)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g_person_mixed_unbound_dec.shex"))
-
-    def test_absolute_mode_2_dec(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=False,
-                        instances_report_mode=MIXED_INSTANCES,
-                        decimals=2)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
-                                                     file_path=_BASE_DIR + "g_person_mixed_2_dec.shex"))
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces
+from test.t_utils import file_vs_str_exact_comparison
+import os.path as pth
+from shexer.consts import TURTLE, MIXED_INSTANCES, ABSOLUTE_INSTANCES, RATIO_INSTANCES
+
+_BASE_DIR = BASE_FILES + "freq_reports" + pth.sep
+
+class TestGraphFileInput(unittest.TestCase):
+
+
+    def test_comments_disabled(self):
+        """
+        Even if a instances report mode is configured, with comments disabled there shouldnt be any
+        other content than the pure shape
+
+        :return:
+        """
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        instances_report_mode=ABSOLUTE_INSTANCES)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g_person_comments_disabled.shex"))
+
+    def test_ratio_mode(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=False,
+                        instances_report_mode=RATIO_INSTANCES)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g_person_every_decimal.shex"))
+
+    def test_absolute_mode(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=False,
+                        instances_report_mode=ABSOLUTE_INSTANCES)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g_person_absolute_instances.shex"))
+
+    def test_absolute_mode_unbound_dec(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=False,
+                        instances_report_mode=MIXED_INSTANCES)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g_person_mixed_unbound_dec.shex"))
+
+    def test_absolute_mode_2_dec(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "g_person_infinite_frequencies.ttl",
+                        namespaces_dict=default_namespaces(),
+                        input_format=TURTLE,
+                        disable_comments=False,
+                        instances_report_mode=MIXED_INSTANCES,
+                        decimals=2)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_exact_comparison(target_str=str_result,
+                                                     file_path=_BASE_DIR + "g_person_mixed_2_dec.shex"))
```

### Comparing `shexer-2.5.1/test/test_instantiation_property.py` & `shexer-2.5.2/test/test_instantiation_property.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,63 +1,63 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "instantiation_prop" + pth.sep
-
-class TestInstantiationProperty(unittest.TestCase):
-
-    def test_explicit_rdf_type(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_implicit_rdf_type(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        # instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_explicit_ex_a(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=_BASE_DIR + "G1_ex_a.ttl",
-                        instantiation_property="http://example.org/a",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "G1_ex_a.shex",
-                                                      str_target=str_result))
-
-    def test_explicit_ex_a_rdf_type_mixed(self):
-        # G1_ex_a_some_rdftype
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=_BASE_DIR + "G1_ex_a_some_rdftype.ttl",
-                        instantiation_property="http://example.org/a",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "G1_ex_a_some_rdftype.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "instantiation_prop" + pth.sep
+
+class TestInstantiationProperty(unittest.TestCase):
+
+    def test_explicit_rdf_type(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_implicit_rdf_type(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        # instantiation_property="http://www.w3.org/1999/02/22-rdf-syntax-ns#type",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_explicit_ex_a(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=_BASE_DIR + "G1_ex_a.ttl",
+                        instantiation_property="http://example.org/a",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "G1_ex_a.shex",
+                                                      str_target=str_result))
+
+    def test_explicit_ex_a_rdf_type_mixed(self):
+        # G1_ex_a_some_rdftype
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=_BASE_DIR + "G1_ex_a_some_rdftype.ttl",
+                        instantiation_property="http://example.org/a",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "G1_ex_a_some_rdftype.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_inverse_paths.py` & `shexer-2.5.2/test/test_inverse_paths.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,45 +1,45 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from test.t_utils import number_of_shapes
-
-from shexer.consts import TURTLE
-
-
-
-_BASE_DIR = BASE_FILES + "inverse_paths" + pth.sep  # We just need something with another instantiation property
-
-
-class TestInversePaths(unittest.TestCase):
-
-    def test_base_g1(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            inverse_paths=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_inverse.shex",
-                                                      str_target=str_result))
-
-    def test_remote_wikidata(self):
-        shape_map_raw = "SPARQL'select ?p where " \
-                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-                        "LIMIT 1'@<Flag>"
-        shaper = Shaper(shape_map_raw=shape_map_raw,
-                        url_endpoint="https://query.wikidata.org/sparql",
-                        namespaces_dict=default_namespaces(),
-                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
-                        disable_comments=True,
-                        depth_for_building_subgraph=1,
-                        track_classes_for_entities_at_last_depth_level=False,
-                        all_classes_mode=False,
-                        inverse_paths=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) == 1)
-        self.assertTrue("^  <http://schema.org/about>  IRI" in str_result)
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from test.t_utils import number_of_shapes
+
+from shexer.consts import TURTLE
+
+
+
+_BASE_DIR = BASE_FILES + "inverse_paths" + pth.sep  # We just need something with another instantiation property
+
+
+class TestInversePaths(unittest.TestCase):
+
+    def test_base_g1(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            inverse_paths=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_inverse.shex",
+                                                      str_target=str_result))
+
+    def test_remote_wikidata(self):
+        shape_map_raw = "SPARQL'select ?p where " \
+                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+                        "LIMIT 1'@<Flag>"
+        shaper = Shaper(shape_map_raw=shape_map_raw,
+                        url_endpoint="https://query.wikidata.org/sparql",
+                        namespaces_dict=default_namespaces(),
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        disable_comments=True,
+                        depth_for_building_subgraph=1,
+                        track_classes_for_entities_at_last_depth_level=False,
+                        all_classes_mode=False,
+                        inverse_paths=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(number_of_shapes(str_result) == 1)
+        self.assertTrue("^  <http://schema.org/about>  IRI" in str_result)
+
```

### Comparing `shexer-2.5.1/test/test_list_of_url_input.py` & `shexer-2.5.2/test/test_list_of_url_input.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,65 +1,65 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces, BASE_FILES_GENERAL
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import NT, TURTLE
-
-_BASE_DIR = BASE_FILES + "graph_list_of_files_input" + pth.sep
-
-
-class TestGraphListOfFilesInput(unittest.TestCase):
-
-    def test_one_turtle(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        list_of_url_input=[
-                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.ttl"],
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_one_nt(self):  # Should be nt
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        list_of_url_input=[
-                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.nt"],
-                        namespaces_dict=default_namespaces(),
-                        input_format=NT,
-                        all_classes_mode=False,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_several_nt(self):  # Should be nt
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        list_of_url_input=[
-                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p1.nt",
-                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p2.nt"],
-                        namespaces_dict=default_namespaces(),
-                        input_format=NT,
-                        all_classes_mode=False,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_several_turtle(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_list_of_files_input=[
-                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p1.ttl",
-                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p2.ttl"],
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces, BASE_FILES_GENERAL
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import NT, TURTLE
+
+_BASE_DIR = BASE_FILES + "graph_list_of_files_input" + pth.sep
+
+
+class TestGraphListOfFilesInput(unittest.TestCase):
+
+    def test_one_turtle(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        list_of_url_input=[
+                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.ttl"],
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_one_nt(self):  # Should be nt
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        list_of_url_input=[
+                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.nt"],
+                        namespaces_dict=default_namespaces(),
+                        input_format=NT,
+                        all_classes_mode=False,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_several_nt(self):  # Should be nt
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        list_of_url_input=[
+                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p1.nt",
+                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p2.nt"],
+                        namespaces_dict=default_namespaces(),
+                        input_format=NT,
+                        all_classes_mode=False,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
+
+    def test_several_turtle(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_list_of_files_input=[
+                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p1.ttl",
+                            "https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/graph_list_of_files_input/g1_p2.ttl"],
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=BASE_FILES_GENERAL + "g1_all_classes_no_comments.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_namespaces_dict.py` & `shexer-2.5.2/test/test_namespaces_dict.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,76 +1,76 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1_NT, G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE, NT
-
-_BASE_DIR = BASE_FILES + "namespaces_dict" + pth.sep
-
-class TestNamespacesDict(unittest.TestCase):
-
-    def test_same_namespaces_as_source_ttl_file(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_no_foaf(self):
-        namespaces = {"http://example.org/" : "ex",
-                               "http://www.w3.org/XML/1998/namespace/" : "xml",
-                               "http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
-                               "http://www.w3.org/2000/01/rdf-schema#" : "rdfs",
-                               "http://www.w3.org/2001/XMLSchema#": "xsd"
-                               # "http://xmlns.com/foaf/0.1/": "foaf"
-                               }
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1_NT,
-                        namespaces_dict=namespaces,
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + pth.sep +"no_foaf.shex",
-                                                      str_target=str_result))
-
-    def test_overwrite_empty(self):
-        namespaces = default_namespaces()
-        namespaces["http://unuseful.but.yet/here/"] = ""
-
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=namespaces,
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + pth.sep +"overwrite_empty.shex",
-                                                      str_target=str_result))
-
-    def test_overwrite_some_namespaces(self):
-        namespaces = {"http://example.org/": "ex",
-                      "http://www.w3.org/XML/1998/namespace/": "xml",
-                      "http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
-                      "http://www.w3.org/2000/01/rdf-schema#": "rdfs",
-                      "http://www.w3.org/2001/XMLSchema#": "xxssdd",
-                      "http://xmlns.com/foaf/0.1/": "fooo"
-                      }
-
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=namespaces,
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + pth.sep +"overwrite.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1_NT, G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE, NT
+
+_BASE_DIR = BASE_FILES + "namespaces_dict" + pth.sep
+
+class TestNamespacesDict(unittest.TestCase):
+
+    def test_same_namespaces_as_source_ttl_file(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_no_foaf(self):
+        namespaces = {"http://example.org/" : "ex",
+                               "http://www.w3.org/XML/1998/namespace/" : "xml",
+                               "http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
+                               "http://www.w3.org/2000/01/rdf-schema#" : "rdfs",
+                               "http://www.w3.org/2001/XMLSchema#": "xsd"
+                               # "http://xmlns.com/foaf/0.1/": "foaf"
+                               }
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1_NT,
+                        namespaces_dict=namespaces,
+                        all_classes_mode=False,
+                        input_format=NT,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + pth.sep +"no_foaf.shex",
+                                                      str_target=str_result))
+
+    def test_overwrite_empty(self):
+        namespaces = default_namespaces()
+        namespaces["http://unuseful.but.yet/here/"] = ""
+
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=namespaces,
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + pth.sep +"overwrite_empty.shex",
+                                                      str_target=str_result))
+
+    def test_overwrite_some_namespaces(self):
+        namespaces = {"http://example.org/": "ex",
+                      "http://www.w3.org/XML/1998/namespace/": "xml",
+                      "http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
+                      "http://www.w3.org/2000/01/rdf-schema#": "rdfs",
+                      "http://www.w3.org/2001/XMLSchema#": "xxssdd",
+                      "http://xmlns.com/foaf/0.1/": "fooo"
+                      }
+
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=namespaces,
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + pth.sep +"overwrite.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_namespaces_to_ignore.py` & `shexer-2.5.2/test/test_sort.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,41 +1,52 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "namespaces_to_ignore" + pth.sep
-
-class TestNamespacesToIgnore(unittest.TestCase):
-
-    def test_excluding_other(self):
-
-        namespaces = {key:value for key, value in default_namespaces().items()}
-
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=_BASE_DIR + "g1_namespaces.ttl",
-                        namespaces_dict=namespaces,
-                        namespaces_to_ignore=["http://other.org/"],
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_other_namespace.shex",
-                                                      str_target=str_result))
-
-    def test_excluding_direct_other(self):
-        namespaces = {key: value for key, value in default_namespaces().items()}
-
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=_BASE_DIR + "g1_namespaces_indirect.ttl",
-                        namespaces_dict=namespaces,
-                        namespaces_to_ignore=["http://other.org/"],
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_other_namespace_indirect.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE, SHAPES_DEFAULT_NAMESPACE
+
+_BASE_DIR = BASE_FILES + "sort" + pth.sep # We just need something with another instantiation property
+
+
+class TestSort(unittest.TestCase):
+
+    def test_outgoing_links(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "g_sort.ttl",
+            namespaces_dict=default_namespaces(),
+            target_classes=["foaf:Person"],
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace=SHAPES_DEFAULT_NAMESPACE)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g_sort.shex",
+                                                      str_target=str_result,
+                                                      check_order=True))
+
+    def test_incoming_links(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "g_sort_incoming.ttl",
+            namespaces_dict=default_namespaces(),
+            target_classes=["foaf:Person"],
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
+            inverse_paths=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g_sort_incoming.shex",
+                                                      str_target=str_result,
+                                                      check_order=True))
+
+    def test_mixed_links(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR + "g_sort_mixed.ttl",
+            namespaces_dict=default_namespaces(),
+            target_classes=["foaf:Person"],
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace=SHAPES_DEFAULT_NAMESPACE,
+            inverse_paths=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g_sort_mixed.shex",
+                                                      str_target=str_result,
+                                                      check_order=True))
```

### Comparing `shexer-2.5.1/test/test_rdflib_graph.py` & `shexer-2.5.2/test/test_infer_numeric_types_for_untyped_literals.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,41 +1,36 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from rdflib import Graph
-
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "general" + pth.sep
-
-class TestGraphFileInput(unittest.TestCase):
-
-    def test_parsing_file(self):
-        a_g = Graph()
-        a_g.parse(G1, format="turtle")
-
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        rdflib_graph=a_g,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
-    def test_all_classes_mode(self):
-        a_g = Graph()
-        a_g.parse(G1, format="turtle")
-
-        shaper = Shaper(all_classes_mode=True,
-                        rdflib_graph=a_g,
-                        namespaces_dict=default_namespaces(),
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments.shex",
-                                                      str_target=str_result))
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import NT
+
+_BASE_DIR = BASE_FILES + "untyped_numbers" + pth.sep
+
+class TestInferNumericTypesForUntypedLiterals(unittest.TestCase):
+
+    def test_untyped_int(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=_BASE_DIR + "g1_untyped_age.nt",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        infer_numeric_types_for_untyped_literals=True,
+                        input_format=NT,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_untyped_int_and_float(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=_BASE_DIR + "g1_untyped_age.nt",  # TODO CHANGE THIS AND MORE
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        infer_numeric_types_for_untyped_literals=True,
+                        input_format=NT,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_remove_empty_sahpes.py` & `shexer-2.5.2/test/test_threshold.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,57 +1,59 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison, number_of_shapes
-import os.path as pth
-
-_BASE_DIR = BASE_FILES + "empty_shapes" + pth.sep
-
-class TestRemoveEmptyShapes(unittest.TestCase):
-
-    def test_one_empty_remove(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Machine"],
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True,
-                        remove_empty_shapes=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) == 0)
-
-    def test_one_empty_not_remove(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Machine"],
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True,
-                        remove_empty_shapes=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "one_empty_not_remove.shex",
-                                                      str_target=str_result))
-
-
-    def test_some_empty_remove(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Machine",
-                                        "http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True,
-                        remove_empty_shapes=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_some_empty_not_remove(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Machine",
-                                        "http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        all_classes_mode=False,
-                        input_format="turtle",
-                        disable_comments=True,
-                        remove_empty_shapes=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "some_empty_not_remove.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, G1_ALL_CLASSES_NO_COMMENTS, default_namespaces
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "threshold" + pth.sep
+
+class TestGraphFileInput(unittest.TestCase):
+
+    def test_t_0(self):
+        shaper = Shaper(graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True,
+                                       acceptance_threshold=0)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+    def test_t_1(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True,
+                                       acceptance_threshold=1)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_t1.shex",
+                                                      str_target=str_result))
+
+    def test_t_05(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True,
+                                       acceptance_threshold=.5)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_t05.shex",
+                                                      str_target=str_result))
+
+    def test_t_051(self):
+        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
+                                        "http://xmlns.com/foaf/0.1/Document"],
+                        graph_file_input=G1,
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=False,
+                        input_format=TURTLE,
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True,
+                                       acceptance_threshold=.51)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_t051.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_shacl/test_class_selection.py` & `shexer-2.5.2/test/test_shapes_namespaces.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,50 +1,63 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces
-from test.t_utils import graph_comparison_file_vs_str
-import os.path as pth
-from shexer.consts import TURTLE, SHACL_TURTLE
-
-_BASE_DIR = BASE_FILES + "shacl" + pth.sep
-
-
-class TestClassSelection(unittest.TestCase):
-
-    def test_all_classes_mode(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "g1_all_classes.ttl",
-                                                     str_target=str_result))
-
-    def test_all_classes_with_target_classes(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=False,
-            target_classes=["http://xmlns.com/foaf/0.1/Person",
-                            "http://xmlns.com/foaf/0.1/Document"],
-            input_format=TURTLE,
-            disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "g1_all_classes.ttl",
-                                                     str_target=str_result))
-
-    def test_some_classes_with_target_classes(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=False,
-            target_classes=["http://xmlns.com/foaf/0.1/Person"],
-            input_format=TURTLE,
-            disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "g1_person.ttl",
-                                                     str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE, SHAPES_DEFAULT_NAMESPACE
+
+_BASE_DIR = BASE_FILES + "shapes_namespace" + pth.sep # We just need something with another instantiation property
+
+
+class TestShapesNamespaces(unittest.TestCase):
+
+    def test_default_namespace(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace=SHAPES_DEFAULT_NAMESPACE)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_different_namespace(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace="http://weso.es/DIfferentShapes#")
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "different_namespace.shex",
+                                                      str_target=str_result))
+
+    def test_empty_prefix_used(self):
+        namespaces = default_namespaces()
+        namespaces["http://unuseful.but.yet/here/"] = ""
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=namespaces,
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace=SHAPES_DEFAULT_NAMESPACE)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "empty_prefix_used.shex",
+                                                      str_target=str_result))
+
+    def test_empty_prefix_used_and_no_default(self):
+        namespaces = default_namespaces()
+        namespaces["http://unuseful.but.yet/here/"] = ""
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=namespaces,
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            shapes_namespace="http://weso.es/DIfferentShapes#")
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "empty_prefix_used_and_no_def.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_shacl/test_detect_minimal_iri.py` & `shexer-2.5.2/test/test_detect_minimal_iri.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,72 +1,80 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison, graph_comparison_file_vs_str
-import os.path as pth
-
-from shexer.consts import TURTLE, SHACL_TURTLE
-
-
-
-_BASE_DIR = BASE_FILES + "min_iri" + pth.sep  # We just need something with another instantiation property
-
-
-class TestDetectMinimalIri(unittest.TestCase):
-
-    def test_all_classes_g1_enabled(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            detect_minimal_iri=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "shacl_g1_all_classes_no_comments_min_iri.ttl",
-                                                     str_target=str_result))
-
-    def test_g1_different_namespaces_per_class(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR+"g1_different_namespaces_per_class.ttl",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            detect_minimal_iri=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "shacl_g1_different_namespaces_per_class.ttl",
-                                                     str_target=str_result))
-
-
-    def test_g1_different_namespaces_per_instance(self):
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR+"g1_different_namespaces_per_instance.ttl",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            detect_minimal_iri=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "shacl_g1_different_namespaces_per_instance.ttl",
-                                                     str_target=str_result))
-
-    def test_g1_different_base_per_instance_no_sep_char(self):
-        """
-        :Person should be [http://example.org/ns1/], not [http://example.org/ns1/aa]
-        :return:
-        """
-        shaper = Shaper(
-            graph_file_input=_BASE_DIR+"g1_different_base_per_instance_no_sep_char.ttl",
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            detect_minimal_iri=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "shacl_g1_different_namespaces_per_class.ttl",
-                                                     str_target=str_result))
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+
+from shexer.consts import TURTLE
+
+
+
+_BASE_DIR = BASE_FILES + "min_iri" + pth.sep  # We just need something with another instantiation property
+
+
+class TestDetectMinimalIri(unittest.TestCase):
+
+    def test_all_classes_g1_disabled(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            detect_minimal_iri=False)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
+                                                      str_target=str_result))
+
+    def test_all_classes_g1_enabled(self):
+        shaper = Shaper(
+            graph_file_input=G1,
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            detect_minimal_iri=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_all_classes_no_comments_min_iri.shex",
+                                                      str_target=str_result))
+
+    def test_g1_different_namespaces_per_class(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR+"g1_different_namespaces_per_class.ttl",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            detect_minimal_iri=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_different_namespaces_per_class.shex",
+                                                      str_target=str_result))
+
+
+    def test_g1_different_namespaces_per_instance(self):
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR+"g1_different_namespaces_per_instance.ttl",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            detect_minimal_iri=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_different_namespaces_per_instance.shex",
+                                                      str_target=str_result))
+
+    def test_g1_different_base_per_instance_no_sep_char(self):
+        """
+        :Person should be [http://example.org/ns1/], not [http://example.org/ns1/aa]
+        :return:
+        """
+        shaper = Shaper(
+            graph_file_input=_BASE_DIR+"g1_different_base_per_instance_no_sep_char.ttl",
+            namespaces_dict=default_namespaces(),
+            all_classes_mode=True,
+            input_format=TURTLE,
+            disable_comments=True,
+            detect_minimal_iri=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_different_namespaces_per_class.shex",
+                                                      str_target=str_result))
+
```

### Comparing `shexer-2.5.1/test/test_shacl/test_https.py` & `shexer-2.5.2/test/test_shacl/test_https.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,25 +1,25 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES
-from test.t_utils import graph_comparison_file_vs_str
-import os.path as pth
-from shexer.consts import SHACL_TURTLE
-
-_BASE_DIR = BASE_FILES + "https" + pth.sep
-
-
-class TestHttps(unittest.TestCase):
-
-
-    def test_some_https_uris(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "https.ttl",
-                        input_format="turtle",
-                        disable_comments=True,
-                        )
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "https_shacl.ttl",
-                                                     str_target=str_result))
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES
+from test.t_utils import graph_comparison_file_vs_str
+import os.path as pth
+from shexer.consts import SHACL_TURTLE
+
+_BASE_DIR = BASE_FILES + "https" + pth.sep
+
+
+class TestHttps(unittest.TestCase):
+
+
+    def test_some_https_uris(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "https.ttl",
+                        input_format="turtle",
+                        disable_comments=True,
+                        )
+        str_result = shaper.shex_graph(string_output=True,
+                                       output_format=SHACL_TURTLE)
+
+        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "https_shacl.ttl",
+                                                     str_target=str_result))
+
```

### Comparing `shexer-2.5.1/test/test_shacl/test_literal_types.py` & `shexer-2.5.2/test/test_shacl/test_literal_types.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,36 +1,36 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES
-from test.t_utils import graph_comparison_file_vs_str
-import os.path as pth
-from shexer.consts import SHACL_TURTLE
-
-_BASE_DIR = BASE_FILES + "literals" + pth.sep
-
-
-class TestLiteralTypes(unittest.TestCase):
-
-
-    def test_different_literals(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "different_literals.ttl",
-                        input_format="turtle",
-                        disable_comments=True,
-                        )
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "different_literals_shacl.ttl",
-                                                     str_target=str_result))
-
-    def test_some_literal_types_out_of_xsd_namespace(self):
-        shaper = Shaper(all_classes_mode=True,
-                        graph_file_input=_BASE_DIR + "literals_no_xsd.ttl",
-                        input_format="turtle",
-                        disable_comments=True,
-                        )
-        str_result = shaper.shex_graph(string_output=True,
-                                       output_format=SHACL_TURTLE)
-
-        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "literals_no_xsd_shacl.ttl",
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES
+from test.t_utils import graph_comparison_file_vs_str
+import os.path as pth
+from shexer.consts import SHACL_TURTLE
+
+_BASE_DIR = BASE_FILES + "literals" + pth.sep
+
+
+class TestLiteralTypes(unittest.TestCase):
+
+
+    def test_different_literals(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "different_literals.ttl",
+                        input_format="turtle",
+                        disable_comments=True,
+                        )
+        str_result = shaper.shex_graph(string_output=True,
+                                       output_format=SHACL_TURTLE)
+
+        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "different_literals_shacl.ttl",
+                                                     str_target=str_result))
+
+    def test_some_literal_types_out_of_xsd_namespace(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "literals_no_xsd.ttl",
+                        input_format="turtle",
+                        disable_comments=True,
+                        )
+        str_result = shaper.shex_graph(string_output=True,
+                                       output_format=SHACL_TURTLE)
+
+        self.assertTrue(graph_comparison_file_vs_str(file_path=_BASE_DIR + "literals_no_xsd_shacl.ttl",
                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_shapes_namespaces.py` & `shexer-2.5.2/test/test_disable_or_statements.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,63 +1,48 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE, SHAPES_DEFAULT_NAMESPACE
-
-_BASE_DIR = BASE_FILES + "shapes_namespace" + pth.sep # We just need something with another instantiation property
-
-
-class TestShapesNamespaces(unittest.TestCase):
-
-    def test_default_namespace(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            shapes_namespace=SHAPES_DEFAULT_NAMESPACE)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-    def test_different_namespace(self):
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=default_namespaces(),
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            shapes_namespace="http://weso.es/DIfferentShapes#")
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "different_namespace.shex",
-                                                      str_target=str_result))
-
-    def test_empty_prefix_used(self):
-        namespaces = default_namespaces()
-        namespaces["http://unuseful.but.yet/here/"] = ""
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=namespaces,
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            shapes_namespace=SHAPES_DEFAULT_NAMESPACE)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "empty_prefix_used.shex",
-                                                      str_target=str_result))
-
-    def test_empty_prefix_used_and_no_default(self):
-        namespaces = default_namespaces()
-        namespaces["http://unuseful.but.yet/here/"] = ""
-        shaper = Shaper(
-            graph_file_input=G1,
-            namespaces_dict=namespaces,
-            all_classes_mode=True,
-            input_format=TURTLE,
-            disable_comments=True,
-            shapes_namespace="http://weso.es/DIfferentShapes#")
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "empty_prefix_used_and_no_def.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES, default_namespaces
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+from shexer.consts import TURTLE
+
+_BASE_DIR = BASE_FILES + "disable_or" + pth.sep
+
+class TestDisableOrStatements(unittest.TestCase):
+
+    def test_or_enabled_choice_useful_IRI(self):
+        shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        disable_or_statements=False)
+        str_result = shaper.shex_graph(string_output=True)
+        # In case the choice includes the IRI macro, then no OR should appear
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_disabled.shex",
+                                                      str_target=str_result,
+                                                      or_shapes=True))
+
+    def test_or_enabled_choice_expendable_IRI(self):
+        shaper = Shaper(graph_file_input=_BASE_DIR + "g_or_example_expandable_IRI.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        disable_or_statements=False)
+        str_result = shaper.shex_graph(string_output=True)
+        # In case the choice includes the IRI macro, then no OR should appear
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_enabled.shex",
+                                                      str_target=str_result,
+                                                      or_shapes=True))
+
+    def test_or_disabled(self):
+        shaper = Shaper(graph_file_input=_BASE_DIR + "g3_or_example.ttl",
+                        namespaces_dict=default_namespaces(),
+                        all_classes_mode=True,
+                        input_format=TURTLE,
+                        disable_comments=True,
+                        disable_or_statements=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "or_disabled.shex",
+                                                      str_target=str_result,
+                                                      or_shapes=True))
```

### Comparing `shexer-2.5.1/test/test_threshold.py` & `shexer-2.5.2/test/test_file_target_classes.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,59 +1,43 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import G1, BASE_FILES, G1_ALL_CLASSES_NO_COMMENTS, default_namespaces
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import TURTLE
-
-_BASE_DIR = BASE_FILES + "threshold" + pth.sep
-
-class TestGraphFileInput(unittest.TestCase):
-
-    def test_t_0(self):
-        shaper = Shaper(graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=True,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       acceptance_threshold=0)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-    def test_t_1(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       acceptance_threshold=1)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_t1.shex",
-                                                      str_target=str_result))
-
-    def test_t_05(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       acceptance_threshold=.5)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_t05.shex",
-                                                      str_target=str_result))
-
-    def test_t_051(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        graph_file_input=G1,
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True,
-                                       acceptance_threshold=.51)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "g1_t051.shex",
-                                                      str_target=str_result))
+import unittest
+from shexer.shaper import Shaper
+from test.const import G1, BASE_FILES
+from test.t_utils import file_vs_str_tunned_comparison
+import os.path as pth
+
+_BASE_DIR = BASE_FILES + "target_classes" + pth.sep
+
+class TestFileTargetClasses(unittest.TestCase):
+
+    def test_one_target(self):
+        shaper = Shaper(file_target_classes=_BASE_DIR + "input_classes_one_target.tsv",
+                        graph_file_input=G1,
+                        all_classes_mode=False,
+                        input_format="turtle",
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "one_target.shex",
+                                                      str_target=str_result))
+
+
+    def test_several_targets(self):
+        shaper = Shaper(file_target_classes=_BASE_DIR + "input_classes_two_targets.tsv",
+                        graph_file_input=G1,
+                        all_classes_mode=False,
+                        input_format="turtle",
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "two_targets.shex",
+                                                      str_target=str_result))
+
+    # NOT SUPPORTED YET
+    #
+    def test_one_target_prefixed_targets(self):
+        shaper = Shaper(file_target_classes=_BASE_DIR + "input_classes_one_target_prefixed.tsv",  # Not written yet
+                        namespaces_dict={"http://xmlns.com/foaf/0.1/" : "foaf"},
+                        graph_file_input=G1,
+                        all_classes_mode=False,
+                        input_format="turtle",
+                        disable_comments=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "one_target.shex",
+                                                      str_target=str_result))
```

### Comparing `shexer-2.5.1/test/test_url_endpoint.py` & `shexer-2.5.2/test/test_disable_endpoint_cache.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,52 +1,59 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import default_namespaces
-from test.t_utils import number_of_shapes
-
-
-class TestUrlEndpoint(unittest.TestCase):
-
-    """
-    These test cannot be too precise, since they are made against "live" content in Wikidata and DBpedia.
-
-    """
-
-    def test_wikidata(self):
-        shape_map_raw = "SPARQL'select ?p where " \
-                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
-                        "LIMIT 1'@<Flag>"
-        shaper = Shaper(shape_map_raw=shape_map_raw,
-                        url_endpoint="https://query.wikidata.org/sparql",
-                        namespaces_dict=default_namespaces(),
-                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
-                        disable_comments=True,
-                        depth_for_building_subgraph=1,
-                        track_classes_for_entities_at_last_depth_level=False,
-                        all_classes_mode=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) == 1)
-
-    def test_dbpedia(self):
-        shape_map_raw = "SPARQL'select ?s where {?s a <http://dbpedia.org/ontology/Person>} LIMIT 1'@<Flag>"
-        shaper = Shaper(shape_map_raw=shape_map_raw,
-                        url_endpoint="https://dbpedia.org/sparql",
-                        namespaces_dict=default_namespaces(),
-                        disable_comments=True,
-                        depth_for_building_subgraph=1,
-                        track_classes_for_entities_at_last_depth_level=False,
-                        all_classes_mode=False)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) == 1)
-
-    def test_all_classes_mode(self):
-        # shape_map_raw = "SPARQL'select ?s where {?s a <http://dbpedia.org/ontology/Person>} LIMIT 1'@<Flag>"
-        shaper = Shaper(all_classes_mode=True,
-                        url_endpoint="https://agrovoc.fao.org/sparql",
-                        namespaces_dict=default_namespaces(),
-                        disable_comments=True,
-                        depth_for_building_subgraph=1,
-                        track_classes_for_entities_at_last_depth_level=False,
-                        limit_remote_instances=5)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(number_of_shapes(str_result) > 2)
-        pass  #
+import unittest
+from shexer.shaper import Shaper
+from test.const import default_namespaces
+from test.t_utils import number_of_shapes
+
+
+class TestDisableEndpointCache(unittest.TestCase):
+
+    """
+    Note! These tests are similar to the ones found in TestUrlInput.
+    We are only checking that if you try the same stuff without the cache, this will still work.
+
+
+    These tests cannot be too precise, since they are made against "live" content in Wikidata and DBpedia.
+
+    """
+
+    def test_wikidata(self):
+        shape_map_raw = "SPARQL'select ?p where " \
+                        "{ ?p <http://www.wikidata.org/prop/direct/P31> <http://www.wikidata.org/entity/Q14660> } " \
+                        "LIMIT 1'@<Flag>"
+        shaper = Shaper(shape_map_raw=shape_map_raw,
+                        url_endpoint="https://query.wikidata.org/sparql",
+                        namespaces_dict=default_namespaces(),
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        disable_comments=True,
+                        depth_for_building_subgraph=1,
+                        track_classes_for_entities_at_last_depth_level=False,
+                        all_classes_mode=False,
+                        disable_endpoint_cache=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(number_of_shapes(str_result) == 1)
+
+    def test_dbpedia(self):
+        shape_map_raw = "SPARQL'select ?s where {?s a <http://dbpedia.org/ontology/Person>} LIMIT 1'@<Flag>"
+        shaper = Shaper(shape_map_raw=shape_map_raw,
+                        url_endpoint="https://dbpedia.org/sparql",
+                        namespaces_dict=default_namespaces(),
+                        disable_comments=True,
+                        depth_for_building_subgraph=1,
+                        track_classes_for_entities_at_last_depth_level=False,
+                        all_classes_mode=False,
+                        disable_endpoint_cache=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(number_of_shapes(str_result) == 1)
+
+    def test_all_classes_mode(self):
+        # shape_map_raw = "SPARQL'select ?s where {?s a <http://dbpedia.org/ontology/Person>} LIMIT 1'@<Flag>"
+        shaper = Shaper(all_classes_mode=True,
+                        url_endpoint="https://agrovoc.fao.org/sparql",
+                        namespaces_dict=default_namespaces(),
+                        disable_comments=True,
+                        depth_for_building_subgraph=1,
+                        track_classes_for_entities_at_last_depth_level=False,
+                        limit_remote_instances=5,
+                        disable_endpoint_cache=True)
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(number_of_shapes(str_result) > 2)
+        pass  #
```

### Comparing `shexer-2.5.1/test/test_url_graph.py` & `shexer-2.5.2/test/test_wikidata_annotation.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,37 +1,38 @@
-import unittest
-from shexer.shaper import Shaper
-from test.const import BASE_FILES, default_namespaces, G1_ALL_CLASSES_NO_COMMENTS
-from test.t_utils import file_vs_str_tunned_comparison
-import os.path as pth
-from shexer.consts import NT, TURTLE
-
-_BASE_DIR = BASE_FILES + "general" + pth.sep
-
-class TestUrlGraphFormat(unittest.TestCase):
-
-    def test_ttl(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        url_graph_input="https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.ttl",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=TURTLE,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-
-    def test_nt(self):
-        shaper = Shaper(target_classes=["http://xmlns.com/foaf/0.1/Person",
-                                        "http://xmlns.com/foaf/0.1/Document"],
-                        url_graph_input="https://raw.githubusercontent.com/DaniFdezAlvarez/shexerp3/develop/test/t_files/t_graph_1.nt",
-                        namespaces_dict=default_namespaces(),
-                        all_classes_mode=False,
-                        input_format=NT,
-                        disable_comments=True)
-        str_result = shaper.shex_graph(string_output=True)
-        self.assertTrue(file_vs_str_tunned_comparison(file_path=G1_ALL_CLASSES_NO_COMMENTS,
-                                                      str_target=str_result))
-
-
+import unittest
+from shexer.shaper import Shaper
+from test.const import BASE_FILES
+from test.t_utils import file_vs_str_tunned_comparison, text_contains_lines
+import os.path as pth
+
+_BASE_DIR = BASE_FILES + "wikidata_annotation" + pth.sep
+
+class TestWikidataAnnotation(unittest.TestCase):
+
+    def test_no_annotation(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "wiki_example.ttl",
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        input_format="turtle",
+                        disable_comments=True,
+                        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(file_vs_str_tunned_comparison(file_path=_BASE_DIR + "wiki_example_noanot.shex",
+                                                      str_target=str_result))
+
+    def test_annotation(self):
+        shaper = Shaper(all_classes_mode=True,
+                        graph_file_input=_BASE_DIR + "wiki_example.ttl",
+                        instantiation_property="http://www.wikidata.org/prop/direct/P31",
+                        input_format="turtle",
+                        disable_comments=True,
+                        wikidata_annotation=True
+                        )
+        str_result = shaper.shex_graph(string_output=True)
+        self.assertTrue(text_contains_lines(text=str_result,
+                                            list_lines=[
+                                                "rdfs:comment",
+                                                "Q5  -->  human",
+                                                "P31  -->  instance of",
+                                                "Q215627  -->  person",
+                                                "Q11689315  -->  (no label available)"
+                                            ]))
```

### Comparing `shexer-2.5.1/ws/shexer_rest.py` & `shexer-2.5.2/ws/shexer_rest.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,518 +1,518 @@
-import traceback
-from flask import Flask, request
-from flask_cors import CORS
-from shexer.consts import NT, RDF_TYPE
-from shexer.shaper import Shaper
-from shexer.utils.uri import remove_corners
-import json
-import sys
-
-################ CONFIG
-
-# PORT = 8080
-HOST = "0.0.0.0"
-MAX_LEN = 100000
-
-
-################ Default namespace
-
-default_namespaces = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
-                      "http://www.w3.org/2000/01/rdf-schema#": "rdfs",
-                      "http://www.w3.org/2001/XMLSchema#": "xsd",
-                      "http://www.w3.org/XML/1998/namespace/": "xml",
-                      "http://www.w3.org/2002/07/owl#": "owl"
-                      }
-
-
-################ PARAM NAMES
-
-TARGET_CLASSES_PARAM = "target_classes"
-"""
-List of strings: List of target classes to associate a shape with
-"""
-
-TARGET_GRAPH_PARAM = "raw_graph"
-"""
-String: RDF content to be analyzed
-"""
-
-INPUT_FORMAT_PARAM = "input_format"
-"""
-String: RDF syntax used. Ntriples is used by default Accepted values -->
-
-"nt" (n-triples)
-"turtle" (turtle)
-"xml" (RDF/XML)
-"n3" (n3)
-"json-ld" (JSON LD)
-"tsv_spo" (lines with subject predicate and object separated by tab '\\t' chars 
-"""
-
-
-INSTANTIATION_PROPERTY_PARAM = "instantiation_prop"
-"""
-String: property used to links an instance with its class. rdf:type by default.
-"""
-
-
-NAMESPACES_TO_IGNORE_PARAM = "ignore"
-"""
-List of Strings: List of namespaces whose properties should be ignored during the shexing process.
-"""
-
-INFER_NUMERIC_TYPES_PARAM = "infer_untyped_nums"
-"""
-Bool: default, True. If True, it tries to infer the numeric type (xsd:int, xsd:float..) of 
-untyped numeric literals 
-"""
-
-DISCARD_USELESS_CONSTRAINTS_PARAM = "discard_useless_constraints"
-"""
-Bool: default, True. default, True. If True, it keeps just the most possible specific constraint w.r.t. cardinality 
-"""
-
-ALL_INSTANCES_COMPLIANT_PARAM = "all_compliant"
-"""
-Bool: default, True. default, True. If False, the shapes produced may not be compliant with all the entities considered
-to build them. This is because it won't use Kleene closeres for any constraint. 
-"""
-
-KEEP_LESS_SPECIFIC_PARAM = "keep_less_specific"
-"""
-Bool: default, True. It prefers to use "+" closures rather than exact cardinalities in the triple constraints
-"""
-
-ACEPTANCE_THRESHOLD_PARAM = "threshold"
-"""
-Float: number in [0,1] that indicates the minimum proportion of entities that should have a given feature for this
-to be accepted as a triple constraint in the produced shape.
-"""
-
-ALL_CLASSES_MODE_PARAM = "all_classes"
-"""
-Bool: default, False. If True, it generates a shape for every elements with at least an instance 
-in the considered graph.
-"""
-SHAPE_MAP_PARAM = "shape_map"
-"""
-String: shape map to associate nodes with shapes. It uses the same syntax of validation shape maps. 
-"""
-
-REMOTE_GRAPH_PARAM = "graph_url"
-"""
-String: URL to retrieve an online raw graph.
-"""
-
-ENDPOINT_GRAPH_PARAM = "endpoint"
-"""
-String: URL of an SPARQL endpoint.
-"""
-
-NAMESPACES_PARAM = "prefixes"
-"""
-Dict. key are namespaces and values are prefixes. The pairs key value provided here will be used 
-to parse the RDF content and t write the resulting shapes.
-"""
-
-QUERY_DEPTH_PARAM = "query_depth"
-"""
-Integer: default, 1. It indicates the depth to generate queries when targeting a SPARQL endpoint.
-Currently it can be 1 or 2.
-"""
-
-DISABLE_COMMENTS_PARAM = "disable_comments"
-"""
-Bool: default, False. When set to True, the shapes do not include comment 
-with ratio of entities compliant with a triple constraint
-"""
-
-QUALIFIER_NAMESPACES_PARAM = "namespaces_for_qualifiers"
-"""
-List. Default, None. When a list with elements is provided, the properties in the namespaces specified are considered
-to be pointers to qualifier nodes.
-"""
-
-SHAPE_QUALIFIERS_MODE_PARAM = "shape_qualifiers_mode"
-"""
-Bool: default, False. When set to true, a shape is generated for those nodes detected as qualifiers according to
-Wikidata data model and the properties pointing to them specified in QUALIFIER_NAMESPACES_PARAM
-"""
-
-
-
-
-################ SUPPORT FUNCTIONS
-
-
-def _build_namespaces_dict(new_prefixes, defaults):
-    """
-    It merges the default list of namespaces with a
-
-    :param new_prefixes:
-    :param defaults:
-    :return:
-    """
-    for a_key in new_prefixes:
-        defaults[a_key] = new_prefixes[a_key]
-    return defaults
-
-
-def _jsonize_response(response):
-    result = json.dumps({'result' : response})
-    return result
-    # result = {'result' : response}
-    # return json.dumps(result)
-    # return response
-
-
-def _return_json_error_pool(error_pool):
-    result = '{"Errors" : ['
-    result += '"' + error_pool[0] + '"'
-    for i in range(1, len(error_pool)):
-        result += ', "' + error_pool[i] + '"'
-    result += "]}"
-    return _jsonize_response(result)
-
-
-def _missing_param_error(param):
-    return "Missing mandatory param: " + param
-
-
-def _parse_endpoint_sparql(data, error_pool):
-    if ENDPOINT_GRAPH_PARAM not in data:
-        return None
-    if type(data[ENDPOINT_GRAPH_PARAM]) != str:
-        error_pool.append("You must provide a URL (string) in the field " + ENDPOINT_GRAPH_PARAM)
-        return None
-    return str(data[ENDPOINT_GRAPH_PARAM])
-
-
-def _parse_remote_graph(data, error_pool):
-    if REMOTE_GRAPH_PARAM not in data:
-        return None
-    if type(data[REMOTE_GRAPH_PARAM]) != str:
-        error_pool.append("You must provide a URL (string) in the field " + REMOTE_GRAPH_PARAM)
-        return None
-    return str(data[REMOTE_GRAPH_PARAM])
-
-
-def _parse_shape_map(data, error_pool):
-    if SHAPE_MAP_PARAM not in data:
-        return None
-    if type(data[SHAPE_MAP_PARAM]) != str:
-        error_pool.append("You must provide a string containing the shape map")
-        return
-    return str(data[SHAPE_MAP_PARAM])
-
-
-def _parse_namespaces_to_ignore(data, error_pool):
-    if NAMESPACES_TO_IGNORE_PARAM not in data:
-        return None
-    if type(data[NAMESPACES_TO_IGNORE_PARAM]) != list:
-        error_pool.append("You must provide a non-empty list of URIs (string) in " + NAMESPACES_TO_IGNORE_PARAM)
-        return None
-    if len(data[NAMESPACES_TO_IGNORE_PARAM]) == 0 or type(data[NAMESPACES_TO_IGNORE_PARAM][0]) != str:
-        error_pool.append("You must provide a non-empty list of URIs (string) in " + NAMESPACES_TO_IGNORE_PARAM)
-        return
-    return [str(a_uri) for a_uri in data[NAMESPACES_TO_IGNORE_PARAM]]
-
-
-def _parse_namespaces_for_qualifiers(data, error_pool):
-    if QUALIFIER_NAMESPACES_PARAM not in data:
-        return None
-    if type(data[QUALIFIER_NAMESPACES_PARAM]) != list:
-        error_pool.append("You must provide a non-empty list of URIs (string) in " + QUALIFIER_NAMESPACES_PARAM)
-        return None
-    if len(data[QUALIFIER_NAMESPACES_PARAM]) == 0 or type(data[QUALIFIER_NAMESPACES_PARAM][0]) != str:
-        error_pool.append("You must provide a non-empty list of URIs (string) in " + QUALIFIER_NAMESPACES_PARAM)
-        return
-    return [str(a_uri) for a_uri in data[QUALIFIER_NAMESPACES_PARAM]]
-
-
-
-def _parse_namespaces(data, error_pool):
-    if NAMESPACES_PARAM not in data:
-        return {}
-    if type(data[NAMESPACES_PARAM]) != dict:
-        error_pool.append("You must provide a dict namespace_URI --> prefix  in " + NAMESPACES_PARAM)
-        return {}
-    if len(data[NAMESPACES_PARAM]) == 0:
-        error_pool.append("You must provide a dict namespace_URI --> prefix  in " + NAMESPACES_PARAM)
-        return {}
-    result = {}
-    for a_key in data[NAMESPACES_PARAM]:
-        result[str(a_key)] = str(data[NAMESPACES_PARAM][a_key])
-    return result
-
-
-def _parse_target_classes(data, error_pool):
-    if TARGET_CLASSES_PARAM not in data:
-        return None
-    if type(data[TARGET_CLASSES_PARAM]) != list:
-        error_pool.append("You must provide a non-empty list of URIs (string) in " + TARGET_CLASSES_PARAM)
-        return
-    if len(data[TARGET_CLASSES_PARAM]) == 0 or type(data[TARGET_CLASSES_PARAM][0]) != str:
-        error_pool.append("You must provide a non-empty list of URIs (string) in " + TARGET_CLASSES_PARAM)
-        return
-    return [str(a_uri) for a_uri in data[TARGET_CLASSES_PARAM]]
-
-
-def _parse_graph(data, error_pool):
-    if TARGET_GRAPH_PARAM not in data:
-        return None
-    if type(data[TARGET_GRAPH_PARAM]) != str:
-        error_pool.append("You must provide a str containing an RDF graph ")
-        return
-    if len(data[TARGET_GRAPH_PARAM]) > MAX_LEN:
-        error_pool.append("The size of the graphic is too big for this deployment. Introduce a graph using less than "
-                          + str(MAX_LEN) + " chars")
-        return
-    return str(data[TARGET_GRAPH_PARAM])
-
-
-def _parse_str_param(data, error_pool, key, default_value, opt_message=""):
-    result = default_value
-    if key in data:
-        if type(data[key]) == str:
-            result = data[key]
-        else:
-            error_pool.append(key + " must be a str. " + opt_message)
-            return
-    return result
-
-
-def _parse_bool_param(data, error_pool, key, default_value, opt_message=""):
-    result = default_value
-    if key in data:
-        if type(data[key]) == bool:
-            result = data[key]
-        else:
-            error_pool.append(key + " must be 'true' or 'false'. " + opt_message)
-            return
-
-    return result
-
-
-def _parse_input_format(data, error_pool):
-    return _parse_str_param(data=data, error_pool=error_pool, key=INPUT_FORMAT_PARAM, default_value=NT)
-
-
-def _parse_instantiation_prop(data, error_pool):
-    candidate = _parse_str_param(data=data, error_pool=error_pool, key=INSTANTIATION_PROPERTY_PARAM,
-                                 default_value=RDF_TYPE,
-                                 opt_message="The default value is rdf:type")
-    return remove_corners(a_uri=candidate,
-                          raise_error_if_no_corners=False)
-
-
-def _parse_infer_untyped_num(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=INFER_NUMERIC_TYPES_PARAM, default_value=True,
-                             opt_message="The default value is True")
-
-
-def _parse_discard_useless(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=DISCARD_USELESS_CONSTRAINTS_PARAM, default_value=True,
-                             opt_message="The default value is True")
-
-
-def _parse_all_compliant(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=ALL_INSTANCES_COMPLIANT_PARAM,
-                             default_value=True,
-                             opt_message="The default value is True")
-
-
-def _parse_all_classes_mode(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=ALL_CLASSES_MODE_PARAM,
-                             default_value=False,
-                             opt_message="The default value is False")
-
-def _parse_shape_qualifiers_mode(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=SHAPE_QUALIFIERS_MODE_PARAM,
-                             default_value=False,
-                             opt_message="The default value is False")
-
-def _parse_disable_comments(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=DISABLE_COMMENTS_PARAM,
-                             default_value=False,
-                             opt_message="The default value is False")
-
-
-def _parse_keep_less_specific(data, error_pool):
-    return _parse_bool_param(data=data, error_pool=error_pool, key=ALL_INSTANCES_COMPLIANT_PARAM,
-                             default_value=True,
-                             opt_message="The default value is True")
-
-
-def _parse_threshold(data, error_pool):
-    if ACEPTANCE_THRESHOLD_PARAM in data:
-        try:
-            result = float(data[ACEPTANCE_THRESHOLD_PARAM])
-            if result < 0 or result > 1:
-                raise ValueError()
-            return result
-        except BaseException as e:
-            error_pool.append(ACEPTANCE_THRESHOLD_PARAM + " must contain a float number in [0,1]. The default value is 0.")
-    return 0.0
-
-
-def _parse_query_depth(data, error_pool):
-    if QUERY_DEPTH_PARAM in data:
-        try:
-            result = int(data[QUERY_DEPTH_PARAM])
-            if result > 2 or result < 1:
-                raise ValueError()
-            return result
-        except BaseException as e:
-            error_pool.append(QUERY_DEPTH_PARAM + " must contain a an integer (1 or 2). The default value is 1.")
-    return 1
-
-
-
-def _call_shaper(target_classes, graph, input_fotmat, instantiation_prop,
-                 infer_untyped_num, discard_useles_constraints, all_compliant,
-                 keep_less_specific, threshold, all_classes_mode, namespaces_dict,
-                 namespaces_to_ignore, shape_map, remote_graph, endpoint_sparql,
-                 query_depth, disable_comments, namespaces_for_qualifier_props,
-                 shape_qualifiers_mode):
-    shaper = Shaper(target_classes=target_classes,
-                    input_format=input_fotmat,
-                    instantiation_property=instantiation_prop,
-                    infer_numeric_types_for_untyped_literals=infer_untyped_num,
-                    discard_useless_constraints_with_positive_closure=discard_useles_constraints,
-                    all_instances_are_compliant_mode=all_compliant,
-                    keep_less_specific=keep_less_specific,
-                    raw_graph=graph,
-                    all_classes_mode=all_classes_mode,
-                    namespaces_dict=namespaces_dict,
-                    namespaces_to_ignore=namespaces_to_ignore,
-                    shape_map_raw=shape_map,
-                    url_graph_input=remote_graph,
-                    url_endpoint=endpoint_sparql,
-                    depth_for_building_subgraph=query_depth,
-                    disable_comments=disable_comments,
-                    namespaces_for_qualifier_props=namespaces_for_qualifier_props,
-                    shape_qualifiers_mode=shape_qualifiers_mode,
-                    wikidata_annotation=True
-                    )
-    result = shaper.shex_graph(acceptance_threshold=threshold, string_output=True)
-    return _jsonize_response(result)
-
-
-def _check_combination_error_input_data(data, error_pool):
-    target_params = [TARGET_GRAPH_PARAM, REMOTE_GRAPH_PARAM, ENDPOINT_GRAPH_PARAM]
-    counter = 0
-    for elem in target_params:
-        if elem in data:
-
-            counter += 1
-    if counter != 1:
-        error_pool.append("You must provide exactly one of the following params: " + ", ".join(target_params) + ".")
-        return True
-    return False
-
-
-def _check_combination_error_target_shapes(data, error_pool, all_classes_mode):
-    target_params = [TARGET_CLASSES_PARAM, SHAPE_MAP_PARAM]
-    counter = 0
-    for elem in target_params:
-        if elem in data:
-            counter += 1
-    if counter == 1:
-        return False
-    if counter == 0 and ALL_CLASSES_MODE_PARAM in data and all_classes_mode == True:
-        return False
-    error_pool.append("Yoy must provide exactly one of " + ", ".join(target_params) + " or set " + ALL_CLASSES_MODE_PARAM + " to True")
-    return True
-
-def _check_all_classes_mode_uncompatibility(data, error_pool, all_classes_mode):
-    if all_classes_mode and ENDPOINT_GRAPH_PARAM in data and SHAPE_MAP_PARAM not in data:
-        error_pool.append("If you use all classes mode with input via endpoint, you must provide a shape map as well "
-                          "to let sheXer knows what part of the graph it should consider.")
-
-
-
-################ WS
-
-app = Flask(__name__)
-
-@app.route('/shexer', methods=['POST'])
-def shexer():
-    error_pool = []
-    try:
-        data = request.json
-        input_fotmat = _parse_input_format(data, error_pool)
-        instantiation_prop = _parse_instantiation_prop(data, error_pool)
-        infer_untyped_num = _parse_infer_untyped_num(data, error_pool)
-        discard_useles_constraints = _parse_discard_useless(data, error_pool)
-        all_compliant = _parse_all_compliant(data, error_pool)
-        keep_less_specific = _parse_keep_less_specific(data, error_pool)
-        threshold = _parse_threshold(data, error_pool)
-        all_classes_mode = _parse_all_classes_mode(data, error_pool)
-        namespaces_to_ignore = _parse_namespaces_to_ignore(data, error_pool)
-        namespaces = _parse_namespaces(data, error_pool)
-        query_depth = _parse_query_depth(data, error_pool)
-        disable_comments = _parse_disable_comments(data, error_pool)
-
-        shape_qualifiers_mode = _parse_shape_qualifiers_mode(data, error_pool)
-        namespaces_for_qualifier_props = _parse_namespaces_for_qualifiers(data, error_pool)
-
-        target_classes = None
-        graph = None
-        shape_map = None
-        remote_graph = None
-        endpoint_sparql = None
-
-        err_input = _check_combination_error_input_data(data, error_pool)
-        if not err_input:
-            graph = _parse_graph(data, error_pool)
-            remote_graph = _parse_remote_graph(data, error_pool)
-            endpoint_sparql = _parse_endpoint_sparql(data, error_pool)
-
-        err_target = _check_combination_error_target_shapes(data, error_pool, all_classes_mode)
-        if not err_target:
-            target_classes = _parse_target_classes(data, error_pool)
-            shape_map = _parse_shape_map(data, error_pool)
-            _check_all_classes_mode_uncompatibility(data, error_pool, all_classes_mode)
-
-        # remote_graph = _parse_remote_graph(data, error_pool)
-        # endpoint_sparql = _parse_endpoint_sparql(data, error_pool)
-
-        if len(error_pool) == 0:
-            #todo: Call shaper with the new params!
-            return _call_shaper(target_classes=target_classes,
-                                graph=graph,
-                                input_fotmat=input_fotmat,
-                                instantiation_prop=instantiation_prop,
-                                infer_untyped_num=infer_untyped_num,
-                                discard_useles_constraints=discard_useles_constraints,
-                                all_compliant=all_compliant,
-                                keep_less_specific=keep_less_specific,
-                                threshold=threshold,
-                                all_classes_mode=all_classes_mode,
-                                namespaces_dict=_build_namespaces_dict(namespaces, default_namespaces),
-                                endpoint_sparql=endpoint_sparql,
-                                shape_map=shape_map,
-                                remote_graph=remote_graph,
-                                namespaces_to_ignore=namespaces_to_ignore,
-                                query_depth=query_depth,
-                                disable_comments=disable_comments,
-                                namespaces_for_qualifier_props=namespaces_for_qualifier_props,
-                                shape_qualifiers_mode=shape_qualifiers_mode
-                                )
-
-
-        else:
-           return _return_json_error_pool(error_pool)
-
-    except BaseException as e:
-        traceback.print_exc()
-        error_pool.append("Internal unexpected server error: " + str(e))
-        return _return_json_error_pool(error_pool)
-
-def run():
-    port = 80 if len(sys.argv) < 2 else int(sys.argv[1])
-    CORS(app)
-    app.run(port=port, host=HOST, ssl_context='adhoc')
-
-if __name__ == "__main__":
-    run()
+import traceback
+from flask import Flask, request
+from flask_cors import CORS
+from shexer.consts import NT, RDF_TYPE
+from shexer.shaper import Shaper
+from shexer.utils.uri import remove_corners
+import json
+import sys
+
+################ CONFIG
+
+# PORT = 8080
+HOST = "0.0.0.0"
+MAX_LEN = 100000
+
+
+################ Default namespace
+
+default_namespaces = {"http://www.w3.org/1999/02/22-rdf-syntax-ns#": "rdf",
+                      "http://www.w3.org/2000/01/rdf-schema#": "rdfs",
+                      "http://www.w3.org/2001/XMLSchema#": "xsd",
+                      "http://www.w3.org/XML/1998/namespace/": "xml",
+                      "http://www.w3.org/2002/07/owl#": "owl"
+                      }
+
+
+################ PARAM NAMES
+
+TARGET_CLASSES_PARAM = "target_classes"
+"""
+List of strings: List of target classes to associate a shape with
+"""
+
+TARGET_GRAPH_PARAM = "raw_graph"
+"""
+String: RDF content to be analyzed
+"""
+
+INPUT_FORMAT_PARAM = "input_format"
+"""
+String: RDF syntax used. Ntriples is used by default Accepted values -->
+
+"nt" (n-triples)
+"turtle" (turtle)
+"xml" (RDF/XML)
+"n3" (n3)
+"json-ld" (JSON LD)
+"tsv_spo" (lines with subject predicate and object separated by tab '\\t' chars 
+"""
+
+
+INSTANTIATION_PROPERTY_PARAM = "instantiation_prop"
+"""
+String: property used to links an instance with its class. rdf:type by default.
+"""
+
+
+NAMESPACES_TO_IGNORE_PARAM = "ignore"
+"""
+List of Strings: List of namespaces whose properties should be ignored during the shexing process.
+"""
+
+INFER_NUMERIC_TYPES_PARAM = "infer_untyped_nums"
+"""
+Bool: default, True. If True, it tries to infer the numeric type (xsd:int, xsd:float..) of 
+untyped numeric literals 
+"""
+
+DISCARD_USELESS_CONSTRAINTS_PARAM = "discard_useless_constraints"
+"""
+Bool: default, True. default, True. If True, it keeps just the most possible specific constraint w.r.t. cardinality 
+"""
+
+ALL_INSTANCES_COMPLIANT_PARAM = "all_compliant"
+"""
+Bool: default, True. default, True. If False, the shapes produced may not be compliant with all the entities considered
+to build them. This is because it won't use Kleene closeres for any constraint. 
+"""
+
+KEEP_LESS_SPECIFIC_PARAM = "keep_less_specific"
+"""
+Bool: default, True. It prefers to use "+" closures rather than exact cardinalities in the triple constraints
+"""
+
+ACEPTANCE_THRESHOLD_PARAM = "threshold"
+"""
+Float: number in [0,1] that indicates the minimum proportion of entities that should have a given feature for this
+to be accepted as a triple constraint in the produced shape.
+"""
+
+ALL_CLASSES_MODE_PARAM = "all_classes"
+"""
+Bool: default, False. If True, it generates a shape for every elements with at least an instance 
+in the considered graph.
+"""
+SHAPE_MAP_PARAM = "shape_map"
+"""
+String: shape map to associate nodes with shapes. It uses the same syntax of validation shape maps. 
+"""
+
+REMOTE_GRAPH_PARAM = "graph_url"
+"""
+String: URL to retrieve an online raw graph.
+"""
+
+ENDPOINT_GRAPH_PARAM = "endpoint"
+"""
+String: URL of an SPARQL endpoint.
+"""
+
+NAMESPACES_PARAM = "prefixes"
+"""
+Dict. key are namespaces and values are prefixes. The pairs key value provided here will be used 
+to parse the RDF content and t write the resulting shapes.
+"""
+
+QUERY_DEPTH_PARAM = "query_depth"
+"""
+Integer: default, 1. It indicates the depth to generate queries when targeting a SPARQL endpoint.
+Currently it can be 1 or 2.
+"""
+
+DISABLE_COMMENTS_PARAM = "disable_comments"
+"""
+Bool: default, False. When set to True, the shapes do not include comment 
+with ratio of entities compliant with a triple constraint
+"""
+
+QUALIFIER_NAMESPACES_PARAM = "namespaces_for_qualifiers"
+"""
+List. Default, None. When a list with elements is provided, the properties in the namespaces specified are considered
+to be pointers to qualifier nodes.
+"""
+
+SHAPE_QUALIFIERS_MODE_PARAM = "shape_qualifiers_mode"
+"""
+Bool: default, False. When set to true, a shape is generated for those nodes detected as qualifiers according to
+Wikidata data model and the properties pointing to them specified in QUALIFIER_NAMESPACES_PARAM
+"""
+
+
+
+
+################ SUPPORT FUNCTIONS
+
+
+def _build_namespaces_dict(new_prefixes, defaults):
+    """
+    It merges the default list of namespaces with a
+
+    :param new_prefixes:
+    :param defaults:
+    :return:
+    """
+    for a_key in new_prefixes:
+        defaults[a_key] = new_prefixes[a_key]
+    return defaults
+
+
+def _jsonize_response(response):
+    result = json.dumps({'result' : response})
+    return result
+    # result = {'result' : response}
+    # return json.dumps(result)
+    # return response
+
+
+def _return_json_error_pool(error_pool):
+    result = '{"Errors" : ['
+    result += '"' + error_pool[0] + '"'
+    for i in range(1, len(error_pool)):
+        result += ', "' + error_pool[i] + '"'
+    result += "]}"
+    return _jsonize_response(result)
+
+
+def _missing_param_error(param):
+    return "Missing mandatory param: " + param
+
+
+def _parse_endpoint_sparql(data, error_pool):
+    if ENDPOINT_GRAPH_PARAM not in data:
+        return None
+    if type(data[ENDPOINT_GRAPH_PARAM]) != str:
+        error_pool.append("You must provide a URL (string) in the field " + ENDPOINT_GRAPH_PARAM)
+        return None
+    return str(data[ENDPOINT_GRAPH_PARAM])
+
+
+def _parse_remote_graph(data, error_pool):
+    if REMOTE_GRAPH_PARAM not in data:
+        return None
+    if type(data[REMOTE_GRAPH_PARAM]) != str:
+        error_pool.append("You must provide a URL (string) in the field " + REMOTE_GRAPH_PARAM)
+        return None
+    return str(data[REMOTE_GRAPH_PARAM])
+
+
+def _parse_shape_map(data, error_pool):
+    if SHAPE_MAP_PARAM not in data:
+        return None
+    if type(data[SHAPE_MAP_PARAM]) != str:
+        error_pool.append("You must provide a string containing the shape map")
+        return
+    return str(data[SHAPE_MAP_PARAM])
+
+
+def _parse_namespaces_to_ignore(data, error_pool):
+    if NAMESPACES_TO_IGNORE_PARAM not in data:
+        return None
+    if type(data[NAMESPACES_TO_IGNORE_PARAM]) != list:
+        error_pool.append("You must provide a non-empty list of URIs (string) in " + NAMESPACES_TO_IGNORE_PARAM)
+        return None
+    if len(data[NAMESPACES_TO_IGNORE_PARAM]) == 0 or type(data[NAMESPACES_TO_IGNORE_PARAM][0]) != str:
+        error_pool.append("You must provide a non-empty list of URIs (string) in " + NAMESPACES_TO_IGNORE_PARAM)
+        return
+    return [str(a_uri) for a_uri in data[NAMESPACES_TO_IGNORE_PARAM]]
+
+
+def _parse_namespaces_for_qualifiers(data, error_pool):
+    if QUALIFIER_NAMESPACES_PARAM not in data:
+        return None
+    if type(data[QUALIFIER_NAMESPACES_PARAM]) != list:
+        error_pool.append("You must provide a non-empty list of URIs (string) in " + QUALIFIER_NAMESPACES_PARAM)
+        return None
+    if len(data[QUALIFIER_NAMESPACES_PARAM]) == 0 or type(data[QUALIFIER_NAMESPACES_PARAM][0]) != str:
+        error_pool.append("You must provide a non-empty list of URIs (string) in " + QUALIFIER_NAMESPACES_PARAM)
+        return
+    return [str(a_uri) for a_uri in data[QUALIFIER_NAMESPACES_PARAM]]
+
+
+
+def _parse_namespaces(data, error_pool):
+    if NAMESPACES_PARAM not in data:
+        return {}
+    if type(data[NAMESPACES_PARAM]) != dict:
+        error_pool.append("You must provide a dict namespace_URI --> prefix  in " + NAMESPACES_PARAM)
+        return {}
+    if len(data[NAMESPACES_PARAM]) == 0:
+        error_pool.append("You must provide a dict namespace_URI --> prefix  in " + NAMESPACES_PARAM)
+        return {}
+    result = {}
+    for a_key in data[NAMESPACES_PARAM]:
+        result[str(a_key)] = str(data[NAMESPACES_PARAM][a_key])
+    return result
+
+
+def _parse_target_classes(data, error_pool):
+    if TARGET_CLASSES_PARAM not in data:
+        return None
+    if type(data[TARGET_CLASSES_PARAM]) != list:
+        error_pool.append("You must provide a non-empty list of URIs (string) in " + TARGET_CLASSES_PARAM)
+        return
+    if len(data[TARGET_CLASSES_PARAM]) == 0 or type(data[TARGET_CLASSES_PARAM][0]) != str:
+        error_pool.append("You must provide a non-empty list of URIs (string) in " + TARGET_CLASSES_PARAM)
+        return
+    return [str(a_uri) for a_uri in data[TARGET_CLASSES_PARAM]]
+
+
+def _parse_graph(data, error_pool):
+    if TARGET_GRAPH_PARAM not in data:
+        return None
+    if type(data[TARGET_GRAPH_PARAM]) != str:
+        error_pool.append("You must provide a str containing an RDF graph ")
+        return
+    if len(data[TARGET_GRAPH_PARAM]) > MAX_LEN:
+        error_pool.append("The size of the graphic is too big for this deployment. Introduce a graph using less than "
+                          + str(MAX_LEN) + " chars")
+        return
+    return str(data[TARGET_GRAPH_PARAM])
+
+
+def _parse_str_param(data, error_pool, key, default_value, opt_message=""):
+    result = default_value
+    if key in data:
+        if type(data[key]) == str:
+            result = data[key]
+        else:
+            error_pool.append(key + " must be a str. " + opt_message)
+            return
+    return result
+
+
+def _parse_bool_param(data, error_pool, key, default_value, opt_message=""):
+    result = default_value
+    if key in data:
+        if type(data[key]) == bool:
+            result = data[key]
+        else:
+            error_pool.append(key + " must be 'true' or 'false'. " + opt_message)
+            return
+
+    return result
+
+
+def _parse_input_format(data, error_pool):
+    return _parse_str_param(data=data, error_pool=error_pool, key=INPUT_FORMAT_PARAM, default_value=NT)
+
+
+def _parse_instantiation_prop(data, error_pool):
+    candidate = _parse_str_param(data=data, error_pool=error_pool, key=INSTANTIATION_PROPERTY_PARAM,
+                                 default_value=RDF_TYPE,
+                                 opt_message="The default value is rdf:type")
+    return remove_corners(a_uri=candidate,
+                          raise_error_if_no_corners=False)
+
+
+def _parse_infer_untyped_num(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=INFER_NUMERIC_TYPES_PARAM, default_value=True,
+                             opt_message="The default value is True")
+
+
+def _parse_discard_useless(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=DISCARD_USELESS_CONSTRAINTS_PARAM, default_value=True,
+                             opt_message="The default value is True")
+
+
+def _parse_all_compliant(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=ALL_INSTANCES_COMPLIANT_PARAM,
+                             default_value=True,
+                             opt_message="The default value is True")
+
+
+def _parse_all_classes_mode(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=ALL_CLASSES_MODE_PARAM,
+                             default_value=False,
+                             opt_message="The default value is False")
+
+def _parse_shape_qualifiers_mode(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=SHAPE_QUALIFIERS_MODE_PARAM,
+                             default_value=False,
+                             opt_message="The default value is False")
+
+def _parse_disable_comments(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=DISABLE_COMMENTS_PARAM,
+                             default_value=False,
+                             opt_message="The default value is False")
+
+
+def _parse_keep_less_specific(data, error_pool):
+    return _parse_bool_param(data=data, error_pool=error_pool, key=ALL_INSTANCES_COMPLIANT_PARAM,
+                             default_value=True,
+                             opt_message="The default value is True")
+
+
+def _parse_threshold(data, error_pool):
+    if ACEPTANCE_THRESHOLD_PARAM in data:
+        try:
+            result = float(data[ACEPTANCE_THRESHOLD_PARAM])
+            if result < 0 or result > 1:
+                raise ValueError()
+            return result
+        except BaseException as e:
+            error_pool.append(ACEPTANCE_THRESHOLD_PARAM + " must contain a float number in [0,1]. The default value is 0.")
+    return 0.0
+
+
+def _parse_query_depth(data, error_pool):
+    if QUERY_DEPTH_PARAM in data:
+        try:
+            result = int(data[QUERY_DEPTH_PARAM])
+            if result > 2 or result < 1:
+                raise ValueError()
+            return result
+        except BaseException as e:
+            error_pool.append(QUERY_DEPTH_PARAM + " must contain a an integer (1 or 2). The default value is 1.")
+    return 1
+
+
+
+def _call_shaper(target_classes, graph, input_fotmat, instantiation_prop,
+                 infer_untyped_num, discard_useles_constraints, all_compliant,
+                 keep_less_specific, threshold, all_classes_mode, namespaces_dict,
+                 namespaces_to_ignore, shape_map, remote_graph, endpoint_sparql,
+                 query_depth, disable_comments, namespaces_for_qualifier_props,
+                 shape_qualifiers_mode):
+    shaper = Shaper(target_classes=target_classes,
+                    input_format=input_fotmat,
+                    instantiation_property=instantiation_prop,
+                    infer_numeric_types_for_untyped_literals=infer_untyped_num,
+                    discard_useless_constraints_with_positive_closure=discard_useles_constraints,
+                    all_instances_are_compliant_mode=all_compliant,
+                    keep_less_specific=keep_less_specific,
+                    raw_graph=graph,
+                    all_classes_mode=all_classes_mode,
+                    namespaces_dict=namespaces_dict,
+                    namespaces_to_ignore=namespaces_to_ignore,
+                    shape_map_raw=shape_map,
+                    url_graph_input=remote_graph,
+                    url_endpoint=endpoint_sparql,
+                    depth_for_building_subgraph=query_depth,
+                    disable_comments=disable_comments,
+                    namespaces_for_qualifier_props=namespaces_for_qualifier_props,
+                    shape_qualifiers_mode=shape_qualifiers_mode,
+                    wikidata_annotation=True
+                    )
+    result = shaper.shex_graph(acceptance_threshold=threshold, string_output=True)
+    return _jsonize_response(result)
+
+
+def _check_combination_error_input_data(data, error_pool):
+    target_params = [TARGET_GRAPH_PARAM, REMOTE_GRAPH_PARAM, ENDPOINT_GRAPH_PARAM]
+    counter = 0
+    for elem in target_params:
+        if elem in data:
+
+            counter += 1
+    if counter != 1:
+        error_pool.append("You must provide exactly one of the following params: " + ", ".join(target_params) + ".")
+        return True
+    return False
+
+
+def _check_combination_error_target_shapes(data, error_pool, all_classes_mode):
+    target_params = [TARGET_CLASSES_PARAM, SHAPE_MAP_PARAM]
+    counter = 0
+    for elem in target_params:
+        if elem in data:
+            counter += 1
+    if counter == 1:
+        return False
+    if counter == 0 and ALL_CLASSES_MODE_PARAM in data and all_classes_mode == True:
+        return False
+    error_pool.append("Yoy must provide exactly one of " + ", ".join(target_params) + " or set " + ALL_CLASSES_MODE_PARAM + " to True")
+    return True
+
+def _check_all_classes_mode_uncompatibility(data, error_pool, all_classes_mode):
+    if all_classes_mode and ENDPOINT_GRAPH_PARAM in data and SHAPE_MAP_PARAM not in data:
+        error_pool.append("If you use all classes mode with input via endpoint, you must provide a shape map as well "
+                          "to let sheXer knows what part of the graph it should consider.")
+
+
+
+################ WS
+
+app = Flask(__name__)
+
+@app.route('/shexer', methods=['POST'])
+def shexer():
+    error_pool = []
+    try:
+        data = request.json
+        input_fotmat = _parse_input_format(data, error_pool)
+        instantiation_prop = _parse_instantiation_prop(data, error_pool)
+        infer_untyped_num = _parse_infer_untyped_num(data, error_pool)
+        discard_useles_constraints = _parse_discard_useless(data, error_pool)
+        all_compliant = _parse_all_compliant(data, error_pool)
+        keep_less_specific = _parse_keep_less_specific(data, error_pool)
+        threshold = _parse_threshold(data, error_pool)
+        all_classes_mode = _parse_all_classes_mode(data, error_pool)
+        namespaces_to_ignore = _parse_namespaces_to_ignore(data, error_pool)
+        namespaces = _parse_namespaces(data, error_pool)
+        query_depth = _parse_query_depth(data, error_pool)
+        disable_comments = _parse_disable_comments(data, error_pool)
+
+        shape_qualifiers_mode = _parse_shape_qualifiers_mode(data, error_pool)
+        namespaces_for_qualifier_props = _parse_namespaces_for_qualifiers(data, error_pool)
+
+        target_classes = None
+        graph = None
+        shape_map = None
+        remote_graph = None
+        endpoint_sparql = None
+
+        err_input = _check_combination_error_input_data(data, error_pool)
+        if not err_input:
+            graph = _parse_graph(data, error_pool)
+            remote_graph = _parse_remote_graph(data, error_pool)
+            endpoint_sparql = _parse_endpoint_sparql(data, error_pool)
+
+        err_target = _check_combination_error_target_shapes(data, error_pool, all_classes_mode)
+        if not err_target:
+            target_classes = _parse_target_classes(data, error_pool)
+            shape_map = _parse_shape_map(data, error_pool)
+            _check_all_classes_mode_uncompatibility(data, error_pool, all_classes_mode)
+
+        # remote_graph = _parse_remote_graph(data, error_pool)
+        # endpoint_sparql = _parse_endpoint_sparql(data, error_pool)
+
+        if len(error_pool) == 0:
+            #todo: Call shaper with the new params!
+            return _call_shaper(target_classes=target_classes,
+                                graph=graph,
+                                input_fotmat=input_fotmat,
+                                instantiation_prop=instantiation_prop,
+                                infer_untyped_num=infer_untyped_num,
+                                discard_useles_constraints=discard_useles_constraints,
+                                all_compliant=all_compliant,
+                                keep_less_specific=keep_less_specific,
+                                threshold=threshold,
+                                all_classes_mode=all_classes_mode,
+                                namespaces_dict=_build_namespaces_dict(namespaces, default_namespaces),
+                                endpoint_sparql=endpoint_sparql,
+                                shape_map=shape_map,
+                                remote_graph=remote_graph,
+                                namespaces_to_ignore=namespaces_to_ignore,
+                                query_depth=query_depth,
+                                disable_comments=disable_comments,
+                                namespaces_for_qualifier_props=namespaces_for_qualifier_props,
+                                shape_qualifiers_mode=shape_qualifiers_mode
+                                )
+
+
+        else:
+           return _return_json_error_pool(error_pool)
+
+    except BaseException as e:
+        traceback.print_exc()
+        error_pool.append("Internal unexpected server error: " + str(e))
+        return _return_json_error_pool(error_pool)
+
+def run():
+    port = 80 if len(sys.argv) < 2 else int(sys.argv[1])
+    CORS(app)
+    app.run(port=port, host=HOST, ssl_context='adhoc')
+
+if __name__ == "__main__":
+    run()
```

